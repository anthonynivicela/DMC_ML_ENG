2025-05-12 20:59:51,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 20:59:51,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 20:59:51,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 20:59:51,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:01:56,179:INFO:PyCaret RegressionExperiment
2025-05-12 21:01:56,179:INFO:Logging name: reg-default-name
2025-05-12 21:01:56,179:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 21:01:56,180:INFO:version 3.3.2
2025-05-12 21:01:56,180:INFO:Initializing setup()
2025-05-12 21:01:56,180:INFO:self.USI: c989
2025-05-12 21:01:56,180:INFO:self._variable_keys: {'exp_id', 'transform_target_param', 'X_test', 'X_train', 'y_train', 'memory', 'log_plots_param', 'X', 'y', 'target_param', 'gpu_param', 'html_param', 'exp_name_log', 'USI', 'data', 'pipeline', 'y_test', '_ml_usecase', 'seed', '_available_plots', 'fold_groups_param', 'idx', 'fold_shuffle_param', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'logging_param'}
2025-05-12 21:01:56,180:INFO:Checking environment
2025-05-12 21:01:56,180:INFO:python_version: 3.11.8
2025-05-12 21:01:56,180:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 21:01:56,180:INFO:machine: AMD64
2025-05-12 21:01:56,180:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 21:01:56,189:INFO:Memory: svmem(total=16907886592, available=3690487808, percent=78.2, used=13217398784, free=3690487808)
2025-05-12 21:01:56,189:INFO:Physical Core: 4
2025-05-12 21:01:56,190:INFO:Logical Core: 8
2025-05-12 21:01:56,190:INFO:Checking libraries
2025-05-12 21:01:56,190:INFO:System:
2025-05-12 21:01:56,190:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 21:01:56,190:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 21:01:56,190:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 21:01:56,190:INFO:PyCaret required dependencies:
2025-05-12 21:01:56,297:INFO:                 pip: 24.0
2025-05-12 21:01:56,297:INFO:          setuptools: 65.5.0
2025-05-12 21:01:56,297:INFO:             pycaret: 3.3.2
2025-05-12 21:01:56,297:INFO:             IPython: 9.2.0
2025-05-12 21:01:56,297:INFO:          ipywidgets: 8.1.7
2025-05-12 21:01:56,297:INFO:                tqdm: 4.67.1
2025-05-12 21:01:56,297:INFO:               numpy: 1.26.4
2025-05-12 21:01:56,297:INFO:              pandas: 2.1.4
2025-05-12 21:01:56,297:INFO:              jinja2: 3.1.6
2025-05-12 21:01:56,297:INFO:               scipy: 1.11.4
2025-05-12 21:01:56,297:INFO:              joblib: 1.3.2
2025-05-12 21:01:56,297:INFO:             sklearn: 1.4.2
2025-05-12 21:01:56,297:INFO:                pyod: 2.0.5
2025-05-12 21:01:56,297:INFO:            imblearn: 0.13.0
2025-05-12 21:01:56,297:INFO:   category_encoders: 2.7.0
2025-05-12 21:01:56,297:INFO:            lightgbm: 4.6.0
2025-05-12 21:01:56,297:INFO:               numba: 0.61.2
2025-05-12 21:01:56,297:INFO:            requests: 2.32.3
2025-05-12 21:01:56,298:INFO:          matplotlib: 3.7.5
2025-05-12 21:01:56,298:INFO:          scikitplot: 0.3.7
2025-05-12 21:01:56,298:INFO:         yellowbrick: 1.5
2025-05-12 21:01:56,298:INFO:              plotly: 5.24.1
2025-05-12 21:01:56,298:INFO:    plotly-resampler: Not installed
2025-05-12 21:01:56,298:INFO:             kaleido: 0.2.1
2025-05-12 21:01:56,298:INFO:           schemdraw: 0.15
2025-05-12 21:01:56,298:INFO:         statsmodels: 0.14.4
2025-05-12 21:01:56,298:INFO:              sktime: 0.26.0
2025-05-12 21:01:56,298:INFO:               tbats: 1.1.3
2025-05-12 21:01:56,298:INFO:            pmdarima: 2.0.4
2025-05-12 21:01:56,298:INFO:              psutil: 7.0.0
2025-05-12 21:01:56,298:INFO:          markupsafe: 3.0.2
2025-05-12 21:01:56,298:INFO:             pickle5: Not installed
2025-05-12 21:01:56,298:INFO:         cloudpickle: 3.1.1
2025-05-12 21:01:56,298:INFO:         deprecation: 2.1.0
2025-05-12 21:01:56,298:INFO:              xxhash: 3.5.0
2025-05-12 21:01:56,298:INFO:           wurlitzer: Not installed
2025-05-12 21:01:56,298:INFO:PyCaret optional dependencies:
2025-05-12 21:01:56,312:INFO:                shap: Not installed
2025-05-12 21:01:56,312:INFO:           interpret: Not installed
2025-05-12 21:01:56,312:INFO:                umap: Not installed
2025-05-12 21:01:56,312:INFO:     ydata_profiling: Not installed
2025-05-12 21:01:56,312:INFO:  explainerdashboard: Not installed
2025-05-12 21:01:56,312:INFO:             autoviz: Not installed
2025-05-12 21:01:56,312:INFO:           fairlearn: Not installed
2025-05-12 21:01:56,312:INFO:          deepchecks: Not installed
2025-05-12 21:01:56,312:INFO:             xgboost: Not installed
2025-05-12 21:01:56,312:INFO:            catboost: Not installed
2025-05-12 21:01:56,312:INFO:              kmodes: Not installed
2025-05-12 21:01:56,312:INFO:             mlxtend: Not installed
2025-05-12 21:01:56,312:INFO:       statsforecast: Not installed
2025-05-12 21:01:56,312:INFO:        tune_sklearn: Not installed
2025-05-12 21:01:56,312:INFO:                 ray: Not installed
2025-05-12 21:01:56,312:INFO:            hyperopt: Not installed
2025-05-12 21:01:56,312:INFO:              optuna: Not installed
2025-05-12 21:01:56,312:INFO:               skopt: Not installed
2025-05-12 21:01:56,312:INFO:              mlflow: Not installed
2025-05-12 21:01:56,312:INFO:              gradio: Not installed
2025-05-12 21:01:56,312:INFO:             fastapi: Not installed
2025-05-12 21:01:56,312:INFO:             uvicorn: Not installed
2025-05-12 21:01:56,312:INFO:              m2cgen: Not installed
2025-05-12 21:01:56,312:INFO:           evidently: Not installed
2025-05-12 21:01:56,312:INFO:               fugue: Not installed
2025-05-12 21:01:56,312:INFO:           streamlit: Not installed
2025-05-12 21:01:56,312:INFO:             prophet: Not installed
2025-05-12 21:01:56,312:INFO:None
2025-05-12 21:01:56,312:INFO:Set up data.
2025-05-12 21:01:56,318:INFO:Set up folding strategy.
2025-05-12 21:01:56,319:INFO:Set up train/test split.
2025-05-12 21:01:56,372:INFO:Set up index.
2025-05-12 21:01:56,372:INFO:Assigning column types.
2025-05-12 21:01:56,376:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 21:01:56,377:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,380:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,385:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,480:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,481:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,481:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,485:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,490:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,545:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,591:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,592:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 21:01:56,597:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,600:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,651:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,699:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,704:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,756:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,797:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 21:01:56,806:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,856:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,896:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,904:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,998:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 21:01:57,056:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:57,096:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:57,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,097:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,154:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:57,195:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:57,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,198:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 21:01:57,254:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:57,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,352:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:57,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,391:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,392:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 21:01:57,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,594:INFO:Preparing preprocessing pipeline...
2025-05-12 21:01:57,594:INFO:Set up simple imputation.
2025-05-12 21:01:57,595:INFO:Set up encoding of categorical features.
2025-05-12 21:01:57,595:INFO:Set up feature normalization.
2025-05-12 21:01:57,641:INFO:Finished creating preprocessing pipeline.
2025-05-12 21:01:57,648:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 21:01:57,648:INFO:Creating final display dataframe.
2025-05-12 21:01:57,771:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            precio
2                   Target type        Regression
3           Original data shape          (100, 7)
4        Transformed data shape         (100, 10)
5   Transformed train set shape          (70, 10)
6    Transformed test set shape          (30, 10)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              c989
2025-05-12 21:01:57,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:58,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:58,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:58,002:INFO:setup() successfully completed in 1.83s...............
2025-05-12 21:07:08,707:INFO:Initializing compare_models()
2025-05-12 21:07:08,707:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 21:07:08,707:INFO:Checking exceptions
2025-05-12 21:07:08,711:INFO:Preparing display monitor
2025-05-12 21:07:08,755:INFO:Initializing Linear Regression
2025-05-12 21:07:08,756:INFO:Total runtime is 1.663366953531901e-05 minutes
2025-05-12 21:07:08,759:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:08,760:INFO:Initializing create_model()
2025-05-12 21:07:08,760:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:08,760:INFO:Checking exceptions
2025-05-12 21:07:08,761:INFO:Importing libraries
2025-05-12 21:07:08,761:INFO:Copying training dataset
2025-05-12 21:07:08,767:INFO:Defining folds
2025-05-12 21:07:08,767:INFO:Declaring metric variables
2025-05-12 21:07:08,771:INFO:Importing untrained model
2025-05-12 21:07:08,777:INFO:Linear Regression Imported successfully
2025-05-12 21:07:08,788:INFO:Starting cross validation
2025-05-12 21:07:08,800:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:17,461:INFO:Calculating mean and std
2025-05-12 21:07:17,462:INFO:Creating metrics dataframe
2025-05-12 21:07:17,465:INFO:Uploading results into container
2025-05-12 21:07:17,465:INFO:Uploading model into container now
2025-05-12 21:07:17,465:INFO:_master_model_container: 1
2025-05-12 21:07:17,467:INFO:_display_container: 2
2025-05-12 21:07:17,467:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:07:17,467:INFO:create_model() successfully completed......................................
2025-05-12 21:07:17,562:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:17,562:INFO:Creating metrics dataframe
2025-05-12 21:07:17,570:INFO:Initializing Lasso Regression
2025-05-12 21:07:17,570:INFO:Total runtime is 0.14691134293874106 minutes
2025-05-12 21:07:17,572:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:17,573:INFO:Initializing create_model()
2025-05-12 21:07:17,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:17,573:INFO:Checking exceptions
2025-05-12 21:07:17,573:INFO:Importing libraries
2025-05-12 21:07:17,573:INFO:Copying training dataset
2025-05-12 21:07:17,579:INFO:Defining folds
2025-05-12 21:07:17,579:INFO:Declaring metric variables
2025-05-12 21:07:17,584:INFO:Importing untrained model
2025-05-12 21:07:17,588:INFO:Lasso Regression Imported successfully
2025-05-12 21:07:17,598:INFO:Starting cross validation
2025-05-12 21:07:17,599:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:17,796:INFO:Calculating mean and std
2025-05-12 21:07:17,797:INFO:Creating metrics dataframe
2025-05-12 21:07:17,800:INFO:Uploading results into container
2025-05-12 21:07:17,801:INFO:Uploading model into container now
2025-05-12 21:07:17,801:INFO:_master_model_container: 2
2025-05-12 21:07:17,801:INFO:_display_container: 2
2025-05-12 21:07:17,801:INFO:Lasso(random_state=123)
2025-05-12 21:07:17,801:INFO:create_model() successfully completed......................................
2025-05-12 21:07:17,884:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:17,885:INFO:Creating metrics dataframe
2025-05-12 21:07:17,894:INFO:Initializing Ridge Regression
2025-05-12 21:07:17,894:INFO:Total runtime is 0.15231239000956218 minutes
2025-05-12 21:07:17,898:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:17,898:INFO:Initializing create_model()
2025-05-12 21:07:17,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:17,898:INFO:Checking exceptions
2025-05-12 21:07:17,898:INFO:Importing libraries
2025-05-12 21:07:17,898:INFO:Copying training dataset
2025-05-12 21:07:17,901:INFO:Defining folds
2025-05-12 21:07:17,902:INFO:Declaring metric variables
2025-05-12 21:07:17,908:INFO:Importing untrained model
2025-05-12 21:07:17,914:INFO:Ridge Regression Imported successfully
2025-05-12 21:07:17,923:INFO:Starting cross validation
2025-05-12 21:07:17,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:18,128:INFO:Calculating mean and std
2025-05-12 21:07:18,130:INFO:Creating metrics dataframe
2025-05-12 21:07:18,131:INFO:Uploading results into container
2025-05-12 21:07:18,132:INFO:Uploading model into container now
2025-05-12 21:07:18,133:INFO:_master_model_container: 3
2025-05-12 21:07:18,133:INFO:_display_container: 2
2025-05-12 21:07:18,133:INFO:Ridge(random_state=123)
2025-05-12 21:07:18,133:INFO:create_model() successfully completed......................................
2025-05-12 21:07:18,216:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:18,216:INFO:Creating metrics dataframe
2025-05-12 21:07:18,224:INFO:Initializing Elastic Net
2025-05-12 21:07:18,224:INFO:Total runtime is 0.15782576402028403 minutes
2025-05-12 21:07:18,228:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:18,229:INFO:Initializing create_model()
2025-05-12 21:07:18,229:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:18,229:INFO:Checking exceptions
2025-05-12 21:07:18,229:INFO:Importing libraries
2025-05-12 21:07:18,229:INFO:Copying training dataset
2025-05-12 21:07:18,233:INFO:Defining folds
2025-05-12 21:07:18,233:INFO:Declaring metric variables
2025-05-12 21:07:18,237:INFO:Importing untrained model
2025-05-12 21:07:18,241:INFO:Elastic Net Imported successfully
2025-05-12 21:07:18,251:INFO:Starting cross validation
2025-05-12 21:07:18,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:18,443:INFO:Calculating mean and std
2025-05-12 21:07:18,444:INFO:Creating metrics dataframe
2025-05-12 21:07:18,447:INFO:Uploading results into container
2025-05-12 21:07:18,447:INFO:Uploading model into container now
2025-05-12 21:07:18,448:INFO:_master_model_container: 4
2025-05-12 21:07:18,448:INFO:_display_container: 2
2025-05-12 21:07:18,448:INFO:ElasticNet(random_state=123)
2025-05-12 21:07:18,449:INFO:create_model() successfully completed......................................
2025-05-12 21:07:18,530:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:18,531:INFO:Creating metrics dataframe
2025-05-12 21:07:18,538:INFO:Initializing Least Angle Regression
2025-05-12 21:07:18,538:INFO:Total runtime is 0.16304643154144288 minutes
2025-05-12 21:07:18,542:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:18,543:INFO:Initializing create_model()
2025-05-12 21:07:18,543:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:18,543:INFO:Checking exceptions
2025-05-12 21:07:18,543:INFO:Importing libraries
2025-05-12 21:07:18,543:INFO:Copying training dataset
2025-05-12 21:07:18,548:INFO:Defining folds
2025-05-12 21:07:18,548:INFO:Declaring metric variables
2025-05-12 21:07:18,551:INFO:Importing untrained model
2025-05-12 21:07:18,555:INFO:Least Angle Regression Imported successfully
2025-05-12 21:07:18,565:INFO:Starting cross validation
2025-05-12 21:07:18,566:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:18,790:INFO:Calculating mean and std
2025-05-12 21:07:18,792:INFO:Creating metrics dataframe
2025-05-12 21:07:18,794:INFO:Uploading results into container
2025-05-12 21:07:18,794:INFO:Uploading model into container now
2025-05-12 21:07:18,795:INFO:_master_model_container: 5
2025-05-12 21:07:18,795:INFO:_display_container: 2
2025-05-12 21:07:18,795:INFO:Lars(random_state=123)
2025-05-12 21:07:18,795:INFO:create_model() successfully completed......................................
2025-05-12 21:07:18,882:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:18,882:INFO:Creating metrics dataframe
2025-05-12 21:07:18,892:INFO:Initializing Lasso Least Angle Regression
2025-05-12 21:07:18,892:INFO:Total runtime is 0.16894732316335043 minutes
2025-05-12 21:07:18,896:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:18,896:INFO:Initializing create_model()
2025-05-12 21:07:18,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:18,896:INFO:Checking exceptions
2025-05-12 21:07:18,897:INFO:Importing libraries
2025-05-12 21:07:18,897:INFO:Copying training dataset
2025-05-12 21:07:18,902:INFO:Defining folds
2025-05-12 21:07:18,902:INFO:Declaring metric variables
2025-05-12 21:07:18,907:INFO:Importing untrained model
2025-05-12 21:07:18,912:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 21:07:18,919:INFO:Starting cross validation
2025-05-12 21:07:18,922:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:19,146:INFO:Calculating mean and std
2025-05-12 21:07:19,147:INFO:Creating metrics dataframe
2025-05-12 21:07:19,149:INFO:Uploading results into container
2025-05-12 21:07:19,150:INFO:Uploading model into container now
2025-05-12 21:07:19,150:INFO:_master_model_container: 6
2025-05-12 21:07:19,150:INFO:_display_container: 2
2025-05-12 21:07:19,151:INFO:LassoLars(random_state=123)
2025-05-12 21:07:19,151:INFO:create_model() successfully completed......................................
2025-05-12 21:07:19,238:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:19,238:INFO:Creating metrics dataframe
2025-05-12 21:07:19,247:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 21:07:19,247:INFO:Total runtime is 0.17486355702082315 minutes
2025-05-12 21:07:19,250:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:19,251:INFO:Initializing create_model()
2025-05-12 21:07:19,251:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:19,251:INFO:Checking exceptions
2025-05-12 21:07:19,251:INFO:Importing libraries
2025-05-12 21:07:19,251:INFO:Copying training dataset
2025-05-12 21:07:19,255:INFO:Defining folds
2025-05-12 21:07:19,255:INFO:Declaring metric variables
2025-05-12 21:07:19,259:INFO:Importing untrained model
2025-05-12 21:07:19,261:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 21:07:19,270:INFO:Starting cross validation
2025-05-12 21:07:19,271:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:19,460:INFO:Calculating mean and std
2025-05-12 21:07:19,462:INFO:Creating metrics dataframe
2025-05-12 21:07:19,464:INFO:Uploading results into container
2025-05-12 21:07:19,464:INFO:Uploading model into container now
2025-05-12 21:07:19,465:INFO:_master_model_container: 7
2025-05-12 21:07:19,465:INFO:_display_container: 2
2025-05-12 21:07:19,465:INFO:OrthogonalMatchingPursuit()
2025-05-12 21:07:19,465:INFO:create_model() successfully completed......................................
2025-05-12 21:07:19,546:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:19,546:INFO:Creating metrics dataframe
2025-05-12 21:07:19,555:INFO:Initializing Bayesian Ridge
2025-05-12 21:07:19,556:INFO:Total runtime is 0.18001383145650227 minutes
2025-05-12 21:07:19,560:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:19,560:INFO:Initializing create_model()
2025-05-12 21:07:19,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:19,560:INFO:Checking exceptions
2025-05-12 21:07:19,560:INFO:Importing libraries
2025-05-12 21:07:19,560:INFO:Copying training dataset
2025-05-12 21:07:19,564:INFO:Defining folds
2025-05-12 21:07:19,565:INFO:Declaring metric variables
2025-05-12 21:07:19,568:INFO:Importing untrained model
2025-05-12 21:07:19,572:INFO:Bayesian Ridge Imported successfully
2025-05-12 21:07:19,581:INFO:Starting cross validation
2025-05-12 21:07:19,582:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:19,788:INFO:Calculating mean and std
2025-05-12 21:07:19,790:INFO:Creating metrics dataframe
2025-05-12 21:07:19,792:INFO:Uploading results into container
2025-05-12 21:07:19,793:INFO:Uploading model into container now
2025-05-12 21:07:19,793:INFO:_master_model_container: 8
2025-05-12 21:07:19,793:INFO:_display_container: 2
2025-05-12 21:07:19,793:INFO:BayesianRidge()
2025-05-12 21:07:19,793:INFO:create_model() successfully completed......................................
2025-05-12 21:07:19,873:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:19,874:INFO:Creating metrics dataframe
2025-05-12 21:07:19,882:INFO:Initializing Passive Aggressive Regressor
2025-05-12 21:07:19,884:INFO:Total runtime is 0.1854825735092163 minutes
2025-05-12 21:07:19,886:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:19,888:INFO:Initializing create_model()
2025-05-12 21:07:19,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:19,888:INFO:Checking exceptions
2025-05-12 21:07:19,888:INFO:Importing libraries
2025-05-12 21:07:19,888:INFO:Copying training dataset
2025-05-12 21:07:19,892:INFO:Defining folds
2025-05-12 21:07:19,892:INFO:Declaring metric variables
2025-05-12 21:07:19,895:INFO:Importing untrained model
2025-05-12 21:07:19,899:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 21:07:19,907:INFO:Starting cross validation
2025-05-12 21:07:19,908:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:19,988:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:19,990:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:19,993:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:19,998:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:20,009:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:20,018:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:20,018:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:20,022:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:20,087:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:20,090:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:20,123:INFO:Calculating mean and std
2025-05-12 21:07:20,125:INFO:Creating metrics dataframe
2025-05-12 21:07:20,126:INFO:Uploading results into container
2025-05-12 21:07:20,128:INFO:Uploading model into container now
2025-05-12 21:07:20,128:INFO:_master_model_container: 9
2025-05-12 21:07:20,128:INFO:_display_container: 2
2025-05-12 21:07:20,128:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 21:07:20,129:INFO:create_model() successfully completed......................................
2025-05-12 21:07:20,210:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:20,211:INFO:Creating metrics dataframe
2025-05-12 21:07:20,220:INFO:Initializing Huber Regressor
2025-05-12 21:07:20,220:INFO:Total runtime is 0.19107828934987384 minutes
2025-05-12 21:07:20,224:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:20,225:INFO:Initializing create_model()
2025-05-12 21:07:20,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:20,225:INFO:Checking exceptions
2025-05-12 21:07:20,225:INFO:Importing libraries
2025-05-12 21:07:20,225:INFO:Copying training dataset
2025-05-12 21:07:20,228:INFO:Defining folds
2025-05-12 21:07:20,228:INFO:Declaring metric variables
2025-05-12 21:07:20,233:INFO:Importing untrained model
2025-05-12 21:07:20,235:INFO:Huber Regressor Imported successfully
2025-05-12 21:07:20,245:INFO:Starting cross validation
2025-05-12 21:07:20,246:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:20,458:INFO:Calculating mean and std
2025-05-12 21:07:20,459:INFO:Creating metrics dataframe
2025-05-12 21:07:20,461:INFO:Uploading results into container
2025-05-12 21:07:20,461:INFO:Uploading model into container now
2025-05-12 21:07:20,463:INFO:_master_model_container: 10
2025-05-12 21:07:20,463:INFO:_display_container: 2
2025-05-12 21:07:20,463:INFO:HuberRegressor()
2025-05-12 21:07:20,463:INFO:create_model() successfully completed......................................
2025-05-12 21:07:20,546:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:20,546:INFO:Creating metrics dataframe
2025-05-12 21:07:20,555:INFO:Initializing K Neighbors Regressor
2025-05-12 21:07:20,555:INFO:Total runtime is 0.19666815996170042 minutes
2025-05-12 21:07:20,560:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:20,560:INFO:Initializing create_model()
2025-05-12 21:07:20,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:20,560:INFO:Checking exceptions
2025-05-12 21:07:20,560:INFO:Importing libraries
2025-05-12 21:07:20,561:INFO:Copying training dataset
2025-05-12 21:07:20,564:INFO:Defining folds
2025-05-12 21:07:20,564:INFO:Declaring metric variables
2025-05-12 21:07:20,569:INFO:Importing untrained model
2025-05-12 21:07:20,572:INFO:K Neighbors Regressor Imported successfully
2025-05-12 21:07:20,582:INFO:Starting cross validation
2025-05-12 21:07:20,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:20,887:INFO:Calculating mean and std
2025-05-12 21:07:20,888:INFO:Creating metrics dataframe
2025-05-12 21:07:20,892:INFO:Uploading results into container
2025-05-12 21:07:20,893:INFO:Uploading model into container now
2025-05-12 21:07:20,893:INFO:_master_model_container: 11
2025-05-12 21:07:20,893:INFO:_display_container: 2
2025-05-12 21:07:20,894:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 21:07:20,894:INFO:create_model() successfully completed......................................
2025-05-12 21:07:20,974:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:20,974:INFO:Creating metrics dataframe
2025-05-12 21:07:20,984:INFO:Initializing Decision Tree Regressor
2025-05-12 21:07:20,984:INFO:Total runtime is 0.2038112163543701 minutes
2025-05-12 21:07:20,989:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:20,989:INFO:Initializing create_model()
2025-05-12 21:07:20,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:20,989:INFO:Checking exceptions
2025-05-12 21:07:20,989:INFO:Importing libraries
2025-05-12 21:07:20,989:INFO:Copying training dataset
2025-05-12 21:07:20,994:INFO:Defining folds
2025-05-12 21:07:20,994:INFO:Declaring metric variables
2025-05-12 21:07:20,997:INFO:Importing untrained model
2025-05-12 21:07:21,001:INFO:Decision Tree Regressor Imported successfully
2025-05-12 21:07:21,011:INFO:Starting cross validation
2025-05-12 21:07:21,014:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:21,224:INFO:Calculating mean and std
2025-05-12 21:07:21,225:INFO:Creating metrics dataframe
2025-05-12 21:07:21,227:INFO:Uploading results into container
2025-05-12 21:07:21,228:INFO:Uploading model into container now
2025-05-12 21:07:21,228:INFO:_master_model_container: 12
2025-05-12 21:07:21,228:INFO:_display_container: 2
2025-05-12 21:07:21,228:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 21:07:21,228:INFO:create_model() successfully completed......................................
2025-05-12 21:07:21,308:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:21,308:INFO:Creating metrics dataframe
2025-05-12 21:07:21,319:INFO:Initializing Random Forest Regressor
2025-05-12 21:07:21,319:INFO:Total runtime is 0.20939798355102537 minutes
2025-05-12 21:07:21,322:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:21,322:INFO:Initializing create_model()
2025-05-12 21:07:21,322:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:21,322:INFO:Checking exceptions
2025-05-12 21:07:21,324:INFO:Importing libraries
2025-05-12 21:07:21,324:INFO:Copying training dataset
2025-05-12 21:07:21,327:INFO:Defining folds
2025-05-12 21:07:21,327:INFO:Declaring metric variables
2025-05-12 21:07:21,332:INFO:Importing untrained model
2025-05-12 21:07:21,335:INFO:Random Forest Regressor Imported successfully
2025-05-12 21:07:21,342:INFO:Starting cross validation
2025-05-12 21:07:21,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:22,119:INFO:Calculating mean and std
2025-05-12 21:07:22,120:INFO:Creating metrics dataframe
2025-05-12 21:07:22,122:INFO:Uploading results into container
2025-05-12 21:07:22,123:INFO:Uploading model into container now
2025-05-12 21:07:22,123:INFO:_master_model_container: 13
2025-05-12 21:07:22,123:INFO:_display_container: 2
2025-05-12 21:07:22,125:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:07:22,125:INFO:create_model() successfully completed......................................
2025-05-12 21:07:22,207:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:22,207:INFO:Creating metrics dataframe
2025-05-12 21:07:22,218:INFO:Initializing Extra Trees Regressor
2025-05-12 21:07:22,218:INFO:Total runtime is 0.22437867323557534 minutes
2025-05-12 21:07:22,222:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:22,222:INFO:Initializing create_model()
2025-05-12 21:07:22,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:22,222:INFO:Checking exceptions
2025-05-12 21:07:22,222:INFO:Importing libraries
2025-05-12 21:07:22,222:INFO:Copying training dataset
2025-05-12 21:07:22,225:INFO:Defining folds
2025-05-12 21:07:22,226:INFO:Declaring metric variables
2025-05-12 21:07:22,230:INFO:Importing untrained model
2025-05-12 21:07:22,232:INFO:Extra Trees Regressor Imported successfully
2025-05-12 21:07:22,240:INFO:Starting cross validation
2025-05-12 21:07:22,242:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:22,976:INFO:Calculating mean and std
2025-05-12 21:07:22,978:INFO:Creating metrics dataframe
2025-05-12 21:07:22,979:INFO:Uploading results into container
2025-05-12 21:07:22,981:INFO:Uploading model into container now
2025-05-12 21:07:22,982:INFO:_master_model_container: 14
2025-05-12 21:07:22,982:INFO:_display_container: 2
2025-05-12 21:07:22,983:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:07:22,983:INFO:create_model() successfully completed......................................
2025-05-12 21:07:23,069:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:23,069:INFO:Creating metrics dataframe
2025-05-12 21:07:23,080:INFO:Initializing AdaBoost Regressor
2025-05-12 21:07:23,080:INFO:Total runtime is 0.23874803781509396 minutes
2025-05-12 21:07:23,083:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:23,083:INFO:Initializing create_model()
2025-05-12 21:07:23,083:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:23,083:INFO:Checking exceptions
2025-05-12 21:07:23,083:INFO:Importing libraries
2025-05-12 21:07:23,083:INFO:Copying training dataset
2025-05-12 21:07:23,089:INFO:Defining folds
2025-05-12 21:07:23,089:INFO:Declaring metric variables
2025-05-12 21:07:23,092:INFO:Importing untrained model
2025-05-12 21:07:23,097:INFO:AdaBoost Regressor Imported successfully
2025-05-12 21:07:23,105:INFO:Starting cross validation
2025-05-12 21:07:23,106:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:23,569:INFO:Calculating mean and std
2025-05-12 21:07:23,570:INFO:Creating metrics dataframe
2025-05-12 21:07:23,572:INFO:Uploading results into container
2025-05-12 21:07:23,572:INFO:Uploading model into container now
2025-05-12 21:07:23,572:INFO:_master_model_container: 15
2025-05-12 21:07:23,574:INFO:_display_container: 2
2025-05-12 21:07:23,574:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 21:07:23,574:INFO:create_model() successfully completed......................................
2025-05-12 21:07:23,659:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:23,659:INFO:Creating metrics dataframe
2025-05-12 21:07:23,671:INFO:Initializing Gradient Boosting Regressor
2025-05-12 21:07:23,671:INFO:Total runtime is 0.24859412511189774 minutes
2025-05-12 21:07:23,673:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:23,673:INFO:Initializing create_model()
2025-05-12 21:07:23,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:23,673:INFO:Checking exceptions
2025-05-12 21:07:23,673:INFO:Importing libraries
2025-05-12 21:07:23,673:INFO:Copying training dataset
2025-05-12 21:07:23,678:INFO:Defining folds
2025-05-12 21:07:23,679:INFO:Declaring metric variables
2025-05-12 21:07:23,682:INFO:Importing untrained model
2025-05-12 21:07:23,686:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 21:07:23,693:INFO:Starting cross validation
2025-05-12 21:07:23,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:24,060:INFO:Calculating mean and std
2025-05-12 21:07:24,061:INFO:Creating metrics dataframe
2025-05-12 21:07:24,062:INFO:Uploading results into container
2025-05-12 21:07:24,064:INFO:Uploading model into container now
2025-05-12 21:07:24,065:INFO:_master_model_container: 16
2025-05-12 21:07:24,065:INFO:_display_container: 2
2025-05-12 21:07:24,065:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 21:07:24,065:INFO:create_model() successfully completed......................................
2025-05-12 21:07:24,146:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:24,146:INFO:Creating metrics dataframe
2025-05-12 21:07:24,157:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 21:07:24,157:INFO:Total runtime is 0.2566994190216064 minutes
2025-05-12 21:07:24,159:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:24,160:INFO:Initializing create_model()
2025-05-12 21:07:24,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:24,160:INFO:Checking exceptions
2025-05-12 21:07:24,160:INFO:Importing libraries
2025-05-12 21:07:24,160:INFO:Copying training dataset
2025-05-12 21:07:24,164:INFO:Defining folds
2025-05-12 21:07:24,164:INFO:Declaring metric variables
2025-05-12 21:07:24,167:INFO:Importing untrained model
2025-05-12 21:07:24,172:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 21:07:24,181:INFO:Starting cross validation
2025-05-12 21:07:24,182:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:24,650:INFO:Calculating mean and std
2025-05-12 21:07:24,654:INFO:Creating metrics dataframe
2025-05-12 21:07:24,658:INFO:Uploading results into container
2025-05-12 21:07:24,659:INFO:Uploading model into container now
2025-05-12 21:07:24,660:INFO:_master_model_container: 17
2025-05-12 21:07:24,660:INFO:_display_container: 2
2025-05-12 21:07:24,661:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:07:24,662:INFO:create_model() successfully completed......................................
2025-05-12 21:07:24,780:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:24,780:INFO:Creating metrics dataframe
2025-05-12 21:07:24,795:INFO:Initializing Dummy Regressor
2025-05-12 21:07:24,795:INFO:Total runtime is 0.26733943223953244 minutes
2025-05-12 21:07:24,798:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:24,799:INFO:Initializing create_model()
2025-05-12 21:07:24,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:24,799:INFO:Checking exceptions
2025-05-12 21:07:24,799:INFO:Importing libraries
2025-05-12 21:07:24,799:INFO:Copying training dataset
2025-05-12 21:07:24,805:INFO:Defining folds
2025-05-12 21:07:24,805:INFO:Declaring metric variables
2025-05-12 21:07:24,810:INFO:Importing untrained model
2025-05-12 21:07:24,816:INFO:Dummy Regressor Imported successfully
2025-05-12 21:07:24,824:INFO:Starting cross validation
2025-05-12 21:07:24,827:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:25,043:INFO:Calculating mean and std
2025-05-12 21:07:25,045:INFO:Creating metrics dataframe
2025-05-12 21:07:25,047:INFO:Uploading results into container
2025-05-12 21:07:25,048:INFO:Uploading model into container now
2025-05-12 21:07:25,049:INFO:_master_model_container: 18
2025-05-12 21:07:25,049:INFO:_display_container: 2
2025-05-12 21:07:25,050:INFO:DummyRegressor()
2025-05-12 21:07:25,050:INFO:create_model() successfully completed......................................
2025-05-12 21:07:25,135:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:25,135:INFO:Creating metrics dataframe
2025-05-12 21:07:25,149:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 21:07:25,158:INFO:Initializing create_model()
2025-05-12 21:07:25,158:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:25,158:INFO:Checking exceptions
2025-05-12 21:07:25,160:INFO:Importing libraries
2025-05-12 21:07:25,160:INFO:Copying training dataset
2025-05-12 21:07:25,165:INFO:Defining folds
2025-05-12 21:07:25,165:INFO:Declaring metric variables
2025-05-12 21:07:25,165:INFO:Importing untrained model
2025-05-12 21:07:25,165:INFO:Declaring custom model
2025-05-12 21:07:25,165:INFO:Linear Regression Imported successfully
2025-05-12 21:07:25,167:INFO:Cross validation set to False
2025-05-12 21:07:25,168:INFO:Fitting Model
2025-05-12 21:07:25,206:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:07:25,206:INFO:create_model() successfully completed......................................
2025-05-12 21:07:25,319:INFO:_master_model_container: 18
2025-05-12 21:07:25,319:INFO:_display_container: 2
2025-05-12 21:07:25,319:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:07:25,319:INFO:compare_models() successfully completed......................................
2025-05-12 21:20:31,144:INFO:Initializing create_model()
2025-05-12 21:20:31,144:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:20:31,144:INFO:Checking exceptions
2025-05-12 21:20:31,159:INFO:Importing libraries
2025-05-12 21:20:31,159:INFO:Copying training dataset
2025-05-12 21:20:31,166:INFO:Defining folds
2025-05-12 21:20:31,167:INFO:Declaring metric variables
2025-05-12 21:20:31,171:INFO:Importing untrained model
2025-05-12 21:20:31,176:INFO:Linear Regression Imported successfully
2025-05-12 21:20:31,182:INFO:Starting cross validation
2025-05-12 21:20:31,184:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:20:40,263:INFO:Calculating mean and std
2025-05-12 21:20:40,265:INFO:Creating metrics dataframe
2025-05-12 21:20:40,279:INFO:Finalizing model
2025-05-12 21:20:40,355:INFO:Uploading results into container
2025-05-12 21:20:40,357:INFO:Uploading model into container now
2025-05-12 21:20:40,370:INFO:_master_model_container: 19
2025-05-12 21:20:40,370:INFO:_display_container: 3
2025-05-12 21:20:40,370:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:20:40,370:INFO:create_model() successfully completed......................................
2025-05-12 21:24:48,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:24:48,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:24:48,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:24:48,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:24:49,252:INFO:PyCaret RegressionExperiment
2025-05-12 21:24:49,253:INFO:Logging name: reg-default-name
2025-05-12 21:24:49,253:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 21:24:49,253:INFO:version 3.3.2
2025-05-12 21:24:49,253:INFO:Initializing setup()
2025-05-12 21:24:49,253:INFO:self.USI: afdb
2025-05-12 21:24:49,253:INFO:self._variable_keys: {'X_test', 'logging_param', 'exp_name_log', '_ml_usecase', '_available_plots', 'y_test', 'X_train', 'seed', 'X', 'idx', 'USI', 'y', 'data', 'memory', 'exp_id', 'n_jobs_param', 'pipeline', 'html_param', 'y_train', 'transform_target_param', 'fold_shuffle_param', 'target_param', 'gpu_n_jobs_param', 'fold_generator', 'gpu_param', 'log_plots_param', 'fold_groups_param'}
2025-05-12 21:24:49,253:INFO:Checking environment
2025-05-12 21:24:49,254:INFO:python_version: 3.11.8
2025-05-12 21:24:49,254:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 21:24:49,254:INFO:machine: AMD64
2025-05-12 21:24:49,254:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 21:24:49,259:INFO:Memory: svmem(total=16907886592, available=2661965824, percent=84.3, used=14245920768, free=2661965824)
2025-05-12 21:24:49,259:INFO:Physical Core: 4
2025-05-12 21:24:49,259:INFO:Logical Core: 8
2025-05-12 21:24:49,259:INFO:Checking libraries
2025-05-12 21:24:49,259:INFO:System:
2025-05-12 21:24:49,259:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 21:24:49,259:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 21:24:49,259:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 21:24:49,259:INFO:PyCaret required dependencies:
2025-05-12 21:24:49,292:INFO:                 pip: 24.0
2025-05-12 21:24:49,292:INFO:          setuptools: 65.5.0
2025-05-12 21:24:49,292:INFO:             pycaret: 3.3.2
2025-05-12 21:24:49,292:INFO:             IPython: 9.2.0
2025-05-12 21:24:49,292:INFO:          ipywidgets: 8.1.7
2025-05-12 21:24:49,292:INFO:                tqdm: 4.67.1
2025-05-12 21:24:49,292:INFO:               numpy: 1.26.4
2025-05-12 21:24:49,292:INFO:              pandas: 2.1.4
2025-05-12 21:24:49,292:INFO:              jinja2: 3.1.6
2025-05-12 21:24:49,292:INFO:               scipy: 1.11.4
2025-05-12 21:24:49,292:INFO:              joblib: 1.3.2
2025-05-12 21:24:49,292:INFO:             sklearn: 1.4.2
2025-05-12 21:24:49,292:INFO:                pyod: 2.0.5
2025-05-12 21:24:49,292:INFO:            imblearn: 0.13.0
2025-05-12 21:24:49,292:INFO:   category_encoders: 2.7.0
2025-05-12 21:24:49,292:INFO:            lightgbm: 4.6.0
2025-05-12 21:24:49,292:INFO:               numba: 0.61.2
2025-05-12 21:24:49,292:INFO:            requests: 2.32.3
2025-05-12 21:24:49,292:INFO:          matplotlib: 3.7.5
2025-05-12 21:24:49,292:INFO:          scikitplot: 0.3.7
2025-05-12 21:24:49,292:INFO:         yellowbrick: 1.5
2025-05-12 21:24:49,292:INFO:              plotly: 5.24.1
2025-05-12 21:24:49,292:INFO:    plotly-resampler: Not installed
2025-05-12 21:24:49,292:INFO:             kaleido: 0.2.1
2025-05-12 21:24:49,292:INFO:           schemdraw: 0.15
2025-05-12 21:24:49,292:INFO:         statsmodels: 0.14.4
2025-05-12 21:24:49,292:INFO:              sktime: 0.26.0
2025-05-12 21:24:49,292:INFO:               tbats: 1.1.3
2025-05-12 21:24:49,292:INFO:            pmdarima: 2.0.4
2025-05-12 21:24:49,292:INFO:              psutil: 7.0.0
2025-05-12 21:24:49,292:INFO:          markupsafe: 3.0.2
2025-05-12 21:24:49,292:INFO:             pickle5: Not installed
2025-05-12 21:24:49,292:INFO:         cloudpickle: 3.1.1
2025-05-12 21:24:49,292:INFO:         deprecation: 2.1.0
2025-05-12 21:24:49,292:INFO:              xxhash: 3.5.0
2025-05-12 21:24:49,292:INFO:           wurlitzer: Not installed
2025-05-12 21:24:49,294:INFO:PyCaret optional dependencies:
2025-05-12 21:24:49,308:INFO:                shap: Not installed
2025-05-12 21:24:49,308:INFO:           interpret: Not installed
2025-05-12 21:24:49,308:INFO:                umap: Not installed
2025-05-12 21:24:49,308:INFO:     ydata_profiling: Not installed
2025-05-12 21:24:49,308:INFO:  explainerdashboard: Not installed
2025-05-12 21:24:49,309:INFO:             autoviz: Not installed
2025-05-12 21:24:49,309:INFO:           fairlearn: Not installed
2025-05-12 21:24:49,309:INFO:          deepchecks: Not installed
2025-05-12 21:24:49,309:INFO:             xgboost: Not installed
2025-05-12 21:24:49,309:INFO:            catboost: Not installed
2025-05-12 21:24:49,309:INFO:              kmodes: Not installed
2025-05-12 21:24:49,310:INFO:             mlxtend: Not installed
2025-05-12 21:24:49,310:INFO:       statsforecast: Not installed
2025-05-12 21:24:49,310:INFO:        tune_sklearn: Not installed
2025-05-12 21:24:49,310:INFO:                 ray: Not installed
2025-05-12 21:24:49,310:INFO:            hyperopt: Not installed
2025-05-12 21:24:49,310:INFO:              optuna: Not installed
2025-05-12 21:24:49,310:INFO:               skopt: Not installed
2025-05-12 21:24:49,310:INFO:              mlflow: Not installed
2025-05-12 21:24:49,310:INFO:              gradio: Not installed
2025-05-12 21:24:49,310:INFO:             fastapi: Not installed
2025-05-12 21:24:49,310:INFO:             uvicorn: Not installed
2025-05-12 21:24:49,310:INFO:              m2cgen: Not installed
2025-05-12 21:24:49,310:INFO:           evidently: Not installed
2025-05-12 21:24:49,310:INFO:               fugue: Not installed
2025-05-12 21:24:49,310:INFO:           streamlit: Not installed
2025-05-12 21:24:49,310:INFO:             prophet: Not installed
2025-05-12 21:24:49,310:INFO:None
2025-05-12 21:24:49,310:INFO:Set up data.
2025-05-12 21:24:49,317:INFO:Set up folding strategy.
2025-05-12 21:24:49,317:INFO:Set up train/test split.
2025-05-12 21:24:49,322:INFO:Set up index.
2025-05-12 21:24:49,324:INFO:Assigning column types.
2025-05-12 21:24:49,327:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 21:24:49,327:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,332:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,339:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,456:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,457:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,462:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,468:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,526:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,571:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,572:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 21:24:49,575:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,581:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,636:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,684:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,688:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,743:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,786:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,788:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,788:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 21:24:49,797:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,850:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,894:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,905:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,002:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,002:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,002:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 21:24:50,070:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,114:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,180:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,228:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 21:24:50,311:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,505:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 21:24:50,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,746:INFO:Preparing preprocessing pipeline...
2025-05-12 21:24:50,746:INFO:Set up simple imputation.
2025-05-12 21:24:50,748:INFO:Set up encoding of categorical features.
2025-05-12 21:24:50,748:INFO:Set up feature normalization.
2025-05-12 21:24:50,841:INFO:Finished creating preprocessing pipeline.
2025-05-12 21:24:50,849:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 21:24:50,849:INFO:Creating final display dataframe.
2025-05-12 21:24:51,003:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            precio
2                   Target type        Regression
3           Original data shape          (100, 7)
4        Transformed data shape         (100, 10)
5   Transformed train set shape          (70, 10)
6    Transformed test set shape          (30, 10)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              afdb
2025-05-12 21:24:51,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:51,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:51,225:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:51,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:51,226:INFO:setup() successfully completed in 1.98s...............
2025-05-12 21:24:51,235:INFO:Initializing compare_models()
2025-05-12 21:24:51,235:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 21:24:51,235:INFO:Checking exceptions
2025-05-12 21:24:51,237:INFO:Preparing display monitor
2025-05-12 21:24:51,270:INFO:Initializing Linear Regression
2025-05-12 21:24:51,270:INFO:Total runtime is 0.0 minutes
2025-05-12 21:24:51,275:INFO:SubProcess create_model() called ==================================
2025-05-12 21:24:51,275:INFO:Initializing create_model()
2025-05-12 21:24:51,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:24:51,275:INFO:Checking exceptions
2025-05-12 21:24:51,275:INFO:Importing libraries
2025-05-12 21:24:51,276:INFO:Copying training dataset
2025-05-12 21:24:51,281:INFO:Defining folds
2025-05-12 21:24:51,281:INFO:Declaring metric variables
2025-05-12 21:24:51,285:INFO:Importing untrained model
2025-05-12 21:24:51,289:INFO:Linear Regression Imported successfully
2025-05-12 21:24:51,298:INFO:Starting cross validation
2025-05-12 21:24:51,307:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:00,960:INFO:Calculating mean and std
2025-05-12 21:25:00,961:INFO:Creating metrics dataframe
2025-05-12 21:25:00,962:INFO:Uploading results into container
2025-05-12 21:25:00,964:INFO:Uploading model into container now
2025-05-12 21:25:00,964:INFO:_master_model_container: 1
2025-05-12 21:25:00,964:INFO:_display_container: 2
2025-05-12 21:25:00,965:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:25:00,965:INFO:create_model() successfully completed......................................
2025-05-12 21:25:01,041:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:01,041:INFO:Creating metrics dataframe
2025-05-12 21:25:01,047:INFO:Initializing Lasso Regression
2025-05-12 21:25:01,047:INFO:Total runtime is 0.1629357973734538 minutes
2025-05-12 21:25:01,051:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:01,052:INFO:Initializing create_model()
2025-05-12 21:25:01,052:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:01,052:INFO:Checking exceptions
2025-05-12 21:25:01,052:INFO:Importing libraries
2025-05-12 21:25:01,052:INFO:Copying training dataset
2025-05-12 21:25:01,056:INFO:Defining folds
2025-05-12 21:25:01,056:INFO:Declaring metric variables
2025-05-12 21:25:01,059:INFO:Importing untrained model
2025-05-12 21:25:01,062:INFO:Lasso Regression Imported successfully
2025-05-12 21:25:01,072:INFO:Starting cross validation
2025-05-12 21:25:01,074:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:01,259:INFO:Calculating mean and std
2025-05-12 21:25:01,259:INFO:Creating metrics dataframe
2025-05-12 21:25:01,262:INFO:Uploading results into container
2025-05-12 21:25:01,263:INFO:Uploading model into container now
2025-05-12 21:25:01,263:INFO:_master_model_container: 2
2025-05-12 21:25:01,263:INFO:_display_container: 2
2025-05-12 21:25:01,263:INFO:Lasso(random_state=123)
2025-05-12 21:25:01,263:INFO:create_model() successfully completed......................................
2025-05-12 21:25:01,335:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:01,335:INFO:Creating metrics dataframe
2025-05-12 21:25:01,343:INFO:Initializing Ridge Regression
2025-05-12 21:25:01,343:INFO:Total runtime is 0.1678742567698161 minutes
2025-05-12 21:25:01,347:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:01,347:INFO:Initializing create_model()
2025-05-12 21:25:01,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:01,347:INFO:Checking exceptions
2025-05-12 21:25:01,347:INFO:Importing libraries
2025-05-12 21:25:01,347:INFO:Copying training dataset
2025-05-12 21:25:01,352:INFO:Defining folds
2025-05-12 21:25:01,353:INFO:Declaring metric variables
2025-05-12 21:25:01,355:INFO:Importing untrained model
2025-05-12 21:25:01,360:INFO:Ridge Regression Imported successfully
2025-05-12 21:25:01,369:INFO:Starting cross validation
2025-05-12 21:25:01,370:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:01,543:INFO:Calculating mean and std
2025-05-12 21:25:01,543:INFO:Creating metrics dataframe
2025-05-12 21:25:01,546:INFO:Uploading results into container
2025-05-12 21:25:01,546:INFO:Uploading model into container now
2025-05-12 21:25:01,547:INFO:_master_model_container: 3
2025-05-12 21:25:01,547:INFO:_display_container: 2
2025-05-12 21:25:01,548:INFO:Ridge(random_state=123)
2025-05-12 21:25:01,548:INFO:create_model() successfully completed......................................
2025-05-12 21:25:01,622:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:01,623:INFO:Creating metrics dataframe
2025-05-12 21:25:01,629:INFO:Initializing Elastic Net
2025-05-12 21:25:01,629:INFO:Total runtime is 0.17265101671218874 minutes
2025-05-12 21:25:01,632:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:01,634:INFO:Initializing create_model()
2025-05-12 21:25:01,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:01,634:INFO:Checking exceptions
2025-05-12 21:25:01,634:INFO:Importing libraries
2025-05-12 21:25:01,634:INFO:Copying training dataset
2025-05-12 21:25:01,638:INFO:Defining folds
2025-05-12 21:25:01,639:INFO:Declaring metric variables
2025-05-12 21:25:01,641:INFO:Importing untrained model
2025-05-12 21:25:01,645:INFO:Elastic Net Imported successfully
2025-05-12 21:25:01,653:INFO:Starting cross validation
2025-05-12 21:25:01,655:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:01,829:INFO:Calculating mean and std
2025-05-12 21:25:01,831:INFO:Creating metrics dataframe
2025-05-12 21:25:01,832:INFO:Uploading results into container
2025-05-12 21:25:01,833:INFO:Uploading model into container now
2025-05-12 21:25:01,834:INFO:_master_model_container: 4
2025-05-12 21:25:01,834:INFO:_display_container: 2
2025-05-12 21:25:01,834:INFO:ElasticNet(random_state=123)
2025-05-12 21:25:01,834:INFO:create_model() successfully completed......................................
2025-05-12 21:25:01,910:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:01,910:INFO:Creating metrics dataframe
2025-05-12 21:25:01,917:INFO:Initializing Least Angle Regression
2025-05-12 21:25:01,917:INFO:Total runtime is 0.1774511019388835 minutes
2025-05-12 21:25:01,922:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:01,922:INFO:Initializing create_model()
2025-05-12 21:25:01,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:01,922:INFO:Checking exceptions
2025-05-12 21:25:01,922:INFO:Importing libraries
2025-05-12 21:25:01,923:INFO:Copying training dataset
2025-05-12 21:25:01,926:INFO:Defining folds
2025-05-12 21:25:01,927:INFO:Declaring metric variables
2025-05-12 21:25:01,930:INFO:Importing untrained model
2025-05-12 21:25:01,934:INFO:Least Angle Regression Imported successfully
2025-05-12 21:25:01,943:INFO:Starting cross validation
2025-05-12 21:25:01,944:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:02,125:INFO:Calculating mean and std
2025-05-12 21:25:02,125:INFO:Creating metrics dataframe
2025-05-12 21:25:02,127:INFO:Uploading results into container
2025-05-12 21:25:02,128:INFO:Uploading model into container now
2025-05-12 21:25:02,128:INFO:_master_model_container: 5
2025-05-12 21:25:02,128:INFO:_display_container: 2
2025-05-12 21:25:02,129:INFO:Lars(random_state=123)
2025-05-12 21:25:02,129:INFO:create_model() successfully completed......................................
2025-05-12 21:25:02,202:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:02,202:INFO:Creating metrics dataframe
2025-05-12 21:25:02,210:INFO:Initializing Lasso Least Angle Regression
2025-05-12 21:25:02,210:INFO:Total runtime is 0.18232665459314987 minutes
2025-05-12 21:25:02,215:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:02,216:INFO:Initializing create_model()
2025-05-12 21:25:02,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:02,216:INFO:Checking exceptions
2025-05-12 21:25:02,216:INFO:Importing libraries
2025-05-12 21:25:02,216:INFO:Copying training dataset
2025-05-12 21:25:02,219:INFO:Defining folds
2025-05-12 21:25:02,219:INFO:Declaring metric variables
2025-05-12 21:25:02,222:INFO:Importing untrained model
2025-05-12 21:25:02,225:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 21:25:02,234:INFO:Starting cross validation
2025-05-12 21:25:02,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:02,422:INFO:Calculating mean and std
2025-05-12 21:25:02,423:INFO:Creating metrics dataframe
2025-05-12 21:25:02,425:INFO:Uploading results into container
2025-05-12 21:25:02,425:INFO:Uploading model into container now
2025-05-12 21:25:02,425:INFO:_master_model_container: 6
2025-05-12 21:25:02,425:INFO:_display_container: 2
2025-05-12 21:25:02,427:INFO:LassoLars(random_state=123)
2025-05-12 21:25:02,427:INFO:create_model() successfully completed......................................
2025-05-12 21:25:02,499:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:02,499:INFO:Creating metrics dataframe
2025-05-12 21:25:02,506:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 21:25:02,506:INFO:Total runtime is 0.187268344561259 minutes
2025-05-12 21:25:02,509:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:02,509:INFO:Initializing create_model()
2025-05-12 21:25:02,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:02,511:INFO:Checking exceptions
2025-05-12 21:25:02,511:INFO:Importing libraries
2025-05-12 21:25:02,511:INFO:Copying training dataset
2025-05-12 21:25:02,514:INFO:Defining folds
2025-05-12 21:25:02,514:INFO:Declaring metric variables
2025-05-12 21:25:02,517:INFO:Importing untrained model
2025-05-12 21:25:02,521:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 21:25:02,529:INFO:Starting cross validation
2025-05-12 21:25:02,530:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:02,721:INFO:Calculating mean and std
2025-05-12 21:25:02,727:INFO:Creating metrics dataframe
2025-05-12 21:25:02,730:INFO:Uploading results into container
2025-05-12 21:25:02,731:INFO:Uploading model into container now
2025-05-12 21:25:02,731:INFO:_master_model_container: 7
2025-05-12 21:25:02,732:INFO:_display_container: 2
2025-05-12 21:25:02,732:INFO:OrthogonalMatchingPursuit()
2025-05-12 21:25:02,732:INFO:create_model() successfully completed......................................
2025-05-12 21:25:02,852:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:02,852:INFO:Creating metrics dataframe
2025-05-12 21:25:02,861:INFO:Initializing Bayesian Ridge
2025-05-12 21:25:02,861:INFO:Total runtime is 0.1931766788164775 minutes
2025-05-12 21:25:02,867:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:02,867:INFO:Initializing create_model()
2025-05-12 21:25:02,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:02,867:INFO:Checking exceptions
2025-05-12 21:25:02,867:INFO:Importing libraries
2025-05-12 21:25:02,867:INFO:Copying training dataset
2025-05-12 21:25:02,873:INFO:Defining folds
2025-05-12 21:25:02,874:INFO:Declaring metric variables
2025-05-12 21:25:02,879:INFO:Importing untrained model
2025-05-12 21:25:02,884:INFO:Bayesian Ridge Imported successfully
2025-05-12 21:25:02,892:INFO:Starting cross validation
2025-05-12 21:25:02,894:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:03,104:INFO:Calculating mean and std
2025-05-12 21:25:03,105:INFO:Creating metrics dataframe
2025-05-12 21:25:03,108:INFO:Uploading results into container
2025-05-12 21:25:03,109:INFO:Uploading model into container now
2025-05-12 21:25:03,109:INFO:_master_model_container: 8
2025-05-12 21:25:03,109:INFO:_display_container: 2
2025-05-12 21:25:03,111:INFO:BayesianRidge()
2025-05-12 21:25:03,111:INFO:create_model() successfully completed......................................
2025-05-12 21:25:03,184:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:03,184:INFO:Creating metrics dataframe
2025-05-12 21:25:03,192:INFO:Initializing Passive Aggressive Regressor
2025-05-12 21:25:03,192:INFO:Total runtime is 0.1987003842989604 minutes
2025-05-12 21:25:03,195:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:03,196:INFO:Initializing create_model()
2025-05-12 21:25:03,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:03,196:INFO:Checking exceptions
2025-05-12 21:25:03,196:INFO:Importing libraries
2025-05-12 21:25:03,196:INFO:Copying training dataset
2025-05-12 21:25:03,201:INFO:Defining folds
2025-05-12 21:25:03,202:INFO:Declaring metric variables
2025-05-12 21:25:03,205:INFO:Importing untrained model
2025-05-12 21:25:03,208:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 21:25:03,219:INFO:Starting cross validation
2025-05-12 21:25:03,220:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:03,295:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,303:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,309:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,312:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,314:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,315:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,321:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,346:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,388:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,394:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,423:INFO:Calculating mean and std
2025-05-12 21:25:03,423:INFO:Creating metrics dataframe
2025-05-12 21:25:03,426:INFO:Uploading results into container
2025-05-12 21:25:03,427:INFO:Uploading model into container now
2025-05-12 21:25:03,428:INFO:_master_model_container: 9
2025-05-12 21:25:03,428:INFO:_display_container: 2
2025-05-12 21:25:03,428:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 21:25:03,429:INFO:create_model() successfully completed......................................
2025-05-12 21:25:03,543:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:03,543:INFO:Creating metrics dataframe
2025-05-12 21:25:03,563:INFO:Initializing Huber Regressor
2025-05-12 21:25:03,563:INFO:Total runtime is 0.20488003889719647 minutes
2025-05-12 21:25:03,568:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:03,569:INFO:Initializing create_model()
2025-05-12 21:25:03,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:03,569:INFO:Checking exceptions
2025-05-12 21:25:03,569:INFO:Importing libraries
2025-05-12 21:25:03,569:INFO:Copying training dataset
2025-05-12 21:25:03,572:INFO:Defining folds
2025-05-12 21:25:03,573:INFO:Declaring metric variables
2025-05-12 21:25:03,577:INFO:Importing untrained model
2025-05-12 21:25:03,581:INFO:Huber Regressor Imported successfully
2025-05-12 21:25:03,592:INFO:Starting cross validation
2025-05-12 21:25:03,593:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:03,809:INFO:Calculating mean and std
2025-05-12 21:25:03,809:INFO:Creating metrics dataframe
2025-05-12 21:25:03,812:INFO:Uploading results into container
2025-05-12 21:25:03,813:INFO:Uploading model into container now
2025-05-12 21:25:03,814:INFO:_master_model_container: 10
2025-05-12 21:25:03,814:INFO:_display_container: 2
2025-05-12 21:25:03,814:INFO:HuberRegressor()
2025-05-12 21:25:03,814:INFO:create_model() successfully completed......................................
2025-05-12 21:25:03,883:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:03,883:INFO:Creating metrics dataframe
2025-05-12 21:25:03,892:INFO:Initializing K Neighbors Regressor
2025-05-12 21:25:03,892:INFO:Total runtime is 0.21035494804382326 minutes
2025-05-12 21:25:03,896:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:03,897:INFO:Initializing create_model()
2025-05-12 21:25:03,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:03,897:INFO:Checking exceptions
2025-05-12 21:25:03,898:INFO:Importing libraries
2025-05-12 21:25:03,898:INFO:Copying training dataset
2025-05-12 21:25:03,901:INFO:Defining folds
2025-05-12 21:25:03,902:INFO:Declaring metric variables
2025-05-12 21:25:03,904:INFO:Importing untrained model
2025-05-12 21:25:03,908:INFO:K Neighbors Regressor Imported successfully
2025-05-12 21:25:03,916:INFO:Starting cross validation
2025-05-12 21:25:03,917:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:04,142:INFO:Calculating mean and std
2025-05-12 21:25:04,144:INFO:Creating metrics dataframe
2025-05-12 21:25:04,146:INFO:Uploading results into container
2025-05-12 21:25:04,146:INFO:Uploading model into container now
2025-05-12 21:25:04,147:INFO:_master_model_container: 11
2025-05-12 21:25:04,147:INFO:_display_container: 2
2025-05-12 21:25:04,147:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 21:25:04,148:INFO:create_model() successfully completed......................................
2025-05-12 21:25:04,217:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:04,217:INFO:Creating metrics dataframe
2025-05-12 21:25:04,225:INFO:Initializing Decision Tree Regressor
2025-05-12 21:25:04,226:INFO:Total runtime is 0.21593229770660402 minutes
2025-05-12 21:25:04,229:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:04,229:INFO:Initializing create_model()
2025-05-12 21:25:04,229:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:04,229:INFO:Checking exceptions
2025-05-12 21:25:04,229:INFO:Importing libraries
2025-05-12 21:25:04,231:INFO:Copying training dataset
2025-05-12 21:25:04,235:INFO:Defining folds
2025-05-12 21:25:04,235:INFO:Declaring metric variables
2025-05-12 21:25:04,238:INFO:Importing untrained model
2025-05-12 21:25:04,241:INFO:Decision Tree Regressor Imported successfully
2025-05-12 21:25:04,248:INFO:Starting cross validation
2025-05-12 21:25:04,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:04,430:INFO:Calculating mean and std
2025-05-12 21:25:04,432:INFO:Creating metrics dataframe
2025-05-12 21:25:04,435:INFO:Uploading results into container
2025-05-12 21:25:04,436:INFO:Uploading model into container now
2025-05-12 21:25:04,436:INFO:_master_model_container: 12
2025-05-12 21:25:04,437:INFO:_display_container: 2
2025-05-12 21:25:04,437:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 21:25:04,437:INFO:create_model() successfully completed......................................
2025-05-12 21:25:04,508:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:04,508:INFO:Creating metrics dataframe
2025-05-12 21:25:04,519:INFO:Initializing Random Forest Regressor
2025-05-12 21:25:04,519:INFO:Total runtime is 0.22080289522806806 minutes
2025-05-12 21:25:04,523:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:04,523:INFO:Initializing create_model()
2025-05-12 21:25:04,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:04,523:INFO:Checking exceptions
2025-05-12 21:25:04,523:INFO:Importing libraries
2025-05-12 21:25:04,524:INFO:Copying training dataset
2025-05-12 21:25:04,527:INFO:Defining folds
2025-05-12 21:25:04,527:INFO:Declaring metric variables
2025-05-12 21:25:04,530:INFO:Importing untrained model
2025-05-12 21:25:04,535:INFO:Random Forest Regressor Imported successfully
2025-05-12 21:25:04,549:INFO:Starting cross validation
2025-05-12 21:25:04,551:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:05,409:INFO:Calculating mean and std
2025-05-12 21:25:05,409:INFO:Creating metrics dataframe
2025-05-12 21:25:05,411:INFO:Uploading results into container
2025-05-12 21:25:05,412:INFO:Uploading model into container now
2025-05-12 21:25:05,413:INFO:_master_model_container: 13
2025-05-12 21:25:05,413:INFO:_display_container: 2
2025-05-12 21:25:05,414:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:25:05,414:INFO:create_model() successfully completed......................................
2025-05-12 21:25:05,486:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:05,486:INFO:Creating metrics dataframe
2025-05-12 21:25:05,496:INFO:Initializing Extra Trees Regressor
2025-05-12 21:25:05,496:INFO:Total runtime is 0.2371017456054688 minutes
2025-05-12 21:25:05,501:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:05,502:INFO:Initializing create_model()
2025-05-12 21:25:05,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:05,502:INFO:Checking exceptions
2025-05-12 21:25:05,502:INFO:Importing libraries
2025-05-12 21:25:05,502:INFO:Copying training dataset
2025-05-12 21:25:05,506:INFO:Defining folds
2025-05-12 21:25:05,506:INFO:Declaring metric variables
2025-05-12 21:25:05,509:INFO:Importing untrained model
2025-05-12 21:25:05,513:INFO:Extra Trees Regressor Imported successfully
2025-05-12 21:25:05,521:INFO:Starting cross validation
2025-05-12 21:25:05,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:06,141:INFO:Calculating mean and std
2025-05-12 21:25:06,141:INFO:Creating metrics dataframe
2025-05-12 21:25:06,144:INFO:Uploading results into container
2025-05-12 21:25:06,145:INFO:Uploading model into container now
2025-05-12 21:25:06,146:INFO:_master_model_container: 14
2025-05-12 21:25:06,146:INFO:_display_container: 2
2025-05-12 21:25:06,147:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:25:06,147:INFO:create_model() successfully completed......................................
2025-05-12 21:25:06,218:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:06,218:INFO:Creating metrics dataframe
2025-05-12 21:25:06,228:INFO:Initializing AdaBoost Regressor
2025-05-12 21:25:06,228:INFO:Total runtime is 0.24929802417755131 minutes
2025-05-12 21:25:06,232:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:06,232:INFO:Initializing create_model()
2025-05-12 21:25:06,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:06,232:INFO:Checking exceptions
2025-05-12 21:25:06,232:INFO:Importing libraries
2025-05-12 21:25:06,233:INFO:Copying training dataset
2025-05-12 21:25:06,236:INFO:Defining folds
2025-05-12 21:25:06,236:INFO:Declaring metric variables
2025-05-12 21:25:06,239:INFO:Importing untrained model
2025-05-12 21:25:06,243:INFO:AdaBoost Regressor Imported successfully
2025-05-12 21:25:06,253:INFO:Starting cross validation
2025-05-12 21:25:06,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:06,685:INFO:Calculating mean and std
2025-05-12 21:25:06,686:INFO:Creating metrics dataframe
2025-05-12 21:25:06,689:INFO:Uploading results into container
2025-05-12 21:25:06,689:INFO:Uploading model into container now
2025-05-12 21:25:06,691:INFO:_master_model_container: 15
2025-05-12 21:25:06,691:INFO:_display_container: 2
2025-05-12 21:25:06,692:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 21:25:06,692:INFO:create_model() successfully completed......................................
2025-05-12 21:25:06,767:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:06,767:INFO:Creating metrics dataframe
2025-05-12 21:25:06,778:INFO:Initializing Gradient Boosting Regressor
2025-05-12 21:25:06,778:INFO:Total runtime is 0.2584522485733033 minutes
2025-05-12 21:25:06,782:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:06,782:INFO:Initializing create_model()
2025-05-12 21:25:06,782:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:06,782:INFO:Checking exceptions
2025-05-12 21:25:06,782:INFO:Importing libraries
2025-05-12 21:25:06,782:INFO:Copying training dataset
2025-05-12 21:25:06,787:INFO:Defining folds
2025-05-12 21:25:06,787:INFO:Declaring metric variables
2025-05-12 21:25:06,789:INFO:Importing untrained model
2025-05-12 21:25:06,795:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 21:25:06,805:INFO:Starting cross validation
2025-05-12 21:25:06,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:07,153:INFO:Calculating mean and std
2025-05-12 21:25:07,155:INFO:Creating metrics dataframe
2025-05-12 21:25:07,156:INFO:Uploading results into container
2025-05-12 21:25:07,157:INFO:Uploading model into container now
2025-05-12 21:25:07,157:INFO:_master_model_container: 16
2025-05-12 21:25:07,157:INFO:_display_container: 2
2025-05-12 21:25:07,158:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 21:25:07,158:INFO:create_model() successfully completed......................................
2025-05-12 21:25:07,228:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:07,228:INFO:Creating metrics dataframe
2025-05-12 21:25:07,239:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 21:25:07,239:INFO:Total runtime is 0.2661504745483399 minutes
2025-05-12 21:25:07,242:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:07,242:INFO:Initializing create_model()
2025-05-12 21:25:07,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:07,242:INFO:Checking exceptions
2025-05-12 21:25:07,242:INFO:Importing libraries
2025-05-12 21:25:07,243:INFO:Copying training dataset
2025-05-12 21:25:07,248:INFO:Defining folds
2025-05-12 21:25:07,248:INFO:Declaring metric variables
2025-05-12 21:25:07,250:INFO:Importing untrained model
2025-05-12 21:25:07,254:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 21:25:07,262:INFO:Starting cross validation
2025-05-12 21:25:07,265:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:07,776:INFO:Calculating mean and std
2025-05-12 21:25:07,776:INFO:Creating metrics dataframe
2025-05-12 21:25:07,781:INFO:Uploading results into container
2025-05-12 21:25:07,782:INFO:Uploading model into container now
2025-05-12 21:25:07,783:INFO:_master_model_container: 17
2025-05-12 21:25:07,783:INFO:_display_container: 2
2025-05-12 21:25:07,785:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:25:07,785:INFO:create_model() successfully completed......................................
2025-05-12 21:25:07,885:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:07,885:INFO:Creating metrics dataframe
2025-05-12 21:25:07,897:INFO:Initializing Dummy Regressor
2025-05-12 21:25:07,897:INFO:Total runtime is 0.2771038134892782 minutes
2025-05-12 21:25:07,901:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:07,901:INFO:Initializing create_model()
2025-05-12 21:25:07,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:07,902:INFO:Checking exceptions
2025-05-12 21:25:07,902:INFO:Importing libraries
2025-05-12 21:25:07,902:INFO:Copying training dataset
2025-05-12 21:25:07,906:INFO:Defining folds
2025-05-12 21:25:07,906:INFO:Declaring metric variables
2025-05-12 21:25:07,910:INFO:Importing untrained model
2025-05-12 21:25:07,915:INFO:Dummy Regressor Imported successfully
2025-05-12 21:25:07,925:INFO:Starting cross validation
2025-05-12 21:25:07,928:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:08,119:INFO:Calculating mean and std
2025-05-12 21:25:08,120:INFO:Creating metrics dataframe
2025-05-12 21:25:08,122:INFO:Uploading results into container
2025-05-12 21:25:08,123:INFO:Uploading model into container now
2025-05-12 21:25:08,123:INFO:_master_model_container: 18
2025-05-12 21:25:08,124:INFO:_display_container: 2
2025-05-12 21:25:08,124:INFO:DummyRegressor()
2025-05-12 21:25:08,124:INFO:create_model() successfully completed......................................
2025-05-12 21:25:08,198:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:08,199:INFO:Creating metrics dataframe
2025-05-12 21:25:08,210:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 21:25:08,220:INFO:Initializing create_model()
2025-05-12 21:25:08,220:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:08,220:INFO:Checking exceptions
2025-05-12 21:25:08,222:INFO:Importing libraries
2025-05-12 21:25:08,222:INFO:Copying training dataset
2025-05-12 21:25:08,225:INFO:Defining folds
2025-05-12 21:25:08,225:INFO:Declaring metric variables
2025-05-12 21:25:08,225:INFO:Importing untrained model
2025-05-12 21:25:08,226:INFO:Declaring custom model
2025-05-12 21:25:08,226:INFO:Linear Regression Imported successfully
2025-05-12 21:25:08,227:INFO:Cross validation set to False
2025-05-12 21:25:08,227:INFO:Fitting Model
2025-05-12 21:25:08,255:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:25:08,255:INFO:create_model() successfully completed......................................
2025-05-12 21:25:08,350:INFO:_master_model_container: 18
2025-05-12 21:25:08,350:INFO:_display_container: 2
2025-05-12 21:25:08,351:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:25:08,351:INFO:compare_models() successfully completed......................................
2025-05-12 21:25:08,379:INFO:Initializing create_model()
2025-05-12 21:25:08,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:08,380:INFO:Checking exceptions
2025-05-12 21:25:08,398:INFO:Importing libraries
2025-05-12 21:25:08,398:INFO:Copying training dataset
2025-05-12 21:25:08,404:INFO:Defining folds
2025-05-12 21:25:08,404:INFO:Declaring metric variables
2025-05-12 21:25:08,408:INFO:Importing untrained model
2025-05-12 21:25:08,412:INFO:Linear Regression Imported successfully
2025-05-12 21:25:08,422:INFO:Starting cross validation
2025-05-12 21:25:08,423:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:08,622:INFO:Calculating mean and std
2025-05-12 21:25:08,623:INFO:Creating metrics dataframe
2025-05-12 21:25:08,628:INFO:Finalizing model
2025-05-12 21:25:08,668:INFO:Uploading results into container
2025-05-12 21:25:08,669:INFO:Uploading model into container now
2025-05-12 21:25:08,680:INFO:_master_model_container: 19
2025-05-12 21:25:08,680:INFO:_display_container: 3
2025-05-12 21:25:08,681:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:25:08,681:INFO:create_model() successfully completed......................................
2025-05-12 21:40:17,014:INFO:Initializing tune_model()
2025-05-12 21:40:17,015:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 21:40:17,015:INFO:Checking exceptions
2025-05-12 21:40:17,033:INFO:Copying training dataset
2025-05-12 21:40:17,037:INFO:Checking base model
2025-05-12 21:40:17,037:INFO:Base model : Linear Regression
2025-05-12 21:40:17,042:INFO:Declaring metric variables
2025-05-12 21:40:17,045:INFO:Defining Hyperparameters
2025-05-12 21:40:17,045:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-05-12 21:40:17,133:INFO:Tuning with n_jobs=-1
2025-05-12 21:40:17,133:INFO:Initializing GridSearchCV
2025-05-12 21:40:28,451:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-05-12 21:40:28,453:INFO:Hyperparameter search completed
2025-05-12 21:40:28,453:INFO:SubProcess create_model() called ==================================
2025-05-12 21:40:28,455:INFO:Initializing create_model()
2025-05-12 21:40:28,455:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FA59B850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True})
2025-05-12 21:40:28,456:INFO:Checking exceptions
2025-05-12 21:40:28,456:INFO:Importing libraries
2025-05-12 21:40:28,456:INFO:Copying training dataset
2025-05-12 21:40:28,462:INFO:Defining folds
2025-05-12 21:40:28,462:INFO:Declaring metric variables
2025-05-12 21:40:28,466:INFO:Importing untrained model
2025-05-12 21:40:28,466:INFO:Declaring custom model
2025-05-12 21:40:28,472:INFO:Linear Regression Imported successfully
2025-05-12 21:40:28,485:INFO:Starting cross validation
2025-05-12 21:40:28,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:40:28,888:INFO:Calculating mean and std
2025-05-12 21:40:28,890:INFO:Creating metrics dataframe
2025-05-12 21:40:28,903:INFO:Finalizing model
2025-05-12 21:40:28,990:INFO:Uploading results into container
2025-05-12 21:40:28,992:INFO:Uploading model into container now
2025-05-12 21:40:28,993:INFO:_master_model_container: 20
2025-05-12 21:40:28,993:INFO:_display_container: 4
2025-05-12 21:40:28,994:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:40:28,994:INFO:create_model() successfully completed......................................
2025-05-12 21:40:29,128:INFO:SubProcess create_model() end ==================================
2025-05-12 21:40:29,128:INFO:choose_better activated
2025-05-12 21:40:29,135:INFO:SubProcess create_model() called ==================================
2025-05-12 21:40:29,136:INFO:Initializing create_model()
2025-05-12 21:40:29,136:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:40:29,136:INFO:Checking exceptions
2025-05-12 21:40:29,141:INFO:Importing libraries
2025-05-12 21:40:29,141:INFO:Copying training dataset
2025-05-12 21:40:29,146:INFO:Defining folds
2025-05-12 21:40:29,148:INFO:Declaring metric variables
2025-05-12 21:40:29,148:INFO:Importing untrained model
2025-05-12 21:40:29,148:INFO:Declaring custom model
2025-05-12 21:40:29,148:INFO:Linear Regression Imported successfully
2025-05-12 21:40:29,149:INFO:Starting cross validation
2025-05-12 21:40:29,151:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:40:29,432:INFO:Calculating mean and std
2025-05-12 21:40:29,432:INFO:Creating metrics dataframe
2025-05-12 21:40:29,435:INFO:Finalizing model
2025-05-12 21:40:29,502:INFO:Uploading results into container
2025-05-12 21:40:29,502:INFO:Uploading model into container now
2025-05-12 21:40:29,503:INFO:_master_model_container: 21
2025-05-12 21:40:29,503:INFO:_display_container: 5
2025-05-12 21:40:29,504:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:40:29,504:INFO:create_model() successfully completed......................................
2025-05-12 21:40:29,618:INFO:SubProcess create_model() end ==================================
2025-05-12 21:40:29,620:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9592
2025-05-12 21:40:29,620:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9592
2025-05-12 21:40:29,620:INFO:LinearRegression(n_jobs=-1) is best model
2025-05-12 21:40:29,621:INFO:choose_better completed
2025-05-12 21:40:29,621:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 21:40:29,638:INFO:_master_model_container: 21
2025-05-12 21:40:29,638:INFO:_display_container: 4
2025-05-12 21:40:29,640:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:40:29,640:INFO:tune_model() successfully completed......................................
2025-05-12 21:42:56,784:INFO:Initializing evaluate_model()
2025-05-12 21:42:56,784:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 21:42:56,792:INFO:Initializing plot_model()
2025-05-12 21:42:56,792:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 21:42:56,792:INFO:Checking exceptions
2025-05-12 21:42:56,795:INFO:Preloading libraries
2025-05-12 21:42:56,795:INFO:Copying training dataset
2025-05-12 21:42:56,795:INFO:Plot type: pipeline
2025-05-12 21:42:57,042:INFO:Visual Rendered Successfully
2025-05-12 21:42:57,117:INFO:plot_model() successfully completed......................................
2025-05-12 21:43:20,345:INFO:Initializing evaluate_model()
2025-05-12 21:43:20,345:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 21:43:20,354:INFO:Initializing plot_model()
2025-05-12 21:43:20,355:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 21:43:20,355:INFO:Checking exceptions
2025-05-12 21:43:20,356:INFO:Preloading libraries
2025-05-12 21:43:20,356:INFO:Copying training dataset
2025-05-12 21:43:20,358:INFO:Plot type: pipeline
2025-05-12 21:43:20,498:INFO:Visual Rendered Successfully
2025-05-12 21:43:20,576:INFO:plot_model() successfully completed......................................
2025-05-12 21:46:03,300:INFO:Initializing predict_model()
2025-05-12 21:46:03,301:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000180FAA37CE0>)
2025-05-12 21:46:03,301:INFO:Checking exceptions
2025-05-12 21:46:03,301:INFO:Preloading libraries
2025-05-12 21:46:03,388:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 21:49:11,672:INFO:Initializing predict_model()
2025-05-12 21:49:11,672:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000180FABE40E0>)
2025-05-12 21:49:11,672:INFO:Checking exceptions
2025-05-12 21:49:11,672:INFO:Preloading libraries
2025-05-12 21:49:11,750:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 21:58:43,369:INFO:PyCaret RegressionExperiment
2025-05-12 21:58:43,369:INFO:Logging name: reg-default-name
2025-05-12 21:58:43,369:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 21:58:43,369:INFO:version 3.3.2
2025-05-12 21:58:43,370:INFO:Initializing setup()
2025-05-12 21:58:43,370:INFO:self.USI: ae80
2025-05-12 21:58:43,370:INFO:self._variable_keys: {'exp_id', 'transform_target_param', 'X_test', 'X_train', 'y_train', 'memory', 'log_plots_param', 'X', 'y', 'target_param', 'gpu_param', 'html_param', 'exp_name_log', 'USI', 'data', 'pipeline', 'y_test', '_ml_usecase', 'seed', '_available_plots', 'fold_groups_param', 'idx', 'fold_shuffle_param', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'logging_param'}
2025-05-12 21:58:43,370:INFO:Checking environment
2025-05-12 21:58:43,370:INFO:python_version: 3.11.8
2025-05-12 21:58:43,370:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 21:58:43,370:INFO:machine: AMD64
2025-05-12 21:58:43,370:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 21:58:43,384:INFO:Memory: svmem(total=16907886592, available=4335013888, percent=74.4, used=12572872704, free=4335013888)
2025-05-12 21:58:43,385:INFO:Physical Core: 4
2025-05-12 21:58:43,385:INFO:Logical Core: 8
2025-05-12 21:58:43,385:INFO:Checking libraries
2025-05-12 21:58:43,385:INFO:System:
2025-05-12 21:58:43,385:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 21:58:43,385:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 21:58:43,385:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 21:58:43,385:INFO:PyCaret required dependencies:
2025-05-12 21:58:43,385:INFO:                 pip: 24.0
2025-05-12 21:58:43,385:INFO:          setuptools: 65.5.0
2025-05-12 21:58:43,386:INFO:             pycaret: 3.3.2
2025-05-12 21:58:43,386:INFO:             IPython: 9.2.0
2025-05-12 21:58:43,386:INFO:          ipywidgets: 8.1.7
2025-05-12 21:58:43,386:INFO:                tqdm: 4.67.1
2025-05-12 21:58:43,386:INFO:               numpy: 1.26.4
2025-05-12 21:58:43,386:INFO:              pandas: 2.1.4
2025-05-12 21:58:43,386:INFO:              jinja2: 3.1.6
2025-05-12 21:58:43,386:INFO:               scipy: 1.11.4
2025-05-12 21:58:43,386:INFO:              joblib: 1.3.2
2025-05-12 21:58:43,386:INFO:             sklearn: 1.4.2
2025-05-12 21:58:43,386:INFO:                pyod: 2.0.5
2025-05-12 21:58:43,386:INFO:            imblearn: 0.13.0
2025-05-12 21:58:43,386:INFO:   category_encoders: 2.7.0
2025-05-12 21:58:43,386:INFO:            lightgbm: 4.6.0
2025-05-12 21:58:43,386:INFO:               numba: 0.61.2
2025-05-12 21:58:43,386:INFO:            requests: 2.32.3
2025-05-12 21:58:43,387:INFO:          matplotlib: 3.7.5
2025-05-12 21:58:43,387:INFO:          scikitplot: 0.3.7
2025-05-12 21:58:43,387:INFO:         yellowbrick: 1.5
2025-05-12 21:58:43,387:INFO:              plotly: 5.24.1
2025-05-12 21:58:43,387:INFO:    plotly-resampler: Not installed
2025-05-12 21:58:43,388:INFO:             kaleido: 0.2.1
2025-05-12 21:58:43,388:INFO:           schemdraw: 0.15
2025-05-12 21:58:43,388:INFO:         statsmodels: 0.14.4
2025-05-12 21:58:43,388:INFO:              sktime: 0.26.0
2025-05-12 21:58:43,388:INFO:               tbats: 1.1.3
2025-05-12 21:58:43,388:INFO:            pmdarima: 2.0.4
2025-05-12 21:58:43,388:INFO:              psutil: 7.0.0
2025-05-12 21:58:43,389:INFO:          markupsafe: 3.0.2
2025-05-12 21:58:43,389:INFO:             pickle5: Not installed
2025-05-12 21:58:43,389:INFO:         cloudpickle: 3.1.1
2025-05-12 21:58:43,389:INFO:         deprecation: 2.1.0
2025-05-12 21:58:43,389:INFO:              xxhash: 3.5.0
2025-05-12 21:58:43,389:INFO:           wurlitzer: Not installed
2025-05-12 21:58:43,390:INFO:PyCaret optional dependencies:
2025-05-12 21:58:43,390:INFO:                shap: Not installed
2025-05-12 21:58:43,390:INFO:           interpret: Not installed
2025-05-12 21:58:43,390:INFO:                umap: Not installed
2025-05-12 21:58:43,390:INFO:     ydata_profiling: Not installed
2025-05-12 21:58:43,390:INFO:  explainerdashboard: Not installed
2025-05-12 21:58:43,391:INFO:             autoviz: Not installed
2025-05-12 21:58:43,391:INFO:           fairlearn: Not installed
2025-05-12 21:58:43,391:INFO:          deepchecks: Not installed
2025-05-12 21:58:43,391:INFO:             xgboost: Not installed
2025-05-12 21:58:43,391:INFO:            catboost: Not installed
2025-05-12 21:58:43,391:INFO:              kmodes: Not installed
2025-05-12 21:58:43,391:INFO:             mlxtend: Not installed
2025-05-12 21:58:43,391:INFO:       statsforecast: Not installed
2025-05-12 21:58:43,391:INFO:        tune_sklearn: Not installed
2025-05-12 21:58:43,391:INFO:                 ray: Not installed
2025-05-12 21:58:43,391:INFO:            hyperopt: Not installed
2025-05-12 21:58:43,392:INFO:              optuna: Not installed
2025-05-12 21:58:43,392:INFO:               skopt: Not installed
2025-05-12 21:58:43,392:INFO:              mlflow: Not installed
2025-05-12 21:58:43,392:INFO:              gradio: Not installed
2025-05-12 21:58:43,392:INFO:             fastapi: Not installed
2025-05-12 21:58:43,392:INFO:             uvicorn: Not installed
2025-05-12 21:58:43,392:INFO:              m2cgen: Not installed
2025-05-12 21:58:43,392:INFO:           evidently: Not installed
2025-05-12 21:58:43,392:INFO:               fugue: Not installed
2025-05-12 21:58:43,392:INFO:           streamlit: Not installed
2025-05-12 21:58:43,392:INFO:             prophet: Not installed
2025-05-12 21:58:43,392:INFO:None
2025-05-12 21:58:43,393:INFO:Set up data.
2025-05-12 21:58:43,400:INFO:Set up folding strategy.
2025-05-12 21:58:43,400:INFO:Set up train/test split.
2025-05-12 21:58:43,404:INFO:Set up index.
2025-05-12 21:58:43,406:INFO:Assigning column types.
2025-05-12 21:58:43,410:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 21:58:43,411:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,419:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,427:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,486:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,531:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,534:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,540:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,544:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,597:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,641:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 21:58:43,645:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,649:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,744:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,745:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,749:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,752:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,809:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,850:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,850:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,850:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,851:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 21:58:43,859:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,922:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,962:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,971:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,075:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,076:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,077:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 21:58:44,147:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,198:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,198:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,283:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,338:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,339:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 21:58:44,431:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,499:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,500:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,589:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,674:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,674:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 21:58:44,866:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:45,076:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:45,076:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:45,077:INFO:Preparing preprocessing pipeline...
2025-05-12 21:58:45,078:INFO:Set up simple imputation.
2025-05-12 21:58:45,079:INFO:Set up encoding of categorical features.
2025-05-12 21:58:45,081:INFO:Set up feature normalization.
2025-05-12 21:58:45,163:INFO:Finished creating preprocessing pipeline.
2025-05-12 21:58:45,176:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 21:58:45,176:INFO:Creating final display dataframe.
2025-05-12 21:58:45,447:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            precio
2                   Target type        Regression
3           Original data shape          (100, 7)
4        Transformed data shape         (100, 10)
5   Transformed train set shape          (70, 10)
6    Transformed test set shape          (30, 10)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              ae80
2025-05-12 21:58:45,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:45,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:45,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:45,843:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:45,844:INFO:setup() successfully completed in 2.48s...............
2025-05-12 21:58:45,853:INFO:Initializing compare_models()
2025-05-12 21:58:45,853:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA902250>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000180FA902250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 21:58:45,854:INFO:Checking exceptions
2025-05-12 21:58:45,858:INFO:Preparing display monitor
2025-05-12 21:58:45,889:INFO:Initializing Linear Regression
2025-05-12 21:58:45,890:INFO:Total runtime is 1.7495950063069663e-05 minutes
2025-05-12 21:58:45,895:INFO:SubProcess create_model() called ==================================
2025-05-12 21:58:45,896:INFO:Initializing create_model()
2025-05-12 21:58:45,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA902250>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FE375690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:58:45,896:INFO:Checking exceptions
2025-05-12 21:58:45,896:INFO:Importing libraries
2025-05-12 21:58:45,896:INFO:Copying training dataset
2025-05-12 21:58:45,901:INFO:Defining folds
2025-05-12 21:58:45,902:INFO:Declaring metric variables
2025-05-12 21:58:45,907:INFO:Importing untrained model
2025-05-12 21:58:45,913:INFO:Linear Regression Imported successfully
2025-05-12 21:58:45,924:INFO:Starting cross validation
2025-05-12 21:58:45,927:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:07,488:INFO:PyCaret RegressionExperiment
2025-05-12 21:59:07,488:INFO:Logging name: reg-default-name
2025-05-12 21:59:07,488:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 21:59:07,489:INFO:version 3.3.2
2025-05-12 21:59:07,489:INFO:Initializing setup()
2025-05-12 21:59:07,489:INFO:self.USI: 192c
2025-05-12 21:59:07,489:INFO:self._variable_keys: {'exp_id', 'transform_target_param', 'X_test', 'X_train', 'y_train', 'memory', 'log_plots_param', 'X', 'y', 'target_param', 'gpu_param', 'html_param', 'exp_name_log', 'USI', 'data', 'pipeline', 'y_test', '_ml_usecase', 'seed', '_available_plots', 'fold_groups_param', 'idx', 'fold_shuffle_param', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'logging_param'}
2025-05-12 21:59:07,489:INFO:Checking environment
2025-05-12 21:59:07,489:INFO:python_version: 3.11.8
2025-05-12 21:59:07,489:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 21:59:07,489:INFO:machine: AMD64
2025-05-12 21:59:07,490:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 21:59:07,496:INFO:Memory: svmem(total=16907886592, available=4224679936, percent=75.0, used=12683206656, free=4224679936)
2025-05-12 21:59:07,496:INFO:Physical Core: 4
2025-05-12 21:59:07,496:INFO:Logical Core: 8
2025-05-12 21:59:07,497:INFO:Checking libraries
2025-05-12 21:59:07,497:INFO:System:
2025-05-12 21:59:07,497:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 21:59:07,497:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 21:59:07,497:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 21:59:07,497:INFO:PyCaret required dependencies:
2025-05-12 21:59:07,497:INFO:                 pip: 24.0
2025-05-12 21:59:07,497:INFO:          setuptools: 65.5.0
2025-05-12 21:59:07,497:INFO:             pycaret: 3.3.2
2025-05-12 21:59:07,497:INFO:             IPython: 9.2.0
2025-05-12 21:59:07,497:INFO:          ipywidgets: 8.1.7
2025-05-12 21:59:07,498:INFO:                tqdm: 4.67.1
2025-05-12 21:59:07,498:INFO:               numpy: 1.26.4
2025-05-12 21:59:07,498:INFO:              pandas: 2.1.4
2025-05-12 21:59:07,498:INFO:              jinja2: 3.1.6
2025-05-12 21:59:07,498:INFO:               scipy: 1.11.4
2025-05-12 21:59:07,498:INFO:              joblib: 1.3.2
2025-05-12 21:59:07,498:INFO:             sklearn: 1.4.2
2025-05-12 21:59:07,498:INFO:                pyod: 2.0.5
2025-05-12 21:59:07,498:INFO:            imblearn: 0.13.0
2025-05-12 21:59:07,498:INFO:   category_encoders: 2.7.0
2025-05-12 21:59:07,498:INFO:            lightgbm: 4.6.0
2025-05-12 21:59:07,498:INFO:               numba: 0.61.2
2025-05-12 21:59:07,498:INFO:            requests: 2.32.3
2025-05-12 21:59:07,498:INFO:          matplotlib: 3.7.5
2025-05-12 21:59:07,499:INFO:          scikitplot: 0.3.7
2025-05-12 21:59:07,499:INFO:         yellowbrick: 1.5
2025-05-12 21:59:07,499:INFO:              plotly: 5.24.1
2025-05-12 21:59:07,499:INFO:    plotly-resampler: Not installed
2025-05-12 21:59:07,499:INFO:             kaleido: 0.2.1
2025-05-12 21:59:07,499:INFO:           schemdraw: 0.15
2025-05-12 21:59:07,499:INFO:         statsmodels: 0.14.4
2025-05-12 21:59:07,499:INFO:              sktime: 0.26.0
2025-05-12 21:59:07,499:INFO:               tbats: 1.1.3
2025-05-12 21:59:07,499:INFO:            pmdarima: 2.0.4
2025-05-12 21:59:07,500:INFO:              psutil: 7.0.0
2025-05-12 21:59:07,500:INFO:          markupsafe: 3.0.2
2025-05-12 21:59:07,500:INFO:             pickle5: Not installed
2025-05-12 21:59:07,500:INFO:         cloudpickle: 3.1.1
2025-05-12 21:59:07,500:INFO:         deprecation: 2.1.0
2025-05-12 21:59:07,500:INFO:              xxhash: 3.5.0
2025-05-12 21:59:07,500:INFO:           wurlitzer: Not installed
2025-05-12 21:59:07,500:INFO:PyCaret optional dependencies:
2025-05-12 21:59:07,500:INFO:                shap: Not installed
2025-05-12 21:59:07,500:INFO:           interpret: Not installed
2025-05-12 21:59:07,500:INFO:                umap: Not installed
2025-05-12 21:59:07,500:INFO:     ydata_profiling: Not installed
2025-05-12 21:59:07,501:INFO:  explainerdashboard: Not installed
2025-05-12 21:59:07,501:INFO:             autoviz: Not installed
2025-05-12 21:59:07,501:INFO:           fairlearn: Not installed
2025-05-12 21:59:07,501:INFO:          deepchecks: Not installed
2025-05-12 21:59:07,501:INFO:             xgboost: Not installed
2025-05-12 21:59:07,501:INFO:            catboost: Not installed
2025-05-12 21:59:07,501:INFO:              kmodes: Not installed
2025-05-12 21:59:07,501:INFO:             mlxtend: Not installed
2025-05-12 21:59:07,501:INFO:       statsforecast: Not installed
2025-05-12 21:59:07,501:INFO:        tune_sklearn: Not installed
2025-05-12 21:59:07,501:INFO:                 ray: Not installed
2025-05-12 21:59:07,501:INFO:            hyperopt: Not installed
2025-05-12 21:59:07,501:INFO:              optuna: Not installed
2025-05-12 21:59:07,501:INFO:               skopt: Not installed
2025-05-12 21:59:07,501:INFO:              mlflow: Not installed
2025-05-12 21:59:07,501:INFO:              gradio: Not installed
2025-05-12 21:59:07,501:INFO:             fastapi: Not installed
2025-05-12 21:59:07,501:INFO:             uvicorn: Not installed
2025-05-12 21:59:07,503:INFO:              m2cgen: Not installed
2025-05-12 21:59:07,503:INFO:           evidently: Not installed
2025-05-12 21:59:07,503:INFO:               fugue: Not installed
2025-05-12 21:59:07,503:INFO:           streamlit: Not installed
2025-05-12 21:59:07,503:INFO:             prophet: Not installed
2025-05-12 21:59:07,503:INFO:None
2025-05-12 21:59:07,503:INFO:Set up data.
2025-05-12 21:59:07,509:INFO:Set up folding strategy.
2025-05-12 21:59:07,509:INFO:Set up train/test split.
2025-05-12 21:59:07,515:INFO:Set up index.
2025-05-12 21:59:07,516:INFO:Assigning column types.
2025-05-12 21:59:07,521:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 21:59:07,521:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:59:07,532:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:59:07,545:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:59:07,737:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:07,856:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:07,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:07,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:07,858:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:59:07,869:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:59:07,878:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,137:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,138:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,139:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 21:59:08,144:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,151:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,227:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,293:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,293:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,302:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,308:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,392:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,454:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,455:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 21:59:08,469:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,555:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,626:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,627:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,642:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,747:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,818:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 21:59:08,922:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,982:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,982:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,063:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:09,112:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:09,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,113:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 21:59:09,187:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:09,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,297:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:09,342:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,342:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 21:59:09,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,589:INFO:Preparing preprocessing pipeline...
2025-05-12 21:59:09,589:INFO:Set up simple imputation.
2025-05-12 21:59:09,591:INFO:Set up encoding of categorical features.
2025-05-12 21:59:09,591:INFO:Set up feature normalization.
2025-05-12 21:59:09,647:INFO:Finished creating preprocessing pipeline.
2025-05-12 21:59:09,657:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 21:59:09,657:INFO:Creating final display dataframe.
2025-05-12 21:59:09,836:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            precio
2                   Target type        Regression
3           Original data shape          (100, 7)
4        Transformed data shape         (100, 10)
5   Transformed train set shape          (70, 10)
6    Transformed test set shape          (30, 10)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              192c
2025-05-12 21:59:09,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:10,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:10,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:10,126:INFO:setup() successfully completed in 2.64s...............
2025-05-12 21:59:10,137:INFO:Initializing compare_models()
2025-05-12 21:59:10,137:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 21:59:10,137:INFO:Checking exceptions
2025-05-12 21:59:10,141:INFO:Preparing display monitor
2025-05-12 21:59:10,176:INFO:Initializing Linear Regression
2025-05-12 21:59:10,176:INFO:Total runtime is 0.0 minutes
2025-05-12 21:59:10,184:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:10,185:INFO:Initializing create_model()
2025-05-12 21:59:10,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:10,185:INFO:Checking exceptions
2025-05-12 21:59:10,185:INFO:Importing libraries
2025-05-12 21:59:10,185:INFO:Copying training dataset
2025-05-12 21:59:10,190:INFO:Defining folds
2025-05-12 21:59:10,190:INFO:Declaring metric variables
2025-05-12 21:59:10,196:INFO:Importing untrained model
2025-05-12 21:59:10,201:INFO:Linear Regression Imported successfully
2025-05-12 21:59:10,211:INFO:Starting cross validation
2025-05-12 21:59:10,214:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:37,276:INFO:Calculating mean and std
2025-05-12 21:59:37,278:INFO:Creating metrics dataframe
2025-05-12 21:59:37,282:INFO:Uploading results into container
2025-05-12 21:59:37,283:INFO:Uploading model into container now
2025-05-12 21:59:37,284:INFO:_master_model_container: 1
2025-05-12 21:59:37,284:INFO:_display_container: 2
2025-05-12 21:59:37,285:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:59:37,285:INFO:create_model() successfully completed......................................
2025-05-12 21:59:37,428:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:37,428:INFO:Creating metrics dataframe
2025-05-12 21:59:37,436:INFO:Initializing Lasso Regression
2025-05-12 21:59:37,437:INFO:Total runtime is 0.45435139338175456 minutes
2025-05-12 21:59:37,443:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:37,444:INFO:Initializing create_model()
2025-05-12 21:59:37,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:37,444:INFO:Checking exceptions
2025-05-12 21:59:37,445:INFO:Importing libraries
2025-05-12 21:59:37,445:INFO:Copying training dataset
2025-05-12 21:59:37,450:INFO:Defining folds
2025-05-12 21:59:37,451:INFO:Declaring metric variables
2025-05-12 21:59:37,459:INFO:Importing untrained model
2025-05-12 21:59:37,466:INFO:Lasso Regression Imported successfully
2025-05-12 21:59:37,479:INFO:Starting cross validation
2025-05-12 21:59:37,482:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:37,767:INFO:Calculating mean and std
2025-05-12 21:59:37,771:INFO:Creating metrics dataframe
2025-05-12 21:59:37,773:INFO:Uploading results into container
2025-05-12 21:59:37,774:INFO:Uploading model into container now
2025-05-12 21:59:37,774:INFO:_master_model_container: 2
2025-05-12 21:59:37,776:INFO:_display_container: 2
2025-05-12 21:59:37,776:INFO:Lasso(random_state=123)
2025-05-12 21:59:37,777:INFO:create_model() successfully completed......................................
2025-05-12 21:59:37,921:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:37,921:INFO:Creating metrics dataframe
2025-05-12 21:59:37,931:INFO:Initializing Ridge Regression
2025-05-12 21:59:37,932:INFO:Total runtime is 0.46260168552398684 minutes
2025-05-12 21:59:37,938:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:37,938:INFO:Initializing create_model()
2025-05-12 21:59:37,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:37,938:INFO:Checking exceptions
2025-05-12 21:59:37,938:INFO:Importing libraries
2025-05-12 21:59:37,938:INFO:Copying training dataset
2025-05-12 21:59:37,947:INFO:Defining folds
2025-05-12 21:59:37,947:INFO:Declaring metric variables
2025-05-12 21:59:37,954:INFO:Importing untrained model
2025-05-12 21:59:37,961:INFO:Ridge Regression Imported successfully
2025-05-12 21:59:37,973:INFO:Starting cross validation
2025-05-12 21:59:37,976:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:38,236:INFO:Calculating mean and std
2025-05-12 21:59:38,237:INFO:Creating metrics dataframe
2025-05-12 21:59:38,241:INFO:Uploading results into container
2025-05-12 21:59:38,242:INFO:Uploading model into container now
2025-05-12 21:59:38,242:INFO:_master_model_container: 3
2025-05-12 21:59:38,242:INFO:_display_container: 2
2025-05-12 21:59:38,243:INFO:Ridge(random_state=123)
2025-05-12 21:59:38,244:INFO:create_model() successfully completed......................................
2025-05-12 21:59:38,373:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:38,373:INFO:Creating metrics dataframe
2025-05-12 21:59:38,382:INFO:Initializing Elastic Net
2025-05-12 21:59:38,382:INFO:Total runtime is 0.47009887297948205 minutes
2025-05-12 21:59:38,388:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:38,389:INFO:Initializing create_model()
2025-05-12 21:59:38,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:38,389:INFO:Checking exceptions
2025-05-12 21:59:38,389:INFO:Importing libraries
2025-05-12 21:59:38,389:INFO:Copying training dataset
2025-05-12 21:59:38,396:INFO:Defining folds
2025-05-12 21:59:38,396:INFO:Declaring metric variables
2025-05-12 21:59:38,401:INFO:Importing untrained model
2025-05-12 21:59:38,409:INFO:Elastic Net Imported successfully
2025-05-12 21:59:38,422:INFO:Starting cross validation
2025-05-12 21:59:38,423:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:38,663:INFO:Calculating mean and std
2025-05-12 21:59:38,665:INFO:Creating metrics dataframe
2025-05-12 21:59:38,667:INFO:Uploading results into container
2025-05-12 21:59:38,668:INFO:Uploading model into container now
2025-05-12 21:59:38,668:INFO:_master_model_container: 4
2025-05-12 21:59:38,669:INFO:_display_container: 2
2025-05-12 21:59:38,669:INFO:ElasticNet(random_state=123)
2025-05-12 21:59:38,669:INFO:create_model() successfully completed......................................
2025-05-12 21:59:38,787:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:38,787:INFO:Creating metrics dataframe
2025-05-12 21:59:38,799:INFO:Initializing Least Angle Regression
2025-05-12 21:59:38,800:INFO:Total runtime is 0.4770725727081299 minutes
2025-05-12 21:59:38,806:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:38,806:INFO:Initializing create_model()
2025-05-12 21:59:38,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:38,806:INFO:Checking exceptions
2025-05-12 21:59:38,806:INFO:Importing libraries
2025-05-12 21:59:38,806:INFO:Copying training dataset
2025-05-12 21:59:38,812:INFO:Defining folds
2025-05-12 21:59:38,812:INFO:Declaring metric variables
2025-05-12 21:59:38,818:INFO:Importing untrained model
2025-05-12 21:59:38,824:INFO:Least Angle Regression Imported successfully
2025-05-12 21:59:38,834:INFO:Starting cross validation
2025-05-12 21:59:38,836:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:39,037:INFO:Calculating mean and std
2025-05-12 21:59:39,039:INFO:Creating metrics dataframe
2025-05-12 21:59:39,041:INFO:Uploading results into container
2025-05-12 21:59:39,041:INFO:Uploading model into container now
2025-05-12 21:59:39,042:INFO:_master_model_container: 5
2025-05-12 21:59:39,042:INFO:_display_container: 2
2025-05-12 21:59:39,042:INFO:Lars(random_state=123)
2025-05-12 21:59:39,042:INFO:create_model() successfully completed......................................
2025-05-12 21:59:39,192:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:39,192:INFO:Creating metrics dataframe
2025-05-12 21:59:39,202:INFO:Initializing Lasso Least Angle Regression
2025-05-12 21:59:39,202:INFO:Total runtime is 0.4837677836418152 minutes
2025-05-12 21:59:39,207:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:39,208:INFO:Initializing create_model()
2025-05-12 21:59:39,208:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:39,208:INFO:Checking exceptions
2025-05-12 21:59:39,208:INFO:Importing libraries
2025-05-12 21:59:39,208:INFO:Copying training dataset
2025-05-12 21:59:39,213:INFO:Defining folds
2025-05-12 21:59:39,214:INFO:Declaring metric variables
2025-05-12 21:59:39,220:INFO:Importing untrained model
2025-05-12 21:59:39,226:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 21:59:39,234:INFO:Starting cross validation
2025-05-12 21:59:39,237:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:39,449:INFO:Calculating mean and std
2025-05-12 21:59:39,450:INFO:Creating metrics dataframe
2025-05-12 21:59:39,453:INFO:Uploading results into container
2025-05-12 21:59:39,453:INFO:Uploading model into container now
2025-05-12 21:59:39,455:INFO:_master_model_container: 6
2025-05-12 21:59:39,455:INFO:_display_container: 2
2025-05-12 21:59:39,456:INFO:LassoLars(random_state=123)
2025-05-12 21:59:39,456:INFO:create_model() successfully completed......................................
2025-05-12 21:59:39,566:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:39,566:INFO:Creating metrics dataframe
2025-05-12 21:59:39,574:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 21:59:39,575:INFO:Total runtime is 0.4899897654851278 minutes
2025-05-12 21:59:39,578:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:39,578:INFO:Initializing create_model()
2025-05-12 21:59:39,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:39,579:INFO:Checking exceptions
2025-05-12 21:59:39,579:INFO:Importing libraries
2025-05-12 21:59:39,579:INFO:Copying training dataset
2025-05-12 21:59:39,584:INFO:Defining folds
2025-05-12 21:59:39,584:INFO:Declaring metric variables
2025-05-12 21:59:39,591:INFO:Importing untrained model
2025-05-12 21:59:39,596:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 21:59:39,607:INFO:Starting cross validation
2025-05-12 21:59:39,609:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:39,869:INFO:Calculating mean and std
2025-05-12 21:59:39,870:INFO:Creating metrics dataframe
2025-05-12 21:59:39,873:INFO:Uploading results into container
2025-05-12 21:59:39,874:INFO:Uploading model into container now
2025-05-12 21:59:39,874:INFO:_master_model_container: 7
2025-05-12 21:59:39,875:INFO:_display_container: 2
2025-05-12 21:59:39,875:INFO:OrthogonalMatchingPursuit()
2025-05-12 21:59:39,875:INFO:create_model() successfully completed......................................
2025-05-12 21:59:40,007:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:40,008:INFO:Creating metrics dataframe
2025-05-12 21:59:40,024:INFO:Initializing Bayesian Ridge
2025-05-12 21:59:40,025:INFO:Total runtime is 0.4974802374839783 minutes
2025-05-12 21:59:40,030:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:40,031:INFO:Initializing create_model()
2025-05-12 21:59:40,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:40,031:INFO:Checking exceptions
2025-05-12 21:59:40,031:INFO:Importing libraries
2025-05-12 21:59:40,031:INFO:Copying training dataset
2025-05-12 21:59:40,040:INFO:Defining folds
2025-05-12 21:59:40,040:INFO:Declaring metric variables
2025-05-12 21:59:40,043:INFO:Importing untrained model
2025-05-12 21:59:40,054:INFO:Bayesian Ridge Imported successfully
2025-05-12 21:59:40,064:INFO:Starting cross validation
2025-05-12 21:59:40,070:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:40,353:INFO:Calculating mean and std
2025-05-12 21:59:40,355:INFO:Creating metrics dataframe
2025-05-12 21:59:40,357:INFO:Uploading results into container
2025-05-12 21:59:40,358:INFO:Uploading model into container now
2025-05-12 21:59:40,359:INFO:_master_model_container: 8
2025-05-12 21:59:40,359:INFO:_display_container: 2
2025-05-12 21:59:40,359:INFO:BayesianRidge()
2025-05-12 21:59:40,361:INFO:create_model() successfully completed......................................
2025-05-12 21:59:40,488:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:40,488:INFO:Creating metrics dataframe
2025-05-12 21:59:40,499:INFO:Initializing Passive Aggressive Regressor
2025-05-12 21:59:40,499:INFO:Total runtime is 0.5053914825121562 minutes
2025-05-12 21:59:40,506:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:40,506:INFO:Initializing create_model()
2025-05-12 21:59:40,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:40,506:INFO:Checking exceptions
2025-05-12 21:59:40,506:INFO:Importing libraries
2025-05-12 21:59:40,506:INFO:Copying training dataset
2025-05-12 21:59:40,513:INFO:Defining folds
2025-05-12 21:59:40,514:INFO:Declaring metric variables
2025-05-12 21:59:40,558:INFO:Importing untrained model
2025-05-12 21:59:40,565:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 21:59:40,582:INFO:Starting cross validation
2025-05-12 21:59:40,584:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:40,794:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,794:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,794:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,794:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,797:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,807:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,828:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,913:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,925:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,953:INFO:Calculating mean and std
2025-05-12 21:59:40,955:INFO:Creating metrics dataframe
2025-05-12 21:59:40,958:INFO:Uploading results into container
2025-05-12 21:59:40,959:INFO:Uploading model into container now
2025-05-12 21:59:40,959:INFO:_master_model_container: 9
2025-05-12 21:59:40,959:INFO:_display_container: 2
2025-05-12 21:59:40,960:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 21:59:40,960:INFO:create_model() successfully completed......................................
2025-05-12 21:59:41,077:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:41,077:INFO:Creating metrics dataframe
2025-05-12 21:59:41,088:INFO:Initializing Huber Regressor
2025-05-12 21:59:41,088:INFO:Total runtime is 0.5152082641919454 minutes
2025-05-12 21:59:41,091:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:41,092:INFO:Initializing create_model()
2025-05-12 21:59:41,092:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:41,092:INFO:Checking exceptions
2025-05-12 21:59:41,093:INFO:Importing libraries
2025-05-12 21:59:41,093:INFO:Copying training dataset
2025-05-12 21:59:41,100:INFO:Defining folds
2025-05-12 21:59:41,100:INFO:Declaring metric variables
2025-05-12 21:59:41,106:INFO:Importing untrained model
2025-05-12 21:59:41,112:INFO:Huber Regressor Imported successfully
2025-05-12 21:59:41,122:INFO:Starting cross validation
2025-05-12 21:59:41,124:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:41,380:INFO:Calculating mean and std
2025-05-12 21:59:41,382:INFO:Creating metrics dataframe
2025-05-12 21:59:41,383:INFO:Uploading results into container
2025-05-12 21:59:41,385:INFO:Uploading model into container now
2025-05-12 21:59:41,386:INFO:_master_model_container: 10
2025-05-12 21:59:41,387:INFO:_display_container: 2
2025-05-12 21:59:41,387:INFO:HuberRegressor()
2025-05-12 21:59:41,387:INFO:create_model() successfully completed......................................
2025-05-12 21:59:41,500:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:41,501:INFO:Creating metrics dataframe
2025-05-12 21:59:41,511:INFO:Initializing K Neighbors Regressor
2025-05-12 21:59:41,511:INFO:Total runtime is 0.5222517967224122 minutes
2025-05-12 21:59:41,516:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:41,517:INFO:Initializing create_model()
2025-05-12 21:59:41,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:41,517:INFO:Checking exceptions
2025-05-12 21:59:41,517:INFO:Importing libraries
2025-05-12 21:59:41,517:INFO:Copying training dataset
2025-05-12 21:59:41,521:INFO:Defining folds
2025-05-12 21:59:41,521:INFO:Declaring metric variables
2025-05-12 21:59:41,528:INFO:Importing untrained model
2025-05-12 21:59:41,534:INFO:K Neighbors Regressor Imported successfully
2025-05-12 21:59:41,541:INFO:Starting cross validation
2025-05-12 21:59:41,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:41,838:INFO:Calculating mean and std
2025-05-12 21:59:41,839:INFO:Creating metrics dataframe
2025-05-12 21:59:41,841:INFO:Uploading results into container
2025-05-12 21:59:41,842:INFO:Uploading model into container now
2025-05-12 21:59:41,843:INFO:_master_model_container: 11
2025-05-12 21:59:41,843:INFO:_display_container: 2
2025-05-12 21:59:41,843:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 21:59:41,844:INFO:create_model() successfully completed......................................
2025-05-12 21:59:41,957:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:41,957:INFO:Creating metrics dataframe
2025-05-12 21:59:41,967:INFO:Initializing Decision Tree Regressor
2025-05-12 21:59:41,967:INFO:Total runtime is 0.5298539320627849 minutes
2025-05-12 21:59:41,971:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:41,972:INFO:Initializing create_model()
2025-05-12 21:59:41,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:41,972:INFO:Checking exceptions
2025-05-12 21:59:41,972:INFO:Importing libraries
2025-05-12 21:59:41,973:INFO:Copying training dataset
2025-05-12 21:59:41,978:INFO:Defining folds
2025-05-12 21:59:41,978:INFO:Declaring metric variables
2025-05-12 21:59:41,984:INFO:Importing untrained model
2025-05-12 21:59:41,990:INFO:Decision Tree Regressor Imported successfully
2025-05-12 21:59:41,998:INFO:Starting cross validation
2025-05-12 21:59:42,001:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:42,212:INFO:Calculating mean and std
2025-05-12 21:59:42,213:INFO:Creating metrics dataframe
2025-05-12 21:59:42,217:INFO:Uploading results into container
2025-05-12 21:59:42,217:INFO:Uploading model into container now
2025-05-12 21:59:42,219:INFO:_master_model_container: 12
2025-05-12 21:59:42,219:INFO:_display_container: 2
2025-05-12 21:59:42,220:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 21:59:42,220:INFO:create_model() successfully completed......................................
2025-05-12 21:59:42,336:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:42,337:INFO:Creating metrics dataframe
2025-05-12 21:59:42,349:INFO:Initializing Random Forest Regressor
2025-05-12 21:59:42,349:INFO:Total runtime is 0.5362255096435548 minutes
2025-05-12 21:59:42,354:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:42,356:INFO:Initializing create_model()
2025-05-12 21:59:42,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:42,356:INFO:Checking exceptions
2025-05-12 21:59:42,356:INFO:Importing libraries
2025-05-12 21:59:42,356:INFO:Copying training dataset
2025-05-12 21:59:42,361:INFO:Defining folds
2025-05-12 21:59:42,361:INFO:Declaring metric variables
2025-05-12 21:59:42,369:INFO:Importing untrained model
2025-05-12 21:59:42,376:INFO:Random Forest Regressor Imported successfully
2025-05-12 21:59:42,386:INFO:Starting cross validation
2025-05-12 21:59:42,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:43,218:INFO:Calculating mean and std
2025-05-12 21:59:43,219:INFO:Creating metrics dataframe
2025-05-12 21:59:43,222:INFO:Uploading results into container
2025-05-12 21:59:43,222:INFO:Uploading model into container now
2025-05-12 21:59:43,223:INFO:_master_model_container: 13
2025-05-12 21:59:43,223:INFO:_display_container: 2
2025-05-12 21:59:43,224:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:59:43,224:INFO:create_model() successfully completed......................................
2025-05-12 21:59:43,329:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:43,329:INFO:Creating metrics dataframe
2025-05-12 21:59:43,339:INFO:Initializing Extra Trees Regressor
2025-05-12 21:59:43,339:INFO:Total runtime is 0.5527250568072002 minutes
2025-05-12 21:59:43,343:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:43,343:INFO:Initializing create_model()
2025-05-12 21:59:43,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:43,343:INFO:Checking exceptions
2025-05-12 21:59:43,343:INFO:Importing libraries
2025-05-12 21:59:43,343:INFO:Copying training dataset
2025-05-12 21:59:43,350:INFO:Defining folds
2025-05-12 21:59:43,350:INFO:Declaring metric variables
2025-05-12 21:59:43,354:INFO:Importing untrained model
2025-05-12 21:59:43,359:INFO:Extra Trees Regressor Imported successfully
2025-05-12 21:59:43,369:INFO:Starting cross validation
2025-05-12 21:59:43,371:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:44,132:INFO:Calculating mean and std
2025-05-12 21:59:44,133:INFO:Creating metrics dataframe
2025-05-12 21:59:44,136:INFO:Uploading results into container
2025-05-12 21:59:44,137:INFO:Uploading model into container now
2025-05-12 21:59:44,139:INFO:_master_model_container: 14
2025-05-12 21:59:44,139:INFO:_display_container: 2
2025-05-12 21:59:44,140:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:59:44,140:INFO:create_model() successfully completed......................................
2025-05-12 21:59:44,253:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:44,253:INFO:Creating metrics dataframe
2025-05-12 21:59:44,264:INFO:Initializing AdaBoost Regressor
2025-05-12 21:59:44,264:INFO:Total runtime is 0.5681455413500469 minutes
2025-05-12 21:59:44,270:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:44,271:INFO:Initializing create_model()
2025-05-12 21:59:44,271:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:44,271:INFO:Checking exceptions
2025-05-12 21:59:44,271:INFO:Importing libraries
2025-05-12 21:59:44,271:INFO:Copying training dataset
2025-05-12 21:59:44,276:INFO:Defining folds
2025-05-12 21:59:44,276:INFO:Declaring metric variables
2025-05-12 21:59:44,282:INFO:Importing untrained model
2025-05-12 21:59:44,287:INFO:AdaBoost Regressor Imported successfully
2025-05-12 21:59:44,297:INFO:Starting cross validation
2025-05-12 21:59:44,300:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:44,801:INFO:Calculating mean and std
2025-05-12 21:59:44,803:INFO:Creating metrics dataframe
2025-05-12 21:59:44,805:INFO:Uploading results into container
2025-05-12 21:59:44,806:INFO:Uploading model into container now
2025-05-12 21:59:44,807:INFO:_master_model_container: 15
2025-05-12 21:59:44,807:INFO:_display_container: 2
2025-05-12 21:59:44,807:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 21:59:44,808:INFO:create_model() successfully completed......................................
2025-05-12 21:59:44,927:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:44,927:INFO:Creating metrics dataframe
2025-05-12 21:59:44,942:INFO:Initializing Gradient Boosting Regressor
2025-05-12 21:59:44,942:INFO:Total runtime is 0.5794375061988831 minutes
2025-05-12 21:59:44,947:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:44,947:INFO:Initializing create_model()
2025-05-12 21:59:44,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:44,947:INFO:Checking exceptions
2025-05-12 21:59:44,948:INFO:Importing libraries
2025-05-12 21:59:44,948:INFO:Copying training dataset
2025-05-12 21:59:44,955:INFO:Defining folds
2025-05-12 21:59:44,955:INFO:Declaring metric variables
2025-05-12 21:59:44,962:INFO:Importing untrained model
2025-05-12 21:59:44,979:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 21:59:45,009:INFO:Starting cross validation
2025-05-12 21:59:45,011:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:45,605:INFO:Calculating mean and std
2025-05-12 21:59:45,607:INFO:Creating metrics dataframe
2025-05-12 21:59:45,613:INFO:Uploading results into container
2025-05-12 21:59:45,614:INFO:Uploading model into container now
2025-05-12 21:59:45,615:INFO:_master_model_container: 16
2025-05-12 21:59:45,615:INFO:_display_container: 2
2025-05-12 21:59:45,617:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 21:59:45,617:INFO:create_model() successfully completed......................................
2025-05-12 21:59:45,789:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:45,790:INFO:Creating metrics dataframe
2025-05-12 21:59:45,808:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 21:59:45,808:INFO:Total runtime is 0.5938732743263245 minutes
2025-05-12 21:59:45,816:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:45,817:INFO:Initializing create_model()
2025-05-12 21:59:45,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:45,817:INFO:Checking exceptions
2025-05-12 21:59:45,817:INFO:Importing libraries
2025-05-12 21:59:45,817:INFO:Copying training dataset
2025-05-12 21:59:45,829:INFO:Defining folds
2025-05-12 21:59:45,829:INFO:Declaring metric variables
2025-05-12 21:59:45,840:INFO:Importing untrained model
2025-05-12 21:59:45,850:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 21:59:45,866:INFO:Starting cross validation
2025-05-12 21:59:45,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:46,652:INFO:Calculating mean and std
2025-05-12 21:59:46,655:INFO:Creating metrics dataframe
2025-05-12 21:59:46,657:INFO:Uploading results into container
2025-05-12 21:59:46,660:INFO:Uploading model into container now
2025-05-12 21:59:46,661:INFO:_master_model_container: 17
2025-05-12 21:59:46,661:INFO:_display_container: 2
2025-05-12 21:59:46,662:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:59:46,663:INFO:create_model() successfully completed......................................
2025-05-12 21:59:46,809:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:46,809:INFO:Creating metrics dataframe
2025-05-12 21:59:46,823:INFO:Initializing Dummy Regressor
2025-05-12 21:59:46,823:INFO:Total runtime is 0.6107922116915385 minutes
2025-05-12 21:59:46,830:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:46,830:INFO:Initializing create_model()
2025-05-12 21:59:46,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:46,831:INFO:Checking exceptions
2025-05-12 21:59:46,831:INFO:Importing libraries
2025-05-12 21:59:46,831:INFO:Copying training dataset
2025-05-12 21:59:46,837:INFO:Defining folds
2025-05-12 21:59:46,838:INFO:Declaring metric variables
2025-05-12 21:59:46,845:INFO:Importing untrained model
2025-05-12 21:59:46,852:INFO:Dummy Regressor Imported successfully
2025-05-12 21:59:46,861:INFO:Starting cross validation
2025-05-12 21:59:46,864:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:47,089:INFO:Calculating mean and std
2025-05-12 21:59:47,090:INFO:Creating metrics dataframe
2025-05-12 21:59:47,094:INFO:Uploading results into container
2025-05-12 21:59:47,095:INFO:Uploading model into container now
2025-05-12 21:59:47,096:INFO:_master_model_container: 18
2025-05-12 21:59:47,096:INFO:_display_container: 2
2025-05-12 21:59:47,097:INFO:DummyRegressor()
2025-05-12 21:59:47,097:INFO:create_model() successfully completed......................................
2025-05-12 21:59:47,219:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:47,219:INFO:Creating metrics dataframe
2025-05-12 21:59:47,236:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 21:59:47,262:INFO:Initializing create_model()
2025-05-12 21:59:47,262:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:47,262:INFO:Checking exceptions
2025-05-12 21:59:47,265:INFO:Importing libraries
2025-05-12 21:59:47,265:INFO:Copying training dataset
2025-05-12 21:59:47,270:INFO:Defining folds
2025-05-12 21:59:47,270:INFO:Declaring metric variables
2025-05-12 21:59:47,270:INFO:Importing untrained model
2025-05-12 21:59:47,270:INFO:Declaring custom model
2025-05-12 21:59:47,271:INFO:Linear Regression Imported successfully
2025-05-12 21:59:47,272:INFO:Cross validation set to False
2025-05-12 21:59:47,272:INFO:Fitting Model
2025-05-12 21:59:47,308:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:59:47,308:INFO:create_model() successfully completed......................................
2025-05-12 21:59:47,474:INFO:_master_model_container: 18
2025-05-12 21:59:47,474:INFO:_display_container: 2
2025-05-12 21:59:47,474:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:59:47,475:INFO:compare_models() successfully completed......................................
2025-05-12 21:59:47,505:INFO:Initializing create_model()
2025-05-12 21:59:47,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:47,505:INFO:Checking exceptions
2025-05-12 21:59:47,531:INFO:Importing libraries
2025-05-12 21:59:47,531:INFO:Copying training dataset
2025-05-12 21:59:47,552:INFO:Defining folds
2025-05-12 21:59:47,552:INFO:Declaring metric variables
2025-05-12 21:59:47,561:INFO:Importing untrained model
2025-05-12 21:59:47,567:INFO:Linear Regression Imported successfully
2025-05-12 21:59:47,580:INFO:Starting cross validation
2025-05-12 21:59:47,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:47,830:INFO:Calculating mean and std
2025-05-12 21:59:47,831:INFO:Creating metrics dataframe
2025-05-12 21:59:47,836:INFO:Finalizing model
2025-05-12 21:59:47,880:INFO:Uploading results into container
2025-05-12 21:59:47,881:INFO:Uploading model into container now
2025-05-12 21:59:47,896:INFO:_master_model_container: 19
2025-05-12 21:59:47,896:INFO:_display_container: 3
2025-05-12 21:59:47,896:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:59:47,898:INFO:create_model() successfully completed......................................
2025-05-12 21:59:48,022:INFO:Initializing tune_model()
2025-05-12 21:59:48,022:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 21:59:48,022:INFO:Checking exceptions
2025-05-12 21:59:48,044:INFO:Copying training dataset
2025-05-12 21:59:48,050:INFO:Checking base model
2025-05-12 21:59:48,050:INFO:Base model : Linear Regression
2025-05-12 21:59:48,057:INFO:Declaring metric variables
2025-05-12 21:59:48,068:INFO:Defining Hyperparameters
2025-05-12 21:59:48,068:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-05-12 21:59:48,204:INFO:Tuning with n_jobs=-1
2025-05-12 21:59:48,204:INFO:Initializing GridSearchCV
2025-05-12 21:59:48,632:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-05-12 21:59:48,633:INFO:Hyperparameter search completed
2025-05-12 21:59:48,633:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:48,633:INFO:Initializing create_model()
2025-05-12 21:59:48,633:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF3B2AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True})
2025-05-12 21:59:48,633:INFO:Checking exceptions
2025-05-12 21:59:48,635:INFO:Importing libraries
2025-05-12 21:59:48,635:INFO:Copying training dataset
2025-05-12 21:59:48,639:INFO:Defining folds
2025-05-12 21:59:48,639:INFO:Declaring metric variables
2025-05-12 21:59:48,644:INFO:Importing untrained model
2025-05-12 21:59:48,644:INFO:Declaring custom model
2025-05-12 21:59:48,652:INFO:Linear Regression Imported successfully
2025-05-12 21:59:48,667:INFO:Starting cross validation
2025-05-12 21:59:48,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:48,955:INFO:Calculating mean and std
2025-05-12 21:59:48,956:INFO:Creating metrics dataframe
2025-05-12 21:59:48,963:INFO:Finalizing model
2025-05-12 21:59:49,018:INFO:Uploading results into container
2025-05-12 21:59:49,020:INFO:Uploading model into container now
2025-05-12 21:59:49,020:INFO:_master_model_container: 20
2025-05-12 21:59:49,021:INFO:_display_container: 4
2025-05-12 21:59:49,021:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:59:49,021:INFO:create_model() successfully completed......................................
2025-05-12 21:59:49,156:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:49,156:INFO:choose_better activated
2025-05-12 21:59:49,161:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:49,161:INFO:Initializing create_model()
2025-05-12 21:59:49,162:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:49,162:INFO:Checking exceptions
2025-05-12 21:59:49,166:INFO:Importing libraries
2025-05-12 21:59:49,167:INFO:Copying training dataset
2025-05-12 21:59:49,170:INFO:Defining folds
2025-05-12 21:59:49,170:INFO:Declaring metric variables
2025-05-12 21:59:49,171:INFO:Importing untrained model
2025-05-12 21:59:49,171:INFO:Declaring custom model
2025-05-12 21:59:49,171:INFO:Linear Regression Imported successfully
2025-05-12 21:59:49,171:INFO:Starting cross validation
2025-05-12 21:59:49,173:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:49,411:INFO:Calculating mean and std
2025-05-12 21:59:49,412:INFO:Creating metrics dataframe
2025-05-12 21:59:49,413:INFO:Finalizing model
2025-05-12 21:59:49,454:INFO:Uploading results into container
2025-05-12 21:59:49,456:INFO:Uploading model into container now
2025-05-12 21:59:49,456:INFO:_master_model_container: 21
2025-05-12 21:59:49,456:INFO:_display_container: 5
2025-05-12 21:59:49,457:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:59:49,457:INFO:create_model() successfully completed......................................
2025-05-12 21:59:49,576:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:49,576:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9592
2025-05-12 21:59:49,576:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9592
2025-05-12 21:59:49,577:INFO:LinearRegression(n_jobs=-1) is best model
2025-05-12 21:59:49,577:INFO:choose_better completed
2025-05-12 21:59:49,577:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 21:59:49,590:INFO:_master_model_container: 21
2025-05-12 21:59:49,591:INFO:_display_container: 4
2025-05-12 21:59:49,591:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:59:49,591:INFO:tune_model() successfully completed......................................
2025-05-12 21:59:49,728:INFO:Initializing evaluate_model()
2025-05-12 21:59:49,729:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 21:59:49,739:INFO:Initializing plot_model()
2025-05-12 21:59:49,739:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=LinearRegression(n_jobs=-1), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 21:59:49,739:INFO:Checking exceptions
2025-05-12 21:59:49,743:INFO:Preloading libraries
2025-05-12 21:59:49,743:INFO:Copying training dataset
2025-05-12 21:59:49,743:INFO:Plot type: pipeline
2025-05-12 21:59:49,987:INFO:Visual Rendered Successfully
2025-05-12 21:59:50,121:INFO:plot_model() successfully completed......................................
2025-05-12 21:59:50,157:INFO:Initializing predict_model()
2025-05-12 21:59:50,158:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000180FAFCE480>)
2025-05-12 21:59:50,158:INFO:Checking exceptions
2025-05-12 21:59:50,158:INFO:Preloading libraries
2025-05-12 21:59:50,287:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:02:05,675:INFO:Initializing save_model()
2025-05-12 22:02:05,675:INFO:save_model(model=LinearRegression(n_jobs=-1), model_name=modelo_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-12 22:02:05,675:INFO:Adding model into prep_pipe
2025-05-12 22:02:05,691:INFO:modelo_final.pkl saved in current working directory
2025-05-12 22:02:05,702:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', LinearRegression(n_jobs=-1))])
2025-05-12 22:02:05,703:INFO:save_model() successfully completed......................................
2025-05-12 22:08:39,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:08:39,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:08:39,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:08:39,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:10:18,846:INFO:PyCaret RegressionExperiment
2025-05-12 22:10:18,846:INFO:Logging name: reg-default-name
2025-05-12 22:10:18,847:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:10:18,847:INFO:version 3.3.2
2025-05-12 22:10:18,847:INFO:Initializing setup()
2025-05-12 22:10:18,847:INFO:self.USI: 2b1f
2025-05-12 22:10:18,847:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'transform_target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:10:18,847:INFO:Checking environment
2025-05-12 22:10:18,847:INFO:python_version: 3.11.8
2025-05-12 22:10:18,847:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:10:18,847:INFO:machine: AMD64
2025-05-12 22:10:18,847:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:10:18,854:INFO:Memory: svmem(total=16907886592, available=3919495168, percent=76.8, used=12988391424, free=3919495168)
2025-05-12 22:10:18,854:INFO:Physical Core: 4
2025-05-12 22:10:18,855:INFO:Logical Core: 8
2025-05-12 22:10:18,855:INFO:Checking libraries
2025-05-12 22:10:18,855:INFO:System:
2025-05-12 22:10:18,855:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:10:18,855:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:10:18,855:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:10:18,855:INFO:PyCaret required dependencies:
2025-05-12 22:10:18,885:INFO:                 pip: 24.0
2025-05-12 22:10:18,885:INFO:          setuptools: 65.5.0
2025-05-12 22:10:18,885:INFO:             pycaret: 3.3.2
2025-05-12 22:10:18,885:INFO:             IPython: 9.2.0
2025-05-12 22:10:18,885:INFO:          ipywidgets: 8.1.7
2025-05-12 22:10:18,885:INFO:                tqdm: 4.67.1
2025-05-12 22:10:18,885:INFO:               numpy: 1.26.4
2025-05-12 22:10:18,885:INFO:              pandas: 2.1.4
2025-05-12 22:10:18,885:INFO:              jinja2: 3.1.6
2025-05-12 22:10:18,885:INFO:               scipy: 1.11.4
2025-05-12 22:10:18,885:INFO:              joblib: 1.3.2
2025-05-12 22:10:18,885:INFO:             sklearn: 1.4.2
2025-05-12 22:10:18,885:INFO:                pyod: 2.0.5
2025-05-12 22:10:18,886:INFO:            imblearn: 0.13.0
2025-05-12 22:10:18,886:INFO:   category_encoders: 2.7.0
2025-05-12 22:10:18,886:INFO:            lightgbm: 4.6.0
2025-05-12 22:10:18,886:INFO:               numba: 0.61.2
2025-05-12 22:10:18,886:INFO:            requests: 2.32.3
2025-05-12 22:10:18,886:INFO:          matplotlib: 3.7.5
2025-05-12 22:10:18,886:INFO:          scikitplot: 0.3.7
2025-05-12 22:10:18,886:INFO:         yellowbrick: 1.5
2025-05-12 22:10:18,886:INFO:              plotly: 5.24.1
2025-05-12 22:10:18,886:INFO:    plotly-resampler: Not installed
2025-05-12 22:10:18,886:INFO:             kaleido: 0.2.1
2025-05-12 22:10:18,886:INFO:           schemdraw: 0.15
2025-05-12 22:10:18,886:INFO:         statsmodels: 0.14.4
2025-05-12 22:10:18,886:INFO:              sktime: 0.26.0
2025-05-12 22:10:18,886:INFO:               tbats: 1.1.3
2025-05-12 22:10:18,886:INFO:            pmdarima: 2.0.4
2025-05-12 22:10:18,886:INFO:              psutil: 7.0.0
2025-05-12 22:10:18,886:INFO:          markupsafe: 3.0.2
2025-05-12 22:10:18,886:INFO:             pickle5: Not installed
2025-05-12 22:10:18,886:INFO:         cloudpickle: 3.1.1
2025-05-12 22:10:18,886:INFO:         deprecation: 2.1.0
2025-05-12 22:10:18,886:INFO:              xxhash: 3.5.0
2025-05-12 22:10:18,886:INFO:           wurlitzer: Not installed
2025-05-12 22:10:18,886:INFO:PyCaret optional dependencies:
2025-05-12 22:10:18,896:INFO:                shap: Not installed
2025-05-12 22:10:18,896:INFO:           interpret: Not installed
2025-05-12 22:10:18,896:INFO:                umap: Not installed
2025-05-12 22:10:18,896:INFO:     ydata_profiling: Not installed
2025-05-12 22:10:18,896:INFO:  explainerdashboard: Not installed
2025-05-12 22:10:18,896:INFO:             autoviz: Not installed
2025-05-12 22:10:18,896:INFO:           fairlearn: Not installed
2025-05-12 22:10:18,896:INFO:          deepchecks: Not installed
2025-05-12 22:10:18,896:INFO:             xgboost: Not installed
2025-05-12 22:10:18,896:INFO:            catboost: Not installed
2025-05-12 22:10:18,896:INFO:              kmodes: Not installed
2025-05-12 22:10:18,896:INFO:             mlxtend: Not installed
2025-05-12 22:10:18,896:INFO:       statsforecast: Not installed
2025-05-12 22:10:18,896:INFO:        tune_sklearn: Not installed
2025-05-12 22:10:18,896:INFO:                 ray: Not installed
2025-05-12 22:10:18,896:INFO:            hyperopt: Not installed
2025-05-12 22:10:18,896:INFO:              optuna: Not installed
2025-05-12 22:10:18,896:INFO:               skopt: Not installed
2025-05-12 22:10:18,896:INFO:              mlflow: Not installed
2025-05-12 22:10:18,896:INFO:              gradio: Not installed
2025-05-12 22:10:18,896:INFO:             fastapi: Not installed
2025-05-12 22:10:18,896:INFO:             uvicorn: Not installed
2025-05-12 22:10:18,897:INFO:              m2cgen: Not installed
2025-05-12 22:10:18,897:INFO:           evidently: Not installed
2025-05-12 22:10:18,897:INFO:               fugue: Not installed
2025-05-12 22:10:18,897:INFO:           streamlit: Not installed
2025-05-12 22:10:18,897:INFO:             prophet: Not installed
2025-05-12 22:10:18,897:INFO:None
2025-05-12 22:10:18,897:INFO:Set up data.
2025-05-12 22:10:52,323:INFO:PyCaret RegressionExperiment
2025-05-12 22:10:52,324:INFO:Logging name: reg-default-name
2025-05-12 22:10:52,324:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:10:52,324:INFO:version 3.3.2
2025-05-12 22:10:52,324:INFO:Initializing setup()
2025-05-12 22:10:52,324:INFO:self.USI: 9623
2025-05-12 22:10:52,324:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'transform_target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:10:52,324:INFO:Checking environment
2025-05-12 22:10:52,324:INFO:python_version: 3.11.8
2025-05-12 22:10:52,324:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:10:52,324:INFO:machine: AMD64
2025-05-12 22:10:52,324:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:10:52,330:INFO:Memory: svmem(total=16907886592, available=4026912768, percent=76.2, used=12880973824, free=4026912768)
2025-05-12 22:10:52,330:INFO:Physical Core: 4
2025-05-12 22:10:52,330:INFO:Logical Core: 8
2025-05-12 22:10:52,330:INFO:Checking libraries
2025-05-12 22:10:52,330:INFO:System:
2025-05-12 22:10:52,330:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:10:52,330:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:10:52,330:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:10:52,330:INFO:PyCaret required dependencies:
2025-05-12 22:10:52,330:INFO:                 pip: 24.0
2025-05-12 22:10:52,330:INFO:          setuptools: 65.5.0
2025-05-12 22:10:52,330:INFO:             pycaret: 3.3.2
2025-05-12 22:10:52,330:INFO:             IPython: 9.2.0
2025-05-12 22:10:52,330:INFO:          ipywidgets: 8.1.7
2025-05-12 22:10:52,330:INFO:                tqdm: 4.67.1
2025-05-12 22:10:52,330:INFO:               numpy: 1.26.4
2025-05-12 22:10:52,330:INFO:              pandas: 2.1.4
2025-05-12 22:10:52,330:INFO:              jinja2: 3.1.6
2025-05-12 22:10:52,330:INFO:               scipy: 1.11.4
2025-05-12 22:10:52,330:INFO:              joblib: 1.3.2
2025-05-12 22:10:52,330:INFO:             sklearn: 1.4.2
2025-05-12 22:10:52,330:INFO:                pyod: 2.0.5
2025-05-12 22:10:52,330:INFO:            imblearn: 0.13.0
2025-05-12 22:10:52,331:INFO:   category_encoders: 2.7.0
2025-05-12 22:10:52,331:INFO:            lightgbm: 4.6.0
2025-05-12 22:10:52,331:INFO:               numba: 0.61.2
2025-05-12 22:10:52,331:INFO:            requests: 2.32.3
2025-05-12 22:10:52,331:INFO:          matplotlib: 3.7.5
2025-05-12 22:10:52,331:INFO:          scikitplot: 0.3.7
2025-05-12 22:10:52,331:INFO:         yellowbrick: 1.5
2025-05-12 22:10:52,331:INFO:              plotly: 5.24.1
2025-05-12 22:10:52,331:INFO:    plotly-resampler: Not installed
2025-05-12 22:10:52,331:INFO:             kaleido: 0.2.1
2025-05-12 22:10:52,331:INFO:           schemdraw: 0.15
2025-05-12 22:10:52,331:INFO:         statsmodels: 0.14.4
2025-05-12 22:10:52,331:INFO:              sktime: 0.26.0
2025-05-12 22:10:52,331:INFO:               tbats: 1.1.3
2025-05-12 22:10:52,331:INFO:            pmdarima: 2.0.4
2025-05-12 22:10:52,331:INFO:              psutil: 7.0.0
2025-05-12 22:10:52,331:INFO:          markupsafe: 3.0.2
2025-05-12 22:10:52,331:INFO:             pickle5: Not installed
2025-05-12 22:10:52,331:INFO:         cloudpickle: 3.1.1
2025-05-12 22:10:52,331:INFO:         deprecation: 2.1.0
2025-05-12 22:10:52,331:INFO:              xxhash: 3.5.0
2025-05-12 22:10:52,331:INFO:           wurlitzer: Not installed
2025-05-12 22:10:52,331:INFO:PyCaret optional dependencies:
2025-05-12 22:10:52,331:INFO:                shap: Not installed
2025-05-12 22:10:52,331:INFO:           interpret: Not installed
2025-05-12 22:10:52,331:INFO:                umap: Not installed
2025-05-12 22:10:52,331:INFO:     ydata_profiling: Not installed
2025-05-12 22:10:52,332:INFO:  explainerdashboard: Not installed
2025-05-12 22:10:52,332:INFO:             autoviz: Not installed
2025-05-12 22:10:52,332:INFO:           fairlearn: Not installed
2025-05-12 22:10:52,332:INFO:          deepchecks: Not installed
2025-05-12 22:10:52,332:INFO:             xgboost: Not installed
2025-05-12 22:10:52,332:INFO:            catboost: Not installed
2025-05-12 22:10:52,332:INFO:              kmodes: Not installed
2025-05-12 22:10:52,332:INFO:             mlxtend: Not installed
2025-05-12 22:10:52,332:INFO:       statsforecast: Not installed
2025-05-12 22:10:52,332:INFO:        tune_sklearn: Not installed
2025-05-12 22:10:52,332:INFO:                 ray: Not installed
2025-05-12 22:10:52,332:INFO:            hyperopt: Not installed
2025-05-12 22:10:52,332:INFO:              optuna: Not installed
2025-05-12 22:10:52,332:INFO:               skopt: Not installed
2025-05-12 22:10:52,332:INFO:              mlflow: Not installed
2025-05-12 22:10:52,332:INFO:              gradio: Not installed
2025-05-12 22:10:52,332:INFO:             fastapi: Not installed
2025-05-12 22:10:52,332:INFO:             uvicorn: Not installed
2025-05-12 22:10:52,332:INFO:              m2cgen: Not installed
2025-05-12 22:10:52,332:INFO:           evidently: Not installed
2025-05-12 22:10:52,332:INFO:               fugue: Not installed
2025-05-12 22:10:52,332:INFO:           streamlit: Not installed
2025-05-12 22:10:52,332:INFO:             prophet: Not installed
2025-05-12 22:10:52,332:INFO:None
2025-05-12 22:10:52,332:INFO:Set up data.
2025-05-12 22:10:52,339:INFO:Set up folding strategy.
2025-05-12 22:10:52,339:INFO:Set up train/test split.
2025-05-12 22:10:52,374:INFO:Set up index.
2025-05-12 22:10:52,374:INFO:Assigning column types.
2025-05-12 22:10:52,377:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:10:52,377:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,381:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,384:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,479:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,520:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,521:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,525:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,529:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,580:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,616:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,617:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:10:52,621:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,625:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,671:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,705:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,705:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,711:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,715:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,759:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,793:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:10:52,800:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,846:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,880:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,888:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,968:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,969:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:10:53,019:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:53,054:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:53,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,106:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:53,141:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:53,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,142:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,142:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:10:53,193:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:53,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,285:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:53,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,321:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:10:53,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,519:INFO:Preparing preprocessing pipeline...
2025-05-12 22:10:53,519:INFO:Set up simple imputation.
2025-05-12 22:10:53,520:INFO:Set up encoding of categorical features.
2025-05-12 22:10:53,520:INFO:Set up feature normalization.
2025-05-12 22:10:53,585:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:10:53,592:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 22:10:53,592:INFO:Creating final display dataframe.
2025-05-12 22:10:53,742:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type        Regression
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              9623
2025-05-12 22:10:53,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:54,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:54,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:54,048:INFO:setup() successfully completed in 1.73s...............
2025-05-12 22:11:08,125:INFO:Initializing compare_models()
2025-05-12 22:11:08,125:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 22:11:08,125:INFO:Checking exceptions
2025-05-12 22:11:08,127:INFO:Preparing display monitor
2025-05-12 22:11:08,160:INFO:Initializing Linear Regression
2025-05-12 22:11:08,160:INFO:Total runtime is 0.0 minutes
2025-05-12 22:11:08,169:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:08,170:INFO:Initializing create_model()
2025-05-12 22:11:08,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:08,170:INFO:Checking exceptions
2025-05-12 22:11:08,170:INFO:Importing libraries
2025-05-12 22:11:08,170:INFO:Copying training dataset
2025-05-12 22:11:08,175:INFO:Defining folds
2025-05-12 22:11:08,176:INFO:Declaring metric variables
2025-05-12 22:11:08,181:INFO:Importing untrained model
2025-05-12 22:11:08,185:INFO:Linear Regression Imported successfully
2025-05-12 22:11:08,195:INFO:Starting cross validation
2025-05-12 22:11:08,204:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:19,594:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:19,632:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:19,972:INFO:Calculating mean and std
2025-05-12 22:11:19,974:INFO:Creating metrics dataframe
2025-05-12 22:11:19,979:INFO:Uploading results into container
2025-05-12 22:11:19,981:INFO:Uploading model into container now
2025-05-12 22:11:19,982:INFO:_master_model_container: 1
2025-05-12 22:11:19,983:INFO:_display_container: 2
2025-05-12 22:11:19,983:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:11:19,983:INFO:create_model() successfully completed......................................
2025-05-12 22:11:20,098:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:20,098:INFO:Creating metrics dataframe
2025-05-12 22:11:20,107:INFO:Initializing Lasso Regression
2025-05-12 22:11:20,107:INFO:Total runtime is 0.19912593364715575 minutes
2025-05-12 22:11:20,113:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:20,114:INFO:Initializing create_model()
2025-05-12 22:11:20,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:20,114:INFO:Checking exceptions
2025-05-12 22:11:20,114:INFO:Importing libraries
2025-05-12 22:11:20,114:INFO:Copying training dataset
2025-05-12 22:11:20,120:INFO:Defining folds
2025-05-12 22:11:20,121:INFO:Declaring metric variables
2025-05-12 22:11:20,126:INFO:Importing untrained model
2025-05-12 22:11:20,133:INFO:Lasso Regression Imported successfully
2025-05-12 22:11:20,145:INFO:Starting cross validation
2025-05-12 22:11:20,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:20,560:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:20,561:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:20,563:INFO:Calculating mean and std
2025-05-12 22:11:20,567:INFO:Creating metrics dataframe
2025-05-12 22:11:20,570:INFO:Uploading results into container
2025-05-12 22:11:20,570:INFO:Uploading model into container now
2025-05-12 22:11:20,571:INFO:_master_model_container: 2
2025-05-12 22:11:20,571:INFO:_display_container: 2
2025-05-12 22:11:20,571:INFO:Lasso(random_state=123)
2025-05-12 22:11:20,571:INFO:create_model() successfully completed......................................
2025-05-12 22:11:20,675:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:20,675:INFO:Creating metrics dataframe
2025-05-12 22:11:20,684:INFO:Initializing Ridge Regression
2025-05-12 22:11:20,684:INFO:Total runtime is 0.20874226093292236 minutes
2025-05-12 22:11:20,689:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:20,689:INFO:Initializing create_model()
2025-05-12 22:11:20,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:20,690:INFO:Checking exceptions
2025-05-12 22:11:20,690:INFO:Importing libraries
2025-05-12 22:11:20,690:INFO:Copying training dataset
2025-05-12 22:11:20,696:INFO:Defining folds
2025-05-12 22:11:20,696:INFO:Declaring metric variables
2025-05-12 22:11:20,701:INFO:Importing untrained model
2025-05-12 22:11:20,707:INFO:Ridge Regression Imported successfully
2025-05-12 22:11:20,719:INFO:Starting cross validation
2025-05-12 22:11:20,721:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:20,981:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:20,981:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:20,990:INFO:Calculating mean and std
2025-05-12 22:11:20,991:INFO:Creating metrics dataframe
2025-05-12 22:11:20,992:INFO:Uploading results into container
2025-05-12 22:11:20,993:INFO:Uploading model into container now
2025-05-12 22:11:20,993:INFO:_master_model_container: 3
2025-05-12 22:11:20,994:INFO:_display_container: 2
2025-05-12 22:11:20,994:INFO:Ridge(random_state=123)
2025-05-12 22:11:20,994:INFO:create_model() successfully completed......................................
2025-05-12 22:11:21,081:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:21,081:INFO:Creating metrics dataframe
2025-05-12 22:11:21,091:INFO:Initializing Elastic Net
2025-05-12 22:11:21,091:INFO:Total runtime is 0.21550976037979125 minutes
2025-05-12 22:11:21,094:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:21,094:INFO:Initializing create_model()
2025-05-12 22:11:21,094:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:21,095:INFO:Checking exceptions
2025-05-12 22:11:21,095:INFO:Importing libraries
2025-05-12 22:11:21,095:INFO:Copying training dataset
2025-05-12 22:11:21,100:INFO:Defining folds
2025-05-12 22:11:21,100:INFO:Declaring metric variables
2025-05-12 22:11:21,105:INFO:Importing untrained model
2025-05-12 22:11:21,111:INFO:Elastic Net Imported successfully
2025-05-12 22:11:21,120:INFO:Starting cross validation
2025-05-12 22:11:21,121:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:21,430:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:21,431:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:21,436:INFO:Calculating mean and std
2025-05-12 22:11:21,438:INFO:Creating metrics dataframe
2025-05-12 22:11:21,441:INFO:Uploading results into container
2025-05-12 22:11:21,441:INFO:Uploading model into container now
2025-05-12 22:11:21,443:INFO:_master_model_container: 4
2025-05-12 22:11:21,443:INFO:_display_container: 2
2025-05-12 22:11:21,444:INFO:ElasticNet(random_state=123)
2025-05-12 22:11:21,444:INFO:create_model() successfully completed......................................
2025-05-12 22:11:21,537:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:21,537:INFO:Creating metrics dataframe
2025-05-12 22:11:21,545:INFO:Initializing Least Angle Regression
2025-05-12 22:11:21,545:INFO:Total runtime is 0.22307785749435424 minutes
2025-05-12 22:11:21,550:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:21,550:INFO:Initializing create_model()
2025-05-12 22:11:21,550:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:21,550:INFO:Checking exceptions
2025-05-12 22:11:21,550:INFO:Importing libraries
2025-05-12 22:11:21,550:INFO:Copying training dataset
2025-05-12 22:11:21,557:INFO:Defining folds
2025-05-12 22:11:21,558:INFO:Declaring metric variables
2025-05-12 22:11:21,563:INFO:Importing untrained model
2025-05-12 22:11:21,568:INFO:Least Angle Regression Imported successfully
2025-05-12 22:11:21,578:INFO:Starting cross validation
2025-05-12 22:11:21,580:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:21,946:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:21,947:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:21,957:INFO:Calculating mean and std
2025-05-12 22:11:21,959:INFO:Creating metrics dataframe
2025-05-12 22:11:21,962:INFO:Uploading results into container
2025-05-12 22:11:21,963:INFO:Uploading model into container now
2025-05-12 22:11:21,963:INFO:_master_model_container: 5
2025-05-12 22:11:21,964:INFO:_display_container: 2
2025-05-12 22:11:21,964:INFO:Lars(random_state=123)
2025-05-12 22:11:21,964:INFO:create_model() successfully completed......................................
2025-05-12 22:11:22,074:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:22,074:INFO:Creating metrics dataframe
2025-05-12 22:11:22,084:INFO:Initializing Lasso Least Angle Regression
2025-05-12 22:11:22,084:INFO:Total runtime is 0.23206319014231364 minutes
2025-05-12 22:11:22,089:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:22,090:INFO:Initializing create_model()
2025-05-12 22:11:22,090:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:22,090:INFO:Checking exceptions
2025-05-12 22:11:22,090:INFO:Importing libraries
2025-05-12 22:11:22,091:INFO:Copying training dataset
2025-05-12 22:11:22,097:INFO:Defining folds
2025-05-12 22:11:22,097:INFO:Declaring metric variables
2025-05-12 22:11:22,102:INFO:Importing untrained model
2025-05-12 22:11:22,109:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:11:22,119:INFO:Starting cross validation
2025-05-12 22:11:22,121:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:22,389:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:22,389:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:22,398:INFO:Calculating mean and std
2025-05-12 22:11:22,400:INFO:Creating metrics dataframe
2025-05-12 22:11:22,404:INFO:Uploading results into container
2025-05-12 22:11:22,404:INFO:Uploading model into container now
2025-05-12 22:11:22,406:INFO:_master_model_container: 6
2025-05-12 22:11:22,406:INFO:_display_container: 2
2025-05-12 22:11:22,407:INFO:LassoLars(random_state=123)
2025-05-12 22:11:22,408:INFO:create_model() successfully completed......................................
2025-05-12 22:11:22,514:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:22,514:INFO:Creating metrics dataframe
2025-05-12 22:11:22,524:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 22:11:22,524:INFO:Total runtime is 0.23940389951070148 minutes
2025-05-12 22:11:22,529:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:22,529:INFO:Initializing create_model()
2025-05-12 22:11:22,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:22,530:INFO:Checking exceptions
2025-05-12 22:11:22,530:INFO:Importing libraries
2025-05-12 22:11:22,530:INFO:Copying training dataset
2025-05-12 22:11:22,536:INFO:Defining folds
2025-05-12 22:11:22,537:INFO:Declaring metric variables
2025-05-12 22:11:22,542:INFO:Importing untrained model
2025-05-12 22:11:22,549:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 22:11:22,560:INFO:Starting cross validation
2025-05-12 22:11:22,563:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:22,856:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:22,856:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:22,864:INFO:Calculating mean and std
2025-05-12 22:11:22,866:INFO:Creating metrics dataframe
2025-05-12 22:11:22,868:INFO:Uploading results into container
2025-05-12 22:11:22,868:INFO:Uploading model into container now
2025-05-12 22:11:22,869:INFO:_master_model_container: 7
2025-05-12 22:11:22,869:INFO:_display_container: 2
2025-05-12 22:11:22,870:INFO:OrthogonalMatchingPursuit()
2025-05-12 22:11:22,870:INFO:create_model() successfully completed......................................
2025-05-12 22:11:22,966:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:22,967:INFO:Creating metrics dataframe
2025-05-12 22:11:22,976:INFO:Initializing Bayesian Ridge
2025-05-12 22:11:22,976:INFO:Total runtime is 0.2469269871711731 minutes
2025-05-12 22:11:22,981:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:22,981:INFO:Initializing create_model()
2025-05-12 22:11:22,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:22,981:INFO:Checking exceptions
2025-05-12 22:11:22,981:INFO:Importing libraries
2025-05-12 22:11:22,981:INFO:Copying training dataset
2025-05-12 22:11:22,986:INFO:Defining folds
2025-05-12 22:11:22,986:INFO:Declaring metric variables
2025-05-12 22:11:22,991:INFO:Importing untrained model
2025-05-12 22:11:22,999:INFO:Bayesian Ridge Imported successfully
2025-05-12 22:11:23,009:INFO:Starting cross validation
2025-05-12 22:11:23,012:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:23,358:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:23,358:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:23,371:INFO:Calculating mean and std
2025-05-12 22:11:23,373:INFO:Creating metrics dataframe
2025-05-12 22:11:23,377:INFO:Uploading results into container
2025-05-12 22:11:23,378:INFO:Uploading model into container now
2025-05-12 22:11:23,378:INFO:_master_model_container: 8
2025-05-12 22:11:23,379:INFO:_display_container: 2
2025-05-12 22:11:23,380:INFO:BayesianRidge()
2025-05-12 22:11:23,380:INFO:create_model() successfully completed......................................
2025-05-12 22:11:23,483:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:23,483:INFO:Creating metrics dataframe
2025-05-12 22:11:23,493:INFO:Initializing Passive Aggressive Regressor
2025-05-12 22:11:23,493:INFO:Total runtime is 0.25555330912272134 minutes
2025-05-12 22:11:23,498:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:23,498:INFO:Initializing create_model()
2025-05-12 22:11:23,498:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:23,498:INFO:Checking exceptions
2025-05-12 22:11:23,499:INFO:Importing libraries
2025-05-12 22:11:23,499:INFO:Copying training dataset
2025-05-12 22:11:23,504:INFO:Defining folds
2025-05-12 22:11:23,504:INFO:Declaring metric variables
2025-05-12 22:11:23,511:INFO:Importing untrained model
2025-05-12 22:11:23,517:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 22:11:23,525:INFO:Starting cross validation
2025-05-12 22:11:23,529:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:23,837:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:23,837:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:23,847:INFO:Calculating mean and std
2025-05-12 22:11:23,849:INFO:Creating metrics dataframe
2025-05-12 22:11:23,852:INFO:Uploading results into container
2025-05-12 22:11:23,853:INFO:Uploading model into container now
2025-05-12 22:11:23,853:INFO:_master_model_container: 9
2025-05-12 22:11:23,853:INFO:_display_container: 2
2025-05-12 22:11:23,854:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 22:11:23,854:INFO:create_model() successfully completed......................................
2025-05-12 22:11:23,963:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:23,963:INFO:Creating metrics dataframe
2025-05-12 22:11:23,979:INFO:Initializing Huber Regressor
2025-05-12 22:11:23,979:INFO:Total runtime is 0.2636478384335836 minutes
2025-05-12 22:11:23,986:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:23,986:INFO:Initializing create_model()
2025-05-12 22:11:23,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:23,987:INFO:Checking exceptions
2025-05-12 22:11:23,987:INFO:Importing libraries
2025-05-12 22:11:23,987:INFO:Copying training dataset
2025-05-12 22:11:23,993:INFO:Defining folds
2025-05-12 22:11:23,993:INFO:Declaring metric variables
2025-05-12 22:11:24,002:INFO:Importing untrained model
2025-05-12 22:11:24,009:INFO:Huber Regressor Imported successfully
2025-05-12 22:11:24,023:INFO:Starting cross validation
2025-05-12 22:11:24,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:24,470:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:24,470:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:24,477:INFO:Calculating mean and std
2025-05-12 22:11:24,479:INFO:Creating metrics dataframe
2025-05-12 22:11:24,482:INFO:Uploading results into container
2025-05-12 22:11:24,484:INFO:Uploading model into container now
2025-05-12 22:11:24,484:INFO:_master_model_container: 10
2025-05-12 22:11:24,485:INFO:_display_container: 2
2025-05-12 22:11:24,485:INFO:HuberRegressor()
2025-05-12 22:11:24,486:INFO:create_model() successfully completed......................................
2025-05-12 22:11:24,581:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:24,582:INFO:Creating metrics dataframe
2025-05-12 22:11:24,594:INFO:Initializing K Neighbors Regressor
2025-05-12 22:11:24,595:INFO:Total runtime is 0.2739195187886556 minutes
2025-05-12 22:11:24,600:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:24,601:INFO:Initializing create_model()
2025-05-12 22:11:24,601:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:24,601:INFO:Checking exceptions
2025-05-12 22:11:24,601:INFO:Importing libraries
2025-05-12 22:11:24,601:INFO:Copying training dataset
2025-05-12 22:11:24,607:INFO:Defining folds
2025-05-12 22:11:24,607:INFO:Declaring metric variables
2025-05-12 22:11:24,615:INFO:Importing untrained model
2025-05-12 22:11:24,619:INFO:K Neighbors Regressor Imported successfully
2025-05-12 22:11:24,627:INFO:Starting cross validation
2025-05-12 22:11:24,629:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:24,953:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:24,953:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:24,956:INFO:Calculating mean and std
2025-05-12 22:11:24,958:INFO:Creating metrics dataframe
2025-05-12 22:11:24,960:INFO:Uploading results into container
2025-05-12 22:11:24,961:INFO:Uploading model into container now
2025-05-12 22:11:24,962:INFO:_master_model_container: 11
2025-05-12 22:11:24,962:INFO:_display_container: 2
2025-05-12 22:11:24,963:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 22:11:24,963:INFO:create_model() successfully completed......................................
2025-05-12 22:11:25,069:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:25,069:INFO:Creating metrics dataframe
2025-05-12 22:11:25,083:INFO:Initializing Decision Tree Regressor
2025-05-12 22:11:25,083:INFO:Total runtime is 0.28204752604166666 minutes
2025-05-12 22:11:25,088:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:25,089:INFO:Initializing create_model()
2025-05-12 22:11:25,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:25,089:INFO:Checking exceptions
2025-05-12 22:11:25,089:INFO:Importing libraries
2025-05-12 22:11:25,089:INFO:Copying training dataset
2025-05-12 22:11:25,097:INFO:Defining folds
2025-05-12 22:11:25,097:INFO:Declaring metric variables
2025-05-12 22:11:25,104:INFO:Importing untrained model
2025-05-12 22:11:25,111:INFO:Decision Tree Regressor Imported successfully
2025-05-12 22:11:25,140:INFO:Starting cross validation
2025-05-12 22:11:25,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:25,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:25,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:25,626:INFO:Calculating mean and std
2025-05-12 22:11:25,630:INFO:Creating metrics dataframe
2025-05-12 22:11:25,632:INFO:Uploading results into container
2025-05-12 22:11:25,634:INFO:Uploading model into container now
2025-05-12 22:11:25,635:INFO:_master_model_container: 12
2025-05-12 22:11:25,635:INFO:_display_container: 2
2025-05-12 22:11:25,636:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 22:11:25,636:INFO:create_model() successfully completed......................................
2025-05-12 22:11:25,765:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:25,765:INFO:Creating metrics dataframe
2025-05-12 22:11:25,779:INFO:Initializing Random Forest Regressor
2025-05-12 22:11:25,779:INFO:Total runtime is 0.2936530113220215 minutes
2025-05-12 22:11:25,785:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:25,786:INFO:Initializing create_model()
2025-05-12 22:11:25,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:25,786:INFO:Checking exceptions
2025-05-12 22:11:25,786:INFO:Importing libraries
2025-05-12 22:11:25,786:INFO:Copying training dataset
2025-05-12 22:11:25,795:INFO:Defining folds
2025-05-12 22:11:25,795:INFO:Declaring metric variables
2025-05-12 22:11:25,800:INFO:Importing untrained model
2025-05-12 22:11:25,808:INFO:Random Forest Regressor Imported successfully
2025-05-12 22:11:25,822:INFO:Starting cross validation
2025-05-12 22:11:25,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:26,795:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:26,795:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:26,805:INFO:Calculating mean and std
2025-05-12 22:11:26,807:INFO:Creating metrics dataframe
2025-05-12 22:11:26,810:INFO:Uploading results into container
2025-05-12 22:11:26,811:INFO:Uploading model into container now
2025-05-12 22:11:26,813:INFO:_master_model_container: 13
2025-05-12 22:11:26,813:INFO:_display_container: 2
2025-05-12 22:11:26,814:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:11:26,815:INFO:create_model() successfully completed......................................
2025-05-12 22:11:26,919:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:26,920:INFO:Creating metrics dataframe
2025-05-12 22:11:26,933:INFO:Initializing Extra Trees Regressor
2025-05-12 22:11:26,933:INFO:Total runtime is 0.3128852486610413 minutes
2025-05-12 22:11:26,938:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:26,938:INFO:Initializing create_model()
2025-05-12 22:11:26,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:26,939:INFO:Checking exceptions
2025-05-12 22:11:26,939:INFO:Importing libraries
2025-05-12 22:11:26,939:INFO:Copying training dataset
2025-05-12 22:11:26,945:INFO:Defining folds
2025-05-12 22:11:26,946:INFO:Declaring metric variables
2025-05-12 22:11:26,953:INFO:Importing untrained model
2025-05-12 22:11:26,959:INFO:Extra Trees Regressor Imported successfully
2025-05-12 22:11:26,971:INFO:Starting cross validation
2025-05-12 22:11:26,976:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:27,938:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:27,939:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:27,951:INFO:Calculating mean and std
2025-05-12 22:11:27,953:INFO:Creating metrics dataframe
2025-05-12 22:11:27,956:INFO:Uploading results into container
2025-05-12 22:11:27,956:INFO:Uploading model into container now
2025-05-12 22:11:27,957:INFO:_master_model_container: 14
2025-05-12 22:11:27,957:INFO:_display_container: 2
2025-05-12 22:11:27,959:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:11:27,959:INFO:create_model() successfully completed......................................
2025-05-12 22:11:28,112:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:28,112:INFO:Creating metrics dataframe
2025-05-12 22:11:28,135:INFO:Initializing AdaBoost Regressor
2025-05-12 22:11:28,135:INFO:Total runtime is 0.3329196174939474 minutes
2025-05-12 22:11:28,145:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:28,146:INFO:Initializing create_model()
2025-05-12 22:11:28,146:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:28,146:INFO:Checking exceptions
2025-05-12 22:11:28,146:INFO:Importing libraries
2025-05-12 22:11:28,147:INFO:Copying training dataset
2025-05-12 22:11:28,158:INFO:Defining folds
2025-05-12 22:11:28,158:INFO:Declaring metric variables
2025-05-12 22:11:28,166:INFO:Importing untrained model
2025-05-12 22:11:28,175:INFO:AdaBoost Regressor Imported successfully
2025-05-12 22:11:28,216:INFO:Starting cross validation
2025-05-12 22:11:28,222:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:28,815:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:28,815:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:28,824:INFO:Calculating mean and std
2025-05-12 22:11:28,825:INFO:Creating metrics dataframe
2025-05-12 22:11:28,827:INFO:Uploading results into container
2025-05-12 22:11:28,827:INFO:Uploading model into container now
2025-05-12 22:11:28,827:INFO:_master_model_container: 15
2025-05-12 22:11:28,828:INFO:_display_container: 2
2025-05-12 22:11:28,828:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 22:11:28,829:INFO:create_model() successfully completed......................................
2025-05-12 22:11:28,915:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:28,916:INFO:Creating metrics dataframe
2025-05-12 22:11:28,927:INFO:Initializing Gradient Boosting Regressor
2025-05-12 22:11:28,927:INFO:Total runtime is 0.34611835082372033 minutes
2025-05-12 22:11:28,931:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:28,931:INFO:Initializing create_model()
2025-05-12 22:11:28,931:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:28,931:INFO:Checking exceptions
2025-05-12 22:11:28,931:INFO:Importing libraries
2025-05-12 22:11:28,931:INFO:Copying training dataset
2025-05-12 22:11:28,936:INFO:Defining folds
2025-05-12 22:11:28,936:INFO:Declaring metric variables
2025-05-12 22:11:28,940:INFO:Importing untrained model
2025-05-12 22:11:28,946:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 22:11:28,954:INFO:Starting cross validation
2025-05-12 22:11:28,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:29,586:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:29,586:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:29,591:INFO:Calculating mean and std
2025-05-12 22:11:29,593:INFO:Creating metrics dataframe
2025-05-12 22:11:29,596:INFO:Uploading results into container
2025-05-12 22:11:29,597:INFO:Uploading model into container now
2025-05-12 22:11:29,598:INFO:_master_model_container: 16
2025-05-12 22:11:29,599:INFO:_display_container: 2
2025-05-12 22:11:29,600:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 22:11:29,600:INFO:create_model() successfully completed......................................
2025-05-12 22:11:29,706:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:29,706:INFO:Creating metrics dataframe
2025-05-12 22:11:29,720:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:11:29,721:INFO:Total runtime is 0.3593586881955465 minutes
2025-05-12 22:11:29,728:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:29,728:INFO:Initializing create_model()
2025-05-12 22:11:29,728:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:29,729:INFO:Checking exceptions
2025-05-12 22:11:29,729:INFO:Importing libraries
2025-05-12 22:11:29,729:INFO:Copying training dataset
2025-05-12 22:11:29,734:INFO:Defining folds
2025-05-12 22:11:29,734:INFO:Declaring metric variables
2025-05-12 22:11:29,745:INFO:Importing untrained model
2025-05-12 22:11:29,751:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:11:29,769:INFO:Starting cross validation
2025-05-12 22:11:29,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:30,516:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:30,516:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:30,529:INFO:Calculating mean and std
2025-05-12 22:11:30,531:INFO:Creating metrics dataframe
2025-05-12 22:11:30,536:INFO:Uploading results into container
2025-05-12 22:11:30,536:INFO:Uploading model into container now
2025-05-12 22:11:30,538:INFO:_master_model_container: 17
2025-05-12 22:11:30,538:INFO:_display_container: 2
2025-05-12 22:11:30,539:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:11:30,540:INFO:create_model() successfully completed......................................
2025-05-12 22:11:30,657:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:30,657:INFO:Creating metrics dataframe
2025-05-12 22:11:30,670:INFO:Initializing Dummy Regressor
2025-05-12 22:11:30,670:INFO:Total runtime is 0.37517590522766114 minutes
2025-05-12 22:11:30,675:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:30,675:INFO:Initializing create_model()
2025-05-12 22:11:30,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:30,676:INFO:Checking exceptions
2025-05-12 22:11:30,676:INFO:Importing libraries
2025-05-12 22:11:30,676:INFO:Copying training dataset
2025-05-12 22:11:30,681:INFO:Defining folds
2025-05-12 22:11:30,681:INFO:Declaring metric variables
2025-05-12 22:11:30,687:INFO:Importing untrained model
2025-05-12 22:11:30,693:INFO:Dummy Regressor Imported successfully
2025-05-12 22:11:30,702:INFO:Starting cross validation
2025-05-12 22:11:30,704:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:31,008:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:31,008:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:31,011:INFO:Calculating mean and std
2025-05-12 22:11:31,012:INFO:Creating metrics dataframe
2025-05-12 22:11:31,015:INFO:Uploading results into container
2025-05-12 22:11:31,016:INFO:Uploading model into container now
2025-05-12 22:11:31,017:INFO:_master_model_container: 18
2025-05-12 22:11:31,017:INFO:_display_container: 2
2025-05-12 22:11:31,018:INFO:DummyRegressor()
2025-05-12 22:11:31,018:INFO:create_model() successfully completed......................................
2025-05-12 22:11:31,117:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:31,118:INFO:Creating metrics dataframe
2025-05-12 22:11:31,134:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:11:31,150:INFO:Initializing create_model()
2025-05-12 22:11:31,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:31,151:INFO:Checking exceptions
2025-05-12 22:11:31,156:INFO:Importing libraries
2025-05-12 22:11:31,156:INFO:Copying training dataset
2025-05-12 22:11:31,161:INFO:Defining folds
2025-05-12 22:11:31,161:INFO:Declaring metric variables
2025-05-12 22:11:31,161:INFO:Importing untrained model
2025-05-12 22:11:31,161:INFO:Declaring custom model
2025-05-12 22:11:31,163:INFO:Lasso Regression Imported successfully
2025-05-12 22:11:31,164:INFO:Cross validation set to False
2025-05-12 22:11:31,164:INFO:Fitting Model
2025-05-12 22:11:31,240:INFO:Lasso(random_state=123)
2025-05-12 22:11:31,240:INFO:create_model() successfully completed......................................
2025-05-12 22:11:31,394:INFO:_master_model_container: 18
2025-05-12 22:11:31,395:INFO:_display_container: 2
2025-05-12 22:11:31,395:INFO:Lasso(random_state=123)
2025-05-12 22:11:31,395:INFO:compare_models() successfully completed......................................
2025-05-12 22:11:59,653:INFO:Initializing create_model()
2025-05-12 22:11:59,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=lasso, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:59,653:INFO:Checking exceptions
2025-05-12 22:11:59,669:INFO:Importing libraries
2025-05-12 22:11:59,670:INFO:Copying training dataset
2025-05-12 22:11:59,676:INFO:Defining folds
2025-05-12 22:11:59,676:INFO:Declaring metric variables
2025-05-12 22:11:59,681:INFO:Importing untrained model
2025-05-12 22:11:59,687:INFO:Lasso Regression Imported successfully
2025-05-12 22:11:59,698:INFO:Starting cross validation
2025-05-12 22:11:59,700:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:59,899:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:59,899:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:59,904:INFO:Calculating mean and std
2025-05-12 22:11:59,904:INFO:Creating metrics dataframe
2025-05-12 22:11:59,908:INFO:Finalizing model
2025-05-12 22:11:59,941:INFO:Uploading results into container
2025-05-12 22:11:59,942:INFO:Uploading model into container now
2025-05-12 22:11:59,950:INFO:_master_model_container: 19
2025-05-12 22:11:59,951:INFO:_display_container: 3
2025-05-12 22:11:59,951:INFO:Lasso(random_state=123)
2025-05-12 22:11:59,951:INFO:create_model() successfully completed......................................
2025-05-12 22:12:19,541:INFO:Initializing create_model()
2025-05-12 22:12:19,541:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=lasso, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:12:19,541:INFO:Checking exceptions
2025-05-12 22:12:19,558:INFO:Importing libraries
2025-05-12 22:12:19,558:INFO:Copying training dataset
2025-05-12 22:12:19,564:INFO:Defining folds
2025-05-12 22:12:19,564:INFO:Declaring metric variables
2025-05-12 22:12:19,567:INFO:Importing untrained model
2025-05-12 22:12:19,572:INFO:Lasso Regression Imported successfully
2025-05-12 22:12:19,580:INFO:Starting cross validation
2025-05-12 22:12:19,582:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:12:19,869:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:12:19,869:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:12:19,879:INFO:Calculating mean and std
2025-05-12 22:12:19,879:INFO:Creating metrics dataframe
2025-05-12 22:12:19,883:INFO:Finalizing model
2025-05-12 22:12:19,921:INFO:Uploading results into container
2025-05-12 22:12:19,921:INFO:Uploading model into container now
2025-05-12 22:12:19,930:INFO:_master_model_container: 20
2025-05-12 22:12:19,931:INFO:_display_container: 4
2025-05-12 22:12:19,931:INFO:Lasso(random_state=123)
2025-05-12 22:12:19,931:INFO:create_model() successfully completed......................................
2025-05-12 22:12:37,058:INFO:Initializing tune_model()
2025-05-12 22:12:37,058:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=Lasso(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:12:37,058:INFO:Checking exceptions
2025-05-12 22:12:37,076:INFO:Copying training dataset
2025-05-12 22:12:37,079:INFO:Checking base model
2025-05-12 22:12:37,080:INFO:Base model : Lasso Regression
2025-05-12 22:12:37,085:INFO:Declaring metric variables
2025-05-12 22:12:37,089:INFO:Defining Hyperparameters
2025-05-12 22:12:37,251:INFO:Tuning with n_jobs=-1
2025-05-12 22:12:37,251:INFO:Initializing RandomizedSearchCV
2025-05-12 22:12:39,647:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 5.62}
2025-05-12 22:12:39,649:INFO:Hyperparameter search completed
2025-05-12 22:12:39,649:INFO:SubProcess create_model() called ==================================
2025-05-12 22:12:39,651:INFO:Initializing create_model()
2025-05-12 22:12:39,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7AC73D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'alpha': 5.62})
2025-05-12 22:12:39,653:INFO:Checking exceptions
2025-05-12 22:12:39,653:INFO:Importing libraries
2025-05-12 22:12:39,653:INFO:Copying training dataset
2025-05-12 22:12:39,669:INFO:Defining folds
2025-05-12 22:12:39,669:INFO:Declaring metric variables
2025-05-12 22:12:39,676:INFO:Importing untrained model
2025-05-12 22:12:39,676:INFO:Declaring custom model
2025-05-12 22:12:39,683:INFO:Lasso Regression Imported successfully
2025-05-12 22:12:39,699:INFO:Starting cross validation
2025-05-12 22:12:39,701:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:12:40,124:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:12:40,124:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:12:40,126:INFO:Calculating mean and std
2025-05-12 22:12:40,127:INFO:Creating metrics dataframe
2025-05-12 22:12:40,137:INFO:Finalizing model
2025-05-12 22:12:40,228:INFO:Uploading results into container
2025-05-12 22:12:40,230:INFO:Uploading model into container now
2025-05-12 22:12:40,230:INFO:_master_model_container: 21
2025-05-12 22:12:40,230:INFO:_display_container: 5
2025-05-12 22:12:40,231:INFO:Lasso(alpha=5.62, random_state=123)
2025-05-12 22:12:40,231:INFO:create_model() successfully completed......................................
2025-05-12 22:12:40,361:INFO:SubProcess create_model() end ==================================
2025-05-12 22:12:40,361:INFO:choose_better activated
2025-05-12 22:12:40,366:INFO:SubProcess create_model() called ==================================
2025-05-12 22:12:40,367:INFO:Initializing create_model()
2025-05-12 22:12:40,368:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:12:40,368:INFO:Checking exceptions
2025-05-12 22:12:40,371:INFO:Importing libraries
2025-05-12 22:12:40,371:INFO:Copying training dataset
2025-05-12 22:12:40,381:INFO:Defining folds
2025-05-12 22:12:40,382:INFO:Declaring metric variables
2025-05-12 22:12:40,382:INFO:Importing untrained model
2025-05-12 22:12:40,382:INFO:Declaring custom model
2025-05-12 22:12:40,383:INFO:Lasso Regression Imported successfully
2025-05-12 22:12:40,383:INFO:Starting cross validation
2025-05-12 22:12:40,406:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:12:40,864:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:12:40,866:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:12:40,875:INFO:Calculating mean and std
2025-05-12 22:12:40,876:INFO:Creating metrics dataframe
2025-05-12 22:12:40,880:INFO:Finalizing model
2025-05-12 22:12:40,949:INFO:Uploading results into container
2025-05-12 22:12:40,950:INFO:Uploading model into container now
2025-05-12 22:12:40,951:INFO:_master_model_container: 22
2025-05-12 22:12:40,951:INFO:_display_container: 6
2025-05-12 22:12:40,951:INFO:Lasso(random_state=123)
2025-05-12 22:12:40,951:INFO:create_model() successfully completed......................................
2025-05-12 22:12:41,081:INFO:SubProcess create_model() end ==================================
2025-05-12 22:12:41,081:INFO:Lasso(random_state=123) result for R2 is -0.0421
2025-05-12 22:12:41,082:INFO:Lasso(alpha=5.62, random_state=123) result for R2 is -0.0421
2025-05-12 22:12:41,082:INFO:Lasso(random_state=123) is best model
2025-05-12 22:12:41,082:INFO:choose_better completed
2025-05-12 22:12:41,082:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:12:41,097:INFO:_master_model_container: 22
2025-05-12 22:12:41,097:INFO:_display_container: 5
2025-05-12 22:12:41,098:INFO:Lasso(random_state=123)
2025-05-12 22:12:41,098:INFO:tune_model() successfully completed......................................
2025-05-12 22:13:02,146:INFO:Initializing evaluate_model()
2025-05-12 22:13:02,146:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=Lasso(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:13:02,154:INFO:Initializing plot_model()
2025-05-12 22:13:02,155:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=Lasso(random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:13:02,155:INFO:Checking exceptions
2025-05-12 22:13:02,157:INFO:Preloading libraries
2025-05-12 22:13:02,158:INFO:Copying training dataset
2025-05-12 22:13:02,158:INFO:Plot type: pipeline
2025-05-12 22:13:02,322:INFO:Visual Rendered Successfully
2025-05-12 22:13:02,446:INFO:plot_model() successfully completed......................................
2025-05-12 22:13:23,735:INFO:Initializing predict_model()
2025-05-12 22:13:23,735:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=Lasso(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EA7AD94E00>)
2025-05-12 22:13:23,736:INFO:Checking exceptions
2025-05-12 22:13:23,736:INFO:Preloading libraries
2025-05-12 22:13:23,869:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:18:27,340:INFO:PyCaret RegressionExperiment
2025-05-12 22:18:27,341:INFO:Logging name: reg-default-name
2025-05-12 22:18:27,341:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:18:27,341:INFO:version 3.3.2
2025-05-12 22:18:27,341:INFO:Initializing setup()
2025-05-12 22:18:27,341:INFO:self.USI: a4a7
2025-05-12 22:18:27,341:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'transform_target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:18:27,341:INFO:Checking environment
2025-05-12 22:18:27,341:INFO:python_version: 3.11.8
2025-05-12 22:18:27,341:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:18:27,341:INFO:machine: AMD64
2025-05-12 22:18:27,341:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:18:27,347:INFO:Memory: svmem(total=16907886592, available=4068175872, percent=75.9, used=12839710720, free=4068175872)
2025-05-12 22:18:27,348:INFO:Physical Core: 4
2025-05-12 22:18:27,348:INFO:Logical Core: 8
2025-05-12 22:18:27,348:INFO:Checking libraries
2025-05-12 22:18:27,348:INFO:System:
2025-05-12 22:18:27,348:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:18:27,348:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:18:27,348:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:18:27,348:INFO:PyCaret required dependencies:
2025-05-12 22:18:27,348:INFO:                 pip: 24.0
2025-05-12 22:18:27,348:INFO:          setuptools: 65.5.0
2025-05-12 22:18:27,348:INFO:             pycaret: 3.3.2
2025-05-12 22:18:27,348:INFO:             IPython: 9.2.0
2025-05-12 22:18:27,348:INFO:          ipywidgets: 8.1.7
2025-05-12 22:18:27,348:INFO:                tqdm: 4.67.1
2025-05-12 22:18:27,348:INFO:               numpy: 1.26.4
2025-05-12 22:18:27,348:INFO:              pandas: 2.1.4
2025-05-12 22:18:27,348:INFO:              jinja2: 3.1.6
2025-05-12 22:18:27,348:INFO:               scipy: 1.11.4
2025-05-12 22:18:27,348:INFO:              joblib: 1.3.2
2025-05-12 22:18:27,348:INFO:             sklearn: 1.4.2
2025-05-12 22:18:27,348:INFO:                pyod: 2.0.5
2025-05-12 22:18:27,348:INFO:            imblearn: 0.13.0
2025-05-12 22:18:27,349:INFO:   category_encoders: 2.7.0
2025-05-12 22:18:27,349:INFO:            lightgbm: 4.6.0
2025-05-12 22:18:27,349:INFO:               numba: 0.61.2
2025-05-12 22:18:27,349:INFO:            requests: 2.32.3
2025-05-12 22:18:27,349:INFO:          matplotlib: 3.7.5
2025-05-12 22:18:27,349:INFO:          scikitplot: 0.3.7
2025-05-12 22:18:27,349:INFO:         yellowbrick: 1.5
2025-05-12 22:18:27,349:INFO:              plotly: 5.24.1
2025-05-12 22:18:27,349:INFO:    plotly-resampler: Not installed
2025-05-12 22:18:27,349:INFO:             kaleido: 0.2.1
2025-05-12 22:18:27,349:INFO:           schemdraw: 0.15
2025-05-12 22:18:27,349:INFO:         statsmodels: 0.14.4
2025-05-12 22:18:27,349:INFO:              sktime: 0.26.0
2025-05-12 22:18:27,349:INFO:               tbats: 1.1.3
2025-05-12 22:18:27,349:INFO:            pmdarima: 2.0.4
2025-05-12 22:18:27,349:INFO:              psutil: 7.0.0
2025-05-12 22:18:27,349:INFO:          markupsafe: 3.0.2
2025-05-12 22:18:27,350:INFO:             pickle5: Not installed
2025-05-12 22:18:27,350:INFO:         cloudpickle: 3.1.1
2025-05-12 22:18:27,350:INFO:         deprecation: 2.1.0
2025-05-12 22:18:27,350:INFO:              xxhash: 3.5.0
2025-05-12 22:18:27,350:INFO:           wurlitzer: Not installed
2025-05-12 22:18:27,350:INFO:PyCaret optional dependencies:
2025-05-12 22:18:27,350:INFO:                shap: Not installed
2025-05-12 22:18:27,350:INFO:           interpret: Not installed
2025-05-12 22:18:27,350:INFO:                umap: Not installed
2025-05-12 22:18:27,350:INFO:     ydata_profiling: Not installed
2025-05-12 22:18:27,350:INFO:  explainerdashboard: Not installed
2025-05-12 22:18:27,350:INFO:             autoviz: Not installed
2025-05-12 22:18:27,350:INFO:           fairlearn: Not installed
2025-05-12 22:18:27,350:INFO:          deepchecks: Not installed
2025-05-12 22:18:27,350:INFO:             xgboost: Not installed
2025-05-12 22:18:27,351:INFO:            catboost: Not installed
2025-05-12 22:18:27,351:INFO:              kmodes: Not installed
2025-05-12 22:18:27,351:INFO:             mlxtend: Not installed
2025-05-12 22:18:27,351:INFO:       statsforecast: Not installed
2025-05-12 22:18:27,351:INFO:        tune_sklearn: Not installed
2025-05-12 22:18:27,351:INFO:                 ray: Not installed
2025-05-12 22:18:27,351:INFO:            hyperopt: Not installed
2025-05-12 22:18:27,351:INFO:              optuna: Not installed
2025-05-12 22:18:27,351:INFO:               skopt: Not installed
2025-05-12 22:18:27,351:INFO:              mlflow: Not installed
2025-05-12 22:18:27,351:INFO:              gradio: Not installed
2025-05-12 22:18:27,352:INFO:             fastapi: Not installed
2025-05-12 22:18:27,352:INFO:             uvicorn: Not installed
2025-05-12 22:18:27,352:INFO:              m2cgen: Not installed
2025-05-12 22:18:27,352:INFO:           evidently: Not installed
2025-05-12 22:18:27,352:INFO:               fugue: Not installed
2025-05-12 22:18:27,352:INFO:           streamlit: Not installed
2025-05-12 22:18:27,352:INFO:             prophet: Not installed
2025-05-12 22:18:27,352:INFO:None
2025-05-12 22:18:27,352:INFO:Set up data.
2025-05-12 22:18:27,358:INFO:Set up folding strategy.
2025-05-12 22:18:27,358:INFO:Set up train/test split.
2025-05-12 22:18:27,367:INFO:Set up index.
2025-05-12 22:18:27,367:INFO:Assigning column types.
2025-05-12 22:18:27,371:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:18:27,371:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,380:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,389:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,451:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,487:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,487:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,488:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,492:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,544:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,585:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,586:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,586:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:18:27,590:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,593:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,643:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,683:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,687:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,691:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,737:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,771:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,773:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:18:27,781:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,823:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,858:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,859:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,867:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,913:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,950:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,950:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:18:28,005:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:28,043:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:28,044:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:28,129:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:28,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,130:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:18:28,181:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:28,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,270:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:28,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,309:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,309:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:18:28,408:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,498:INFO:Preparing preprocessing pipeline...
2025-05-12 22:18:28,498:INFO:Set up simple imputation.
2025-05-12 22:18:28,500:INFO:Set up encoding of categorical features.
2025-05-12 22:18:28,500:INFO:Set up feature normalization.
2025-05-12 22:18:28,549:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:18:28,554:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 22:18:28,554:INFO:Creating final display dataframe.
2025-05-12 22:18:28,693:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type        Regression
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              a4a7
2025-05-12 22:18:28,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,913:INFO:setup() successfully completed in 1.57s...............
2025-05-12 22:18:28,928:INFO:Initializing compare_models()
2025-05-12 22:18:28,929:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 22:18:28,929:INFO:Checking exceptions
2025-05-12 22:18:28,930:INFO:Preparing display monitor
2025-05-12 22:18:28,954:INFO:Initializing Linear Regression
2025-05-12 22:18:28,954:INFO:Total runtime is 0.0 minutes
2025-05-12 22:18:28,959:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:28,959:INFO:Initializing create_model()
2025-05-12 22:18:28,960:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:28,960:INFO:Checking exceptions
2025-05-12 22:18:28,960:INFO:Importing libraries
2025-05-12 22:18:28,960:INFO:Copying training dataset
2025-05-12 22:18:28,966:INFO:Defining folds
2025-05-12 22:18:28,966:INFO:Declaring metric variables
2025-05-12 22:18:28,971:INFO:Importing untrained model
2025-05-12 22:18:28,974:INFO:Linear Regression Imported successfully
2025-05-12 22:18:28,983:INFO:Starting cross validation
2025-05-12 22:18:28,984:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:38,439:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:38,441:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:38,696:INFO:Calculating mean and std
2025-05-12 22:18:38,697:INFO:Creating metrics dataframe
2025-05-12 22:18:38,701:INFO:Uploading results into container
2025-05-12 22:18:38,703:INFO:Uploading model into container now
2025-05-12 22:18:38,703:INFO:_master_model_container: 1
2025-05-12 22:18:38,705:INFO:_display_container: 2
2025-05-12 22:18:38,706:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:18:38,706:INFO:create_model() successfully completed......................................
2025-05-12 22:18:38,826:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:38,827:INFO:Creating metrics dataframe
2025-05-12 22:18:38,834:INFO:Initializing Lasso Regression
2025-05-12 22:18:38,834:INFO:Total runtime is 0.16466412941614786 minutes
2025-05-12 22:18:38,839:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:38,839:INFO:Initializing create_model()
2025-05-12 22:18:38,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:38,839:INFO:Checking exceptions
2025-05-12 22:18:38,839:INFO:Importing libraries
2025-05-12 22:18:38,839:INFO:Copying training dataset
2025-05-12 22:18:38,844:INFO:Defining folds
2025-05-12 22:18:38,844:INFO:Declaring metric variables
2025-05-12 22:18:38,849:INFO:Importing untrained model
2025-05-12 22:18:38,857:INFO:Lasso Regression Imported successfully
2025-05-12 22:18:38,866:INFO:Starting cross validation
2025-05-12 22:18:38,868:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:39,174:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:39,175:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:39,185:INFO:Calculating mean and std
2025-05-12 22:18:39,187:INFO:Creating metrics dataframe
2025-05-12 22:18:39,190:INFO:Uploading results into container
2025-05-12 22:18:39,191:INFO:Uploading model into container now
2025-05-12 22:18:39,191:INFO:_master_model_container: 2
2025-05-12 22:18:39,191:INFO:_display_container: 2
2025-05-12 22:18:39,191:INFO:Lasso(random_state=123)
2025-05-12 22:18:39,192:INFO:create_model() successfully completed......................................
2025-05-12 22:18:39,282:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:39,282:INFO:Creating metrics dataframe
2025-05-12 22:18:39,292:INFO:Initializing Ridge Regression
2025-05-12 22:18:39,292:INFO:Total runtime is 0.1722898761431376 minutes
2025-05-12 22:18:39,297:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:39,297:INFO:Initializing create_model()
2025-05-12 22:18:39,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:39,297:INFO:Checking exceptions
2025-05-12 22:18:39,297:INFO:Importing libraries
2025-05-12 22:18:39,298:INFO:Copying training dataset
2025-05-12 22:18:39,303:INFO:Defining folds
2025-05-12 22:18:39,304:INFO:Declaring metric variables
2025-05-12 22:18:39,309:INFO:Importing untrained model
2025-05-12 22:18:39,313:INFO:Ridge Regression Imported successfully
2025-05-12 22:18:39,324:INFO:Starting cross validation
2025-05-12 22:18:39,328:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:39,573:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:39,574:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:39,579:INFO:Calculating mean and std
2025-05-12 22:18:39,581:INFO:Creating metrics dataframe
2025-05-12 22:18:39,582:INFO:Uploading results into container
2025-05-12 22:18:39,584:INFO:Uploading model into container now
2025-05-12 22:18:39,584:INFO:_master_model_container: 3
2025-05-12 22:18:39,584:INFO:_display_container: 2
2025-05-12 22:18:39,585:INFO:Ridge(random_state=123)
2025-05-12 22:18:39,585:INFO:create_model() successfully completed......................................
2025-05-12 22:18:39,680:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:39,681:INFO:Creating metrics dataframe
2025-05-12 22:18:39,688:INFO:Initializing Elastic Net
2025-05-12 22:18:39,688:INFO:Total runtime is 0.17889271179835 minutes
2025-05-12 22:18:39,691:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:39,691:INFO:Initializing create_model()
2025-05-12 22:18:39,691:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:39,693:INFO:Checking exceptions
2025-05-12 22:18:39,693:INFO:Importing libraries
2025-05-12 22:18:39,693:INFO:Copying training dataset
2025-05-12 22:18:39,697:INFO:Defining folds
2025-05-12 22:18:39,698:INFO:Declaring metric variables
2025-05-12 22:18:39,701:INFO:Importing untrained model
2025-05-12 22:18:39,713:INFO:Elastic Net Imported successfully
2025-05-12 22:18:39,753:INFO:Starting cross validation
2025-05-12 22:18:39,756:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:40,058:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:40,059:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:40,062:INFO:Calculating mean and std
2025-05-12 22:18:40,063:INFO:Creating metrics dataframe
2025-05-12 22:18:40,066:INFO:Uploading results into container
2025-05-12 22:18:40,067:INFO:Uploading model into container now
2025-05-12 22:18:40,068:INFO:_master_model_container: 4
2025-05-12 22:18:40,069:INFO:_display_container: 2
2025-05-12 22:18:40,070:INFO:ElasticNet(random_state=123)
2025-05-12 22:18:40,070:INFO:create_model() successfully completed......................................
2025-05-12 22:18:40,163:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:40,163:INFO:Creating metrics dataframe
2025-05-12 22:18:40,170:INFO:Initializing Least Angle Regression
2025-05-12 22:18:40,170:INFO:Total runtime is 0.18693626721700032 minutes
2025-05-12 22:18:40,174:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:40,174:INFO:Initializing create_model()
2025-05-12 22:18:40,174:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:40,174:INFO:Checking exceptions
2025-05-12 22:18:40,174:INFO:Importing libraries
2025-05-12 22:18:40,174:INFO:Copying training dataset
2025-05-12 22:18:40,179:INFO:Defining folds
2025-05-12 22:18:40,179:INFO:Declaring metric variables
2025-05-12 22:18:40,184:INFO:Importing untrained model
2025-05-12 22:18:40,191:INFO:Least Angle Regression Imported successfully
2025-05-12 22:18:40,200:INFO:Starting cross validation
2025-05-12 22:18:40,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:40,449:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:40,450:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:40,459:INFO:Calculating mean and std
2025-05-12 22:18:40,460:INFO:Creating metrics dataframe
2025-05-12 22:18:40,463:INFO:Uploading results into container
2025-05-12 22:18:40,463:INFO:Uploading model into container now
2025-05-12 22:18:40,464:INFO:_master_model_container: 5
2025-05-12 22:18:40,464:INFO:_display_container: 2
2025-05-12 22:18:40,464:INFO:Lars(random_state=123)
2025-05-12 22:18:40,464:INFO:create_model() successfully completed......................................
2025-05-12 22:18:40,555:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:40,555:INFO:Creating metrics dataframe
2025-05-12 22:18:40,564:INFO:Initializing Lasso Least Angle Regression
2025-05-12 22:18:40,564:INFO:Total runtime is 0.1934968630472819 minutes
2025-05-12 22:18:40,569:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:40,570:INFO:Initializing create_model()
2025-05-12 22:18:40,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:40,570:INFO:Checking exceptions
2025-05-12 22:18:40,571:INFO:Importing libraries
2025-05-12 22:18:40,571:INFO:Copying training dataset
2025-05-12 22:18:40,575:INFO:Defining folds
2025-05-12 22:18:40,576:INFO:Declaring metric variables
2025-05-12 22:18:40,580:INFO:Importing untrained model
2025-05-12 22:18:40,583:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:18:40,594:INFO:Starting cross validation
2025-05-12 22:18:40,596:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:40,887:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:40,887:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:40,896:INFO:Calculating mean and std
2025-05-12 22:18:40,897:INFO:Creating metrics dataframe
2025-05-12 22:18:40,899:INFO:Uploading results into container
2025-05-12 22:18:40,900:INFO:Uploading model into container now
2025-05-12 22:18:40,901:INFO:_master_model_container: 6
2025-05-12 22:18:40,901:INFO:_display_container: 2
2025-05-12 22:18:40,901:INFO:LassoLars(random_state=123)
2025-05-12 22:18:40,902:INFO:create_model() successfully completed......................................
2025-05-12 22:18:40,994:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:40,994:INFO:Creating metrics dataframe
2025-05-12 22:18:41,004:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 22:18:41,004:INFO:Total runtime is 0.2008352518081665 minutes
2025-05-12 22:18:41,009:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:41,009:INFO:Initializing create_model()
2025-05-12 22:18:41,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:41,009:INFO:Checking exceptions
2025-05-12 22:18:41,009:INFO:Importing libraries
2025-05-12 22:18:41,009:INFO:Copying training dataset
2025-05-12 22:18:41,014:INFO:Defining folds
2025-05-12 22:18:41,015:INFO:Declaring metric variables
2025-05-12 22:18:41,019:INFO:Importing untrained model
2025-05-12 22:18:41,026:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 22:18:41,034:INFO:Starting cross validation
2025-05-12 22:18:41,037:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:41,279:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:41,279:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:41,281:INFO:Calculating mean and std
2025-05-12 22:18:41,283:INFO:Creating metrics dataframe
2025-05-12 22:18:41,286:INFO:Uploading results into container
2025-05-12 22:18:41,287:INFO:Uploading model into container now
2025-05-12 22:18:41,287:INFO:_master_model_container: 7
2025-05-12 22:18:41,287:INFO:_display_container: 2
2025-05-12 22:18:41,288:INFO:OrthogonalMatchingPursuit()
2025-05-12 22:18:41,288:INFO:create_model() successfully completed......................................
2025-05-12 22:18:41,379:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:41,379:INFO:Creating metrics dataframe
2025-05-12 22:18:41,389:INFO:Initializing Bayesian Ridge
2025-05-12 22:18:41,389:INFO:Total runtime is 0.2072447975476583 minutes
2025-05-12 22:18:41,393:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:41,393:INFO:Initializing create_model()
2025-05-12 22:18:41,393:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:41,393:INFO:Checking exceptions
2025-05-12 22:18:41,394:INFO:Importing libraries
2025-05-12 22:18:41,394:INFO:Copying training dataset
2025-05-12 22:18:41,398:INFO:Defining folds
2025-05-12 22:18:41,398:INFO:Declaring metric variables
2025-05-12 22:18:41,403:INFO:Importing untrained model
2025-05-12 22:18:41,408:INFO:Bayesian Ridge Imported successfully
2025-05-12 22:18:41,415:INFO:Starting cross validation
2025-05-12 22:18:41,417:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:41,658:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:41,659:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:41,669:INFO:Calculating mean and std
2025-05-12 22:18:41,671:INFO:Creating metrics dataframe
2025-05-12 22:18:41,674:INFO:Uploading results into container
2025-05-12 22:18:41,676:INFO:Uploading model into container now
2025-05-12 22:18:41,676:INFO:_master_model_container: 8
2025-05-12 22:18:41,676:INFO:_display_container: 2
2025-05-12 22:18:41,677:INFO:BayesianRidge()
2025-05-12 22:18:41,677:INFO:create_model() successfully completed......................................
2025-05-12 22:18:41,767:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:41,768:INFO:Creating metrics dataframe
2025-05-12 22:18:41,776:INFO:Initializing Passive Aggressive Regressor
2025-05-12 22:18:41,776:INFO:Total runtime is 0.21370112895965576 minutes
2025-05-12 22:18:41,780:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:41,780:INFO:Initializing create_model()
2025-05-12 22:18:41,780:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:41,780:INFO:Checking exceptions
2025-05-12 22:18:41,780:INFO:Importing libraries
2025-05-12 22:18:41,780:INFO:Copying training dataset
2025-05-12 22:18:41,785:INFO:Defining folds
2025-05-12 22:18:41,786:INFO:Declaring metric variables
2025-05-12 22:18:41,789:INFO:Importing untrained model
2025-05-12 22:18:41,795:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 22:18:41,804:INFO:Starting cross validation
2025-05-12 22:18:41,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:42,047:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:42,047:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:42,049:INFO:Calculating mean and std
2025-05-12 22:18:42,050:INFO:Creating metrics dataframe
2025-05-12 22:18:42,053:INFO:Uploading results into container
2025-05-12 22:18:42,054:INFO:Uploading model into container now
2025-05-12 22:18:42,055:INFO:_master_model_container: 9
2025-05-12 22:18:42,055:INFO:_display_container: 2
2025-05-12 22:18:42,056:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 22:18:42,056:INFO:create_model() successfully completed......................................
2025-05-12 22:18:42,152:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:42,152:INFO:Creating metrics dataframe
2025-05-12 22:18:42,161:INFO:Initializing Huber Regressor
2025-05-12 22:18:42,161:INFO:Total runtime is 0.220106303691864 minutes
2025-05-12 22:18:42,166:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:42,166:INFO:Initializing create_model()
2025-05-12 22:18:42,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:42,166:INFO:Checking exceptions
2025-05-12 22:18:42,167:INFO:Importing libraries
2025-05-12 22:18:42,167:INFO:Copying training dataset
2025-05-12 22:18:42,171:INFO:Defining folds
2025-05-12 22:18:42,172:INFO:Declaring metric variables
2025-05-12 22:18:42,176:INFO:Importing untrained model
2025-05-12 22:18:42,183:INFO:Huber Regressor Imported successfully
2025-05-12 22:18:42,193:INFO:Starting cross validation
2025-05-12 22:18:42,196:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:42,561:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:42,561:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:42,573:INFO:Calculating mean and std
2025-05-12 22:18:42,574:INFO:Creating metrics dataframe
2025-05-12 22:18:42,577:INFO:Uploading results into container
2025-05-12 22:18:42,577:INFO:Uploading model into container now
2025-05-12 22:18:42,578:INFO:_master_model_container: 10
2025-05-12 22:18:42,578:INFO:_display_container: 2
2025-05-12 22:18:42,578:INFO:HuberRegressor()
2025-05-12 22:18:42,578:INFO:create_model() successfully completed......................................
2025-05-12 22:18:42,676:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:42,676:INFO:Creating metrics dataframe
2025-05-12 22:18:42,687:INFO:Initializing K Neighbors Regressor
2025-05-12 22:18:42,688:INFO:Total runtime is 0.2288930098215739 minutes
2025-05-12 22:18:42,693:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:42,693:INFO:Initializing create_model()
2025-05-12 22:18:42,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:42,693:INFO:Checking exceptions
2025-05-12 22:18:42,693:INFO:Importing libraries
2025-05-12 22:18:42,693:INFO:Copying training dataset
2025-05-12 22:18:42,698:INFO:Defining folds
2025-05-12 22:18:42,698:INFO:Declaring metric variables
2025-05-12 22:18:42,704:INFO:Importing untrained model
2025-05-12 22:18:42,707:INFO:K Neighbors Regressor Imported successfully
2025-05-12 22:18:42,718:INFO:Starting cross validation
2025-05-12 22:18:42,720:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:43,006:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:43,006:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:43,011:INFO:Calculating mean and std
2025-05-12 22:18:43,011:INFO:Creating metrics dataframe
2025-05-12 22:18:43,016:INFO:Uploading results into container
2025-05-12 22:18:43,017:INFO:Uploading model into container now
2025-05-12 22:18:43,017:INFO:_master_model_container: 11
2025-05-12 22:18:43,017:INFO:_display_container: 2
2025-05-12 22:18:43,019:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 22:18:43,019:INFO:create_model() successfully completed......................................
2025-05-12 22:18:43,108:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:43,108:INFO:Creating metrics dataframe
2025-05-12 22:18:43,117:INFO:Initializing Decision Tree Regressor
2025-05-12 22:18:43,118:INFO:Total runtime is 0.23605743646621705 minutes
2025-05-12 22:18:43,120:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:43,121:INFO:Initializing create_model()
2025-05-12 22:18:43,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:43,121:INFO:Checking exceptions
2025-05-12 22:18:43,121:INFO:Importing libraries
2025-05-12 22:18:43,121:INFO:Copying training dataset
2025-05-12 22:18:43,126:INFO:Defining folds
2025-05-12 22:18:43,127:INFO:Declaring metric variables
2025-05-12 22:18:43,131:INFO:Importing untrained model
2025-05-12 22:18:43,136:INFO:Decision Tree Regressor Imported successfully
2025-05-12 22:18:43,146:INFO:Starting cross validation
2025-05-12 22:18:43,148:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:43,420:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:43,421:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:43,428:INFO:Calculating mean and std
2025-05-12 22:18:43,430:INFO:Creating metrics dataframe
2025-05-12 22:18:43,433:INFO:Uploading results into container
2025-05-12 22:18:43,434:INFO:Uploading model into container now
2025-05-12 22:18:43,434:INFO:_master_model_container: 12
2025-05-12 22:18:43,434:INFO:_display_container: 2
2025-05-12 22:18:43,436:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 22:18:43,436:INFO:create_model() successfully completed......................................
2025-05-12 22:18:43,535:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:43,535:INFO:Creating metrics dataframe
2025-05-12 22:18:43,551:INFO:Initializing Random Forest Regressor
2025-05-12 22:18:43,551:INFO:Total runtime is 0.24327282508214315 minutes
2025-05-12 22:18:43,556:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:43,557:INFO:Initializing create_model()
2025-05-12 22:18:43,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:43,557:INFO:Checking exceptions
2025-05-12 22:18:43,557:INFO:Importing libraries
2025-05-12 22:18:43,557:INFO:Copying training dataset
2025-05-12 22:18:43,563:INFO:Defining folds
2025-05-12 22:18:43,563:INFO:Declaring metric variables
2025-05-12 22:18:43,569:INFO:Importing untrained model
2025-05-12 22:18:43,573:INFO:Random Forest Regressor Imported successfully
2025-05-12 22:18:43,584:INFO:Starting cross validation
2025-05-12 22:18:43,587:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:44,795:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:44,796:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:44,813:INFO:Calculating mean and std
2025-05-12 22:18:44,814:INFO:Creating metrics dataframe
2025-05-12 22:18:44,818:INFO:Uploading results into container
2025-05-12 22:18:44,818:INFO:Uploading model into container now
2025-05-12 22:18:44,819:INFO:_master_model_container: 13
2025-05-12 22:18:44,819:INFO:_display_container: 2
2025-05-12 22:18:44,819:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:18:44,820:INFO:create_model() successfully completed......................................
2025-05-12 22:18:44,909:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:44,910:INFO:Creating metrics dataframe
2025-05-12 22:18:44,920:INFO:Initializing Extra Trees Regressor
2025-05-12 22:18:44,920:INFO:Total runtime is 0.2661035100618998 minutes
2025-05-12 22:18:44,924:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:44,924:INFO:Initializing create_model()
2025-05-12 22:18:44,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:44,925:INFO:Checking exceptions
2025-05-12 22:18:44,925:INFO:Importing libraries
2025-05-12 22:18:44,925:INFO:Copying training dataset
2025-05-12 22:18:44,930:INFO:Defining folds
2025-05-12 22:18:44,931:INFO:Declaring metric variables
2025-05-12 22:18:44,935:INFO:Importing untrained model
2025-05-12 22:18:44,940:INFO:Extra Trees Regressor Imported successfully
2025-05-12 22:18:44,961:INFO:Starting cross validation
2025-05-12 22:18:44,965:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:45,646:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:45,647:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:45,651:INFO:Calculating mean and std
2025-05-12 22:18:45,652:INFO:Creating metrics dataframe
2025-05-12 22:18:45,654:INFO:Uploading results into container
2025-05-12 22:18:45,655:INFO:Uploading model into container now
2025-05-12 22:18:45,655:INFO:_master_model_container: 14
2025-05-12 22:18:45,655:INFO:_display_container: 2
2025-05-12 22:18:45,656:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:18:45,656:INFO:create_model() successfully completed......................................
2025-05-12 22:18:45,760:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:45,761:INFO:Creating metrics dataframe
2025-05-12 22:18:45,781:INFO:Initializing AdaBoost Regressor
2025-05-12 22:18:45,781:INFO:Total runtime is 0.2804393212000529 minutes
2025-05-12 22:18:45,788:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:45,788:INFO:Initializing create_model()
2025-05-12 22:18:45,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:45,788:INFO:Checking exceptions
2025-05-12 22:18:45,788:INFO:Importing libraries
2025-05-12 22:18:45,788:INFO:Copying training dataset
2025-05-12 22:18:45,795:INFO:Defining folds
2025-05-12 22:18:45,795:INFO:Declaring metric variables
2025-05-12 22:18:45,803:INFO:Importing untrained model
2025-05-12 22:18:45,808:INFO:AdaBoost Regressor Imported successfully
2025-05-12 22:18:45,821:INFO:Starting cross validation
2025-05-12 22:18:45,825:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:46,377:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:46,378:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:46,381:INFO:Calculating mean and std
2025-05-12 22:18:46,382:INFO:Creating metrics dataframe
2025-05-12 22:18:46,386:INFO:Uploading results into container
2025-05-12 22:18:46,387:INFO:Uploading model into container now
2025-05-12 22:18:46,387:INFO:_master_model_container: 15
2025-05-12 22:18:46,387:INFO:_display_container: 2
2025-05-12 22:18:46,388:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 22:18:46,388:INFO:create_model() successfully completed......................................
2025-05-12 22:18:46,483:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:46,483:INFO:Creating metrics dataframe
2025-05-12 22:18:46,494:INFO:Initializing Gradient Boosting Regressor
2025-05-12 22:18:46,494:INFO:Total runtime is 0.29232976833979285 minutes
2025-05-12 22:18:46,499:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:46,499:INFO:Initializing create_model()
2025-05-12 22:18:46,499:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:46,499:INFO:Checking exceptions
2025-05-12 22:18:46,499:INFO:Importing libraries
2025-05-12 22:18:46,499:INFO:Copying training dataset
2025-05-12 22:18:46,504:INFO:Defining folds
2025-05-12 22:18:46,504:INFO:Declaring metric variables
2025-05-12 22:18:46,509:INFO:Importing untrained model
2025-05-12 22:18:46,515:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 22:18:46,524:INFO:Starting cross validation
2025-05-12 22:18:46,528:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:47,078:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:47,079:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:47,080:INFO:Calculating mean and std
2025-05-12 22:18:47,081:INFO:Creating metrics dataframe
2025-05-12 22:18:47,083:INFO:Uploading results into container
2025-05-12 22:18:47,084:INFO:Uploading model into container now
2025-05-12 22:18:47,085:INFO:_master_model_container: 16
2025-05-12 22:18:47,085:INFO:_display_container: 2
2025-05-12 22:18:47,086:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 22:18:47,086:INFO:create_model() successfully completed......................................
2025-05-12 22:18:47,181:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:47,181:INFO:Creating metrics dataframe
2025-05-12 22:18:47,191:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:18:47,191:INFO:Total runtime is 0.30394897063573195 minutes
2025-05-12 22:18:47,195:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:47,196:INFO:Initializing create_model()
2025-05-12 22:18:47,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:47,196:INFO:Checking exceptions
2025-05-12 22:18:47,196:INFO:Importing libraries
2025-05-12 22:18:47,196:INFO:Copying training dataset
2025-05-12 22:18:47,200:INFO:Defining folds
2025-05-12 22:18:47,200:INFO:Declaring metric variables
2025-05-12 22:18:47,204:INFO:Importing untrained model
2025-05-12 22:18:47,210:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:18:47,218:INFO:Starting cross validation
2025-05-12 22:18:47,220:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:47,815:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:47,815:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:47,817:INFO:Calculating mean and std
2025-05-12 22:18:47,819:INFO:Creating metrics dataframe
2025-05-12 22:18:47,822:INFO:Uploading results into container
2025-05-12 22:18:47,824:INFO:Uploading model into container now
2025-05-12 22:18:47,824:INFO:_master_model_container: 17
2025-05-12 22:18:47,825:INFO:_display_container: 2
2025-05-12 22:18:47,826:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:18:47,827:INFO:create_model() successfully completed......................................
2025-05-12 22:18:47,947:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:47,947:INFO:Creating metrics dataframe
2025-05-12 22:18:47,959:INFO:Initializing Dummy Regressor
2025-05-12 22:18:47,959:INFO:Total runtime is 0.3167533874511718 minutes
2025-05-12 22:18:47,964:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:47,964:INFO:Initializing create_model()
2025-05-12 22:18:47,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:47,964:INFO:Checking exceptions
2025-05-12 22:18:47,964:INFO:Importing libraries
2025-05-12 22:18:47,964:INFO:Copying training dataset
2025-05-12 22:18:47,970:INFO:Defining folds
2025-05-12 22:18:47,970:INFO:Declaring metric variables
2025-05-12 22:18:47,975:INFO:Importing untrained model
2025-05-12 22:18:47,983:INFO:Dummy Regressor Imported successfully
2025-05-12 22:18:47,991:INFO:Starting cross validation
2025-05-12 22:18:47,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:48,238:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:48,239:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:48,246:INFO:Calculating mean and std
2025-05-12 22:18:48,247:INFO:Creating metrics dataframe
2025-05-12 22:18:48,249:INFO:Uploading results into container
2025-05-12 22:18:48,249:INFO:Uploading model into container now
2025-05-12 22:18:48,250:INFO:_master_model_container: 18
2025-05-12 22:18:48,250:INFO:_display_container: 2
2025-05-12 22:18:48,251:INFO:DummyRegressor()
2025-05-12 22:18:48,251:INFO:create_model() successfully completed......................................
2025-05-12 22:18:48,346:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:48,346:INFO:Creating metrics dataframe
2025-05-12 22:18:48,358:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:18:48,369:INFO:Initializing create_model()
2025-05-12 22:18:48,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:48,369:INFO:Checking exceptions
2025-05-12 22:18:48,371:INFO:Importing libraries
2025-05-12 22:18:48,371:INFO:Copying training dataset
2025-05-12 22:18:48,374:INFO:Defining folds
2025-05-12 22:18:48,375:INFO:Declaring metric variables
2025-05-12 22:18:48,375:INFO:Importing untrained model
2025-05-12 22:18:48,376:INFO:Declaring custom model
2025-05-12 22:18:48,377:INFO:Lasso Regression Imported successfully
2025-05-12 22:18:48,379:INFO:Cross validation set to False
2025-05-12 22:18:48,379:INFO:Fitting Model
2025-05-12 22:18:48,426:INFO:Lasso(random_state=123)
2025-05-12 22:18:48,426:INFO:create_model() successfully completed......................................
2025-05-12 22:18:48,606:INFO:_master_model_container: 18
2025-05-12 22:18:48,606:INFO:_display_container: 2
2025-05-12 22:18:48,607:INFO:Lasso(random_state=123)
2025-05-12 22:18:48,607:INFO:compare_models() successfully completed......................................
2025-05-12 22:18:48,664:INFO:Initializing create_model()
2025-05-12 22:18:48,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=en, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:48,664:INFO:Checking exceptions
2025-05-12 22:18:48,685:INFO:Importing libraries
2025-05-12 22:18:48,686:INFO:Copying training dataset
2025-05-12 22:18:48,692:INFO:Defining folds
2025-05-12 22:18:48,692:INFO:Declaring metric variables
2025-05-12 22:18:48,698:INFO:Importing untrained model
2025-05-12 22:18:48,721:INFO:Elastic Net Imported successfully
2025-05-12 22:18:48,738:INFO:Starting cross validation
2025-05-12 22:18:48,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:49,009:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:49,009:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:49,020:INFO:Calculating mean and std
2025-05-12 22:18:49,021:INFO:Creating metrics dataframe
2025-05-12 22:18:49,027:INFO:Finalizing model
2025-05-12 22:18:49,076:INFO:Uploading results into container
2025-05-12 22:18:49,077:INFO:Uploading model into container now
2025-05-12 22:18:49,087:INFO:_master_model_container: 19
2025-05-12 22:18:49,088:INFO:_display_container: 3
2025-05-12 22:18:49,088:INFO:ElasticNet(random_state=123)
2025-05-12 22:18:49,088:INFO:create_model() successfully completed......................................
2025-05-12 22:18:49,191:INFO:Initializing tune_model()
2025-05-12 22:18:49,191:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ElasticNet(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:18:49,192:INFO:Checking exceptions
2025-05-12 22:18:49,211:INFO:Copying training dataset
2025-05-12 22:18:49,215:INFO:Checking base model
2025-05-12 22:18:49,215:INFO:Base model : Elastic Net
2025-05-12 22:18:49,219:INFO:Declaring metric variables
2025-05-12 22:18:49,223:INFO:Defining Hyperparameters
2025-05-12 22:18:49,313:INFO:Tuning with n_jobs=-1
2025-05-12 22:18:49,313:INFO:Initializing RandomizedSearchCV
2025-05-12 22:18:51,893:INFO:best_params: {'actual_estimator__l1_ratio': 0.664, 'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 9.88}
2025-05-12 22:18:51,894:INFO:Hyperparameter search completed
2025-05-12 22:18:51,894:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:51,896:INFO:Initializing create_model()
2025-05-12 22:18:51,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ElasticNet(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA785CCED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'l1_ratio': 0.664, 'fit_intercept': True, 'alpha': 9.88})
2025-05-12 22:18:51,897:INFO:Checking exceptions
2025-05-12 22:18:51,898:INFO:Importing libraries
2025-05-12 22:18:51,898:INFO:Copying training dataset
2025-05-12 22:18:51,904:INFO:Defining folds
2025-05-12 22:18:51,904:INFO:Declaring metric variables
2025-05-12 22:18:51,911:INFO:Importing untrained model
2025-05-12 22:18:51,911:INFO:Declaring custom model
2025-05-12 22:18:51,921:INFO:Elastic Net Imported successfully
2025-05-12 22:18:51,945:INFO:Starting cross validation
2025-05-12 22:18:51,949:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:52,347:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:52,347:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:52,357:INFO:Calculating mean and std
2025-05-12 22:18:52,358:INFO:Creating metrics dataframe
2025-05-12 22:18:52,364:INFO:Finalizing model
2025-05-12 22:18:52,424:INFO:Uploading results into container
2025-05-12 22:18:52,424:INFO:Uploading model into container now
2025-05-12 22:18:52,426:INFO:_master_model_container: 20
2025-05-12 22:18:52,426:INFO:_display_container: 4
2025-05-12 22:18:52,426:INFO:ElasticNet(alpha=9.88, l1_ratio=0.664, random_state=123)
2025-05-12 22:18:52,426:INFO:create_model() successfully completed......................................
2025-05-12 22:18:52,519:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:52,519:INFO:choose_better activated
2025-05-12 22:18:52,523:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:52,523:INFO:Initializing create_model()
2025-05-12 22:18:52,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ElasticNet(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:52,523:INFO:Checking exceptions
2025-05-12 22:18:52,525:INFO:Importing libraries
2025-05-12 22:18:52,525:INFO:Copying training dataset
2025-05-12 22:18:52,529:INFO:Defining folds
2025-05-12 22:18:52,530:INFO:Declaring metric variables
2025-05-12 22:18:52,530:INFO:Importing untrained model
2025-05-12 22:18:52,530:INFO:Declaring custom model
2025-05-12 22:18:52,530:INFO:Elastic Net Imported successfully
2025-05-12 22:18:52,531:INFO:Starting cross validation
2025-05-12 22:18:52,533:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:52,851:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:52,851:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:52,853:INFO:Calculating mean and std
2025-05-12 22:18:52,854:INFO:Creating metrics dataframe
2025-05-12 22:18:52,857:INFO:Finalizing model
2025-05-12 22:18:52,905:INFO:Uploading results into container
2025-05-12 22:18:52,906:INFO:Uploading model into container now
2025-05-12 22:18:52,906:INFO:_master_model_container: 21
2025-05-12 22:18:52,906:INFO:_display_container: 5
2025-05-12 22:18:52,907:INFO:ElasticNet(random_state=123)
2025-05-12 22:18:52,907:INFO:create_model() successfully completed......................................
2025-05-12 22:18:53,000:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:53,000:INFO:ElasticNet(random_state=123) result for R2 is -0.0421
2025-05-12 22:18:53,001:INFO:ElasticNet(alpha=9.88, l1_ratio=0.664, random_state=123) result for R2 is -0.0421
2025-05-12 22:18:53,001:INFO:ElasticNet(random_state=123) is best model
2025-05-12 22:18:53,001:INFO:choose_better completed
2025-05-12 22:18:53,001:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:18:53,011:INFO:_master_model_container: 21
2025-05-12 22:18:53,011:INFO:_display_container: 4
2025-05-12 22:18:53,011:INFO:ElasticNet(random_state=123)
2025-05-12 22:18:53,011:INFO:tune_model() successfully completed......................................
2025-05-12 22:18:53,107:INFO:Initializing evaluate_model()
2025-05-12 22:18:53,107:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ElasticNet(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:18:53,117:INFO:Initializing plot_model()
2025-05-12 22:18:53,117:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ElasticNet(random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:18:53,117:INFO:Checking exceptions
2025-05-12 22:18:53,119:INFO:Preloading libraries
2025-05-12 22:18:53,119:INFO:Copying training dataset
2025-05-12 22:18:53,119:INFO:Plot type: pipeline
2025-05-12 22:18:53,231:INFO:Visual Rendered Successfully
2025-05-12 22:18:53,312:INFO:plot_model() successfully completed......................................
2025-05-12 22:18:53,329:INFO:Initializing predict_model()
2025-05-12 22:18:53,329:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ElasticNet(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EA7AEA2E80>)
2025-05-12 22:18:53,329:INFO:Checking exceptions
2025-05-12 22:18:53,329:INFO:Preloading libraries
2025-05-12 22:18:53,426:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:18:53,534:INFO:Initializing save_model()
2025-05-12 22:18:53,534:INFO:save_model(model=ElasticNet(random_state=123), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-12 22:18:53,534:INFO:Adding model into prep_pipe
2025-05-12 22:18:53,543:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:18:53,549:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', ElasticNet(random_state=123))])
2025-05-12 22:18:53,549:INFO:save_model() successfully completed......................................
2025-05-12 22:22:50,033:INFO:PyCaret RegressionExperiment
2025-05-12 22:22:50,033:INFO:Logging name: reg-default-name
2025-05-12 22:22:50,033:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:22:50,033:INFO:version 3.3.2
2025-05-12 22:22:50,033:INFO:Initializing setup()
2025-05-12 22:22:50,033:INFO:self.USI: e29e
2025-05-12 22:22:50,034:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'transform_target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:22:50,034:INFO:Checking environment
2025-05-12 22:22:50,034:INFO:python_version: 3.11.8
2025-05-12 22:22:50,034:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:22:50,034:INFO:machine: AMD64
2025-05-12 22:22:50,034:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:22:50,038:INFO:Memory: svmem(total=16907886592, available=3052384256, percent=81.9, used=13855502336, free=3052384256)
2025-05-12 22:22:50,039:INFO:Physical Core: 4
2025-05-12 22:22:50,039:INFO:Logical Core: 8
2025-05-12 22:22:50,039:INFO:Checking libraries
2025-05-12 22:22:50,039:INFO:System:
2025-05-12 22:22:50,039:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:22:50,039:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:22:50,039:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:22:50,039:INFO:PyCaret required dependencies:
2025-05-12 22:22:50,039:INFO:                 pip: 24.0
2025-05-12 22:22:50,039:INFO:          setuptools: 65.5.0
2025-05-12 22:22:50,039:INFO:             pycaret: 3.3.2
2025-05-12 22:22:50,039:INFO:             IPython: 9.2.0
2025-05-12 22:22:50,039:INFO:          ipywidgets: 8.1.7
2025-05-12 22:22:50,039:INFO:                tqdm: 4.67.1
2025-05-12 22:22:50,039:INFO:               numpy: 1.26.4
2025-05-12 22:22:50,039:INFO:              pandas: 2.1.4
2025-05-12 22:22:50,039:INFO:              jinja2: 3.1.6
2025-05-12 22:22:50,039:INFO:               scipy: 1.11.4
2025-05-12 22:22:50,039:INFO:              joblib: 1.3.2
2025-05-12 22:22:50,039:INFO:             sklearn: 1.4.2
2025-05-12 22:22:50,039:INFO:                pyod: 2.0.5
2025-05-12 22:22:50,039:INFO:            imblearn: 0.13.0
2025-05-12 22:22:50,039:INFO:   category_encoders: 2.7.0
2025-05-12 22:22:50,039:INFO:            lightgbm: 4.6.0
2025-05-12 22:22:50,039:INFO:               numba: 0.61.2
2025-05-12 22:22:50,039:INFO:            requests: 2.32.3
2025-05-12 22:22:50,039:INFO:          matplotlib: 3.7.5
2025-05-12 22:22:50,039:INFO:          scikitplot: 0.3.7
2025-05-12 22:22:50,039:INFO:         yellowbrick: 1.5
2025-05-12 22:22:50,039:INFO:              plotly: 5.24.1
2025-05-12 22:22:50,039:INFO:    plotly-resampler: Not installed
2025-05-12 22:22:50,039:INFO:             kaleido: 0.2.1
2025-05-12 22:22:50,039:INFO:           schemdraw: 0.15
2025-05-12 22:22:50,039:INFO:         statsmodels: 0.14.4
2025-05-12 22:22:50,039:INFO:              sktime: 0.26.0
2025-05-12 22:22:50,039:INFO:               tbats: 1.1.3
2025-05-12 22:22:50,039:INFO:            pmdarima: 2.0.4
2025-05-12 22:22:50,039:INFO:              psutil: 7.0.0
2025-05-12 22:22:50,039:INFO:          markupsafe: 3.0.2
2025-05-12 22:22:50,039:INFO:             pickle5: Not installed
2025-05-12 22:22:50,039:INFO:         cloudpickle: 3.1.1
2025-05-12 22:22:50,039:INFO:         deprecation: 2.1.0
2025-05-12 22:22:50,040:INFO:              xxhash: 3.5.0
2025-05-12 22:22:50,040:INFO:           wurlitzer: Not installed
2025-05-12 22:22:50,040:INFO:PyCaret optional dependencies:
2025-05-12 22:22:50,040:INFO:                shap: Not installed
2025-05-12 22:22:50,040:INFO:           interpret: Not installed
2025-05-12 22:22:50,040:INFO:                umap: Not installed
2025-05-12 22:22:50,040:INFO:     ydata_profiling: Not installed
2025-05-12 22:22:50,040:INFO:  explainerdashboard: Not installed
2025-05-12 22:22:50,040:INFO:             autoviz: Not installed
2025-05-12 22:22:50,040:INFO:           fairlearn: Not installed
2025-05-12 22:22:50,040:INFO:          deepchecks: Not installed
2025-05-12 22:22:50,040:INFO:             xgboost: Not installed
2025-05-12 22:22:50,040:INFO:            catboost: Not installed
2025-05-12 22:22:50,040:INFO:              kmodes: Not installed
2025-05-12 22:22:50,040:INFO:             mlxtend: Not installed
2025-05-12 22:22:50,040:INFO:       statsforecast: Not installed
2025-05-12 22:22:50,040:INFO:        tune_sklearn: Not installed
2025-05-12 22:22:50,040:INFO:                 ray: Not installed
2025-05-12 22:22:50,040:INFO:            hyperopt: Not installed
2025-05-12 22:22:50,040:INFO:              optuna: Not installed
2025-05-12 22:22:50,040:INFO:               skopt: Not installed
2025-05-12 22:22:50,040:INFO:              mlflow: Not installed
2025-05-12 22:22:50,040:INFO:              gradio: Not installed
2025-05-12 22:22:50,040:INFO:             fastapi: Not installed
2025-05-12 22:22:50,040:INFO:             uvicorn: Not installed
2025-05-12 22:22:50,040:INFO:              m2cgen: Not installed
2025-05-12 22:22:50,040:INFO:           evidently: Not installed
2025-05-12 22:22:50,040:INFO:               fugue: Not installed
2025-05-12 22:22:50,040:INFO:           streamlit: Not installed
2025-05-12 22:22:50,040:INFO:             prophet: Not installed
2025-05-12 22:22:50,040:INFO:None
2025-05-12 22:22:50,040:INFO:Set up data.
2025-05-12 22:22:50,044:INFO:Set up folding strategy.
2025-05-12 22:22:50,044:INFO:Set up train/test split.
2025-05-12 22:22:50,046:INFO:Set up index.
2025-05-12 22:22:50,046:INFO:Assigning column types.
2025-05-12 22:22:50,048:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:22:50,048:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,052:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,056:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,145:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,186:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,187:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,187:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,191:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,194:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,240:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,276:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,277:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:22:50,280:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,284:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,329:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,363:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,364:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,368:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,372:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,419:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,457:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,458:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:22:50,465:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,514:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,549:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,549:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,557:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,599:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,633:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,634:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:22:50,685:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,770:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,804:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:22:50,858:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,960:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,999:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:22:51,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,203:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,203:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,204:INFO:Preparing preprocessing pipeline...
2025-05-12 22:22:51,204:INFO:Set up simple imputation.
2025-05-12 22:22:51,207:INFO:Set up encoding of categorical features.
2025-05-12 22:22:51,207:INFO:Set up feature normalization.
2025-05-12 22:22:51,261:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:22:51,267:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 22:22:51,267:INFO:Creating final display dataframe.
2025-05-12 22:22:51,421:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type        Regression
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              e29e
2025-05-12 22:22:51,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,652:INFO:setup() successfully completed in 1.62s...............
2025-05-12 22:22:51,671:INFO:Initializing compare_models()
2025-05-12 22:22:51,671:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 22:22:51,671:INFO:Checking exceptions
2025-05-12 22:22:51,674:INFO:Preparing display monitor
2025-05-12 22:22:51,694:INFO:Initializing Linear Regression
2025-05-12 22:22:51,695:INFO:Total runtime is 1.666545867919922e-05 minutes
2025-05-12 22:22:51,698:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:51,700:INFO:Initializing create_model()
2025-05-12 22:22:51,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:51,700:INFO:Checking exceptions
2025-05-12 22:22:51,700:INFO:Importing libraries
2025-05-12 22:22:51,700:INFO:Copying training dataset
2025-05-12 22:22:51,704:INFO:Defining folds
2025-05-12 22:22:51,704:INFO:Declaring metric variables
2025-05-12 22:22:51,708:INFO:Importing untrained model
2025-05-12 22:22:51,712:INFO:Linear Regression Imported successfully
2025-05-12 22:22:51,720:INFO:Starting cross validation
2025-05-12 22:22:51,721:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:51,927:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:51,927:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:51,931:INFO:Calculating mean and std
2025-05-12 22:22:51,931:INFO:Creating metrics dataframe
2025-05-12 22:22:51,933:INFO:Uploading results into container
2025-05-12 22:22:51,933:INFO:Uploading model into container now
2025-05-12 22:22:51,933:INFO:_master_model_container: 1
2025-05-12 22:22:51,933:INFO:_display_container: 2
2025-05-12 22:22:51,933:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:22:51,933:INFO:create_model() successfully completed......................................
2025-05-12 22:22:52,018:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:52,018:INFO:Creating metrics dataframe
2025-05-12 22:22:52,024:INFO:Initializing Lasso Regression
2025-05-12 22:22:52,024:INFO:Total runtime is 0.0054997642834981285 minutes
2025-05-12 22:22:52,028:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:52,028:INFO:Initializing create_model()
2025-05-12 22:22:52,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:52,028:INFO:Checking exceptions
2025-05-12 22:22:52,028:INFO:Importing libraries
2025-05-12 22:22:52,028:INFO:Copying training dataset
2025-05-12 22:22:52,031:INFO:Defining folds
2025-05-12 22:22:52,031:INFO:Declaring metric variables
2025-05-12 22:22:52,034:INFO:Importing untrained model
2025-05-12 22:22:52,037:INFO:Lasso Regression Imported successfully
2025-05-12 22:22:52,044:INFO:Starting cross validation
2025-05-12 22:22:52,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:52,209:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:52,210:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:52,216:INFO:Calculating mean and std
2025-05-12 22:22:52,216:INFO:Creating metrics dataframe
2025-05-12 22:22:52,217:INFO:Uploading results into container
2025-05-12 22:22:52,218:INFO:Uploading model into container now
2025-05-12 22:22:52,218:INFO:_master_model_container: 2
2025-05-12 22:22:52,218:INFO:_display_container: 2
2025-05-12 22:22:52,218:INFO:Lasso(random_state=123)
2025-05-12 22:22:52,218:INFO:create_model() successfully completed......................................
2025-05-12 22:22:52,291:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:52,291:INFO:Creating metrics dataframe
2025-05-12 22:22:52,297:INFO:Initializing Ridge Regression
2025-05-12 22:22:52,297:INFO:Total runtime is 0.010042277971903484 minutes
2025-05-12 22:22:52,299:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:52,299:INFO:Initializing create_model()
2025-05-12 22:22:52,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:52,299:INFO:Checking exceptions
2025-05-12 22:22:52,299:INFO:Importing libraries
2025-05-12 22:22:52,299:INFO:Copying training dataset
2025-05-12 22:22:52,301:INFO:Defining folds
2025-05-12 22:22:52,303:INFO:Declaring metric variables
2025-05-12 22:22:52,306:INFO:Importing untrained model
2025-05-12 22:22:52,309:INFO:Ridge Regression Imported successfully
2025-05-12 22:22:52,314:INFO:Starting cross validation
2025-05-12 22:22:52,314:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:52,478:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:52,479:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:52,488:INFO:Calculating mean and std
2025-05-12 22:22:52,488:INFO:Creating metrics dataframe
2025-05-12 22:22:52,489:INFO:Uploading results into container
2025-05-12 22:22:52,490:INFO:Uploading model into container now
2025-05-12 22:22:52,490:INFO:_master_model_container: 3
2025-05-12 22:22:52,490:INFO:_display_container: 2
2025-05-12 22:22:52,490:INFO:Ridge(random_state=123)
2025-05-12 22:22:52,490:INFO:create_model() successfully completed......................................
2025-05-12 22:22:52,567:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:52,568:INFO:Creating metrics dataframe
2025-05-12 22:22:52,574:INFO:Initializing Elastic Net
2025-05-12 22:22:52,574:INFO:Total runtime is 0.014663692315419516 minutes
2025-05-12 22:22:52,577:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:52,578:INFO:Initializing create_model()
2025-05-12 22:22:52,578:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:52,578:INFO:Checking exceptions
2025-05-12 22:22:52,578:INFO:Importing libraries
2025-05-12 22:22:52,578:INFO:Copying training dataset
2025-05-12 22:22:52,581:INFO:Defining folds
2025-05-12 22:22:52,581:INFO:Declaring metric variables
2025-05-12 22:22:52,584:INFO:Importing untrained model
2025-05-12 22:22:52,587:INFO:Elastic Net Imported successfully
2025-05-12 22:22:52,594:INFO:Starting cross validation
2025-05-12 22:22:52,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:52,769:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:52,769:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:52,775:INFO:Calculating mean and std
2025-05-12 22:22:52,776:INFO:Creating metrics dataframe
2025-05-12 22:22:52,777:INFO:Uploading results into container
2025-05-12 22:22:52,777:INFO:Uploading model into container now
2025-05-12 22:22:52,777:INFO:_master_model_container: 4
2025-05-12 22:22:52,777:INFO:_display_container: 2
2025-05-12 22:22:52,779:INFO:ElasticNet(random_state=123)
2025-05-12 22:22:52,779:INFO:create_model() successfully completed......................................
2025-05-12 22:22:52,854:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:52,856:INFO:Creating metrics dataframe
2025-05-12 22:22:52,861:INFO:Initializing Least Angle Regression
2025-05-12 22:22:52,861:INFO:Total runtime is 0.019452619552612307 minutes
2025-05-12 22:22:52,864:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:52,866:INFO:Initializing create_model()
2025-05-12 22:22:52,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:52,866:INFO:Checking exceptions
2025-05-12 22:22:52,866:INFO:Importing libraries
2025-05-12 22:22:52,866:INFO:Copying training dataset
2025-05-12 22:22:52,868:INFO:Defining folds
2025-05-12 22:22:52,868:INFO:Declaring metric variables
2025-05-12 22:22:52,871:INFO:Importing untrained model
2025-05-12 22:22:52,874:INFO:Least Angle Regression Imported successfully
2025-05-12 22:22:52,879:INFO:Starting cross validation
2025-05-12 22:22:52,880:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:53,051:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:53,053:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:53,055:INFO:Calculating mean and std
2025-05-12 22:22:53,056:INFO:Creating metrics dataframe
2025-05-12 22:22:53,057:INFO:Uploading results into container
2025-05-12 22:22:53,057:INFO:Uploading model into container now
2025-05-12 22:22:53,057:INFO:_master_model_container: 5
2025-05-12 22:22:53,057:INFO:_display_container: 2
2025-05-12 22:22:53,059:INFO:Lars(random_state=123)
2025-05-12 22:22:53,059:INFO:create_model() successfully completed......................................
2025-05-12 22:22:53,137:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:53,137:INFO:Creating metrics dataframe
2025-05-12 22:22:53,147:INFO:Initializing Lasso Least Angle Regression
2025-05-12 22:22:53,147:INFO:Total runtime is 0.02421023448308309 minutes
2025-05-12 22:22:53,168:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:53,168:INFO:Initializing create_model()
2025-05-12 22:22:53,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:53,168:INFO:Checking exceptions
2025-05-12 22:22:53,169:INFO:Importing libraries
2025-05-12 22:22:53,169:INFO:Copying training dataset
2025-05-12 22:22:53,179:INFO:Defining folds
2025-05-12 22:22:53,179:INFO:Declaring metric variables
2025-05-12 22:22:53,184:INFO:Importing untrained model
2025-05-12 22:22:53,190:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:22:53,213:INFO:Starting cross validation
2025-05-12 22:22:53,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:53,467:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:53,467:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:53,473:INFO:Calculating mean and std
2025-05-12 22:22:53,474:INFO:Creating metrics dataframe
2025-05-12 22:22:53,476:INFO:Uploading results into container
2025-05-12 22:22:53,477:INFO:Uploading model into container now
2025-05-12 22:22:53,478:INFO:_master_model_container: 6
2025-05-12 22:22:53,478:INFO:_display_container: 2
2025-05-12 22:22:53,479:INFO:LassoLars(random_state=123)
2025-05-12 22:22:53,479:INFO:create_model() successfully completed......................................
2025-05-12 22:22:53,574:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:53,574:INFO:Creating metrics dataframe
2025-05-12 22:22:53,582:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 22:22:53,582:INFO:Total runtime is 0.031459403038024907 minutes
2025-05-12 22:22:53,588:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:53,588:INFO:Initializing create_model()
2025-05-12 22:22:53,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:53,589:INFO:Checking exceptions
2025-05-12 22:22:53,589:INFO:Importing libraries
2025-05-12 22:22:53,589:INFO:Copying training dataset
2025-05-12 22:22:53,593:INFO:Defining folds
2025-05-12 22:22:53,593:INFO:Declaring metric variables
2025-05-12 22:22:53,596:INFO:Importing untrained model
2025-05-12 22:22:53,601:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 22:22:53,611:INFO:Starting cross validation
2025-05-12 22:22:53,613:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:53,950:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:53,950:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:53,955:INFO:Calculating mean and std
2025-05-12 22:22:53,956:INFO:Creating metrics dataframe
2025-05-12 22:22:53,959:INFO:Uploading results into container
2025-05-12 22:22:53,960:INFO:Uploading model into container now
2025-05-12 22:22:53,961:INFO:_master_model_container: 7
2025-05-12 22:22:53,961:INFO:_display_container: 2
2025-05-12 22:22:53,961:INFO:OrthogonalMatchingPursuit()
2025-05-12 22:22:53,961:INFO:create_model() successfully completed......................................
2025-05-12 22:22:54,061:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:54,061:INFO:Creating metrics dataframe
2025-05-12 22:22:54,072:INFO:Initializing Bayesian Ridge
2025-05-12 22:22:54,073:INFO:Total runtime is 0.0396315097808838 minutes
2025-05-12 22:22:54,076:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:54,077:INFO:Initializing create_model()
2025-05-12 22:22:54,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:54,077:INFO:Checking exceptions
2025-05-12 22:22:54,077:INFO:Importing libraries
2025-05-12 22:22:54,077:INFO:Copying training dataset
2025-05-12 22:22:54,082:INFO:Defining folds
2025-05-12 22:22:54,083:INFO:Declaring metric variables
2025-05-12 22:22:54,088:INFO:Importing untrained model
2025-05-12 22:22:54,092:INFO:Bayesian Ridge Imported successfully
2025-05-12 22:22:54,099:INFO:Starting cross validation
2025-05-12 22:22:54,102:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:54,333:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:54,333:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:54,339:INFO:Calculating mean and std
2025-05-12 22:22:54,340:INFO:Creating metrics dataframe
2025-05-12 22:22:54,343:INFO:Uploading results into container
2025-05-12 22:22:54,343:INFO:Uploading model into container now
2025-05-12 22:22:54,344:INFO:_master_model_container: 8
2025-05-12 22:22:54,344:INFO:_display_container: 2
2025-05-12 22:22:54,344:INFO:BayesianRidge()
2025-05-12 22:22:54,344:INFO:create_model() successfully completed......................................
2025-05-12 22:22:54,436:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:54,436:INFO:Creating metrics dataframe
2025-05-12 22:22:54,444:INFO:Initializing Passive Aggressive Regressor
2025-05-12 22:22:54,446:INFO:Total runtime is 0.04586352109909059 minutes
2025-05-12 22:22:54,449:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:54,449:INFO:Initializing create_model()
2025-05-12 22:22:54,450:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:54,450:INFO:Checking exceptions
2025-05-12 22:22:54,450:INFO:Importing libraries
2025-05-12 22:22:54,450:INFO:Copying training dataset
2025-05-12 22:22:54,457:INFO:Defining folds
2025-05-12 22:22:54,457:INFO:Declaring metric variables
2025-05-12 22:22:54,464:INFO:Importing untrained model
2025-05-12 22:22:54,469:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 22:22:54,478:INFO:Starting cross validation
2025-05-12 22:22:54,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:54,713:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:54,713:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:54,719:INFO:Calculating mean and std
2025-05-12 22:22:54,721:INFO:Creating metrics dataframe
2025-05-12 22:22:54,723:INFO:Uploading results into container
2025-05-12 22:22:54,724:INFO:Uploading model into container now
2025-05-12 22:22:54,724:INFO:_master_model_container: 9
2025-05-12 22:22:54,724:INFO:_display_container: 2
2025-05-12 22:22:54,724:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 22:22:54,724:INFO:create_model() successfully completed......................................
2025-05-12 22:22:54,817:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:54,819:INFO:Creating metrics dataframe
2025-05-12 22:22:54,827:INFO:Initializing Huber Regressor
2025-05-12 22:22:54,827:INFO:Total runtime is 0.052217296759287525 minutes
2025-05-12 22:22:54,831:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:54,832:INFO:Initializing create_model()
2025-05-12 22:22:54,832:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:54,832:INFO:Checking exceptions
2025-05-12 22:22:54,832:INFO:Importing libraries
2025-05-12 22:22:54,832:INFO:Copying training dataset
2025-05-12 22:22:54,839:INFO:Defining folds
2025-05-12 22:22:54,839:INFO:Declaring metric variables
2025-05-12 22:22:54,843:INFO:Importing untrained model
2025-05-12 22:22:54,849:INFO:Huber Regressor Imported successfully
2025-05-12 22:22:54,857:INFO:Starting cross validation
2025-05-12 22:22:54,859:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:55,169:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:55,169:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:55,179:INFO:Calculating mean and std
2025-05-12 22:22:55,180:INFO:Creating metrics dataframe
2025-05-12 22:22:55,182:INFO:Uploading results into container
2025-05-12 22:22:55,183:INFO:Uploading model into container now
2025-05-12 22:22:55,183:INFO:_master_model_container: 10
2025-05-12 22:22:55,183:INFO:_display_container: 2
2025-05-12 22:22:55,184:INFO:HuberRegressor()
2025-05-12 22:22:55,184:INFO:create_model() successfully completed......................................
2025-05-12 22:22:55,273:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:55,274:INFO:Creating metrics dataframe
2025-05-12 22:22:55,283:INFO:Initializing K Neighbors Regressor
2025-05-12 22:22:55,283:INFO:Total runtime is 0.05981308221817017 minutes
2025-05-12 22:22:55,287:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:55,287:INFO:Initializing create_model()
2025-05-12 22:22:55,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:55,287:INFO:Checking exceptions
2025-05-12 22:22:55,287:INFO:Importing libraries
2025-05-12 22:22:55,287:INFO:Copying training dataset
2025-05-12 22:22:55,292:INFO:Defining folds
2025-05-12 22:22:55,292:INFO:Declaring metric variables
2025-05-12 22:22:55,296:INFO:Importing untrained model
2025-05-12 22:22:55,300:INFO:K Neighbors Regressor Imported successfully
2025-05-12 22:22:55,307:INFO:Starting cross validation
2025-05-12 22:22:55,311:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:55,590:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:55,590:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:55,597:INFO:Calculating mean and std
2025-05-12 22:22:55,599:INFO:Creating metrics dataframe
2025-05-12 22:22:55,601:INFO:Uploading results into container
2025-05-12 22:22:55,602:INFO:Uploading model into container now
2025-05-12 22:22:55,603:INFO:_master_model_container: 11
2025-05-12 22:22:55,603:INFO:_display_container: 2
2025-05-12 22:22:55,603:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 22:22:55,604:INFO:create_model() successfully completed......................................
2025-05-12 22:22:55,701:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:55,701:INFO:Creating metrics dataframe
2025-05-12 22:22:55,712:INFO:Initializing Decision Tree Regressor
2025-05-12 22:22:55,713:INFO:Total runtime is 0.06696569124857585 minutes
2025-05-12 22:22:55,717:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:55,718:INFO:Initializing create_model()
2025-05-12 22:22:55,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:55,718:INFO:Checking exceptions
2025-05-12 22:22:55,718:INFO:Importing libraries
2025-05-12 22:22:55,718:INFO:Copying training dataset
2025-05-12 22:22:55,723:INFO:Defining folds
2025-05-12 22:22:55,723:INFO:Declaring metric variables
2025-05-12 22:22:55,728:INFO:Importing untrained model
2025-05-12 22:22:55,734:INFO:Decision Tree Regressor Imported successfully
2025-05-12 22:22:55,742:INFO:Starting cross validation
2025-05-12 22:22:55,743:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:55,979:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:55,979:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:55,984:INFO:Calculating mean and std
2025-05-12 22:22:55,985:INFO:Creating metrics dataframe
2025-05-12 22:22:55,987:INFO:Uploading results into container
2025-05-12 22:22:55,989:INFO:Uploading model into container now
2025-05-12 22:22:55,989:INFO:_master_model_container: 12
2025-05-12 22:22:55,990:INFO:_display_container: 2
2025-05-12 22:22:55,990:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 22:22:55,990:INFO:create_model() successfully completed......................................
2025-05-12 22:22:56,077:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:56,079:INFO:Creating metrics dataframe
2025-05-12 22:22:56,088:INFO:Initializing Random Forest Regressor
2025-05-12 22:22:56,088:INFO:Total runtime is 0.0732298493385315 minutes
2025-05-12 22:22:56,091:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:56,091:INFO:Initializing create_model()
2025-05-12 22:22:56,091:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:56,091:INFO:Checking exceptions
2025-05-12 22:22:56,091:INFO:Importing libraries
2025-05-12 22:22:56,091:INFO:Copying training dataset
2025-05-12 22:22:56,097:INFO:Defining folds
2025-05-12 22:22:56,097:INFO:Declaring metric variables
2025-05-12 22:22:56,100:INFO:Importing untrained model
2025-05-12 22:22:56,105:INFO:Random Forest Regressor Imported successfully
2025-05-12 22:22:56,112:INFO:Starting cross validation
2025-05-12 22:22:56,114:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:56,950:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:56,950:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:56,960:INFO:Calculating mean and std
2025-05-12 22:22:56,961:INFO:Creating metrics dataframe
2025-05-12 22:22:56,963:INFO:Uploading results into container
2025-05-12 22:22:56,964:INFO:Uploading model into container now
2025-05-12 22:22:56,965:INFO:_master_model_container: 13
2025-05-12 22:22:56,965:INFO:_display_container: 2
2025-05-12 22:22:56,965:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:22:56,966:INFO:create_model() successfully completed......................................
2025-05-12 22:22:57,051:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:57,051:INFO:Creating metrics dataframe
2025-05-12 22:22:57,059:INFO:Initializing Extra Trees Regressor
2025-05-12 22:22:57,059:INFO:Total runtime is 0.08942150672276815 minutes
2025-05-12 22:22:57,063:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:57,063:INFO:Initializing create_model()
2025-05-12 22:22:57,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:57,064:INFO:Checking exceptions
2025-05-12 22:22:57,064:INFO:Importing libraries
2025-05-12 22:22:57,064:INFO:Copying training dataset
2025-05-12 22:22:57,068:INFO:Defining folds
2025-05-12 22:22:57,069:INFO:Declaring metric variables
2025-05-12 22:22:57,071:INFO:Importing untrained model
2025-05-12 22:22:57,076:INFO:Extra Trees Regressor Imported successfully
2025-05-12 22:22:57,082:INFO:Starting cross validation
2025-05-12 22:22:57,084:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:57,786:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:57,786:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:57,799:INFO:Calculating mean and std
2025-05-12 22:22:57,801:INFO:Creating metrics dataframe
2025-05-12 22:22:57,803:INFO:Uploading results into container
2025-05-12 22:22:57,804:INFO:Uploading model into container now
2025-05-12 22:22:57,804:INFO:_master_model_container: 14
2025-05-12 22:22:57,804:INFO:_display_container: 2
2025-05-12 22:22:57,806:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:22:57,806:INFO:create_model() successfully completed......................................
2025-05-12 22:22:57,893:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:57,893:INFO:Creating metrics dataframe
2025-05-12 22:22:57,903:INFO:Initializing AdaBoost Regressor
2025-05-12 22:22:57,903:INFO:Total runtime is 0.10348397095998128 minutes
2025-05-12 22:22:57,907:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:57,907:INFO:Initializing create_model()
2025-05-12 22:22:57,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:57,907:INFO:Checking exceptions
2025-05-12 22:22:57,907:INFO:Importing libraries
2025-05-12 22:22:57,907:INFO:Copying training dataset
2025-05-12 22:22:57,910:INFO:Defining folds
2025-05-12 22:22:57,910:INFO:Declaring metric variables
2025-05-12 22:22:57,916:INFO:Importing untrained model
2025-05-12 22:22:57,919:INFO:AdaBoost Regressor Imported successfully
2025-05-12 22:22:57,926:INFO:Starting cross validation
2025-05-12 22:22:57,928:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:58,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:58,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:58,629:INFO:Calculating mean and std
2025-05-12 22:22:58,631:INFO:Creating metrics dataframe
2025-05-12 22:22:58,633:INFO:Uploading results into container
2025-05-12 22:22:58,634:INFO:Uploading model into container now
2025-05-12 22:22:58,634:INFO:_master_model_container: 15
2025-05-12 22:22:58,636:INFO:_display_container: 2
2025-05-12 22:22:58,636:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 22:22:58,636:INFO:create_model() successfully completed......................................
2025-05-12 22:22:58,731:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:58,731:INFO:Creating metrics dataframe
2025-05-12 22:22:58,742:INFO:Initializing Gradient Boosting Regressor
2025-05-12 22:22:58,742:INFO:Total runtime is 0.11746471722920736 minutes
2025-05-12 22:22:58,745:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:58,746:INFO:Initializing create_model()
2025-05-12 22:22:58,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:58,747:INFO:Checking exceptions
2025-05-12 22:22:58,747:INFO:Importing libraries
2025-05-12 22:22:58,747:INFO:Copying training dataset
2025-05-12 22:22:58,753:INFO:Defining folds
2025-05-12 22:22:58,753:INFO:Declaring metric variables
2025-05-12 22:22:58,757:INFO:Importing untrained model
2025-05-12 22:22:58,761:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 22:22:58,770:INFO:Starting cross validation
2025-05-12 22:22:58,771:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:59,227:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:59,227:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:59,231:INFO:Calculating mean and std
2025-05-12 22:22:59,233:INFO:Creating metrics dataframe
2025-05-12 22:22:59,236:INFO:Uploading results into container
2025-05-12 22:22:59,236:INFO:Uploading model into container now
2025-05-12 22:22:59,237:INFO:_master_model_container: 16
2025-05-12 22:22:59,237:INFO:_display_container: 2
2025-05-12 22:22:59,238:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 22:22:59,238:INFO:create_model() successfully completed......................................
2025-05-12 22:22:59,333:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:59,333:INFO:Creating metrics dataframe
2025-05-12 22:22:59,344:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:22:59,344:INFO:Total runtime is 0.12749578952789306 minutes
2025-05-12 22:22:59,347:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:59,347:INFO:Initializing create_model()
2025-05-12 22:22:59,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:59,349:INFO:Checking exceptions
2025-05-12 22:22:59,349:INFO:Importing libraries
2025-05-12 22:22:59,349:INFO:Copying training dataset
2025-05-12 22:22:59,354:INFO:Defining folds
2025-05-12 22:22:59,354:INFO:Declaring metric variables
2025-05-12 22:22:59,358:INFO:Importing untrained model
2025-05-12 22:22:59,363:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:22:59,372:INFO:Starting cross validation
2025-05-12 22:22:59,373:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:59,959:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:59,959:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:59,965:INFO:Calculating mean and std
2025-05-12 22:22:59,967:INFO:Creating metrics dataframe
2025-05-12 22:22:59,970:INFO:Uploading results into container
2025-05-12 22:22:59,971:INFO:Uploading model into container now
2025-05-12 22:22:59,971:INFO:_master_model_container: 17
2025-05-12 22:22:59,973:INFO:_display_container: 2
2025-05-12 22:22:59,974:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:22:59,974:INFO:create_model() successfully completed......................................
2025-05-12 22:23:00,089:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:00,089:INFO:Creating metrics dataframe
2025-05-12 22:23:00,101:INFO:Initializing Dummy Regressor
2025-05-12 22:23:00,101:INFO:Total runtime is 0.14011609156926472 minutes
2025-05-12 22:23:00,105:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:00,106:INFO:Initializing create_model()
2025-05-12 22:23:00,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:00,106:INFO:Checking exceptions
2025-05-12 22:23:00,106:INFO:Importing libraries
2025-05-12 22:23:00,106:INFO:Copying training dataset
2025-05-12 22:23:00,110:INFO:Defining folds
2025-05-12 22:23:00,111:INFO:Declaring metric variables
2025-05-12 22:23:00,115:INFO:Importing untrained model
2025-05-12 22:23:00,119:INFO:Dummy Regressor Imported successfully
2025-05-12 22:23:00,127:INFO:Starting cross validation
2025-05-12 22:23:00,130:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:00,348:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:23:00,348:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:23:00,349:INFO:Calculating mean and std
2025-05-12 22:23:00,350:INFO:Creating metrics dataframe
2025-05-12 22:23:00,354:INFO:Uploading results into container
2025-05-12 22:23:00,355:INFO:Uploading model into container now
2025-05-12 22:23:00,355:INFO:_master_model_container: 18
2025-05-12 22:23:00,355:INFO:_display_container: 2
2025-05-12 22:23:00,355:INFO:DummyRegressor()
2025-05-12 22:23:00,355:INFO:create_model() successfully completed......................................
2025-05-12 22:23:00,444:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:00,444:INFO:Creating metrics dataframe
2025-05-12 22:23:00,453:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:23:00,462:INFO:Initializing create_model()
2025-05-12 22:23:00,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:00,463:INFO:Checking exceptions
2025-05-12 22:23:00,464:INFO:Importing libraries
2025-05-12 22:23:00,464:INFO:Copying training dataset
2025-05-12 22:23:00,467:INFO:Defining folds
2025-05-12 22:23:00,468:INFO:Declaring metric variables
2025-05-12 22:23:00,468:INFO:Importing untrained model
2025-05-12 22:23:00,468:INFO:Declaring custom model
2025-05-12 22:23:00,468:INFO:Lasso Regression Imported successfully
2025-05-12 22:23:00,469:INFO:Cross validation set to False
2025-05-12 22:23:00,469:INFO:Fitting Model
2025-05-12 22:23:00,505:INFO:Lasso(random_state=123)
2025-05-12 22:23:00,505:INFO:create_model() successfully completed......................................
2025-05-12 22:23:00,608:INFO:_master_model_container: 18
2025-05-12 22:23:00,609:INFO:_display_container: 2
2025-05-12 22:23:00,609:INFO:Lasso(random_state=123)
2025-05-12 22:23:00,609:INFO:compare_models() successfully completed......................................
2025-05-12 22:23:00,631:INFO:Initializing create_model()
2025-05-12 22:23:00,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=dummy, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:00,631:INFO:Checking exceptions
2025-05-12 22:23:00,671:INFO:Importing libraries
2025-05-12 22:23:00,671:INFO:Copying training dataset
2025-05-12 22:23:00,679:INFO:Defining folds
2025-05-12 22:23:00,679:INFO:Declaring metric variables
2025-05-12 22:23:00,687:INFO:Importing untrained model
2025-05-12 22:23:00,694:INFO:Dummy Regressor Imported successfully
2025-05-12 22:23:00,706:INFO:Starting cross validation
2025-05-12 22:23:00,709:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:00,969:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:23:00,970:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:23:00,974:INFO:Calculating mean and std
2025-05-12 22:23:00,974:INFO:Creating metrics dataframe
2025-05-12 22:23:00,981:INFO:Finalizing model
2025-05-12 22:23:01,034:INFO:Uploading results into container
2025-05-12 22:23:01,036:INFO:Uploading model into container now
2025-05-12 22:23:01,047:INFO:_master_model_container: 19
2025-05-12 22:23:01,047:INFO:_display_container: 3
2025-05-12 22:23:01,048:INFO:DummyRegressor()
2025-05-12 22:23:01,048:INFO:create_model() successfully completed......................................
2025-05-12 22:23:01,146:INFO:Initializing tune_model()
2025-05-12 22:23:01,147:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=DummyRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:23:01,147:INFO:Checking exceptions
2025-05-12 22:23:01,165:INFO:Copying training dataset
2025-05-12 22:23:01,168:INFO:Checking base model
2025-05-12 22:23:01,168:INFO:Base model : Dummy Regressor
2025-05-12 22:23:01,174:INFO:Declaring metric variables
2025-05-12 22:23:01,178:INFO:Defining Hyperparameters
2025-05-12 22:23:01,179:INFO:10 is bigger than total combinations 1, setting search algorithm to grid
2025-05-12 22:23:12,820:INFO:PyCaret ClassificationExperiment
2025-05-12 22:23:12,820:INFO:Logging name: clf-default-name
2025-05-12 22:23:12,820:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-12 22:23:12,820:INFO:version 3.3.2
2025-05-12 22:23:12,820:INFO:Initializing setup()
2025-05-12 22:23:12,820:INFO:self.USI: b78c
2025-05-12 22:23:12,820:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'is_multiclass', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', 'fix_imbalance', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:23:12,820:INFO:Checking environment
2025-05-12 22:23:12,820:INFO:python_version: 3.11.8
2025-05-12 22:23:12,820:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:23:12,820:INFO:machine: AMD64
2025-05-12 22:23:12,820:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:23:12,825:INFO:Memory: svmem(total=16907886592, available=2995605504, percent=82.3, used=13912281088, free=2995605504)
2025-05-12 22:23:12,826:INFO:Physical Core: 4
2025-05-12 22:23:12,826:INFO:Logical Core: 8
2025-05-12 22:23:12,826:INFO:Checking libraries
2025-05-12 22:23:12,826:INFO:System:
2025-05-12 22:23:12,826:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:23:12,826:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:23:12,826:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:23:12,826:INFO:PyCaret required dependencies:
2025-05-12 22:23:12,826:INFO:                 pip: 24.0
2025-05-12 22:23:12,826:INFO:          setuptools: 65.5.0
2025-05-12 22:23:12,826:INFO:             pycaret: 3.3.2
2025-05-12 22:23:12,826:INFO:             IPython: 9.2.0
2025-05-12 22:23:12,826:INFO:          ipywidgets: 8.1.7
2025-05-12 22:23:12,826:INFO:                tqdm: 4.67.1
2025-05-12 22:23:12,826:INFO:               numpy: 1.26.4
2025-05-12 22:23:12,826:INFO:              pandas: 2.1.4
2025-05-12 22:23:12,826:INFO:              jinja2: 3.1.6
2025-05-12 22:23:12,826:INFO:               scipy: 1.11.4
2025-05-12 22:23:12,826:INFO:              joblib: 1.3.2
2025-05-12 22:23:12,826:INFO:             sklearn: 1.4.2
2025-05-12 22:23:12,826:INFO:                pyod: 2.0.5
2025-05-12 22:23:12,826:INFO:            imblearn: 0.13.0
2025-05-12 22:23:12,826:INFO:   category_encoders: 2.7.0
2025-05-12 22:23:12,826:INFO:            lightgbm: 4.6.0
2025-05-12 22:23:12,826:INFO:               numba: 0.61.2
2025-05-12 22:23:12,826:INFO:            requests: 2.32.3
2025-05-12 22:23:12,826:INFO:          matplotlib: 3.7.5
2025-05-12 22:23:12,826:INFO:          scikitplot: 0.3.7
2025-05-12 22:23:12,826:INFO:         yellowbrick: 1.5
2025-05-12 22:23:12,827:INFO:              plotly: 5.24.1
2025-05-12 22:23:12,827:INFO:    plotly-resampler: Not installed
2025-05-12 22:23:12,827:INFO:             kaleido: 0.2.1
2025-05-12 22:23:12,827:INFO:           schemdraw: 0.15
2025-05-12 22:23:12,827:INFO:         statsmodels: 0.14.4
2025-05-12 22:23:12,827:INFO:              sktime: 0.26.0
2025-05-12 22:23:12,827:INFO:               tbats: 1.1.3
2025-05-12 22:23:12,827:INFO:            pmdarima: 2.0.4
2025-05-12 22:23:12,827:INFO:              psutil: 7.0.0
2025-05-12 22:23:12,827:INFO:          markupsafe: 3.0.2
2025-05-12 22:23:12,827:INFO:             pickle5: Not installed
2025-05-12 22:23:12,827:INFO:         cloudpickle: 3.1.1
2025-05-12 22:23:12,827:INFO:         deprecation: 2.1.0
2025-05-12 22:23:12,827:INFO:              xxhash: 3.5.0
2025-05-12 22:23:12,827:INFO:           wurlitzer: Not installed
2025-05-12 22:23:12,827:INFO:PyCaret optional dependencies:
2025-05-12 22:23:12,827:INFO:                shap: Not installed
2025-05-12 22:23:12,827:INFO:           interpret: Not installed
2025-05-12 22:23:12,827:INFO:                umap: Not installed
2025-05-12 22:23:12,827:INFO:     ydata_profiling: Not installed
2025-05-12 22:23:12,827:INFO:  explainerdashboard: Not installed
2025-05-12 22:23:12,827:INFO:             autoviz: Not installed
2025-05-12 22:23:12,827:INFO:           fairlearn: Not installed
2025-05-12 22:23:12,827:INFO:          deepchecks: Not installed
2025-05-12 22:23:12,827:INFO:             xgboost: Not installed
2025-05-12 22:23:12,827:INFO:            catboost: Not installed
2025-05-12 22:23:12,827:INFO:              kmodes: Not installed
2025-05-12 22:23:12,827:INFO:             mlxtend: Not installed
2025-05-12 22:23:12,827:INFO:       statsforecast: Not installed
2025-05-12 22:23:12,827:INFO:        tune_sklearn: Not installed
2025-05-12 22:23:12,827:INFO:                 ray: Not installed
2025-05-12 22:23:12,827:INFO:            hyperopt: Not installed
2025-05-12 22:23:12,827:INFO:              optuna: Not installed
2025-05-12 22:23:12,827:INFO:               skopt: Not installed
2025-05-12 22:23:12,827:INFO:              mlflow: Not installed
2025-05-12 22:23:12,827:INFO:              gradio: Not installed
2025-05-12 22:23:12,827:INFO:             fastapi: Not installed
2025-05-12 22:23:12,827:INFO:             uvicorn: Not installed
2025-05-12 22:23:12,827:INFO:              m2cgen: Not installed
2025-05-12 22:23:12,827:INFO:           evidently: Not installed
2025-05-12 22:23:12,828:INFO:               fugue: Not installed
2025-05-12 22:23:12,828:INFO:           streamlit: Not installed
2025-05-12 22:23:12,828:INFO:             prophet: Not installed
2025-05-12 22:23:12,828:INFO:None
2025-05-12 22:23:12,828:INFO:Set up data.
2025-05-12 22:23:12,832:INFO:Set up folding strategy.
2025-05-12 22:23:12,832:INFO:Set up train/test split.
2025-05-12 22:23:12,839:INFO:Set up index.
2025-05-12 22:23:12,839:INFO:Assigning column types.
2025-05-12 22:23:12,843:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:23:12,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:23:12,881:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:23:12,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:12,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:12,942:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:23:12,943:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:23:12,966:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:12,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:12,966:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:23:13,003:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:23:13,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,029:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,064:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:23:13,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,088:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-12 22:23:13,146:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,146:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,205:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,206:INFO:Preparing preprocessing pipeline...
2025-05-12 22:23:13,207:INFO:Set up simple imputation.
2025-05-12 22:23:13,208:INFO:Set up encoding of categorical features.
2025-05-12 22:23:13,208:INFO:Set up feature normalization.
2025-05-12 22:23:13,259:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:23:13,263:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:23:13,263:INFO:Creating final display dataframe.
2025-05-12 22:23:13,401:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              b78c
2025-05-12 22:23:13,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,581:INFO:setup() successfully completed in 0.76s...............
2025-05-12 22:23:13,596:INFO:Initializing compare_models()
2025-05-12 22:23:13,596:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-12 22:23:13,596:INFO:Checking exceptions
2025-05-12 22:23:13,601:INFO:Preparing display monitor
2025-05-12 22:23:13,620:INFO:Initializing Logistic Regression
2025-05-12 22:23:13,620:INFO:Total runtime is 0.0 minutes
2025-05-12 22:23:13,624:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:13,624:INFO:Initializing create_model()
2025-05-12 22:23:13,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:13,624:INFO:Checking exceptions
2025-05-12 22:23:13,624:INFO:Importing libraries
2025-05-12 22:23:13,624:INFO:Copying training dataset
2025-05-12 22:23:13,629:INFO:Defining folds
2025-05-12 22:23:13,629:INFO:Declaring metric variables
2025-05-12 22:23:13,632:INFO:Importing untrained model
2025-05-12 22:23:13,636:INFO:Logistic Regression Imported successfully
2025-05-12 22:23:13,642:INFO:Starting cross validation
2025-05-12 22:23:13,644:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:13,778:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:13,778:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:13,778:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:13,778:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:13,780:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:13,839:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:13,849:INFO:Calculating mean and std
2025-05-12 22:23:13,849:INFO:Creating metrics dataframe
2025-05-12 22:23:13,851:INFO:Uploading results into container
2025-05-12 22:23:13,851:INFO:Uploading model into container now
2025-05-12 22:23:13,851:INFO:_master_model_container: 1
2025-05-12 22:23:13,851:INFO:_display_container: 2
2025-05-12 22:23:13,852:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-12 22:23:13,852:INFO:create_model() successfully completed......................................
2025-05-12 22:23:13,949:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:13,949:INFO:Creating metrics dataframe
2025-05-12 22:23:13,954:INFO:Initializing K Neighbors Classifier
2025-05-12 22:23:13,954:INFO:Total runtime is 0.005555458863576253 minutes
2025-05-12 22:23:13,956:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:13,957:INFO:Initializing create_model()
2025-05-12 22:23:13,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:13,957:INFO:Checking exceptions
2025-05-12 22:23:13,957:INFO:Importing libraries
2025-05-12 22:23:13,957:INFO:Copying training dataset
2025-05-12 22:23:13,960:INFO:Defining folds
2025-05-12 22:23:13,960:INFO:Declaring metric variables
2025-05-12 22:23:13,963:INFO:Importing untrained model
2025-05-12 22:23:13,965:INFO:K Neighbors Classifier Imported successfully
2025-05-12 22:23:13,972:INFO:Starting cross validation
2025-05-12 22:23:13,974:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:14,118:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,120:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,124:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,137:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,139:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,221:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,232:INFO:Calculating mean and std
2025-05-12 22:23:14,232:INFO:Creating metrics dataframe
2025-05-12 22:23:14,235:INFO:Uploading results into container
2025-05-12 22:23:14,235:INFO:Uploading model into container now
2025-05-12 22:23:14,235:INFO:_master_model_container: 2
2025-05-12 22:23:14,235:INFO:_display_container: 2
2025-05-12 22:23:14,235:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-12 22:23:14,235:INFO:create_model() successfully completed......................................
2025-05-12 22:23:14,322:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:14,322:INFO:Creating metrics dataframe
2025-05-12 22:23:14,327:INFO:Initializing Naive Bayes
2025-05-12 22:23:14,327:INFO:Total runtime is 0.01177448829015096 minutes
2025-05-12 22:23:14,330:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:14,330:INFO:Initializing create_model()
2025-05-12 22:23:14,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:14,330:INFO:Checking exceptions
2025-05-12 22:23:14,330:INFO:Importing libraries
2025-05-12 22:23:14,330:INFO:Copying training dataset
2025-05-12 22:23:14,334:INFO:Defining folds
2025-05-12 22:23:14,335:INFO:Declaring metric variables
2025-05-12 22:23:14,338:INFO:Importing untrained model
2025-05-12 22:23:14,340:INFO:Naive Bayes Imported successfully
2025-05-12 22:23:14,345:INFO:Starting cross validation
2025-05-12 22:23:14,346:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:14,454:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,474:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,487:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,529:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,533:INFO:Calculating mean and std
2025-05-12 22:23:14,533:INFO:Creating metrics dataframe
2025-05-12 22:23:14,534:INFO:Uploading results into container
2025-05-12 22:23:14,534:INFO:Uploading model into container now
2025-05-12 22:23:14,534:INFO:_master_model_container: 3
2025-05-12 22:23:14,534:INFO:_display_container: 2
2025-05-12 22:23:14,534:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-12 22:23:14,536:INFO:create_model() successfully completed......................................
2025-05-12 22:23:14,620:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:14,620:INFO:Creating metrics dataframe
2025-05-12 22:23:14,625:INFO:Initializing Decision Tree Classifier
2025-05-12 22:23:14,625:INFO:Total runtime is 0.016750792662302654 minutes
2025-05-12 22:23:14,627:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:14,627:INFO:Initializing create_model()
2025-05-12 22:23:14,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:14,627:INFO:Checking exceptions
2025-05-12 22:23:14,627:INFO:Importing libraries
2025-05-12 22:23:14,627:INFO:Copying training dataset
2025-05-12 22:23:14,633:INFO:Defining folds
2025-05-12 22:23:14,633:INFO:Declaring metric variables
2025-05-12 22:23:14,635:INFO:Importing untrained model
2025-05-12 22:23:14,639:INFO:Decision Tree Classifier Imported successfully
2025-05-12 22:23:14,644:INFO:Starting cross validation
2025-05-12 22:23:14,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:14,753:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,821:INFO:Calculating mean and std
2025-05-12 22:23:14,822:INFO:Creating metrics dataframe
2025-05-12 22:23:14,823:INFO:Uploading results into container
2025-05-12 22:23:14,824:INFO:Uploading model into container now
2025-05-12 22:23:14,824:INFO:_master_model_container: 4
2025-05-12 22:23:14,824:INFO:_display_container: 2
2025-05-12 22:23:14,824:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-12 22:23:14,824:INFO:create_model() successfully completed......................................
2025-05-12 22:23:14,908:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:14,908:INFO:Creating metrics dataframe
2025-05-12 22:23:14,913:INFO:Initializing SVM - Linear Kernel
2025-05-12 22:23:14,913:INFO:Total runtime is 0.021540633837382 minutes
2025-05-12 22:23:14,917:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:14,917:INFO:Initializing create_model()
2025-05-12 22:23:14,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:14,917:INFO:Checking exceptions
2025-05-12 22:23:14,917:INFO:Importing libraries
2025-05-12 22:23:14,917:INFO:Copying training dataset
2025-05-12 22:23:14,920:INFO:Defining folds
2025-05-12 22:23:14,920:INFO:Declaring metric variables
2025-05-12 22:23:14,923:INFO:Importing untrained model
2025-05-12 22:23:14,925:INFO:SVM - Linear Kernel Imported successfully
2025-05-12 22:23:14,932:INFO:Starting cross validation
2025-05-12 22:23:14,934:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:15,043:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,051:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,110:INFO:Calculating mean and std
2025-05-12 22:23:15,110:INFO:Creating metrics dataframe
2025-05-12 22:23:15,112:INFO:Uploading results into container
2025-05-12 22:23:15,113:INFO:Uploading model into container now
2025-05-12 22:23:15,113:INFO:_master_model_container: 5
2025-05-12 22:23:15,113:INFO:_display_container: 2
2025-05-12 22:23:15,114:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-12 22:23:15,114:INFO:create_model() successfully completed......................................
2025-05-12 22:23:15,197:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:15,197:INFO:Creating metrics dataframe
2025-05-12 22:23:15,202:INFO:Initializing Ridge Classifier
2025-05-12 22:23:15,202:INFO:Total runtime is 0.026363412539164226 minutes
2025-05-12 22:23:15,205:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:15,205:INFO:Initializing create_model()
2025-05-12 22:23:15,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:15,205:INFO:Checking exceptions
2025-05-12 22:23:15,205:INFO:Importing libraries
2025-05-12 22:23:15,205:INFO:Copying training dataset
2025-05-12 22:23:15,207:INFO:Defining folds
2025-05-12 22:23:15,207:INFO:Declaring metric variables
2025-05-12 22:23:15,211:INFO:Importing untrained model
2025-05-12 22:23:15,214:INFO:Ridge Classifier Imported successfully
2025-05-12 22:23:15,221:INFO:Starting cross validation
2025-05-12 22:23:15,223:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:15,323:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,327:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,328:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,328:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,333:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,345:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,390:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,391:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,404:INFO:Calculating mean and std
2025-05-12 22:23:15,404:INFO:Creating metrics dataframe
2025-05-12 22:23:15,407:INFO:Uploading results into container
2025-05-12 22:23:15,407:INFO:Uploading model into container now
2025-05-12 22:23:15,407:INFO:_master_model_container: 6
2025-05-12 22:23:15,407:INFO:_display_container: 2
2025-05-12 22:23:15,408:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-12 22:23:15,408:INFO:create_model() successfully completed......................................
2025-05-12 22:23:15,493:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:15,493:INFO:Creating metrics dataframe
2025-05-12 22:23:15,501:INFO:Initializing Random Forest Classifier
2025-05-12 22:23:15,501:INFO:Total runtime is 0.03133915265401205 minutes
2025-05-12 22:23:15,503:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:15,504:INFO:Initializing create_model()
2025-05-12 22:23:15,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:15,504:INFO:Checking exceptions
2025-05-12 22:23:15,504:INFO:Importing libraries
2025-05-12 22:23:15,504:INFO:Copying training dataset
2025-05-12 22:23:15,507:INFO:Defining folds
2025-05-12 22:23:15,507:INFO:Declaring metric variables
2025-05-12 22:23:15,509:INFO:Importing untrained model
2025-05-12 22:23:15,512:INFO:Random Forest Classifier Imported successfully
2025-05-12 22:23:15,520:INFO:Starting cross validation
2025-05-12 22:23:15,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:15,999:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,027:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,034:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,034:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,058:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,087:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,144:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,385:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,408:INFO:Calculating mean and std
2025-05-12 22:23:16,408:INFO:Creating metrics dataframe
2025-05-12 22:23:16,410:INFO:Uploading results into container
2025-05-12 22:23:16,411:INFO:Uploading model into container now
2025-05-12 22:23:16,411:INFO:_master_model_container: 7
2025-05-12 22:23:16,411:INFO:_display_container: 2
2025-05-12 22:23:16,413:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-12 22:23:16,413:INFO:create_model() successfully completed......................................
2025-05-12 22:23:16,515:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:16,515:INFO:Creating metrics dataframe
2025-05-12 22:23:16,526:INFO:Initializing Quadratic Discriminant Analysis
2025-05-12 22:23:16,526:INFO:Total runtime is 0.048425912857055664 minutes
2025-05-12 22:23:16,531:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:16,531:INFO:Initializing create_model()
2025-05-12 22:23:16,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:16,532:INFO:Checking exceptions
2025-05-12 22:23:16,532:INFO:Importing libraries
2025-05-12 22:23:16,532:INFO:Copying training dataset
2025-05-12 22:23:16,536:INFO:Defining folds
2025-05-12 22:23:16,536:INFO:Declaring metric variables
2025-05-12 22:23:16,541:INFO:Importing untrained model
2025-05-12 22:23:16,547:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-12 22:23:16,559:INFO:Starting cross validation
2025-05-12 22:23:16,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:16,806:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:16,806:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:16,806:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:16,807:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:16,818:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:16,822:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:16,863:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:16,917:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,928:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:17,001:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:17,013:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:17,078:INFO:Calculating mean and std
2025-05-12 22:23:17,079:INFO:Creating metrics dataframe
2025-05-12 22:23:17,083:INFO:Uploading results into container
2025-05-12 22:23:17,085:INFO:Uploading model into container now
2025-05-12 22:23:17,085:INFO:_master_model_container: 8
2025-05-12 22:23:17,085:INFO:_display_container: 2
2025-05-12 22:23:17,086:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-12 22:23:17,086:INFO:create_model() successfully completed......................................
2025-05-12 22:23:17,203:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:17,203:INFO:Creating metrics dataframe
2025-05-12 22:23:17,212:INFO:Initializing Ada Boost Classifier
2025-05-12 22:23:17,212:INFO:Total runtime is 0.059854185581207274 minutes
2025-05-12 22:23:17,219:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:17,219:INFO:Initializing create_model()
2025-05-12 22:23:17,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:17,219:INFO:Checking exceptions
2025-05-12 22:23:17,220:INFO:Importing libraries
2025-05-12 22:23:17,220:INFO:Copying training dataset
2025-05-12 22:23:17,227:INFO:Defining folds
2025-05-12 22:23:17,227:INFO:Declaring metric variables
2025-05-12 22:23:17,234:INFO:Importing untrained model
2025-05-12 22:23:17,238:INFO:Ada Boost Classifier Imported successfully
2025-05-12 22:23:17,247:INFO:Starting cross validation
2025-05-12 22:23:17,249:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:17,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,397:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,397:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,399:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,410:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,436:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,715:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:17,859:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,875:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:17,889:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:18,057:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:18,081:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:18,095:INFO:Calculating mean and std
2025-05-12 22:23:18,098:INFO:Creating metrics dataframe
2025-05-12 22:23:18,100:INFO:Uploading results into container
2025-05-12 22:23:18,100:INFO:Uploading model into container now
2025-05-12 22:23:18,101:INFO:_master_model_container: 9
2025-05-12 22:23:18,101:INFO:_display_container: 2
2025-05-12 22:23:18,103:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-12 22:23:18,103:INFO:create_model() successfully completed......................................
2025-05-12 22:23:18,207:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:18,208:INFO:Creating metrics dataframe
2025-05-12 22:23:18,217:INFO:Initializing Gradient Boosting Classifier
2025-05-12 22:23:18,217:INFO:Total runtime is 0.07660452127456666 minutes
2025-05-12 22:23:18,220:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:18,221:INFO:Initializing create_model()
2025-05-12 22:23:18,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:18,221:INFO:Checking exceptions
2025-05-12 22:23:18,221:INFO:Importing libraries
2025-05-12 22:23:18,221:INFO:Copying training dataset
2025-05-12 22:23:18,226:INFO:Defining folds
2025-05-12 22:23:18,226:INFO:Declaring metric variables
2025-05-12 22:23:18,231:INFO:Importing untrained model
2025-05-12 22:23:18,237:INFO:Gradient Boosting Classifier Imported successfully
2025-05-12 22:23:18,247:INFO:Starting cross validation
2025-05-12 22:23:18,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:18,649:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:18,894:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:18,907:INFO:Calculating mean and std
2025-05-12 22:23:18,908:INFO:Creating metrics dataframe
2025-05-12 22:23:18,910:INFO:Uploading results into container
2025-05-12 22:23:18,911:INFO:Uploading model into container now
2025-05-12 22:23:18,911:INFO:_master_model_container: 10
2025-05-12 22:23:18,911:INFO:_display_container: 2
2025-05-12 22:23:18,913:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-12 22:23:18,913:INFO:create_model() successfully completed......................................
2025-05-12 22:23:19,009:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:19,010:INFO:Creating metrics dataframe
2025-05-12 22:23:19,022:INFO:Initializing Linear Discriminant Analysis
2025-05-12 22:23:19,022:INFO:Total runtime is 0.09002350568771363 minutes
2025-05-12 22:23:19,027:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:19,027:INFO:Initializing create_model()
2025-05-12 22:23:19,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:19,028:INFO:Checking exceptions
2025-05-12 22:23:19,028:INFO:Importing libraries
2025-05-12 22:23:19,028:INFO:Copying training dataset
2025-05-12 22:23:19,033:INFO:Defining folds
2025-05-12 22:23:19,033:INFO:Declaring metric variables
2025-05-12 22:23:19,037:INFO:Importing untrained model
2025-05-12 22:23:19,041:INFO:Linear Discriminant Analysis Imported successfully
2025-05-12 22:23:19,051:INFO:Starting cross validation
2025-05-12 22:23:19,053:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:19,211:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:19,211:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:19,216:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:19,218:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:19,219:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:19,323:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:19,337:INFO:Calculating mean and std
2025-05-12 22:23:19,338:INFO:Creating metrics dataframe
2025-05-12 22:23:19,341:INFO:Uploading results into container
2025-05-12 22:23:19,342:INFO:Uploading model into container now
2025-05-12 22:23:19,344:INFO:_master_model_container: 11
2025-05-12 22:23:19,344:INFO:_display_container: 2
2025-05-12 22:23:19,344:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-12 22:23:19,344:INFO:create_model() successfully completed......................................
2025-05-12 22:23:19,446:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:19,446:INFO:Creating metrics dataframe
2025-05-12 22:23:19,454:INFO:Initializing Extra Trees Classifier
2025-05-12 22:23:19,456:INFO:Total runtime is 0.09725764989852906 minutes
2025-05-12 22:23:19,459:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:19,459:INFO:Initializing create_model()
2025-05-12 22:23:19,460:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:19,460:INFO:Checking exceptions
2025-05-12 22:23:19,460:INFO:Importing libraries
2025-05-12 22:23:19,460:INFO:Copying training dataset
2025-05-12 22:23:19,464:INFO:Defining folds
2025-05-12 22:23:19,465:INFO:Declaring metric variables
2025-05-12 22:23:19,469:INFO:Importing untrained model
2025-05-12 22:23:19,474:INFO:Extra Trees Classifier Imported successfully
2025-05-12 22:23:19,483:INFO:Starting cross validation
2025-05-12 22:23:19,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:20,031:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:20,042:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:20,091:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:20,385:INFO:Calculating mean and std
2025-05-12 22:23:20,386:INFO:Creating metrics dataframe
2025-05-12 22:23:20,389:INFO:Uploading results into container
2025-05-12 22:23:20,389:INFO:Uploading model into container now
2025-05-12 22:23:20,390:INFO:_master_model_container: 12
2025-05-12 22:23:20,390:INFO:_display_container: 2
2025-05-12 22:23:20,390:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-12 22:23:20,390:INFO:create_model() successfully completed......................................
2025-05-12 22:23:20,488:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:20,488:INFO:Creating metrics dataframe
2025-05-12 22:23:20,501:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:23:20,501:INFO:Total runtime is 0.11467044750849406 minutes
2025-05-12 22:23:20,505:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:20,506:INFO:Initializing create_model()
2025-05-12 22:23:20,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:20,506:INFO:Checking exceptions
2025-05-12 22:23:20,506:INFO:Importing libraries
2025-05-12 22:23:20,506:INFO:Copying training dataset
2025-05-12 22:23:20,510:INFO:Defining folds
2025-05-12 22:23:20,511:INFO:Declaring metric variables
2025-05-12 22:23:20,518:INFO:Importing untrained model
2025-05-12 22:23:20,537:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:23:20,584:INFO:Starting cross validation
2025-05-12 22:23:20,587:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:20,997:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,052:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,059:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,224:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,243:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,366:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,387:INFO:Calculating mean and std
2025-05-12 22:23:21,390:INFO:Creating metrics dataframe
2025-05-12 22:23:21,396:INFO:Uploading results into container
2025-05-12 22:23:21,397:INFO:Uploading model into container now
2025-05-12 22:23:21,398:INFO:_master_model_container: 13
2025-05-12 22:23:21,398:INFO:_display_container: 2
2025-05-12 22:23:21,399:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:23:21,399:INFO:create_model() successfully completed......................................
2025-05-12 22:23:21,525:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:21,526:INFO:Creating metrics dataframe
2025-05-12 22:23:21,536:INFO:Initializing Dummy Classifier
2025-05-12 22:23:21,536:INFO:Total runtime is 0.1319331725438436 minutes
2025-05-12 22:23:21,541:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:21,541:INFO:Initializing create_model()
2025-05-12 22:23:21,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:21,541:INFO:Checking exceptions
2025-05-12 22:23:21,542:INFO:Importing libraries
2025-05-12 22:23:21,542:INFO:Copying training dataset
2025-05-12 22:23:21,547:INFO:Defining folds
2025-05-12 22:23:21,547:INFO:Declaring metric variables
2025-05-12 22:23:21,551:INFO:Importing untrained model
2025-05-12 22:23:21,556:INFO:Dummy Classifier Imported successfully
2025-05-12 22:23:21,567:INFO:Starting cross validation
2025-05-12 22:23:21,569:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:21,722:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,727:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,737:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,753:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,754:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,769:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,784:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,881:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,889:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,909:INFO:Calculating mean and std
2025-05-12 22:23:21,911:INFO:Creating metrics dataframe
2025-05-12 22:23:21,914:INFO:Uploading results into container
2025-05-12 22:23:21,917:INFO:Uploading model into container now
2025-05-12 22:23:21,918:INFO:_master_model_container: 14
2025-05-12 22:23:21,918:INFO:_display_container: 2
2025-05-12 22:23:21,919:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:23:21,919:INFO:create_model() successfully completed......................................
2025-05-12 22:23:22,040:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:22,040:INFO:Creating metrics dataframe
2025-05-12 22:23:22,052:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:23:22,064:INFO:Initializing create_model()
2025-05-12 22:23:22,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:22,064:INFO:Checking exceptions
2025-05-12 22:23:22,066:INFO:Importing libraries
2025-05-12 22:23:22,066:INFO:Copying training dataset
2025-05-12 22:23:22,070:INFO:Defining folds
2025-05-12 22:23:22,070:INFO:Declaring metric variables
2025-05-12 22:23:22,070:INFO:Importing untrained model
2025-05-12 22:23:22,070:INFO:Declaring custom model
2025-05-12 22:23:22,071:INFO:Dummy Classifier Imported successfully
2025-05-12 22:23:22,072:INFO:Cross validation set to False
2025-05-12 22:23:22,072:INFO:Fitting Model
2025-05-12 22:23:22,119:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:23:22,119:INFO:create_model() successfully completed......................................
2025-05-12 22:23:22,243:INFO:_master_model_container: 14
2025-05-12 22:23:22,243:INFO:_display_container: 2
2025-05-12 22:23:22,243:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:23:22,243:INFO:compare_models() successfully completed......................................
2025-05-12 22:23:22,261:INFO:Initializing create_model()
2025-05-12 22:23:22,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=dummy, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:22,261:INFO:Checking exceptions
2025-05-12 22:23:22,278:INFO:Importing libraries
2025-05-12 22:23:22,279:INFO:Copying training dataset
2025-05-12 22:23:22,284:INFO:Defining folds
2025-05-12 22:23:22,284:INFO:Declaring metric variables
2025-05-12 22:23:22,290:INFO:Importing untrained model
2025-05-12 22:23:22,296:INFO:Dummy Classifier Imported successfully
2025-05-12 22:23:22,305:INFO:Starting cross validation
2025-05-12 22:23:22,308:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:22,463:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,463:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,466:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,470:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,510:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,513:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,527:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,532:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,585:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,588:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,603:INFO:Calculating mean and std
2025-05-12 22:23:22,603:INFO:Creating metrics dataframe
2025-05-12 22:23:22,609:INFO:Finalizing model
2025-05-12 22:23:22,661:INFO:Uploading results into container
2025-05-12 22:23:22,662:INFO:Uploading model into container now
2025-05-12 22:23:22,673:INFO:_master_model_container: 15
2025-05-12 22:23:22,673:INFO:_display_container: 3
2025-05-12 22:23:22,674:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:23:22,674:INFO:create_model() successfully completed......................................
2025-05-12 22:23:22,843:INFO:Initializing tune_model()
2025-05-12 22:23:22,843:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:23:22,844:INFO:Checking exceptions
2025-05-12 22:23:22,865:INFO:Copying training dataset
2025-05-12 22:23:22,869:INFO:Checking base model
2025-05-12 22:23:22,869:INFO:Base model : Dummy Classifier
2025-05-12 22:23:22,874:INFO:Declaring metric variables
2025-05-12 22:23:22,879:INFO:Defining Hyperparameters
2025-05-12 22:23:22,879:INFO:10 is bigger than total combinations 4, setting search algorithm to grid
2025-05-12 22:23:22,981:INFO:Tuning with n_jobs=-1
2025-05-12 22:23:22,981:INFO:Initializing GridSearchCV
2025-05-12 22:23:23,829:INFO:best_params: {'actual_estimator__strategy': 'most_frequent'}
2025-05-12 22:23:23,829:INFO:Hyperparameter search completed
2025-05-12 22:23:23,830:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:23,830:INFO:Initializing create_model()
2025-05-12 22:23:23,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA790971D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'strategy': 'most_frequent'})
2025-05-12 22:23:23,830:INFO:Checking exceptions
2025-05-12 22:23:23,830:INFO:Importing libraries
2025-05-12 22:23:23,830:INFO:Copying training dataset
2025-05-12 22:23:23,834:INFO:Defining folds
2025-05-12 22:23:23,834:INFO:Declaring metric variables
2025-05-12 22:23:23,840:INFO:Importing untrained model
2025-05-12 22:23:23,840:INFO:Declaring custom model
2025-05-12 22:23:23,846:INFO:Dummy Classifier Imported successfully
2025-05-12 22:23:23,856:INFO:Starting cross validation
2025-05-12 22:23:23,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:24,052:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,052:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,053:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,066:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,083:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,103:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,117:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,126:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,188:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,190:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,201:INFO:Calculating mean and std
2025-05-12 22:23:24,203:INFO:Creating metrics dataframe
2025-05-12 22:23:24,210:INFO:Finalizing model
2025-05-12 22:23:24,266:INFO:Uploading results into container
2025-05-12 22:23:24,266:INFO:Uploading model into container now
2025-05-12 22:23:24,267:INFO:_master_model_container: 16
2025-05-12 22:23:24,267:INFO:_display_container: 4
2025-05-12 22:23:24,268:INFO:DummyClassifier(constant=None, random_state=123, strategy='most_frequent')
2025-05-12 22:23:24,268:INFO:create_model() successfully completed......................................
2025-05-12 22:23:24,380:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:24,380:INFO:choose_better activated
2025-05-12 22:23:24,383:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:24,383:INFO:Initializing create_model()
2025-05-12 22:23:24,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:24,384:INFO:Checking exceptions
2025-05-12 22:23:24,386:INFO:Importing libraries
2025-05-12 22:23:24,386:INFO:Copying training dataset
2025-05-12 22:23:24,388:INFO:Defining folds
2025-05-12 22:23:24,389:INFO:Declaring metric variables
2025-05-12 22:23:24,389:INFO:Importing untrained model
2025-05-12 22:23:24,389:INFO:Declaring custom model
2025-05-12 22:23:24,390:INFO:Dummy Classifier Imported successfully
2025-05-12 22:23:24,390:INFO:Starting cross validation
2025-05-12 22:23:24,392:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:24,539:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,540:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,540:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,557:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,576:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,582:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,586:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,592:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,659:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,663:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,669:INFO:Calculating mean and std
2025-05-12 22:23:24,670:INFO:Creating metrics dataframe
2025-05-12 22:23:24,673:INFO:Finalizing model
2025-05-12 22:23:24,722:INFO:Uploading results into container
2025-05-12 22:23:24,723:INFO:Uploading model into container now
2025-05-12 22:23:24,724:INFO:_master_model_container: 17
2025-05-12 22:23:24,724:INFO:_display_container: 5
2025-05-12 22:23:24,724:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:23:24,724:INFO:create_model() successfully completed......................................
2025-05-12 22:23:24,837:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:24,838:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior') result for Accuracy is 0.8291
2025-05-12 22:23:24,838:INFO:DummyClassifier(constant=None, random_state=123, strategy='most_frequent') result for Accuracy is 0.8291
2025-05-12 22:23:24,838:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior') is best model
2025-05-12 22:23:24,838:INFO:choose_better completed
2025-05-12 22:23:24,839:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:23:24,852:INFO:_master_model_container: 17
2025-05-12 22:23:24,852:INFO:_display_container: 4
2025-05-12 22:23:24,853:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:23:24,853:INFO:tune_model() successfully completed......................................
2025-05-12 22:23:24,977:INFO:Initializing evaluate_model()
2025-05-12 22:23:24,977:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:23:24,988:INFO:Initializing plot_model()
2025-05-12 22:23:24,989:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:23:24,989:INFO:Checking exceptions
2025-05-12 22:23:24,991:INFO:Preloading libraries
2025-05-12 22:23:24,991:INFO:Copying training dataset
2025-05-12 22:23:24,991:INFO:Plot type: pipeline
2025-05-12 22:23:25,123:INFO:Visual Rendered Successfully
2025-05-12 22:23:25,224:INFO:plot_model() successfully completed......................................
2025-05-12 22:23:25,242:INFO:Initializing predict_model()
2025-05-12 22:23:25,242:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EA7AE1FC40>)
2025-05-12 22:23:25,242:INFO:Checking exceptions
2025-05-12 22:23:25,242:INFO:Preloading libraries
2025-05-12 22:23:25,440:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:25,577:INFO:Initializing save_model()
2025-05-12 22:23:25,577:INFO:save_model(model=DummyClassifier(constant=None, random_state=123, strategy='prior'), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-12 22:23:25,577:INFO:Adding model into prep_pipe
2025-05-12 22:23:25,584:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:23:25,591:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 DummyClassifier(constant=None, random_state=123,
                                 strategy='prior'))],
         verbose=False)
2025-05-12 22:23:25,592:INFO:save_model() successfully completed......................................
2025-05-12 22:24:02,824:INFO:PyCaret ClassificationExperiment
2025-05-12 22:24:02,824:INFO:Logging name: clf-default-name
2025-05-12 22:24:02,824:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-12 22:24:02,824:INFO:version 3.3.2
2025-05-12 22:24:02,826:INFO:Initializing setup()
2025-05-12 22:24:02,826:INFO:self.USI: 9efc
2025-05-12 22:24:02,826:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'is_multiclass', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', 'fix_imbalance', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:24:02,826:INFO:Checking environment
2025-05-12 22:24:02,826:INFO:python_version: 3.11.8
2025-05-12 22:24:02,826:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:24:02,826:INFO:machine: AMD64
2025-05-12 22:24:02,826:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:24:02,830:INFO:Memory: svmem(total=16907886592, available=3057942528, percent=81.9, used=13849944064, free=3057942528)
2025-05-12 22:24:02,831:INFO:Physical Core: 4
2025-05-12 22:24:02,831:INFO:Logical Core: 8
2025-05-12 22:24:02,831:INFO:Checking libraries
2025-05-12 22:24:02,831:INFO:System:
2025-05-12 22:24:02,831:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:24:02,831:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:24:02,831:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:24:02,831:INFO:PyCaret required dependencies:
2025-05-12 22:24:02,831:INFO:                 pip: 24.0
2025-05-12 22:24:02,831:INFO:          setuptools: 65.5.0
2025-05-12 22:24:02,831:INFO:             pycaret: 3.3.2
2025-05-12 22:24:02,831:INFO:             IPython: 9.2.0
2025-05-12 22:24:02,831:INFO:          ipywidgets: 8.1.7
2025-05-12 22:24:02,831:INFO:                tqdm: 4.67.1
2025-05-12 22:24:02,831:INFO:               numpy: 1.26.4
2025-05-12 22:24:02,831:INFO:              pandas: 2.1.4
2025-05-12 22:24:02,831:INFO:              jinja2: 3.1.6
2025-05-12 22:24:02,831:INFO:               scipy: 1.11.4
2025-05-12 22:24:02,831:INFO:              joblib: 1.3.2
2025-05-12 22:24:02,831:INFO:             sklearn: 1.4.2
2025-05-12 22:24:02,831:INFO:                pyod: 2.0.5
2025-05-12 22:24:02,831:INFO:            imblearn: 0.13.0
2025-05-12 22:24:02,831:INFO:   category_encoders: 2.7.0
2025-05-12 22:24:02,831:INFO:            lightgbm: 4.6.0
2025-05-12 22:24:02,831:INFO:               numba: 0.61.2
2025-05-12 22:24:02,831:INFO:            requests: 2.32.3
2025-05-12 22:24:02,831:INFO:          matplotlib: 3.7.5
2025-05-12 22:24:02,831:INFO:          scikitplot: 0.3.7
2025-05-12 22:24:02,831:INFO:         yellowbrick: 1.5
2025-05-12 22:24:02,831:INFO:              plotly: 5.24.1
2025-05-12 22:24:02,831:INFO:    plotly-resampler: Not installed
2025-05-12 22:24:02,831:INFO:             kaleido: 0.2.1
2025-05-12 22:24:02,831:INFO:           schemdraw: 0.15
2025-05-12 22:24:02,831:INFO:         statsmodels: 0.14.4
2025-05-12 22:24:02,831:INFO:              sktime: 0.26.0
2025-05-12 22:24:02,831:INFO:               tbats: 1.1.3
2025-05-12 22:24:02,831:INFO:            pmdarima: 2.0.4
2025-05-12 22:24:02,831:INFO:              psutil: 7.0.0
2025-05-12 22:24:02,831:INFO:          markupsafe: 3.0.2
2025-05-12 22:24:02,831:INFO:             pickle5: Not installed
2025-05-12 22:24:02,831:INFO:         cloudpickle: 3.1.1
2025-05-12 22:24:02,831:INFO:         deprecation: 2.1.0
2025-05-12 22:24:02,831:INFO:              xxhash: 3.5.0
2025-05-12 22:24:02,831:INFO:           wurlitzer: Not installed
2025-05-12 22:24:02,831:INFO:PyCaret optional dependencies:
2025-05-12 22:24:02,833:INFO:                shap: Not installed
2025-05-12 22:24:02,833:INFO:           interpret: Not installed
2025-05-12 22:24:02,833:INFO:                umap: Not installed
2025-05-12 22:24:02,833:INFO:     ydata_profiling: Not installed
2025-05-12 22:24:02,833:INFO:  explainerdashboard: Not installed
2025-05-12 22:24:02,833:INFO:             autoviz: Not installed
2025-05-12 22:24:02,833:INFO:           fairlearn: Not installed
2025-05-12 22:24:02,833:INFO:          deepchecks: Not installed
2025-05-12 22:24:02,833:INFO:             xgboost: Not installed
2025-05-12 22:24:02,833:INFO:            catboost: Not installed
2025-05-12 22:24:02,833:INFO:              kmodes: Not installed
2025-05-12 22:24:02,833:INFO:             mlxtend: Not installed
2025-05-12 22:24:02,833:INFO:       statsforecast: Not installed
2025-05-12 22:24:02,833:INFO:        tune_sklearn: Not installed
2025-05-12 22:24:02,833:INFO:                 ray: Not installed
2025-05-12 22:24:02,833:INFO:            hyperopt: Not installed
2025-05-12 22:24:02,833:INFO:              optuna: Not installed
2025-05-12 22:24:02,833:INFO:               skopt: Not installed
2025-05-12 22:24:02,833:INFO:              mlflow: Not installed
2025-05-12 22:24:02,833:INFO:              gradio: Not installed
2025-05-12 22:24:02,833:INFO:             fastapi: Not installed
2025-05-12 22:24:02,833:INFO:             uvicorn: Not installed
2025-05-12 22:24:02,833:INFO:              m2cgen: Not installed
2025-05-12 22:24:02,833:INFO:           evidently: Not installed
2025-05-12 22:24:02,833:INFO:               fugue: Not installed
2025-05-12 22:24:02,833:INFO:           streamlit: Not installed
2025-05-12 22:24:02,833:INFO:             prophet: Not installed
2025-05-12 22:24:02,833:INFO:None
2025-05-12 22:24:02,833:INFO:Set up data.
2025-05-12 22:24:02,836:INFO:Set up folding strategy.
2025-05-12 22:24:02,836:INFO:Set up train/test split.
2025-05-12 22:24:02,839:INFO:Set up index.
2025-05-12 22:24:02,839:INFO:Assigning column types.
2025-05-12 22:24:02,840:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:24:02,876:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:24:02,876:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:24:02,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:02,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:02,931:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:24:02,931:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:24:02,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:02,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:02,954:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:24:02,988:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:24:03,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,009:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,044:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:24:03,066:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,066:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,066:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-12 22:24:03,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,180:INFO:Preparing preprocessing pipeline...
2025-05-12 22:24:03,181:INFO:Set up simple imputation.
2025-05-12 22:24:03,183:INFO:Set up encoding of categorical features.
2025-05-12 22:24:03,183:INFO:Set up feature normalization.
2025-05-12 22:24:03,232:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:24:03,237:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:24:03,238:INFO:Creating final display dataframe.
2025-05-12 22:24:03,378:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              9efc
2025-05-12 22:24:03,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,496:INFO:setup() successfully completed in 0.67s...............
2025-05-12 22:24:03,508:INFO:Initializing compare_models()
2025-05-12 22:24:03,508:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-12 22:24:03,508:INFO:Checking exceptions
2025-05-12 22:24:03,510:INFO:Preparing display monitor
2025-05-12 22:24:03,530:INFO:Initializing Logistic Regression
2025-05-12 22:24:03,531:INFO:Total runtime is 1.6721089680989585e-05 minutes
2025-05-12 22:24:03,534:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:03,534:INFO:Initializing create_model()
2025-05-12 22:24:03,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:03,536:INFO:Checking exceptions
2025-05-12 22:24:03,536:INFO:Importing libraries
2025-05-12 22:24:03,536:INFO:Copying training dataset
2025-05-12 22:24:03,543:INFO:Defining folds
2025-05-12 22:24:03,544:INFO:Declaring metric variables
2025-05-12 22:24:03,568:INFO:Importing untrained model
2025-05-12 22:24:03,586:INFO:Logistic Regression Imported successfully
2025-05-12 22:24:03,601:INFO:Starting cross validation
2025-05-12 22:24:03,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:03,763:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,768:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,779:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,790:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,791:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,797:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,803:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,848:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,852:INFO:Calculating mean and std
2025-05-12 22:24:03,852:INFO:Creating metrics dataframe
2025-05-12 22:24:03,853:INFO:Uploading results into container
2025-05-12 22:24:03,854:INFO:Uploading model into container now
2025-05-12 22:24:03,854:INFO:_master_model_container: 1
2025-05-12 22:24:03,854:INFO:_display_container: 2
2025-05-12 22:24:03,855:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-12 22:24:03,855:INFO:create_model() successfully completed......................................
2025-05-12 22:24:03,943:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:03,944:INFO:Creating metrics dataframe
2025-05-12 22:24:03,948:INFO:Initializing K Neighbors Classifier
2025-05-12 22:24:03,948:INFO:Total runtime is 0.006966094175974528 minutes
2025-05-12 22:24:03,951:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:03,952:INFO:Initializing create_model()
2025-05-12 22:24:03,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:03,952:INFO:Checking exceptions
2025-05-12 22:24:03,952:INFO:Importing libraries
2025-05-12 22:24:03,952:INFO:Copying training dataset
2025-05-12 22:24:03,954:INFO:Defining folds
2025-05-12 22:24:03,954:INFO:Declaring metric variables
2025-05-12 22:24:03,957:INFO:Importing untrained model
2025-05-12 22:24:03,959:INFO:K Neighbors Classifier Imported successfully
2025-05-12 22:24:03,966:INFO:Starting cross validation
2025-05-12 22:24:03,968:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:04,111:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,111:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,115:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,131:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,144:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,206:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,218:INFO:Calculating mean and std
2025-05-12 22:24:04,218:INFO:Creating metrics dataframe
2025-05-12 22:24:04,219:INFO:Uploading results into container
2025-05-12 22:24:04,220:INFO:Uploading model into container now
2025-05-12 22:24:04,220:INFO:_master_model_container: 2
2025-05-12 22:24:04,220:INFO:_display_container: 2
2025-05-12 22:24:04,220:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-12 22:24:04,220:INFO:create_model() successfully completed......................................
2025-05-12 22:24:04,304:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:04,304:INFO:Creating metrics dataframe
2025-05-12 22:24:04,310:INFO:Initializing Naive Bayes
2025-05-12 22:24:04,310:INFO:Total runtime is 0.012993101278940836 minutes
2025-05-12 22:24:04,312:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:04,313:INFO:Initializing create_model()
2025-05-12 22:24:04,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:04,313:INFO:Checking exceptions
2025-05-12 22:24:04,313:INFO:Importing libraries
2025-05-12 22:24:04,313:INFO:Copying training dataset
2025-05-12 22:24:04,316:INFO:Defining folds
2025-05-12 22:24:04,316:INFO:Declaring metric variables
2025-05-12 22:24:04,317:INFO:Importing untrained model
2025-05-12 22:24:04,321:INFO:Naive Bayes Imported successfully
2025-05-12 22:24:04,328:INFO:Starting cross validation
2025-05-12 22:24:04,329:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:04,429:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,437:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,443:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,497:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,505:INFO:Calculating mean and std
2025-05-12 22:24:04,505:INFO:Creating metrics dataframe
2025-05-12 22:24:04,506:INFO:Uploading results into container
2025-05-12 22:24:04,507:INFO:Uploading model into container now
2025-05-12 22:24:04,507:INFO:_master_model_container: 3
2025-05-12 22:24:04,507:INFO:_display_container: 2
2025-05-12 22:24:04,507:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-12 22:24:04,507:INFO:create_model() successfully completed......................................
2025-05-12 22:24:04,591:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:04,591:INFO:Creating metrics dataframe
2025-05-12 22:24:04,597:INFO:Initializing Decision Tree Classifier
2025-05-12 22:24:04,597:INFO:Total runtime is 0.017779342333475747 minutes
2025-05-12 22:24:04,599:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:04,599:INFO:Initializing create_model()
2025-05-12 22:24:04,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:04,600:INFO:Checking exceptions
2025-05-12 22:24:04,600:INFO:Importing libraries
2025-05-12 22:24:04,600:INFO:Copying training dataset
2025-05-12 22:24:04,604:INFO:Defining folds
2025-05-12 22:24:04,604:INFO:Declaring metric variables
2025-05-12 22:24:04,606:INFO:Importing untrained model
2025-05-12 22:24:04,610:INFO:Decision Tree Classifier Imported successfully
2025-05-12 22:24:04,616:INFO:Starting cross validation
2025-05-12 22:24:04,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:04,728:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,805:INFO:Calculating mean and std
2025-05-12 22:24:04,805:INFO:Creating metrics dataframe
2025-05-12 22:24:04,807:INFO:Uploading results into container
2025-05-12 22:24:04,807:INFO:Uploading model into container now
2025-05-12 22:24:04,807:INFO:_master_model_container: 4
2025-05-12 22:24:04,809:INFO:_display_container: 2
2025-05-12 22:24:04,809:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-12 22:24:04,809:INFO:create_model() successfully completed......................................
2025-05-12 22:24:04,894:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:04,894:INFO:Creating metrics dataframe
2025-05-12 22:24:04,900:INFO:Initializing SVM - Linear Kernel
2025-05-12 22:24:04,900:INFO:Total runtime is 0.022830323378245032 minutes
2025-05-12 22:24:04,903:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:04,903:INFO:Initializing create_model()
2025-05-12 22:24:04,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:04,903:INFO:Checking exceptions
2025-05-12 22:24:04,903:INFO:Importing libraries
2025-05-12 22:24:04,903:INFO:Copying training dataset
2025-05-12 22:24:04,906:INFO:Defining folds
2025-05-12 22:24:04,906:INFO:Declaring metric variables
2025-05-12 22:24:04,909:INFO:Importing untrained model
2025-05-12 22:24:04,912:INFO:SVM - Linear Kernel Imported successfully
2025-05-12 22:24:04,919:INFO:Starting cross validation
2025-05-12 22:24:04,920:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:05,027:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,037:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,099:INFO:Calculating mean and std
2025-05-12 22:24:05,100:INFO:Creating metrics dataframe
2025-05-12 22:24:05,101:INFO:Uploading results into container
2025-05-12 22:24:05,102:INFO:Uploading model into container now
2025-05-12 22:24:05,102:INFO:_master_model_container: 5
2025-05-12 22:24:05,102:INFO:_display_container: 2
2025-05-12 22:24:05,103:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-12 22:24:05,103:INFO:create_model() successfully completed......................................
2025-05-12 22:24:05,188:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:05,189:INFO:Creating metrics dataframe
2025-05-12 22:24:05,194:INFO:Initializing Ridge Classifier
2025-05-12 22:24:05,194:INFO:Total runtime is 0.027726264794667558 minutes
2025-05-12 22:24:05,197:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:05,198:INFO:Initializing create_model()
2025-05-12 22:24:05,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:05,198:INFO:Checking exceptions
2025-05-12 22:24:05,198:INFO:Importing libraries
2025-05-12 22:24:05,198:INFO:Copying training dataset
2025-05-12 22:24:05,201:INFO:Defining folds
2025-05-12 22:24:05,202:INFO:Declaring metric variables
2025-05-12 22:24:05,205:INFO:Importing untrained model
2025-05-12 22:24:05,209:INFO:Ridge Classifier Imported successfully
2025-05-12 22:24:05,215:INFO:Starting cross validation
2025-05-12 22:24:05,216:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:05,322:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,323:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,325:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,328:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,337:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,338:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,340:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,387:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,389:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,397:INFO:Calculating mean and std
2025-05-12 22:24:05,398:INFO:Creating metrics dataframe
2025-05-12 22:24:05,399:INFO:Uploading results into container
2025-05-12 22:24:05,399:INFO:Uploading model into container now
2025-05-12 22:24:05,400:INFO:_master_model_container: 6
2025-05-12 22:24:05,400:INFO:_display_container: 2
2025-05-12 22:24:05,400:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-12 22:24:05,400:INFO:create_model() successfully completed......................................
2025-05-12 22:24:05,484:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:05,484:INFO:Creating metrics dataframe
2025-05-12 22:24:05,493:INFO:Initializing Random Forest Classifier
2025-05-12 22:24:05,493:INFO:Total runtime is 0.032708982626597084 minutes
2025-05-12 22:24:05,496:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:05,496:INFO:Initializing create_model()
2025-05-12 22:24:05,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:05,496:INFO:Checking exceptions
2025-05-12 22:24:05,496:INFO:Importing libraries
2025-05-12 22:24:05,496:INFO:Copying training dataset
2025-05-12 22:24:05,500:INFO:Defining folds
2025-05-12 22:24:05,500:INFO:Declaring metric variables
2025-05-12 22:24:05,503:INFO:Importing untrained model
2025-05-12 22:24:05,507:INFO:Random Forest Classifier Imported successfully
2025-05-12 22:24:05,513:INFO:Starting cross validation
2025-05-12 22:24:05,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:05,899:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,903:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,905:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,920:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,923:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,939:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,996:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:06,120:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:06,130:INFO:Calculating mean and std
2025-05-12 22:24:06,131:INFO:Creating metrics dataframe
2025-05-12 22:24:06,133:INFO:Uploading results into container
2025-05-12 22:24:06,134:INFO:Uploading model into container now
2025-05-12 22:24:06,134:INFO:_master_model_container: 7
2025-05-12 22:24:06,135:INFO:_display_container: 2
2025-05-12 22:24:06,135:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-12 22:24:06,135:INFO:create_model() successfully completed......................................
2025-05-12 22:24:06,221:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:06,221:INFO:Creating metrics dataframe
2025-05-12 22:24:06,227:INFO:Initializing Quadratic Discriminant Analysis
2025-05-12 22:24:06,227:INFO:Total runtime is 0.044942271709442136 minutes
2025-05-12 22:24:06,229:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:06,229:INFO:Initializing create_model()
2025-05-12 22:24:06,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:06,230:INFO:Checking exceptions
2025-05-12 22:24:06,230:INFO:Importing libraries
2025-05-12 22:24:06,230:INFO:Copying training dataset
2025-05-12 22:24:06,234:INFO:Defining folds
2025-05-12 22:24:06,234:INFO:Declaring metric variables
2025-05-12 22:24:06,237:INFO:Importing untrained model
2025-05-12 22:24:06,240:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-12 22:24:06,246:INFO:Starting cross validation
2025-05-12 22:24:06,247:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:06,313:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,316:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,317:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,317:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,320:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,321:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,322:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,351:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:06,356:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,422:INFO:Calculating mean and std
2025-05-12 22:24:06,423:INFO:Creating metrics dataframe
2025-05-12 22:24:06,424:INFO:Uploading results into container
2025-05-12 22:24:06,424:INFO:Uploading model into container now
2025-05-12 22:24:06,424:INFO:_master_model_container: 8
2025-05-12 22:24:06,425:INFO:_display_container: 2
2025-05-12 22:24:06,425:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-12 22:24:06,425:INFO:create_model() successfully completed......................................
2025-05-12 22:24:06,510:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:06,511:INFO:Creating metrics dataframe
2025-05-12 22:24:06,518:INFO:Initializing Ada Boost Classifier
2025-05-12 22:24:06,518:INFO:Total runtime is 0.04980565309524536 minutes
2025-05-12 22:24:06,521:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:06,521:INFO:Initializing create_model()
2025-05-12 22:24:06,521:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:06,521:INFO:Checking exceptions
2025-05-12 22:24:06,521:INFO:Importing libraries
2025-05-12 22:24:06,521:INFO:Copying training dataset
2025-05-12 22:24:06,525:INFO:Defining folds
2025-05-12 22:24:06,525:INFO:Declaring metric variables
2025-05-12 22:24:06,527:INFO:Importing untrained model
2025-05-12 22:24:06,531:INFO:Ada Boost Classifier Imported successfully
2025-05-12 22:24:06,539:INFO:Starting cross validation
2025-05-12 22:24:06,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:06,606:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,608:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,610:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,611:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,617:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,620:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,625:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,629:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,808:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:06,813:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:06,830:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,830:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,947:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:06,951:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:06,966:INFO:Calculating mean and std
2025-05-12 22:24:06,966:INFO:Creating metrics dataframe
2025-05-12 22:24:06,969:INFO:Uploading results into container
2025-05-12 22:24:06,969:INFO:Uploading model into container now
2025-05-12 22:24:06,969:INFO:_master_model_container: 9
2025-05-12 22:24:06,970:INFO:_display_container: 2
2025-05-12 22:24:06,970:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-12 22:24:06,970:INFO:create_model() successfully completed......................................
2025-05-12 22:24:07,064:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:07,064:INFO:Creating metrics dataframe
2025-05-12 22:24:07,071:INFO:Initializing Gradient Boosting Classifier
2025-05-12 22:24:07,071:INFO:Total runtime is 0.059021850426991776 minutes
2025-05-12 22:24:07,075:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:07,076:INFO:Initializing create_model()
2025-05-12 22:24:07,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:07,076:INFO:Checking exceptions
2025-05-12 22:24:07,076:INFO:Importing libraries
2025-05-12 22:24:07,076:INFO:Copying training dataset
2025-05-12 22:24:07,080:INFO:Defining folds
2025-05-12 22:24:07,080:INFO:Declaring metric variables
2025-05-12 22:24:07,084:INFO:Importing untrained model
2025-05-12 22:24:07,088:INFO:Gradient Boosting Classifier Imported successfully
2025-05-12 22:24:07,095:INFO:Starting cross validation
2025-05-12 22:24:07,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:07,477:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:07,713:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:07,723:INFO:Calculating mean and std
2025-05-12 22:24:07,724:INFO:Creating metrics dataframe
2025-05-12 22:24:07,726:INFO:Uploading results into container
2025-05-12 22:24:07,727:INFO:Uploading model into container now
2025-05-12 22:24:07,727:INFO:_master_model_container: 10
2025-05-12 22:24:07,727:INFO:_display_container: 2
2025-05-12 22:24:07,727:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-12 22:24:07,727:INFO:create_model() successfully completed......................................
2025-05-12 22:24:07,825:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:07,825:INFO:Creating metrics dataframe
2025-05-12 22:24:07,836:INFO:Initializing Linear Discriminant Analysis
2025-05-12 22:24:07,837:INFO:Total runtime is 0.07177834908167521 minutes
2025-05-12 22:24:07,842:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:07,842:INFO:Initializing create_model()
2025-05-12 22:24:07,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:07,843:INFO:Checking exceptions
2025-05-12 22:24:07,843:INFO:Importing libraries
2025-05-12 22:24:07,843:INFO:Copying training dataset
2025-05-12 22:24:07,847:INFO:Defining folds
2025-05-12 22:24:07,847:INFO:Declaring metric variables
2025-05-12 22:24:07,851:INFO:Importing untrained model
2025-05-12 22:24:07,856:INFO:Linear Discriminant Analysis Imported successfully
2025-05-12 22:24:07,864:INFO:Starting cross validation
2025-05-12 22:24:07,867:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:08,059:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:08,063:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:08,103:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:08,113:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:08,177:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:08,215:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:08,229:INFO:Calculating mean and std
2025-05-12 22:24:08,231:INFO:Creating metrics dataframe
2025-05-12 22:24:08,233:INFO:Uploading results into container
2025-05-12 22:24:08,234:INFO:Uploading model into container now
2025-05-12 22:24:08,235:INFO:_master_model_container: 11
2025-05-12 22:24:08,235:INFO:_display_container: 2
2025-05-12 22:24:08,236:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-12 22:24:08,236:INFO:create_model() successfully completed......................................
2025-05-12 22:24:08,357:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:08,357:INFO:Creating metrics dataframe
2025-05-12 22:24:08,367:INFO:Initializing Extra Trees Classifier
2025-05-12 22:24:08,367:INFO:Total runtime is 0.08061438004175822 minutes
2025-05-12 22:24:08,371:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:08,371:INFO:Initializing create_model()
2025-05-12 22:24:08,371:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:08,371:INFO:Checking exceptions
2025-05-12 22:24:08,371:INFO:Importing libraries
2025-05-12 22:24:08,371:INFO:Copying training dataset
2025-05-12 22:24:08,377:INFO:Defining folds
2025-05-12 22:24:08,377:INFO:Declaring metric variables
2025-05-12 22:24:08,381:INFO:Importing untrained model
2025-05-12 22:24:08,387:INFO:Extra Trees Classifier Imported successfully
2025-05-12 22:24:08,394:INFO:Starting cross validation
2025-05-12 22:24:08,397:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:08,904:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:08,986:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:09,049:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:09,271:INFO:Calculating mean and std
2025-05-12 22:24:09,273:INFO:Creating metrics dataframe
2025-05-12 22:24:09,276:INFO:Uploading results into container
2025-05-12 22:24:09,276:INFO:Uploading model into container now
2025-05-12 22:24:09,277:INFO:_master_model_container: 12
2025-05-12 22:24:09,277:INFO:_display_container: 2
2025-05-12 22:24:09,278:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-12 22:24:09,279:INFO:create_model() successfully completed......................................
2025-05-12 22:24:09,377:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:09,378:INFO:Creating metrics dataframe
2025-05-12 22:24:09,387:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:24:09,387:INFO:Total runtime is 0.09761213858922323 minutes
2025-05-12 22:24:09,389:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:09,390:INFO:Initializing create_model()
2025-05-12 22:24:09,390:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:09,390:INFO:Checking exceptions
2025-05-12 22:24:09,390:INFO:Importing libraries
2025-05-12 22:24:09,390:INFO:Copying training dataset
2025-05-12 22:24:09,395:INFO:Defining folds
2025-05-12 22:24:09,395:INFO:Declaring metric variables
2025-05-12 22:24:09,398:INFO:Importing untrained model
2025-05-12 22:24:09,402:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:24:09,409:INFO:Starting cross validation
2025-05-12 22:24:09,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:09,709:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:09,719:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:09,734:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:09,788:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:09,824:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:09,981:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,000:INFO:Calculating mean and std
2025-05-12 22:24:10,003:INFO:Creating metrics dataframe
2025-05-12 22:24:10,007:INFO:Uploading results into container
2025-05-12 22:24:10,008:INFO:Uploading model into container now
2025-05-12 22:24:10,009:INFO:_master_model_container: 13
2025-05-12 22:24:10,009:INFO:_display_container: 2
2025-05-12 22:24:10,010:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:24:10,010:INFO:create_model() successfully completed......................................
2025-05-12 22:24:10,130:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:10,130:INFO:Creating metrics dataframe
2025-05-12 22:24:10,140:INFO:Initializing Dummy Classifier
2025-05-12 22:24:10,141:INFO:Total runtime is 0.11017510096232097 minutes
2025-05-12 22:24:10,143:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:10,144:INFO:Initializing create_model()
2025-05-12 22:24:10,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:10,144:INFO:Checking exceptions
2025-05-12 22:24:10,144:INFO:Importing libraries
2025-05-12 22:24:10,144:INFO:Copying training dataset
2025-05-12 22:24:10,149:INFO:Defining folds
2025-05-12 22:24:10,149:INFO:Declaring metric variables
2025-05-12 22:24:10,153:INFO:Importing untrained model
2025-05-12 22:24:10,157:INFO:Dummy Classifier Imported successfully
2025-05-12 22:24:10,167:INFO:Starting cross validation
2025-05-12 22:24:10,168:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:10,305:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,310:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,318:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,321:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,324:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,333:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,341:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,341:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,407:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,409:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,426:INFO:Calculating mean and std
2025-05-12 22:24:10,427:INFO:Creating metrics dataframe
2025-05-12 22:24:10,429:INFO:Uploading results into container
2025-05-12 22:24:10,429:INFO:Uploading model into container now
2025-05-12 22:24:10,430:INFO:_master_model_container: 14
2025-05-12 22:24:10,430:INFO:_display_container: 2
2025-05-12 22:24:10,430:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:24:10,430:INFO:create_model() successfully completed......................................
2025-05-12 22:24:10,533:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:10,533:INFO:Creating metrics dataframe
2025-05-12 22:24:10,545:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:24:10,554:INFO:Initializing create_model()
2025-05-12 22:24:10,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:10,554:INFO:Checking exceptions
2025-05-12 22:24:10,556:INFO:Importing libraries
2025-05-12 22:24:10,556:INFO:Copying training dataset
2025-05-12 22:24:10,559:INFO:Defining folds
2025-05-12 22:24:10,559:INFO:Declaring metric variables
2025-05-12 22:24:10,559:INFO:Importing untrained model
2025-05-12 22:24:10,559:INFO:Declaring custom model
2025-05-12 22:24:10,559:INFO:Dummy Classifier Imported successfully
2025-05-12 22:24:10,561:INFO:Cross validation set to False
2025-05-12 22:24:10,561:INFO:Fitting Model
2025-05-12 22:24:10,599:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:24:10,600:INFO:create_model() successfully completed......................................
2025-05-12 22:24:10,718:INFO:_master_model_container: 14
2025-05-12 22:24:10,718:INFO:_display_container: 2
2025-05-12 22:24:10,718:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:24:10,718:INFO:compare_models() successfully completed......................................
2025-05-12 22:24:10,743:INFO:Initializing create_model()
2025-05-12 22:24:10,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:10,743:INFO:Checking exceptions
2025-05-12 22:24:10,761:INFO:Importing libraries
2025-05-12 22:24:10,761:INFO:Copying training dataset
2025-05-12 22:24:10,767:INFO:Defining folds
2025-05-12 22:24:10,769:INFO:Declaring metric variables
2025-05-12 22:24:10,773:INFO:Importing untrained model
2025-05-12 22:24:10,779:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:24:10,788:INFO:Starting cross validation
2025-05-12 22:24:10,790:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:11,255:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:11,258:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:11,349:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:11,417:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:11,433:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:11,544:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:11,559:INFO:Calculating mean and std
2025-05-12 22:24:11,561:INFO:Creating metrics dataframe
2025-05-12 22:24:11,569:INFO:Finalizing model
2025-05-12 22:24:11,650:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:24:11,650:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.
2025-05-12 22:24:11,650:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-12 22:24:11,651:INFO:[LightGBM] [Info] Total Bins 117
2025-05-12 22:24:11,651:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:24:11,651:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:24:11,651:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:24:11,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,693:INFO:Uploading results into container
2025-05-12 22:24:11,696:INFO:Uploading model into container now
2025-05-12 22:24:11,715:INFO:_master_model_container: 15
2025-05-12 22:24:11,716:INFO:_display_container: 3
2025-05-12 22:24:11,716:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:24:11,717:INFO:create_model() successfully completed......................................
2025-05-12 22:24:11,879:INFO:Initializing tune_model()
2025-05-12 22:24:11,879:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:24:11,879:INFO:Checking exceptions
2025-05-12 22:24:11,902:INFO:Copying training dataset
2025-05-12 22:24:11,907:INFO:Checking base model
2025-05-12 22:24:11,909:INFO:Base model : Light Gradient Boosting Machine
2025-05-12 22:24:11,914:INFO:Declaring metric variables
2025-05-12 22:24:11,920:INFO:Defining Hyperparameters
2025-05-12 22:24:12,050:INFO:Tuning with n_jobs=-1
2025-05-12 22:24:12,050:INFO:Initializing RandomizedSearchCV
2025-05-12 22:24:19,325:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2025-05-12 22:24:19,327:INFO:Hyperparameter search completed
2025-05-12 22:24:19,327:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:19,329:INFO:Initializing create_model()
2025-05-12 22:24:19,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E027D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2025-05-12 22:24:19,330:INFO:Checking exceptions
2025-05-12 22:24:19,330:INFO:Importing libraries
2025-05-12 22:24:19,330:INFO:Copying training dataset
2025-05-12 22:24:19,338:INFO:Defining folds
2025-05-12 22:24:19,339:INFO:Declaring metric variables
2025-05-12 22:24:19,347:INFO:Importing untrained model
2025-05-12 22:24:19,347:INFO:Declaring custom model
2025-05-12 22:24:19,357:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:24:19,377:INFO:Starting cross validation
2025-05-12 22:24:19,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:19,804:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:19,813:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:19,816:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:19,839:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:19,863:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:19,888:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:19,947:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:20,026:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:20,071:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:20,072:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:20,093:INFO:Calculating mean and std
2025-05-12 22:24:20,096:INFO:Creating metrics dataframe
2025-05-12 22:24:20,109:INFO:Finalizing model
2025-05-12 22:24:20,183:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:24:20,183:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:24:20,183:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:24:20,183:INFO:[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.
2025-05-12 22:24:20,185:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:24:20,185:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:24:20,185:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:24:20,185:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:24:20,185:INFO:[LightGBM] [Info] Total Bins 0
2025-05-12 22:24:20,185:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 0
2025-05-12 22:24:20,185:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:24:20,186:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:24:20,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,201:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,201:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,201:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,201:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,201:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,216:INFO:Uploading results into container
2025-05-12 22:24:20,219:INFO:Uploading model into container now
2025-05-12 22:24:20,220:INFO:_master_model_container: 16
2025-05-12 22:24:20,220:INFO:_display_container: 4
2025-05-12 22:24:20,223:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:24:20,223:INFO:create_model() successfully completed......................................
2025-05-12 22:24:20,364:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:20,365:INFO:choose_better activated
2025-05-12 22:24:20,369:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:20,371:INFO:Initializing create_model()
2025-05-12 22:24:20,371:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:20,371:INFO:Checking exceptions
2025-05-12 22:24:20,373:INFO:Importing libraries
2025-05-12 22:24:20,373:INFO:Copying training dataset
2025-05-12 22:24:20,376:INFO:Defining folds
2025-05-12 22:24:20,377:INFO:Declaring metric variables
2025-05-12 22:24:20,377:INFO:Importing untrained model
2025-05-12 22:24:20,377:INFO:Declaring custom model
2025-05-12 22:24:20,378:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:24:20,378:INFO:Starting cross validation
2025-05-12 22:24:20,380:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:21,039:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:21,216:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:21,285:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:21,299:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:21,346:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:21,439:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:21,463:INFO:Calculating mean and std
2025-05-12 22:24:21,463:INFO:Creating metrics dataframe
2025-05-12 22:24:21,466:INFO:Finalizing model
2025-05-12 22:24:21,540:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:24:21,540:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.
2025-05-12 22:24:21,541:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-12 22:24:21,541:INFO:[LightGBM] [Info] Total Bins 117
2025-05-12 22:24:21,541:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:24:21,541:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:24:21,541:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:24:21,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,596:INFO:Uploading results into container
2025-05-12 22:24:21,597:INFO:Uploading model into container now
2025-05-12 22:24:21,598:INFO:_master_model_container: 17
2025-05-12 22:24:21,598:INFO:_display_container: 5
2025-05-12 22:24:21,599:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:24:21,599:INFO:create_model() successfully completed......................................
2025-05-12 22:24:21,751:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:21,753:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7891
2025-05-12 22:24:21,754:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8291
2025-05-12 22:24:21,754:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-12 22:24:21,756:INFO:choose_better completed
2025-05-12 22:24:21,769:INFO:_master_model_container: 17
2025-05-12 22:24:21,769:INFO:_display_container: 4
2025-05-12 22:24:21,770:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:24:21,771:INFO:tune_model() successfully completed......................................
2025-05-12 22:24:21,896:INFO:Initializing evaluate_model()
2025-05-12 22:24:21,896:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:24:21,907:INFO:Initializing plot_model()
2025-05-12 22:24:21,907:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:24:21,907:INFO:Checking exceptions
2025-05-12 22:24:21,910:INFO:Preloading libraries
2025-05-12 22:24:21,912:INFO:Copying training dataset
2025-05-12 22:24:21,912:INFO:Plot type: pipeline
2025-05-12 22:24:22,077:INFO:Visual Rendered Successfully
2025-05-12 22:24:22,183:INFO:plot_model() successfully completed......................................
2025-05-12 22:24:22,218:INFO:Initializing predict_model()
2025-05-12 22:24:22,219:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EA7E11FF60>)
2025-05-12 22:24:22,219:INFO:Checking exceptions
2025-05-12 22:24:22,219:INFO:Preloading libraries
2025-05-12 22:24:22,351:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:22,542:INFO:Initializing save_model()
2025-05-12 22:24:22,542:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-12 22:24:22,542:INFO:Adding model into prep_pipe
2025-05-12 22:24:22,557:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:24:22,577:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-12 22:24:22,577:INFO:save_model() successfully completed......................................
2025-05-12 22:25:09,778:INFO:PyCaret RegressionExperiment
2025-05-12 22:25:09,778:INFO:Logging name: reg-default-name
2025-05-12 22:25:09,778:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:25:09,778:INFO:version 3.3.2
2025-05-12 22:25:09,778:INFO:Initializing setup()
2025-05-12 22:25:09,778:INFO:self.USI: 36ac
2025-05-12 22:25:09,778:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'transform_target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:25:09,778:INFO:Checking environment
2025-05-12 22:25:09,778:INFO:python_version: 3.11.8
2025-05-12 22:25:09,778:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:25:09,778:INFO:machine: AMD64
2025-05-12 22:25:09,778:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:25:09,785:INFO:Memory: svmem(total=16907886592, available=2838208512, percent=83.2, used=14069678080, free=2838208512)
2025-05-12 22:25:09,785:INFO:Physical Core: 4
2025-05-12 22:25:09,785:INFO:Logical Core: 8
2025-05-12 22:25:09,785:INFO:Checking libraries
2025-05-12 22:25:09,785:INFO:System:
2025-05-12 22:25:09,785:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:25:09,785:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:25:09,785:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:25:09,785:INFO:PyCaret required dependencies:
2025-05-12 22:25:09,785:INFO:                 pip: 24.0
2025-05-12 22:25:09,785:INFO:          setuptools: 65.5.0
2025-05-12 22:25:09,785:INFO:             pycaret: 3.3.2
2025-05-12 22:25:09,785:INFO:             IPython: 9.2.0
2025-05-12 22:25:09,785:INFO:          ipywidgets: 8.1.7
2025-05-12 22:25:09,785:INFO:                tqdm: 4.67.1
2025-05-12 22:25:09,785:INFO:               numpy: 1.26.4
2025-05-12 22:25:09,785:INFO:              pandas: 2.1.4
2025-05-12 22:25:09,785:INFO:              jinja2: 3.1.6
2025-05-12 22:25:09,785:INFO:               scipy: 1.11.4
2025-05-12 22:25:09,785:INFO:              joblib: 1.3.2
2025-05-12 22:25:09,785:INFO:             sklearn: 1.4.2
2025-05-12 22:25:09,785:INFO:                pyod: 2.0.5
2025-05-12 22:25:09,785:INFO:            imblearn: 0.13.0
2025-05-12 22:25:09,786:INFO:   category_encoders: 2.7.0
2025-05-12 22:25:09,786:INFO:            lightgbm: 4.6.0
2025-05-12 22:25:09,786:INFO:               numba: 0.61.2
2025-05-12 22:25:09,786:INFO:            requests: 2.32.3
2025-05-12 22:25:09,786:INFO:          matplotlib: 3.7.5
2025-05-12 22:25:09,786:INFO:          scikitplot: 0.3.7
2025-05-12 22:25:09,786:INFO:         yellowbrick: 1.5
2025-05-12 22:25:09,786:INFO:              plotly: 5.24.1
2025-05-12 22:25:09,786:INFO:    plotly-resampler: Not installed
2025-05-12 22:25:09,786:INFO:             kaleido: 0.2.1
2025-05-12 22:25:09,786:INFO:           schemdraw: 0.15
2025-05-12 22:25:09,786:INFO:         statsmodels: 0.14.4
2025-05-12 22:25:09,786:INFO:              sktime: 0.26.0
2025-05-12 22:25:09,786:INFO:               tbats: 1.1.3
2025-05-12 22:25:09,786:INFO:            pmdarima: 2.0.4
2025-05-12 22:25:09,786:INFO:              psutil: 7.0.0
2025-05-12 22:25:09,787:INFO:          markupsafe: 3.0.2
2025-05-12 22:25:09,787:INFO:             pickle5: Not installed
2025-05-12 22:25:09,787:INFO:         cloudpickle: 3.1.1
2025-05-12 22:25:09,787:INFO:         deprecation: 2.1.0
2025-05-12 22:25:09,787:INFO:              xxhash: 3.5.0
2025-05-12 22:25:09,787:INFO:           wurlitzer: Not installed
2025-05-12 22:25:09,787:INFO:PyCaret optional dependencies:
2025-05-12 22:25:09,787:INFO:                shap: Not installed
2025-05-12 22:25:09,787:INFO:           interpret: Not installed
2025-05-12 22:25:09,787:INFO:                umap: Not installed
2025-05-12 22:25:09,787:INFO:     ydata_profiling: Not installed
2025-05-12 22:25:09,787:INFO:  explainerdashboard: Not installed
2025-05-12 22:25:09,788:INFO:             autoviz: Not installed
2025-05-12 22:25:09,788:INFO:           fairlearn: Not installed
2025-05-12 22:25:09,788:INFO:          deepchecks: Not installed
2025-05-12 22:25:09,788:INFO:             xgboost: Not installed
2025-05-12 22:25:09,788:INFO:            catboost: Not installed
2025-05-12 22:25:09,788:INFO:              kmodes: Not installed
2025-05-12 22:25:09,788:INFO:             mlxtend: Not installed
2025-05-12 22:25:09,788:INFO:       statsforecast: Not installed
2025-05-12 22:25:09,788:INFO:        tune_sklearn: Not installed
2025-05-12 22:25:09,788:INFO:                 ray: Not installed
2025-05-12 22:25:09,788:INFO:            hyperopt: Not installed
2025-05-12 22:25:09,788:INFO:              optuna: Not installed
2025-05-12 22:25:09,788:INFO:               skopt: Not installed
2025-05-12 22:25:09,788:INFO:              mlflow: Not installed
2025-05-12 22:25:09,789:INFO:              gradio: Not installed
2025-05-12 22:25:09,789:INFO:             fastapi: Not installed
2025-05-12 22:25:09,789:INFO:             uvicorn: Not installed
2025-05-12 22:25:09,789:INFO:              m2cgen: Not installed
2025-05-12 22:25:09,789:INFO:           evidently: Not installed
2025-05-12 22:25:09,789:INFO:               fugue: Not installed
2025-05-12 22:25:09,789:INFO:           streamlit: Not installed
2025-05-12 22:25:09,790:INFO:             prophet: Not installed
2025-05-12 22:25:09,790:INFO:None
2025-05-12 22:25:09,790:INFO:Set up data.
2025-05-12 22:25:09,795:INFO:Set up folding strategy.
2025-05-12 22:25:09,796:INFO:Set up train/test split.
2025-05-12 22:25:09,799:INFO:Set up index.
2025-05-12 22:25:09,799:INFO:Assigning column types.
2025-05-12 22:25:09,803:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:25:09,803:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,807:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,811:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,867:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:09,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:09,907:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,909:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,913:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,993:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:09,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:09,994:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:25:09,998:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,001:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,047:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,081:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,081:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,086:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,090:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,171:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:25:10,179:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,224:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,258:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,258:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,265:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,344:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,344:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,344:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,344:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:25:10,394:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,430:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,431:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,481:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,516:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:25:10,567:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,654:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,693:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,693:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:25:10,790:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,884:INFO:Preparing preprocessing pipeline...
2025-05-12 22:25:10,884:INFO:Set up simple imputation.
2025-05-12 22:25:10,887:INFO:Set up encoding of categorical features.
2025-05-12 22:25:10,887:INFO:Set up feature normalization.
2025-05-12 22:25:10,936:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:25:10,939:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:25:10,939:INFO:Creating final display dataframe.
2025-05-12 22:25:11,127:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type        Regression
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              36ac
2025-05-12 22:25:11,229:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:11,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:11,331:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:11,332:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:11,332:INFO:setup() successfully completed in 1.56s...............
2025-05-12 22:25:11,351:INFO:Initializing compare_models()
2025-05-12 22:25:11,351:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 22:25:11,352:INFO:Checking exceptions
2025-05-12 22:25:11,354:INFO:Preparing display monitor
2025-05-12 22:25:11,388:INFO:Initializing Linear Regression
2025-05-12 22:25:11,388:INFO:Total runtime is 1.6701221466064452e-05 minutes
2025-05-12 22:25:11,393:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:11,394:INFO:Initializing create_model()
2025-05-12 22:25:11,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:11,394:INFO:Checking exceptions
2025-05-12 22:25:11,394:INFO:Importing libraries
2025-05-12 22:25:11,394:INFO:Copying training dataset
2025-05-12 22:25:11,399:INFO:Defining folds
2025-05-12 22:25:11,399:INFO:Declaring metric variables
2025-05-12 22:25:11,402:INFO:Importing untrained model
2025-05-12 22:25:11,407:INFO:Linear Regression Imported successfully
2025-05-12 22:25:11,413:INFO:Starting cross validation
2025-05-12 22:25:11,415:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:11,608:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:11,608:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:11,617:INFO:Calculating mean and std
2025-05-12 22:25:11,617:INFO:Creating metrics dataframe
2025-05-12 22:25:11,620:INFO:Uploading results into container
2025-05-12 22:25:11,620:INFO:Uploading model into container now
2025-05-12 22:25:11,621:INFO:_master_model_container: 1
2025-05-12 22:25:11,621:INFO:_display_container: 2
2025-05-12 22:25:11,621:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-05-12 22:25:11,621:INFO:create_model() successfully completed......................................
2025-05-12 22:25:11,721:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:11,721:INFO:Creating metrics dataframe
2025-05-12 22:25:11,726:INFO:Initializing Lasso Regression
2025-05-12 22:25:11,726:INFO:Total runtime is 0.005647528171539307 minutes
2025-05-12 22:25:11,729:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:11,729:INFO:Initializing create_model()
2025-05-12 22:25:11,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:11,729:INFO:Checking exceptions
2025-05-12 22:25:11,729:INFO:Importing libraries
2025-05-12 22:25:11,729:INFO:Copying training dataset
2025-05-12 22:25:11,732:INFO:Defining folds
2025-05-12 22:25:11,732:INFO:Declaring metric variables
2025-05-12 22:25:11,736:INFO:Importing untrained model
2025-05-12 22:25:11,741:INFO:Lasso Regression Imported successfully
2025-05-12 22:25:11,747:INFO:Starting cross validation
2025-05-12 22:25:11,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:11,934:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:11,934:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:11,937:INFO:Calculating mean and std
2025-05-12 22:25:11,937:INFO:Creating metrics dataframe
2025-05-12 22:25:11,937:INFO:Uploading results into container
2025-05-12 22:25:11,939:INFO:Uploading model into container now
2025-05-12 22:25:11,940:INFO:_master_model_container: 2
2025-05-12 22:25:11,940:INFO:_display_container: 2
2025-05-12 22:25:11,940:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-05-12 22:25:11,941:INFO:create_model() successfully completed......................................
2025-05-12 22:25:12,047:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:12,047:INFO:Creating metrics dataframe
2025-05-12 22:25:12,052:INFO:Initializing Ridge Regression
2025-05-12 22:25:12,053:INFO:Total runtime is 0.011103037993113199 minutes
2025-05-12 22:25:12,056:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:12,056:INFO:Initializing create_model()
2025-05-12 22:25:12,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:12,056:INFO:Checking exceptions
2025-05-12 22:25:12,056:INFO:Importing libraries
2025-05-12 22:25:12,056:INFO:Copying training dataset
2025-05-12 22:25:12,060:INFO:Defining folds
2025-05-12 22:25:12,060:INFO:Declaring metric variables
2025-05-12 22:25:12,063:INFO:Importing untrained model
2025-05-12 22:25:12,067:INFO:Ridge Regression Imported successfully
2025-05-12 22:25:12,073:INFO:Starting cross validation
2025-05-12 22:25:12,074:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:12,284:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:12,284:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:12,293:INFO:Calculating mean and std
2025-05-12 22:25:12,293:INFO:Creating metrics dataframe
2025-05-12 22:25:12,294:INFO:Uploading results into container
2025-05-12 22:25:12,294:INFO:Uploading model into container now
2025-05-12 22:25:12,296:INFO:_master_model_container: 3
2025-05-12 22:25:12,296:INFO:_display_container: 2
2025-05-12 22:25:12,296:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-05-12 22:25:12,296:INFO:create_model() successfully completed......................................
2025-05-12 22:25:12,401:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:12,403:INFO:Creating metrics dataframe
2025-05-12 22:25:12,409:INFO:Initializing Elastic Net
2025-05-12 22:25:12,409:INFO:Total runtime is 0.017030918598175047 minutes
2025-05-12 22:25:12,413:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:12,414:INFO:Initializing create_model()
2025-05-12 22:25:12,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:12,414:INFO:Checking exceptions
2025-05-12 22:25:12,414:INFO:Importing libraries
2025-05-12 22:25:12,414:INFO:Copying training dataset
2025-05-12 22:25:12,419:INFO:Defining folds
2025-05-12 22:25:12,419:INFO:Declaring metric variables
2025-05-12 22:25:12,423:INFO:Importing untrained model
2025-05-12 22:25:12,428:INFO:Elastic Net Imported successfully
2025-05-12 22:25:12,438:INFO:Starting cross validation
2025-05-12 22:25:12,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:12,739:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:12,739:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:12,749:INFO:Calculating mean and std
2025-05-12 22:25:12,752:INFO:Creating metrics dataframe
2025-05-12 22:25:12,754:INFO:Uploading results into container
2025-05-12 22:25:12,754:INFO:Uploading model into container now
2025-05-12 22:25:12,756:INFO:_master_model_container: 4
2025-05-12 22:25:12,756:INFO:_display_container: 2
2025-05-12 22:25:12,757:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-05-12 22:25:12,757:INFO:create_model() successfully completed......................................
2025-05-12 22:25:12,873:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:12,873:INFO:Creating metrics dataframe
2025-05-12 22:25:12,881:INFO:Initializing Least Angle Regression
2025-05-12 22:25:12,881:INFO:Total runtime is 0.0248988668123881 minutes
2025-05-12 22:25:12,888:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:12,888:INFO:Initializing create_model()
2025-05-12 22:25:12,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:12,888:INFO:Checking exceptions
2025-05-12 22:25:12,888:INFO:Importing libraries
2025-05-12 22:25:12,888:INFO:Copying training dataset
2025-05-12 22:25:12,893:INFO:Defining folds
2025-05-12 22:25:12,893:INFO:Declaring metric variables
2025-05-12 22:25:12,897:INFO:Importing untrained model
2025-05-12 22:25:12,903:INFO:Least Angle Regression Imported successfully
2025-05-12 22:25:12,911:INFO:Starting cross validation
2025-05-12 22:25:12,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:13,235:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:13,235:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:13,244:INFO:Calculating mean and std
2025-05-12 22:25:13,245:INFO:Creating metrics dataframe
2025-05-12 22:25:13,248:INFO:Uploading results into container
2025-05-12 22:25:13,248:INFO:Uploading model into container now
2025-05-12 22:25:13,251:INFO:_master_model_container: 5
2025-05-12 22:25:13,251:INFO:_display_container: 2
2025-05-12 22:25:13,252:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-05-12 22:25:13,252:INFO:create_model() successfully completed......................................
2025-05-12 22:25:13,375:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:13,375:INFO:Creating metrics dataframe
2025-05-12 22:25:13,383:INFO:Initializing Lasso Least Angle Regression
2025-05-12 22:25:13,383:INFO:Total runtime is 0.033265928427378334 minutes
2025-05-12 22:25:13,387:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:13,387:INFO:Initializing create_model()
2025-05-12 22:25:13,387:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:13,389:INFO:Checking exceptions
2025-05-12 22:25:13,389:INFO:Importing libraries
2025-05-12 22:25:13,389:INFO:Copying training dataset
2025-05-12 22:25:13,393:INFO:Defining folds
2025-05-12 22:25:13,394:INFO:Declaring metric variables
2025-05-12 22:25:13,398:INFO:Importing untrained model
2025-05-12 22:25:13,403:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:25:13,412:INFO:Starting cross validation
2025-05-12 22:25:13,413:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:13,698:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:13,699:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:13,700:INFO:Calculating mean and std
2025-05-12 22:25:13,701:INFO:Creating metrics dataframe
2025-05-12 22:25:13,704:INFO:Uploading results into container
2025-05-12 22:25:13,705:INFO:Uploading model into container now
2025-05-12 22:25:13,706:INFO:_master_model_container: 6
2025-05-12 22:25:13,706:INFO:_display_container: 2
2025-05-12 22:25:13,706:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-05-12 22:25:13,707:INFO:create_model() successfully completed......................................
2025-05-12 22:25:13,824:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:13,824:INFO:Creating metrics dataframe
2025-05-12 22:25:13,833:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 22:25:13,834:INFO:Total runtime is 0.040789866447448725 minutes
2025-05-12 22:25:13,839:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:13,839:INFO:Initializing create_model()
2025-05-12 22:25:13,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:13,839:INFO:Checking exceptions
2025-05-12 22:25:13,839:INFO:Importing libraries
2025-05-12 22:25:13,839:INFO:Copying training dataset
2025-05-12 22:25:13,845:INFO:Defining folds
2025-05-12 22:25:13,845:INFO:Declaring metric variables
2025-05-12 22:25:13,851:INFO:Importing untrained model
2025-05-12 22:25:13,856:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 22:25:13,865:INFO:Starting cross validation
2025-05-12 22:25:13,867:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:14,199:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:14,199:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:14,208:INFO:Calculating mean and std
2025-05-12 22:25:14,210:INFO:Creating metrics dataframe
2025-05-12 22:25:14,213:INFO:Uploading results into container
2025-05-12 22:25:14,214:INFO:Uploading model into container now
2025-05-12 22:25:14,214:INFO:_master_model_container: 7
2025-05-12 22:25:14,214:INFO:_display_container: 2
2025-05-12 22:25:14,216:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-05-12 22:25:14,216:INFO:create_model() successfully completed......................................
2025-05-12 22:25:14,327:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:14,327:INFO:Creating metrics dataframe
2025-05-12 22:25:14,335:INFO:Initializing Bayesian Ridge
2025-05-12 22:25:14,336:INFO:Total runtime is 0.04914723634719848 minutes
2025-05-12 22:25:14,339:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:14,339:INFO:Initializing create_model()
2025-05-12 22:25:14,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:14,339:INFO:Checking exceptions
2025-05-12 22:25:14,339:INFO:Importing libraries
2025-05-12 22:25:14,339:INFO:Copying training dataset
2025-05-12 22:25:14,343:INFO:Defining folds
2025-05-12 22:25:14,343:INFO:Declaring metric variables
2025-05-12 22:25:14,347:INFO:Importing untrained model
2025-05-12 22:25:14,354:INFO:Bayesian Ridge Imported successfully
2025-05-12 22:25:14,362:INFO:Starting cross validation
2025-05-12 22:25:14,366:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:14,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:14,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:14,626:INFO:Calculating mean and std
2025-05-12 22:25:14,627:INFO:Creating metrics dataframe
2025-05-12 22:25:14,630:INFO:Uploading results into container
2025-05-12 22:25:14,631:INFO:Uploading model into container now
2025-05-12 22:25:14,633:INFO:_master_model_container: 8
2025-05-12 22:25:14,633:INFO:_display_container: 2
2025-05-12 22:25:14,633:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-05-12 22:25:14,633:INFO:create_model() successfully completed......................................
2025-05-12 22:25:14,737:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:14,738:INFO:Creating metrics dataframe
2025-05-12 22:25:14,746:INFO:Initializing Passive Aggressive Regressor
2025-05-12 22:25:14,746:INFO:Total runtime is 0.055983444054921463 minutes
2025-05-12 22:25:14,750:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:14,750:INFO:Initializing create_model()
2025-05-12 22:25:14,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:14,750:INFO:Checking exceptions
2025-05-12 22:25:14,750:INFO:Importing libraries
2025-05-12 22:25:14,750:INFO:Copying training dataset
2025-05-12 22:25:14,755:INFO:Defining folds
2025-05-12 22:25:14,756:INFO:Declaring metric variables
2025-05-12 22:25:14,759:INFO:Importing untrained model
2025-05-12 22:25:14,764:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 22:25:14,773:INFO:Starting cross validation
2025-05-12 22:25:14,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:15,011:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:15,011:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:15,017:INFO:Calculating mean and std
2025-05-12 22:25:15,019:INFO:Creating metrics dataframe
2025-05-12 22:25:15,021:INFO:Uploading results into container
2025-05-12 22:25:15,021:INFO:Uploading model into container now
2025-05-12 22:25:15,022:INFO:_master_model_container: 9
2025-05-12 22:25:15,022:INFO:_display_container: 2
2025-05-12 22:25:15,022:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-12 22:25:15,022:INFO:create_model() successfully completed......................................
2025-05-12 22:25:15,125:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:15,125:INFO:Creating metrics dataframe
2025-05-12 22:25:15,134:INFO:Initializing Huber Regressor
2025-05-12 22:25:15,134:INFO:Total runtime is 0.062446180979410806 minutes
2025-05-12 22:25:15,136:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:15,137:INFO:Initializing create_model()
2025-05-12 22:25:15,137:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:15,137:INFO:Checking exceptions
2025-05-12 22:25:15,137:INFO:Importing libraries
2025-05-12 22:25:15,137:INFO:Copying training dataset
2025-05-12 22:25:15,143:INFO:Defining folds
2025-05-12 22:25:15,143:INFO:Declaring metric variables
2025-05-12 22:25:15,148:INFO:Importing untrained model
2025-05-12 22:25:15,153:INFO:Huber Regressor Imported successfully
2025-05-12 22:25:15,160:INFO:Starting cross validation
2025-05-12 22:25:15,161:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:15,474:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:15,474:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:15,481:INFO:Calculating mean and std
2025-05-12 22:25:15,483:INFO:Creating metrics dataframe
2025-05-12 22:25:15,487:INFO:Uploading results into container
2025-05-12 22:25:15,489:INFO:Uploading model into container now
2025-05-12 22:25:15,489:INFO:_master_model_container: 10
2025-05-12 22:25:15,490:INFO:_display_container: 2
2025-05-12 22:25:15,490:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-05-12 22:25:15,491:INFO:create_model() successfully completed......................................
2025-05-12 22:25:15,595:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:15,595:INFO:Creating metrics dataframe
2025-05-12 22:25:15,605:INFO:Initializing K Neighbors Regressor
2025-05-12 22:25:15,606:INFO:Total runtime is 0.07032041947046916 minutes
2025-05-12 22:25:15,610:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:15,610:INFO:Initializing create_model()
2025-05-12 22:25:15,610:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:15,611:INFO:Checking exceptions
2025-05-12 22:25:15,611:INFO:Importing libraries
2025-05-12 22:25:15,611:INFO:Copying training dataset
2025-05-12 22:25:15,617:INFO:Defining folds
2025-05-12 22:25:15,617:INFO:Declaring metric variables
2025-05-12 22:25:15,621:INFO:Importing untrained model
2025-05-12 22:25:15,626:INFO:K Neighbors Regressor Imported successfully
2025-05-12 22:25:15,657:INFO:Starting cross validation
2025-05-12 22:25:15,659:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:15,982:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:15,983:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:15,994:INFO:Calculating mean and std
2025-05-12 22:25:15,995:INFO:Creating metrics dataframe
2025-05-12 22:25:15,998:INFO:Uploading results into container
2025-05-12 22:25:15,998:INFO:Uploading model into container now
2025-05-12 22:25:15,999:INFO:_master_model_container: 11
2025-05-12 22:25:16,000:INFO:_display_container: 2
2025-05-12 22:25:16,000:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-05-12 22:25:16,000:INFO:create_model() successfully completed......................................
2025-05-12 22:25:16,104:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:16,104:INFO:Creating metrics dataframe
2025-05-12 22:25:16,124:INFO:Initializing Decision Tree Regressor
2025-05-12 22:25:16,124:INFO:Total runtime is 0.07895351648330688 minutes
2025-05-12 22:25:16,149:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:16,149:INFO:Initializing create_model()
2025-05-12 22:25:16,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:16,149:INFO:Checking exceptions
2025-05-12 22:25:16,149:INFO:Importing libraries
2025-05-12 22:25:16,150:INFO:Copying training dataset
2025-05-12 22:25:16,157:INFO:Defining folds
2025-05-12 22:25:16,157:INFO:Declaring metric variables
2025-05-12 22:25:16,179:INFO:Importing untrained model
2025-05-12 22:25:16,198:INFO:Decision Tree Regressor Imported successfully
2025-05-12 22:25:16,215:INFO:Starting cross validation
2025-05-12 22:25:16,219:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:16,526:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:16,527:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:16,533:INFO:Calculating mean and std
2025-05-12 22:25:16,535:INFO:Creating metrics dataframe
2025-05-12 22:25:16,538:INFO:Uploading results into container
2025-05-12 22:25:16,539:INFO:Uploading model into container now
2025-05-12 22:25:16,540:INFO:_master_model_container: 12
2025-05-12 22:25:16,540:INFO:_display_container: 2
2025-05-12 22:25:16,541:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-05-12 22:25:16,541:INFO:create_model() successfully completed......................................
2025-05-12 22:25:16,657:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:16,658:INFO:Creating metrics dataframe
2025-05-12 22:25:16,669:INFO:Initializing Random Forest Regressor
2025-05-12 22:25:16,669:INFO:Total runtime is 0.08803116083145142 minutes
2025-05-12 22:25:16,673:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:16,674:INFO:Initializing create_model()
2025-05-12 22:25:16,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:16,674:INFO:Checking exceptions
2025-05-12 22:25:16,674:INFO:Importing libraries
2025-05-12 22:25:16,674:INFO:Copying training dataset
2025-05-12 22:25:16,679:INFO:Defining folds
2025-05-12 22:25:16,680:INFO:Declaring metric variables
2025-05-12 22:25:16,685:INFO:Importing untrained model
2025-05-12 22:25:16,691:INFO:Random Forest Regressor Imported successfully
2025-05-12 22:25:16,700:INFO:Starting cross validation
2025-05-12 22:25:16,704:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:17,638:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:17,638:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:17,649:INFO:Calculating mean and std
2025-05-12 22:25:17,650:INFO:Creating metrics dataframe
2025-05-12 22:25:17,653:INFO:Uploading results into container
2025-05-12 22:25:17,654:INFO:Uploading model into container now
2025-05-12 22:25:17,655:INFO:_master_model_container: 13
2025-05-12 22:25:17,655:INFO:_display_container: 2
2025-05-12 22:25:17,656:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-05-12 22:25:17,656:INFO:create_model() successfully completed......................................
2025-05-12 22:25:17,771:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:17,771:INFO:Creating metrics dataframe
2025-05-12 22:25:17,783:INFO:Initializing Extra Trees Regressor
2025-05-12 22:25:17,783:INFO:Total runtime is 0.10659570296605428 minutes
2025-05-12 22:25:17,787:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:17,787:INFO:Initializing create_model()
2025-05-12 22:25:17,787:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:17,787:INFO:Checking exceptions
2025-05-12 22:25:17,787:INFO:Importing libraries
2025-05-12 22:25:17,788:INFO:Copying training dataset
2025-05-12 22:25:17,791:INFO:Defining folds
2025-05-12 22:25:17,793:INFO:Declaring metric variables
2025-05-12 22:25:17,797:INFO:Importing untrained model
2025-05-12 22:25:17,801:INFO:Extra Trees Regressor Imported successfully
2025-05-12 22:25:17,809:INFO:Starting cross validation
2025-05-12 22:25:17,813:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:18,488:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:18,488:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:18,499:INFO:Calculating mean and std
2025-05-12 22:25:18,500:INFO:Creating metrics dataframe
2025-05-12 22:25:18,503:INFO:Uploading results into container
2025-05-12 22:25:18,504:INFO:Uploading model into container now
2025-05-12 22:25:18,505:INFO:_master_model_container: 14
2025-05-12 22:25:18,505:INFO:_display_container: 2
2025-05-12 22:25:18,505:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-05-12 22:25:18,506:INFO:create_model() successfully completed......................................
2025-05-12 22:25:18,607:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:18,607:INFO:Creating metrics dataframe
2025-05-12 22:25:18,618:INFO:Initializing AdaBoost Regressor
2025-05-12 22:25:18,618:INFO:Total runtime is 0.12051774263381958 minutes
2025-05-12 22:25:18,621:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:18,621:INFO:Initializing create_model()
2025-05-12 22:25:18,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:18,621:INFO:Checking exceptions
2025-05-12 22:25:18,622:INFO:Importing libraries
2025-05-12 22:25:18,622:INFO:Copying training dataset
2025-05-12 22:25:18,626:INFO:Defining folds
2025-05-12 22:25:18,626:INFO:Declaring metric variables
2025-05-12 22:25:18,629:INFO:Importing untrained model
2025-05-12 22:25:18,634:INFO:AdaBoost Regressor Imported successfully
2025-05-12 22:25:18,641:INFO:Starting cross validation
2025-05-12 22:25:18,643:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:19,247:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:19,247:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:19,250:INFO:Calculating mean and std
2025-05-12 22:25:19,251:INFO:Creating metrics dataframe
2025-05-12 22:25:19,253:INFO:Uploading results into container
2025-05-12 22:25:19,254:INFO:Uploading model into container now
2025-05-12 22:25:19,254:INFO:_master_model_container: 15
2025-05-12 22:25:19,254:INFO:_display_container: 2
2025-05-12 22:25:19,255:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-05-12 22:25:19,255:INFO:create_model() successfully completed......................................
2025-05-12 22:25:19,365:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:19,365:INFO:Creating metrics dataframe
2025-05-12 22:25:19,376:INFO:Initializing Gradient Boosting Regressor
2025-05-12 22:25:19,376:INFO:Total runtime is 0.1331573208173116 minutes
2025-05-12 22:25:19,381:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:19,381:INFO:Initializing create_model()
2025-05-12 22:25:19,381:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:19,381:INFO:Checking exceptions
2025-05-12 22:25:19,381:INFO:Importing libraries
2025-05-12 22:25:19,381:INFO:Copying training dataset
2025-05-12 22:25:19,387:INFO:Defining folds
2025-05-12 22:25:19,387:INFO:Declaring metric variables
2025-05-12 22:25:19,390:INFO:Importing untrained model
2025-05-12 22:25:19,397:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 22:25:19,404:INFO:Starting cross validation
2025-05-12 22:25:19,407:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:19,923:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:19,924:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:19,933:INFO:Calculating mean and std
2025-05-12 22:25:19,934:INFO:Creating metrics dataframe
2025-05-12 22:25:19,936:INFO:Uploading results into container
2025-05-12 22:25:19,937:INFO:Uploading model into container now
2025-05-12 22:25:19,938:INFO:_master_model_container: 16
2025-05-12 22:25:19,938:INFO:_display_container: 2
2025-05-12 22:25:19,938:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-12 22:25:19,939:INFO:create_model() successfully completed......................................
2025-05-12 22:25:20,059:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:20,060:INFO:Creating metrics dataframe
2025-05-12 22:25:20,073:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:25:20,073:INFO:Total runtime is 0.1447648564974467 minutes
2025-05-12 22:25:20,079:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:20,080:INFO:Initializing create_model()
2025-05-12 22:25:20,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:20,080:INFO:Checking exceptions
2025-05-12 22:25:20,080:INFO:Importing libraries
2025-05-12 22:25:20,080:INFO:Copying training dataset
2025-05-12 22:25:20,084:INFO:Defining folds
2025-05-12 22:25:20,086:INFO:Declaring metric variables
2025-05-12 22:25:20,089:INFO:Importing untrained model
2025-05-12 22:25:20,096:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:25:20,106:INFO:Starting cross validation
2025-05-12 22:25:20,108:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:20,649:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:20,649:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:20,657:INFO:Calculating mean and std
2025-05-12 22:25:20,660:INFO:Creating metrics dataframe
2025-05-12 22:25:20,664:INFO:Uploading results into container
2025-05-12 22:25:20,664:INFO:Uploading model into container now
2025-05-12 22:25:20,666:INFO:_master_model_container: 17
2025-05-12 22:25:20,666:INFO:_display_container: 2
2025-05-12 22:25:20,668:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:25:20,668:INFO:create_model() successfully completed......................................
2025-05-12 22:25:20,803:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:20,804:INFO:Creating metrics dataframe
2025-05-12 22:25:20,816:INFO:Initializing Dummy Regressor
2025-05-12 22:25:20,816:INFO:Total runtime is 0.15715911785761516 minutes
2025-05-12 22:25:20,820:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:20,821:INFO:Initializing create_model()
2025-05-12 22:25:20,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:20,821:INFO:Checking exceptions
2025-05-12 22:25:20,821:INFO:Importing libraries
2025-05-12 22:25:20,821:INFO:Copying training dataset
2025-05-12 22:25:20,826:INFO:Defining folds
2025-05-12 22:25:20,826:INFO:Declaring metric variables
2025-05-12 22:25:20,831:INFO:Importing untrained model
2025-05-12 22:25:20,844:INFO:Dummy Regressor Imported successfully
2025-05-12 22:25:20,867:INFO:Starting cross validation
2025-05-12 22:25:20,872:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:21,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:21,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:21,181:INFO:Calculating mean and std
2025-05-12 22:25:21,183:INFO:Creating metrics dataframe
2025-05-12 22:25:21,186:INFO:Uploading results into container
2025-05-12 22:25:21,187:INFO:Uploading model into container now
2025-05-12 22:25:21,187:INFO:_master_model_container: 18
2025-05-12 22:25:21,188:INFO:_display_container: 2
2025-05-12 22:25:21,188:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-05-12 22:25:21,188:INFO:create_model() successfully completed......................................
2025-05-12 22:25:21,298:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:21,298:INFO:Creating metrics dataframe
2025-05-12 22:25:21,311:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:25:21,321:INFO:Initializing create_model()
2025-05-12 22:25:21,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:21,321:INFO:Checking exceptions
2025-05-12 22:25:21,324:INFO:Importing libraries
2025-05-12 22:25:21,324:INFO:Copying training dataset
2025-05-12 22:25:21,328:INFO:Defining folds
2025-05-12 22:25:21,329:INFO:Declaring metric variables
2025-05-12 22:25:21,329:INFO:Importing untrained model
2025-05-12 22:25:21,329:INFO:Declaring custom model
2025-05-12 22:25:21,329:INFO:Lasso Regression Imported successfully
2025-05-12 22:25:21,331:INFO:Cross validation set to False
2025-05-12 22:25:21,331:INFO:Fitting Model
2025-05-12 22:25:21,378:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-05-12 22:25:21,378:INFO:create_model() successfully completed......................................
2025-05-12 22:25:21,511:INFO:_master_model_container: 18
2025-05-12 22:25:21,511:INFO:_display_container: 2
2025-05-12 22:25:21,512:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-05-12 22:25:21,512:INFO:compare_models() successfully completed......................................
2025-05-12 22:25:21,579:INFO:Initializing create_model()
2025-05-12 22:25:21,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:21,579:INFO:Checking exceptions
2025-05-12 22:25:21,603:INFO:Importing libraries
2025-05-12 22:25:21,603:INFO:Copying training dataset
2025-05-12 22:25:21,611:INFO:Defining folds
2025-05-12 22:25:21,612:INFO:Declaring metric variables
2025-05-12 22:25:21,621:INFO:Importing untrained model
2025-05-12 22:25:21,636:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:25:21,650:INFO:Starting cross validation
2025-05-12 22:25:21,653:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:22,287:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:22,288:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:22,303:INFO:Calculating mean and std
2025-05-12 22:25:22,303:INFO:Creating metrics dataframe
2025-05-12 22:25:22,311:INFO:Finalizing model
2025-05-12 22:25:22,381:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.
2025-05-12 22:25:22,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-12 22:25:22,383:INFO:[LightGBM] [Info] Total Bins 116
2025-05-12 22:25:22,383:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:25:22,383:INFO:[LightGBM] [Info] Start training from score 0.161905
2025-05-12 22:25:22,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,420:INFO:Uploading results into container
2025-05-12 22:25:22,423:INFO:Uploading model into container now
2025-05-12 22:25:22,443:INFO:_master_model_container: 19
2025-05-12 22:25:22,443:INFO:_display_container: 3
2025-05-12 22:25:22,444:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:25:22,444:INFO:create_model() successfully completed......................................
2025-05-12 22:25:22,599:INFO:Initializing tune_model()
2025-05-12 22:25:22,600:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:25:22,600:INFO:Checking exceptions
2025-05-12 22:25:22,623:INFO:Copying training dataset
2025-05-12 22:25:22,627:INFO:Checking base model
2025-05-12 22:25:22,627:INFO:Base model : Light Gradient Boosting Machine
2025-05-12 22:25:22,632:INFO:Declaring metric variables
2025-05-12 22:25:22,638:INFO:Defining Hyperparameters
2025-05-12 22:25:22,749:INFO:Tuning with n_jobs=-1
2025-05-12 22:25:22,749:INFO:Initializing RandomizedSearchCV
2025-05-12 22:25:29,564:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2025-05-12 22:25:29,567:INFO:Hyperparameter search completed
2025-05-12 22:25:29,567:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:29,569:INFO:Initializing create_model()
2025-05-12 22:25:29,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E0A7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2025-05-12 22:25:29,570:INFO:Checking exceptions
2025-05-12 22:25:29,570:INFO:Importing libraries
2025-05-12 22:25:29,570:INFO:Copying training dataset
2025-05-12 22:25:29,576:INFO:Defining folds
2025-05-12 22:25:29,576:INFO:Declaring metric variables
2025-05-12 22:25:29,581:INFO:Importing untrained model
2025-05-12 22:25:29,581:INFO:Declaring custom model
2025-05-12 22:25:29,590:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:25:29,603:INFO:Starting cross validation
2025-05-12 22:25:29,606:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:30,115:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:30,116:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:30,135:INFO:Calculating mean and std
2025-05-12 22:25:30,137:INFO:Creating metrics dataframe
2025-05-12 22:25:30,150:INFO:Finalizing model
2025-05-12 22:25:30,215:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:25:30,215:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:25:30,215:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:25:30,215:INFO:[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.
2025-05-12 22:25:30,217:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:25:30,217:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:25:30,217:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:25:30,217:INFO:[LightGBM] [Info] Total Bins 0
2025-05-12 22:25:30,217:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 0
2025-05-12 22:25:30,217:INFO:[LightGBM] [Info] Start training from score 0.161905
2025-05-12 22:25:30,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,229:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,232:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,232:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,232:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,236:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,236:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,236:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,236:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,236:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,249:INFO:Uploading results into container
2025-05-12 22:25:30,250:INFO:Uploading model into container now
2025-05-12 22:25:30,251:INFO:_master_model_container: 20
2025-05-12 22:25:30,251:INFO:_display_container: 4
2025-05-12 22:25:30,254:INFO:LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:25:30,254:INFO:create_model() successfully completed......................................
2025-05-12 22:25:30,435:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:30,435:INFO:choose_better activated
2025-05-12 22:25:30,446:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:30,448:INFO:Initializing create_model()
2025-05-12 22:25:30,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:30,449:INFO:Checking exceptions
2025-05-12 22:25:30,451:INFO:Importing libraries
2025-05-12 22:25:30,453:INFO:Copying training dataset
2025-05-12 22:25:30,457:INFO:Defining folds
2025-05-12 22:25:30,457:INFO:Declaring metric variables
2025-05-12 22:25:30,459:INFO:Importing untrained model
2025-05-12 22:25:30,459:INFO:Declaring custom model
2025-05-12 22:25:30,460:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:25:30,460:INFO:Starting cross validation
2025-05-12 22:25:30,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:31,067:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:31,067:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:31,097:INFO:Calculating mean and std
2025-05-12 22:25:31,098:INFO:Creating metrics dataframe
2025-05-12 22:25:31,101:INFO:Finalizing model
2025-05-12 22:25:31,238:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.
2025-05-12 22:25:31,238:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-12 22:25:31,238:INFO:[LightGBM] [Info] Total Bins 116
2025-05-12 22:25:31,238:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:25:31,239:INFO:[LightGBM] [Info] Start training from score 0.161905
2025-05-12 22:25:31,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,337:INFO:Uploading results into container
2025-05-12 22:25:31,338:INFO:Uploading model into container now
2025-05-12 22:25:31,339:INFO:_master_model_container: 21
2025-05-12 22:25:31,339:INFO:_display_container: 5
2025-05-12 22:25:31,340:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:25:31,340:INFO:create_model() successfully completed......................................
2025-05-12 22:25:31,483:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:31,483:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for R2 is -0.2315
2025-05-12 22:25:31,484:INFO:LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for R2 is -0.0421
2025-05-12 22:25:31,486:INFO:LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-12 22:25:31,486:INFO:choose_better completed
2025-05-12 22:25:31,498:INFO:_master_model_container: 21
2025-05-12 22:25:31,498:INFO:_display_container: 4
2025-05-12 22:25:31,500:INFO:LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:25:31,500:INFO:tune_model() successfully completed......................................
2025-05-12 22:25:31,671:INFO:Initializing evaluate_model()
2025-05-12 22:25:31,671:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:25:31,687:INFO:Initializing plot_model()
2025-05-12 22:25:31,687:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:25:31,688:INFO:Checking exceptions
2025-05-12 22:25:31,692:INFO:Preloading libraries
2025-05-12 22:25:31,693:INFO:Copying training dataset
2025-05-12 22:25:31,693:INFO:Plot type: pipeline
2025-05-12 22:25:31,900:INFO:Visual Rendered Successfully
2025-05-12 22:25:32,019:INFO:plot_model() successfully completed......................................
2025-05-12 22:25:32,044:INFO:Initializing predict_model()
2025-05-12 22:25:32,044:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EA7B591C60>)
2025-05-12 22:25:32,046:INFO:Checking exceptions
2025-05-12 22:25:32,046:INFO:Preloading libraries
2025-05-12 22:25:32,169:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:25:32,358:INFO:Initializing save_model()
2025-05-12 22:25:32,358:INFO:save_model(model=LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-12 22:25:32,358:INFO:Adding model into prep_pipe
2025-05-12 22:25:32,372:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:25:32,389:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                               boosting_type='gbdt', class_weight=None,
                               colsample_bytree=1.0, feature_fraction=0.9,
                               importance_type='split', learning_rate=1e-07,
                               max_depth=-1, min_child_samples=91,
                               min_child_weight=0.001, min_split_gain=0.5,
                               n_estimators=130, n_jobs=-1, num_leaves=80,
                               objective=None, random_state=123, reg_alpha=4,
                               reg_lambda=1e-06, subsample=1.0,
                               subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-12 22:25:32,389:INFO:save_model() successfully completed......................................
2025-05-12 22:25:36,929:INFO:PyCaret RegressionExperiment
2025-05-12 22:25:36,930:INFO:Logging name: reg-default-name
2025-05-12 22:25:36,930:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:25:36,930:INFO:version 3.3.2
2025-05-12 22:25:36,930:INFO:Initializing setup()
2025-05-12 22:25:36,930:INFO:self.USI: 53fa
2025-05-12 22:25:36,930:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'transform_target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:25:36,930:INFO:Checking environment
2025-05-12 22:25:36,930:INFO:python_version: 3.11.8
2025-05-12 22:25:36,930:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:25:36,930:INFO:machine: AMD64
2025-05-12 22:25:36,930:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:25:36,935:INFO:Memory: svmem(total=16907886592, available=2867486720, percent=83.0, used=14040399872, free=2867486720)
2025-05-12 22:25:36,935:INFO:Physical Core: 4
2025-05-12 22:25:36,935:INFO:Logical Core: 8
2025-05-12 22:25:36,935:INFO:Checking libraries
2025-05-12 22:25:36,936:INFO:System:
2025-05-12 22:25:36,936:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:25:36,936:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:25:36,936:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:25:36,936:INFO:PyCaret required dependencies:
2025-05-12 22:25:36,936:INFO:                 pip: 24.0
2025-05-12 22:25:36,936:INFO:          setuptools: 65.5.0
2025-05-12 22:25:36,936:INFO:             pycaret: 3.3.2
2025-05-12 22:25:36,936:INFO:             IPython: 9.2.0
2025-05-12 22:25:36,936:INFO:          ipywidgets: 8.1.7
2025-05-12 22:25:36,936:INFO:                tqdm: 4.67.1
2025-05-12 22:25:36,936:INFO:               numpy: 1.26.4
2025-05-12 22:25:36,936:INFO:              pandas: 2.1.4
2025-05-12 22:25:36,936:INFO:              jinja2: 3.1.6
2025-05-12 22:25:36,936:INFO:               scipy: 1.11.4
2025-05-12 22:25:36,936:INFO:              joblib: 1.3.2
2025-05-12 22:25:36,936:INFO:             sklearn: 1.4.2
2025-05-12 22:25:36,936:INFO:                pyod: 2.0.5
2025-05-12 22:25:36,936:INFO:            imblearn: 0.13.0
2025-05-12 22:25:36,936:INFO:   category_encoders: 2.7.0
2025-05-12 22:25:36,936:INFO:            lightgbm: 4.6.0
2025-05-12 22:25:36,936:INFO:               numba: 0.61.2
2025-05-12 22:25:36,936:INFO:            requests: 2.32.3
2025-05-12 22:25:36,936:INFO:          matplotlib: 3.7.5
2025-05-12 22:25:36,936:INFO:          scikitplot: 0.3.7
2025-05-12 22:25:36,936:INFO:         yellowbrick: 1.5
2025-05-12 22:25:36,936:INFO:              plotly: 5.24.1
2025-05-12 22:25:36,936:INFO:    plotly-resampler: Not installed
2025-05-12 22:25:36,936:INFO:             kaleido: 0.2.1
2025-05-12 22:25:36,936:INFO:           schemdraw: 0.15
2025-05-12 22:25:36,936:INFO:         statsmodels: 0.14.4
2025-05-12 22:25:36,936:INFO:              sktime: 0.26.0
2025-05-12 22:25:36,936:INFO:               tbats: 1.1.3
2025-05-12 22:25:36,936:INFO:            pmdarima: 2.0.4
2025-05-12 22:25:36,936:INFO:              psutil: 7.0.0
2025-05-12 22:25:36,936:INFO:          markupsafe: 3.0.2
2025-05-12 22:25:36,936:INFO:             pickle5: Not installed
2025-05-12 22:25:36,937:INFO:         cloudpickle: 3.1.1
2025-05-12 22:25:36,937:INFO:         deprecation: 2.1.0
2025-05-12 22:25:36,937:INFO:              xxhash: 3.5.0
2025-05-12 22:25:36,937:INFO:           wurlitzer: Not installed
2025-05-12 22:25:36,937:INFO:PyCaret optional dependencies:
2025-05-12 22:25:36,937:INFO:                shap: Not installed
2025-05-12 22:25:36,937:INFO:           interpret: Not installed
2025-05-12 22:25:36,937:INFO:                umap: Not installed
2025-05-12 22:25:36,937:INFO:     ydata_profiling: Not installed
2025-05-12 22:25:36,937:INFO:  explainerdashboard: Not installed
2025-05-12 22:25:36,937:INFO:             autoviz: Not installed
2025-05-12 22:25:36,937:INFO:           fairlearn: Not installed
2025-05-12 22:25:36,937:INFO:          deepchecks: Not installed
2025-05-12 22:25:36,937:INFO:             xgboost: Not installed
2025-05-12 22:25:36,937:INFO:            catboost: Not installed
2025-05-12 22:25:36,937:INFO:              kmodes: Not installed
2025-05-12 22:25:36,937:INFO:             mlxtend: Not installed
2025-05-12 22:25:36,937:INFO:       statsforecast: Not installed
2025-05-12 22:25:36,937:INFO:        tune_sklearn: Not installed
2025-05-12 22:25:36,937:INFO:                 ray: Not installed
2025-05-12 22:25:36,937:INFO:            hyperopt: Not installed
2025-05-12 22:25:36,937:INFO:              optuna: Not installed
2025-05-12 22:25:36,937:INFO:               skopt: Not installed
2025-05-12 22:25:36,937:INFO:              mlflow: Not installed
2025-05-12 22:25:36,937:INFO:              gradio: Not installed
2025-05-12 22:25:36,937:INFO:             fastapi: Not installed
2025-05-12 22:25:36,937:INFO:             uvicorn: Not installed
2025-05-12 22:25:36,937:INFO:              m2cgen: Not installed
2025-05-12 22:25:36,937:INFO:           evidently: Not installed
2025-05-12 22:25:36,937:INFO:               fugue: Not installed
2025-05-12 22:25:36,937:INFO:           streamlit: Not installed
2025-05-12 22:25:36,937:INFO:             prophet: Not installed
2025-05-12 22:25:36,937:INFO:None
2025-05-12 22:25:36,937:INFO:Set up data.
2025-05-12 22:25:36,941:INFO:Set up folding strategy.
2025-05-12 22:25:36,941:INFO:Set up train/test split.
2025-05-12 22:25:36,943:INFO:Set up index.
2025-05-12 22:25:36,943:INFO:Assigning column types.
2025-05-12 22:25:36,944:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:25:36,946:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:25:36,949:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:36,952:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:36,997:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,033:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,036:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,040:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,084:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,119:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,120:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:25:37,123:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,128:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,173:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,206:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,211:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,214:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,259:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,293:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,294:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:25:37,302:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,346:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,379:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,379:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,379:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,386:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,429:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,466:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,467:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:25:37,519:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,553:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,605:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,648:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,648:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,648:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,648:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:25:37,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,786:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,821:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,823:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:25:37,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,914:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:38,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:38,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:38,009:INFO:Preparing preprocessing pipeline...
2025-05-12 22:25:38,009:INFO:Set up simple imputation.
2025-05-12 22:25:38,010:INFO:Set up encoding of categorical features.
2025-05-12 22:25:38,010:INFO:Set up feature normalization.
2025-05-12 22:25:38,056:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:25:38,061:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:25:38,061:INFO:Creating final display dataframe.
2025-05-12 22:25:38,188:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type        Regression
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              53fa
2025-05-12 22:25:38,286:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:38,286:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:38,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:38,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:38,381:INFO:setup() successfully completed in 1.45s...............
2025-05-12 22:25:38,394:INFO:Initializing compare_models()
2025-05-12 22:25:38,394:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 22:25:38,394:INFO:Checking exceptions
2025-05-12 22:25:38,397:INFO:Preparing display monitor
2025-05-12 22:25:38,420:INFO:Initializing Linear Regression
2025-05-12 22:25:38,420:INFO:Total runtime is 0.0 minutes
2025-05-12 22:25:38,424:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:38,425:INFO:Initializing create_model()
2025-05-12 22:25:38,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:38,425:INFO:Checking exceptions
2025-05-12 22:25:38,425:INFO:Importing libraries
2025-05-12 22:25:38,425:INFO:Copying training dataset
2025-05-12 22:25:38,429:INFO:Defining folds
2025-05-12 22:25:38,429:INFO:Declaring metric variables
2025-05-12 22:25:38,434:INFO:Importing untrained model
2025-05-12 22:25:38,438:INFO:Linear Regression Imported successfully
2025-05-12 22:25:38,446:INFO:Starting cross validation
2025-05-12 22:25:38,449:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:38,741:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:38,741:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:38,749:INFO:Calculating mean and std
2025-05-12 22:25:38,750:INFO:Creating metrics dataframe
2025-05-12 22:25:38,751:INFO:Uploading results into container
2025-05-12 22:25:38,753:INFO:Uploading model into container now
2025-05-12 22:25:38,754:INFO:_master_model_container: 1
2025-05-12 22:25:38,754:INFO:_display_container: 2
2025-05-12 22:25:38,754:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-05-12 22:25:38,754:INFO:create_model() successfully completed......................................
2025-05-12 22:25:38,897:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:38,897:INFO:Creating metrics dataframe
2025-05-12 22:25:38,927:INFO:Initializing Lasso Regression
2025-05-12 22:25:38,927:INFO:Total runtime is 0.008444428443908691 minutes
2025-05-12 22:25:38,933:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:38,933:INFO:Initializing create_model()
2025-05-12 22:25:38,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:38,935:INFO:Checking exceptions
2025-05-12 22:25:38,935:INFO:Importing libraries
2025-05-12 22:25:38,935:INFO:Copying training dataset
2025-05-12 22:25:38,941:INFO:Defining folds
2025-05-12 22:25:38,941:INFO:Declaring metric variables
2025-05-12 22:25:38,947:INFO:Importing untrained model
2025-05-12 22:25:38,953:INFO:Lasso Regression Imported successfully
2025-05-12 22:25:38,968:INFO:Starting cross validation
2025-05-12 22:25:38,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:39,263:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:39,263:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:39,268:INFO:Calculating mean and std
2025-05-12 22:25:39,269:INFO:Creating metrics dataframe
2025-05-12 22:25:39,271:INFO:Uploading results into container
2025-05-12 22:25:39,271:INFO:Uploading model into container now
2025-05-12 22:25:39,272:INFO:_master_model_container: 2
2025-05-12 22:25:39,272:INFO:_display_container: 2
2025-05-12 22:25:39,272:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-05-12 22:25:39,272:INFO:create_model() successfully completed......................................
2025-05-12 22:25:39,380:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:39,380:INFO:Creating metrics dataframe
2025-05-12 22:25:39,387:INFO:Initializing Ridge Regression
2025-05-12 22:25:39,387:INFO:Total runtime is 0.016120497385660806 minutes
2025-05-12 22:25:39,391:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:39,391:INFO:Initializing create_model()
2025-05-12 22:25:39,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:39,391:INFO:Checking exceptions
2025-05-12 22:25:39,392:INFO:Importing libraries
2025-05-12 22:25:39,392:INFO:Copying training dataset
2025-05-12 22:25:39,395:INFO:Defining folds
2025-05-12 22:25:39,395:INFO:Declaring metric variables
2025-05-12 22:25:39,398:INFO:Importing untrained model
2025-05-12 22:25:39,401:INFO:Ridge Regression Imported successfully
2025-05-12 22:25:39,410:INFO:Starting cross validation
2025-05-12 22:25:39,412:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:39,644:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:39,644:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:39,647:INFO:Calculating mean and std
2025-05-12 22:25:39,649:INFO:Creating metrics dataframe
2025-05-12 22:25:39,654:INFO:Uploading results into container
2025-05-12 22:25:39,655:INFO:Uploading model into container now
2025-05-12 22:25:39,656:INFO:_master_model_container: 3
2025-05-12 22:25:39,656:INFO:_display_container: 2
2025-05-12 22:25:39,657:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-05-12 22:25:39,658:INFO:create_model() successfully completed......................................
2025-05-12 22:25:39,793:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:39,793:INFO:Creating metrics dataframe
2025-05-12 22:25:39,801:INFO:Initializing Elastic Net
2025-05-12 22:25:39,801:INFO:Total runtime is 0.023012268543243408 minutes
2025-05-12 22:25:39,804:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:39,804:INFO:Initializing create_model()
2025-05-12 22:25:39,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:39,806:INFO:Checking exceptions
2025-05-12 22:25:39,806:INFO:Importing libraries
2025-05-12 22:25:39,806:INFO:Copying training dataset
2025-05-12 22:25:39,812:INFO:Defining folds
2025-05-12 22:25:39,813:INFO:Declaring metric variables
2025-05-12 22:25:39,817:INFO:Importing untrained model
2025-05-12 22:25:39,824:INFO:Elastic Net Imported successfully
2025-05-12 22:25:39,836:INFO:Starting cross validation
2025-05-12 22:25:39,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:40,115:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:40,115:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:40,122:INFO:Calculating mean and std
2025-05-12 22:25:40,124:INFO:Creating metrics dataframe
2025-05-12 22:25:40,127:INFO:Uploading results into container
2025-05-12 22:25:40,129:INFO:Uploading model into container now
2025-05-12 22:25:40,130:INFO:_master_model_container: 4
2025-05-12 22:25:40,130:INFO:_display_container: 2
2025-05-12 22:25:40,131:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-05-12 22:25:40,131:INFO:create_model() successfully completed......................................
2025-05-12 22:25:40,256:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:40,256:INFO:Creating metrics dataframe
2025-05-12 22:25:40,267:INFO:Initializing Least Angle Regression
2025-05-12 22:25:40,267:INFO:Total runtime is 0.030776119232177733 minutes
2025-05-12 22:25:40,272:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:40,273:INFO:Initializing create_model()
2025-05-12 22:25:40,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:40,273:INFO:Checking exceptions
2025-05-12 22:25:40,273:INFO:Importing libraries
2025-05-12 22:25:40,273:INFO:Copying training dataset
2025-05-12 22:25:40,279:INFO:Defining folds
2025-05-12 22:25:40,280:INFO:Declaring metric variables
2025-05-12 22:25:40,284:INFO:Importing untrained model
2025-05-12 22:25:40,291:INFO:Least Angle Regression Imported successfully
2025-05-12 22:25:40,303:INFO:Starting cross validation
2025-05-12 22:25:40,306:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:40,638:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:40,638:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:40,649:INFO:Calculating mean and std
2025-05-12 22:25:40,650:INFO:Creating metrics dataframe
2025-05-12 22:25:40,653:INFO:Uploading results into container
2025-05-12 22:25:40,654:INFO:Uploading model into container now
2025-05-12 22:25:40,654:INFO:_master_model_container: 5
2025-05-12 22:25:40,654:INFO:_display_container: 2
2025-05-12 22:25:40,656:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-05-12 22:25:40,656:INFO:create_model() successfully completed......................................
2025-05-12 22:25:40,770:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:40,770:INFO:Creating metrics dataframe
2025-05-12 22:25:40,780:INFO:Initializing Lasso Least Angle Regression
2025-05-12 22:25:40,780:INFO:Total runtime is 0.03933552503585815 minutes
2025-05-12 22:25:40,784:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:40,784:INFO:Initializing create_model()
2025-05-12 22:25:40,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:40,785:INFO:Checking exceptions
2025-05-12 22:25:40,785:INFO:Importing libraries
2025-05-12 22:25:40,785:INFO:Copying training dataset
2025-05-12 22:25:40,790:INFO:Defining folds
2025-05-12 22:25:40,791:INFO:Declaring metric variables
2025-05-12 22:25:40,795:INFO:Importing untrained model
2025-05-12 22:25:40,800:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:25:40,809:INFO:Starting cross validation
2025-05-12 22:25:40,811:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:41,045:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:41,045:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:41,056:INFO:Calculating mean and std
2025-05-12 22:25:41,058:INFO:Creating metrics dataframe
2025-05-12 22:25:41,060:INFO:Uploading results into container
2025-05-12 22:25:41,060:INFO:Uploading model into container now
2025-05-12 22:25:41,061:INFO:_master_model_container: 6
2025-05-12 22:25:41,061:INFO:_display_container: 2
2025-05-12 22:25:41,062:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-05-12 22:25:41,062:INFO:create_model() successfully completed......................................
2025-05-12 22:25:41,166:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:41,166:INFO:Creating metrics dataframe
2025-05-12 22:25:41,173:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 22:25:41,174:INFO:Total runtime is 0.04587920904159546 minutes
2025-05-12 22:25:41,178:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:41,178:INFO:Initializing create_model()
2025-05-12 22:25:41,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:41,178:INFO:Checking exceptions
2025-05-12 22:25:41,179:INFO:Importing libraries
2025-05-12 22:25:41,179:INFO:Copying training dataset
2025-05-12 22:25:41,183:INFO:Defining folds
2025-05-12 22:25:41,183:INFO:Declaring metric variables
2025-05-12 22:25:41,186:INFO:Importing untrained model
2025-05-12 22:25:41,191:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 22:25:41,199:INFO:Starting cross validation
2025-05-12 22:25:41,200:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:41,416:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:41,416:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:41,418:INFO:Calculating mean and std
2025-05-12 22:25:41,420:INFO:Creating metrics dataframe
2025-05-12 22:25:41,421:INFO:Uploading results into container
2025-05-12 22:25:41,422:INFO:Uploading model into container now
2025-05-12 22:25:41,423:INFO:_master_model_container: 7
2025-05-12 22:25:41,423:INFO:_display_container: 2
2025-05-12 22:25:41,423:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-05-12 22:25:41,423:INFO:create_model() successfully completed......................................
2025-05-12 22:25:41,526:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:41,527:INFO:Creating metrics dataframe
2025-05-12 22:25:41,535:INFO:Initializing Bayesian Ridge
2025-05-12 22:25:41,536:INFO:Total runtime is 0.05192452669143677 minutes
2025-05-12 22:25:41,540:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:41,541:INFO:Initializing create_model()
2025-05-12 22:25:41,541:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:41,541:INFO:Checking exceptions
2025-05-12 22:25:41,541:INFO:Importing libraries
2025-05-12 22:25:41,541:INFO:Copying training dataset
2025-05-12 22:25:41,546:INFO:Defining folds
2025-05-12 22:25:41,546:INFO:Declaring metric variables
2025-05-12 22:25:41,550:INFO:Importing untrained model
2025-05-12 22:25:41,555:INFO:Bayesian Ridge Imported successfully
2025-05-12 22:25:41,563:INFO:Starting cross validation
2025-05-12 22:25:41,565:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:41,817:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:41,817:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:41,826:INFO:Calculating mean and std
2025-05-12 22:25:41,827:INFO:Creating metrics dataframe
2025-05-12 22:25:41,829:INFO:Uploading results into container
2025-05-12 22:25:41,830:INFO:Uploading model into container now
2025-05-12 22:25:41,830:INFO:_master_model_container: 8
2025-05-12 22:25:41,830:INFO:_display_container: 2
2025-05-12 22:25:41,831:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-05-12 22:25:41,831:INFO:create_model() successfully completed......................................
2025-05-12 22:25:41,934:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:41,934:INFO:Creating metrics dataframe
2025-05-12 22:25:41,943:INFO:Initializing Passive Aggressive Regressor
2025-05-12 22:25:41,943:INFO:Total runtime is 0.05871344407399495 minutes
2025-05-12 22:25:41,947:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:41,948:INFO:Initializing create_model()
2025-05-12 22:25:41,948:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:41,948:INFO:Checking exceptions
2025-05-12 22:25:41,948:INFO:Importing libraries
2025-05-12 22:25:41,948:INFO:Copying training dataset
2025-05-12 22:25:41,953:INFO:Defining folds
2025-05-12 22:25:41,953:INFO:Declaring metric variables
2025-05-12 22:25:41,958:INFO:Importing untrained model
2025-05-12 22:25:41,963:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 22:25:41,970:INFO:Starting cross validation
2025-05-12 22:25:41,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:42,196:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:42,196:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:42,203:INFO:Calculating mean and std
2025-05-12 22:25:42,204:INFO:Creating metrics dataframe
2025-05-12 22:25:42,206:INFO:Uploading results into container
2025-05-12 22:25:42,207:INFO:Uploading model into container now
2025-05-12 22:25:42,207:INFO:_master_model_container: 9
2025-05-12 22:25:42,207:INFO:_display_container: 2
2025-05-12 22:25:42,207:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-12 22:25:42,208:INFO:create_model() successfully completed......................................
2025-05-12 22:25:42,323:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:42,323:INFO:Creating metrics dataframe
2025-05-12 22:25:42,331:INFO:Initializing Huber Regressor
2025-05-12 22:25:42,331:INFO:Total runtime is 0.0651872436205546 minutes
2025-05-12 22:25:42,336:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:42,336:INFO:Initializing create_model()
2025-05-12 22:25:42,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:42,336:INFO:Checking exceptions
2025-05-12 22:25:42,337:INFO:Importing libraries
2025-05-12 22:25:42,337:INFO:Copying training dataset
2025-05-12 22:25:42,343:INFO:Defining folds
2025-05-12 22:25:42,343:INFO:Declaring metric variables
2025-05-12 22:25:42,346:INFO:Importing untrained model
2025-05-12 22:25:42,349:INFO:Huber Regressor Imported successfully
2025-05-12 22:25:42,358:INFO:Starting cross validation
2025-05-12 22:25:42,361:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:42,890:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:42,890:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:42,897:INFO:Calculating mean and std
2025-05-12 22:25:42,899:INFO:Creating metrics dataframe
2025-05-12 22:25:42,901:INFO:Uploading results into container
2025-05-12 22:25:42,902:INFO:Uploading model into container now
2025-05-12 22:25:42,903:INFO:_master_model_container: 10
2025-05-12 22:25:42,903:INFO:_display_container: 2
2025-05-12 22:25:42,904:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-05-12 22:25:42,904:INFO:create_model() successfully completed......................................
2025-05-12 22:25:43,032:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:43,032:INFO:Creating metrics dataframe
2025-05-12 22:25:43,043:INFO:Initializing K Neighbors Regressor
2025-05-12 22:25:43,043:INFO:Total runtime is 0.07705143292744954 minutes
2025-05-12 22:25:43,047:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:43,048:INFO:Initializing create_model()
2025-05-12 22:25:43,048:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:43,049:INFO:Checking exceptions
2025-05-12 22:25:43,049:INFO:Importing libraries
2025-05-12 22:25:43,049:INFO:Copying training dataset
2025-05-12 22:25:43,057:INFO:Defining folds
2025-05-12 22:25:43,058:INFO:Declaring metric variables
2025-05-12 22:25:43,065:INFO:Importing untrained model
2025-05-12 22:25:43,071:INFO:K Neighbors Regressor Imported successfully
2025-05-12 22:25:43,083:INFO:Starting cross validation
2025-05-12 22:25:43,084:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:43,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:43,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:43,407:INFO:Calculating mean and std
2025-05-12 22:25:43,409:INFO:Creating metrics dataframe
2025-05-12 22:25:43,410:INFO:Uploading results into container
2025-05-12 22:25:43,411:INFO:Uploading model into container now
2025-05-12 22:25:43,411:INFO:_master_model_container: 11
2025-05-12 22:25:43,411:INFO:_display_container: 2
2025-05-12 22:25:43,412:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-05-12 22:25:43,412:INFO:create_model() successfully completed......................................
2025-05-12 22:25:43,515:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:43,515:INFO:Creating metrics dataframe
2025-05-12 22:25:43,526:INFO:Initializing Decision Tree Regressor
2025-05-12 22:25:43,527:INFO:Total runtime is 0.08510981003443399 minutes
2025-05-12 22:25:43,530:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:43,531:INFO:Initializing create_model()
2025-05-12 22:25:43,531:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:43,531:INFO:Checking exceptions
2025-05-12 22:25:43,531:INFO:Importing libraries
2025-05-12 22:25:43,531:INFO:Copying training dataset
2025-05-12 22:25:43,537:INFO:Defining folds
2025-05-12 22:25:43,537:INFO:Declaring metric variables
2025-05-12 22:25:43,541:INFO:Importing untrained model
2025-05-12 22:25:43,546:INFO:Decision Tree Regressor Imported successfully
2025-05-12 22:25:43,557:INFO:Starting cross validation
2025-05-12 22:25:43,559:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:43,859:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:43,859:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:43,870:INFO:Calculating mean and std
2025-05-12 22:25:43,871:INFO:Creating metrics dataframe
2025-05-12 22:25:43,874:INFO:Uploading results into container
2025-05-12 22:25:43,875:INFO:Uploading model into container now
2025-05-12 22:25:43,875:INFO:_master_model_container: 12
2025-05-12 22:25:43,876:INFO:_display_container: 2
2025-05-12 22:25:43,876:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-05-12 22:25:43,877:INFO:create_model() successfully completed......................................
2025-05-12 22:25:43,993:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:43,993:INFO:Creating metrics dataframe
2025-05-12 22:25:44,003:INFO:Initializing Random Forest Regressor
2025-05-12 22:25:44,003:INFO:Total runtime is 0.09304766257603962 minutes
2025-05-12 22:25:44,007:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:44,008:INFO:Initializing create_model()
2025-05-12 22:25:44,008:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:44,008:INFO:Checking exceptions
2025-05-12 22:25:44,008:INFO:Importing libraries
2025-05-12 22:25:44,008:INFO:Copying training dataset
2025-05-12 22:25:44,014:INFO:Defining folds
2025-05-12 22:25:44,014:INFO:Declaring metric variables
2025-05-12 22:25:44,020:INFO:Importing untrained model
2025-05-12 22:25:44,026:INFO:Random Forest Regressor Imported successfully
2025-05-12 22:25:44,036:INFO:Starting cross validation
2025-05-12 22:25:44,038:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:44,989:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:44,989:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:44,997:INFO:Calculating mean and std
2025-05-12 22:25:44,998:INFO:Creating metrics dataframe
2025-05-12 22:25:44,999:INFO:Uploading results into container
2025-05-12 22:25:45,000:INFO:Uploading model into container now
2025-05-12 22:25:45,001:INFO:_master_model_container: 13
2025-05-12 22:25:45,001:INFO:_display_container: 2
2025-05-12 22:25:45,001:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-05-12 22:25:45,003:INFO:create_model() successfully completed......................................
2025-05-12 22:25:45,106:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:45,107:INFO:Creating metrics dataframe
2025-05-12 22:25:45,117:INFO:Initializing Extra Trees Regressor
2025-05-12 22:25:45,117:INFO:Total runtime is 0.11161555846532184 minutes
2025-05-12 22:25:45,123:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:45,123:INFO:Initializing create_model()
2025-05-12 22:25:45,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:45,124:INFO:Checking exceptions
2025-05-12 22:25:45,124:INFO:Importing libraries
2025-05-12 22:25:45,124:INFO:Copying training dataset
2025-05-12 22:25:45,128:INFO:Defining folds
2025-05-12 22:25:45,128:INFO:Declaring metric variables
2025-05-12 22:25:45,131:INFO:Importing untrained model
2025-05-12 22:25:45,137:INFO:Extra Trees Regressor Imported successfully
2025-05-12 22:25:45,147:INFO:Starting cross validation
2025-05-12 22:25:45,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:46,013:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:46,014:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:46,015:INFO:Calculating mean and std
2025-05-12 22:25:46,016:INFO:Creating metrics dataframe
2025-05-12 22:25:46,017:INFO:Uploading results into container
2025-05-12 22:25:46,019:INFO:Uploading model into container now
2025-05-12 22:25:46,020:INFO:_master_model_container: 14
2025-05-12 22:25:46,020:INFO:_display_container: 2
2025-05-12 22:25:46,021:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-05-12 22:25:46,021:INFO:create_model() successfully completed......................................
2025-05-12 22:25:46,129:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:46,130:INFO:Creating metrics dataframe
2025-05-12 22:25:46,141:INFO:Initializing AdaBoost Regressor
2025-05-12 22:25:46,143:INFO:Total runtime is 0.1287141720453898 minutes
2025-05-12 22:25:46,148:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:46,149:INFO:Initializing create_model()
2025-05-12 22:25:46,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:46,149:INFO:Checking exceptions
2025-05-12 22:25:46,149:INFO:Importing libraries
2025-05-12 22:25:46,149:INFO:Copying training dataset
2025-05-12 22:25:46,155:INFO:Defining folds
2025-05-12 22:25:46,155:INFO:Declaring metric variables
2025-05-12 22:25:46,159:INFO:Importing untrained model
2025-05-12 22:25:46,164:INFO:AdaBoost Regressor Imported successfully
2025-05-12 22:25:46,172:INFO:Starting cross validation
2025-05-12 22:25:46,175:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:46,818:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:46,818:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:46,825:INFO:Calculating mean and std
2025-05-12 22:25:46,827:INFO:Creating metrics dataframe
2025-05-12 22:25:46,829:INFO:Uploading results into container
2025-05-12 22:25:46,829:INFO:Uploading model into container now
2025-05-12 22:25:46,830:INFO:_master_model_container: 15
2025-05-12 22:25:46,830:INFO:_display_container: 2
2025-05-12 22:25:46,830:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-05-12 22:25:46,830:INFO:create_model() successfully completed......................................
2025-05-12 22:25:46,941:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:46,941:INFO:Creating metrics dataframe
2025-05-12 22:25:46,953:INFO:Initializing Gradient Boosting Regressor
2025-05-12 22:25:46,953:INFO:Total runtime is 0.1422084371248881 minutes
2025-05-12 22:25:46,957:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:46,957:INFO:Initializing create_model()
2025-05-12 22:25:46,957:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:46,957:INFO:Checking exceptions
2025-05-12 22:25:46,957:INFO:Importing libraries
2025-05-12 22:25:46,958:INFO:Copying training dataset
2025-05-12 22:25:46,962:INFO:Defining folds
2025-05-12 22:25:46,962:INFO:Declaring metric variables
2025-05-12 22:25:46,965:INFO:Importing untrained model
2025-05-12 22:25:46,971:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 22:25:46,979:INFO:Starting cross validation
2025-05-12 22:25:46,981:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:47,441:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:47,441:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:47,445:INFO:Calculating mean and std
2025-05-12 22:25:47,446:INFO:Creating metrics dataframe
2025-05-12 22:25:47,447:INFO:Uploading results into container
2025-05-12 22:25:47,449:INFO:Uploading model into container now
2025-05-12 22:25:47,450:INFO:_master_model_container: 16
2025-05-12 22:25:47,450:INFO:_display_container: 2
2025-05-12 22:25:47,451:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-12 22:25:47,451:INFO:create_model() successfully completed......................................
2025-05-12 22:25:47,551:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:47,551:INFO:Creating metrics dataframe
2025-05-12 22:25:47,563:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:25:47,563:INFO:Total runtime is 0.15237617095311481 minutes
2025-05-12 22:25:47,567:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:47,568:INFO:Initializing create_model()
2025-05-12 22:25:47,568:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:47,568:INFO:Checking exceptions
2025-05-12 22:25:47,568:INFO:Importing libraries
2025-05-12 22:25:47,568:INFO:Copying training dataset
2025-05-12 22:25:47,573:INFO:Defining folds
2025-05-12 22:25:47,573:INFO:Declaring metric variables
2025-05-12 22:25:47,577:INFO:Importing untrained model
2025-05-12 22:25:47,583:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:25:47,608:INFO:Starting cross validation
2025-05-12 22:25:47,610:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:48,302:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:48,303:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:48,313:INFO:Calculating mean and std
2025-05-12 22:25:48,317:INFO:Creating metrics dataframe
2025-05-12 22:25:48,321:INFO:Uploading results into container
2025-05-12 22:25:48,323:INFO:Uploading model into container now
2025-05-12 22:25:48,324:INFO:_master_model_container: 17
2025-05-12 22:25:48,324:INFO:_display_container: 2
2025-05-12 22:25:48,325:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:25:48,326:INFO:create_model() successfully completed......................................
2025-05-12 22:25:48,467:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:48,467:INFO:Creating metrics dataframe
2025-05-12 22:25:48,481:INFO:Initializing Dummy Regressor
2025-05-12 22:25:48,481:INFO:Total runtime is 0.16768298546473184 minutes
2025-05-12 22:25:48,486:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:48,487:INFO:Initializing create_model()
2025-05-12 22:25:48,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:48,487:INFO:Checking exceptions
2025-05-12 22:25:48,487:INFO:Importing libraries
2025-05-12 22:25:48,487:INFO:Copying training dataset
2025-05-12 22:25:48,492:INFO:Defining folds
2025-05-12 22:25:48,492:INFO:Declaring metric variables
2025-05-12 22:25:48,496:INFO:Importing untrained model
2025-05-12 22:25:48,501:INFO:Dummy Regressor Imported successfully
2025-05-12 22:25:48,513:INFO:Starting cross validation
2025-05-12 22:25:48,517:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:48,749:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:48,750:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:48,764:INFO:Calculating mean and std
2025-05-12 22:25:48,766:INFO:Creating metrics dataframe
2025-05-12 22:25:48,768:INFO:Uploading results into container
2025-05-12 22:25:48,769:INFO:Uploading model into container now
2025-05-12 22:25:48,770:INFO:_master_model_container: 18
2025-05-12 22:25:48,770:INFO:_display_container: 2
2025-05-12 22:25:48,770:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-05-12 22:25:48,771:INFO:create_model() successfully completed......................................
2025-05-12 22:25:48,874:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:48,874:INFO:Creating metrics dataframe
2025-05-12 22:25:48,884:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:25:48,894:INFO:Initializing create_model()
2025-05-12 22:25:48,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:48,894:INFO:Checking exceptions
2025-05-12 22:25:48,896:INFO:Importing libraries
2025-05-12 22:25:48,896:INFO:Copying training dataset
2025-05-12 22:25:48,899:INFO:Defining folds
2025-05-12 22:25:48,899:INFO:Declaring metric variables
2025-05-12 22:25:48,899:INFO:Importing untrained model
2025-05-12 22:25:48,900:INFO:Declaring custom model
2025-05-12 22:25:48,900:INFO:Lasso Regression Imported successfully
2025-05-12 22:25:48,901:INFO:Cross validation set to False
2025-05-12 22:25:48,901:INFO:Fitting Model
2025-05-12 22:25:48,948:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-05-12 22:25:48,948:INFO:create_model() successfully completed......................................
2025-05-12 22:25:49,129:INFO:_master_model_container: 18
2025-05-12 22:25:49,129:INFO:_display_container: 2
2025-05-12 22:25:49,129:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-05-12 22:25:49,129:INFO:compare_models() successfully completed......................................
2025-05-12 22:25:49,149:INFO:Initializing create_model()
2025-05-12 22:25:49,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=lar, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:49,149:INFO:Checking exceptions
2025-05-12 22:25:49,169:INFO:Importing libraries
2025-05-12 22:25:49,169:INFO:Copying training dataset
2025-05-12 22:25:49,175:INFO:Defining folds
2025-05-12 22:25:49,177:INFO:Declaring metric variables
2025-05-12 22:25:49,182:INFO:Importing untrained model
2025-05-12 22:25:49,187:INFO:Least Angle Regression Imported successfully
2025-05-12 22:25:49,196:INFO:Starting cross validation
2025-05-12 22:25:49,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:49,581:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:49,581:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:49,589:INFO:Calculating mean and std
2025-05-12 22:25:49,589:INFO:Creating metrics dataframe
2025-05-12 22:25:49,595:INFO:Finalizing model
2025-05-12 22:25:49,653:INFO:Uploading results into container
2025-05-12 22:25:49,654:INFO:Uploading model into container now
2025-05-12 22:25:49,666:INFO:_master_model_container: 19
2025-05-12 22:25:49,666:INFO:_display_container: 3
2025-05-12 22:25:49,666:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-05-12 22:25:49,666:INFO:create_model() successfully completed......................................
2025-05-12 22:25:49,800:INFO:Initializing tune_model()
2025-05-12 22:25:49,801:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:25:49,801:INFO:Checking exceptions
2025-05-12 22:25:49,823:INFO:Copying training dataset
2025-05-12 22:25:49,828:INFO:Checking base model
2025-05-12 22:25:49,829:INFO:Base model : Least Angle Regression
2025-05-12 22:25:49,836:INFO:Declaring metric variables
2025-05-12 22:25:49,841:INFO:Defining Hyperparameters
2025-05-12 22:25:49,980:INFO:Tuning with n_jobs=-1
2025-05-12 22:25:49,980:INFO:Initializing RandomizedSearchCV
2025-05-12 22:25:52,355:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__eps': 1e-05}
2025-05-12 22:25:52,356:INFO:Hyperparameter search completed
2025-05-12 22:25:52,356:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:52,357:INFO:Initializing create_model()
2025-05-12 22:25:52,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7EB1F290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'eps': 1e-05})
2025-05-12 22:25:52,357:INFO:Checking exceptions
2025-05-12 22:25:52,357:INFO:Importing libraries
2025-05-12 22:25:52,358:INFO:Copying training dataset
2025-05-12 22:25:52,363:INFO:Defining folds
2025-05-12 22:25:52,363:INFO:Declaring metric variables
2025-05-12 22:25:52,370:INFO:Importing untrained model
2025-05-12 22:25:52,370:INFO:Declaring custom model
2025-05-12 22:25:52,376:INFO:Least Angle Regression Imported successfully
2025-05-12 22:25:52,389:INFO:Starting cross validation
2025-05-12 22:25:52,393:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:52,800:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:52,800:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:52,809:INFO:Calculating mean and std
2025-05-12 22:25:52,813:INFO:Creating metrics dataframe
2025-05-12 22:25:52,823:INFO:Finalizing model
2025-05-12 22:25:52,890:INFO:Uploading results into container
2025-05-12 22:25:52,891:INFO:Uploading model into container now
2025-05-12 22:25:52,892:INFO:_master_model_container: 20
2025-05-12 22:25:52,892:INFO:_display_container: 4
2025-05-12 22:25:52,892:INFO:Lars(copy_X=True, eps=1e-05, fit_intercept=True, fit_path=True, jitter=None,
     n_nonzero_coefs=500, precompute='auto', random_state=123, verbose=False)
2025-05-12 22:25:52,892:INFO:create_model() successfully completed......................................
2025-05-12 22:25:53,008:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:53,008:INFO:choose_better activated
2025-05-12 22:25:53,013:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:53,014:INFO:Initializing create_model()
2025-05-12 22:25:53,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:53,015:INFO:Checking exceptions
2025-05-12 22:25:53,017:INFO:Importing libraries
2025-05-12 22:25:53,017:INFO:Copying training dataset
2025-05-12 22:25:53,021:INFO:Defining folds
2025-05-12 22:25:53,021:INFO:Declaring metric variables
2025-05-12 22:25:53,021:INFO:Importing untrained model
2025-05-12 22:25:53,021:INFO:Declaring custom model
2025-05-12 22:25:53,021:INFO:Least Angle Regression Imported successfully
2025-05-12 22:25:53,022:INFO:Starting cross validation
2025-05-12 22:25:53,023:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:53,320:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:53,320:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:53,326:INFO:Calculating mean and std
2025-05-12 22:25:53,327:INFO:Creating metrics dataframe
2025-05-12 22:25:53,330:INFO:Finalizing model
2025-05-12 22:25:53,389:INFO:Uploading results into container
2025-05-12 22:25:53,389:INFO:Uploading model into container now
2025-05-12 22:25:53,390:INFO:_master_model_container: 21
2025-05-12 22:25:53,390:INFO:_display_container: 5
2025-05-12 22:25:53,390:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-05-12 22:25:53,390:INFO:create_model() successfully completed......................................
2025-05-12 22:25:53,503:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:53,504:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False) result for R2 is -0.1521
2025-05-12 22:25:53,504:INFO:Lars(copy_X=True, eps=1e-05, fit_intercept=True, fit_path=True, jitter=None,
     n_nonzero_coefs=500, precompute='auto', random_state=123, verbose=False) result for R2 is -0.1521
2025-05-12 22:25:53,504:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False) is best model
2025-05-12 22:25:53,504:INFO:choose_better completed
2025-05-12 22:25:53,505:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:25:53,517:INFO:_master_model_container: 21
2025-05-12 22:25:53,517:INFO:_display_container: 4
2025-05-12 22:25:53,519:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-05-12 22:25:53,519:INFO:tune_model() successfully completed......................................
2025-05-12 22:25:53,641:INFO:Initializing evaluate_model()
2025-05-12 22:25:53,642:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:25:53,654:INFO:Initializing plot_model()
2025-05-12 22:25:53,654:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:25:53,654:INFO:Checking exceptions
2025-05-12 22:25:53,658:INFO:Preloading libraries
2025-05-12 22:25:53,658:INFO:Copying training dataset
2025-05-12 22:25:53,658:INFO:Plot type: pipeline
2025-05-12 22:25:53,771:INFO:Visual Rendered Successfully
2025-05-12 22:25:53,872:INFO:plot_model() successfully completed......................................
2025-05-12 22:25:53,889:INFO:Initializing predict_model()
2025-05-12 22:25:53,889:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EA7AE1FC40>)
2025-05-12 22:25:53,890:INFO:Checking exceptions
2025-05-12 22:25:53,890:INFO:Preloading libraries
2025-05-12 22:25:53,986:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:25:54,106:INFO:Initializing save_model()
2025-05-12 22:25:54,106:INFO:save_model(model=Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-12 22:25:54,106:INFO:Adding model into prep_pipe
2025-05-12 22:25:54,117:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:25:54,123:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 Lars(copy_X=True, eps=2.220446049250313e-16,
                      fit_intercept=True, fit_path=True, jitter=None,
                      n_nonzero_coefs=500, precompute='auto', random_state=123,
                      verbose=False))],
         verbose=False)
2025-05-12 22:25:54,123:INFO:save_model() successfully completed......................................
2025-05-12 22:27:07,904:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:27:07,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:27:07,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:27:07,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:27:08,623:INFO:PyCaret ClassificationExperiment
2025-05-12 22:27:08,623:INFO:Logging name: clf-default-name
2025-05-12 22:27:08,623:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-12 22:27:08,623:INFO:version 3.3.2
2025-05-12 22:27:08,624:INFO:Initializing setup()
2025-05-12 22:27:08,624:INFO:self.USI: 7ca3
2025-05-12 22:27:08,624:INFO:self._variable_keys: {'fold_groups_param', 'memory', 'n_jobs_param', 'fold_generator', 'X', 'seed', '_available_plots', '_ml_usecase', 'y_train', 'html_param', 'logging_param', 'target_param', 'idx', 'log_plots_param', 'pipeline', 'fix_imbalance', 'gpu_n_jobs_param', 'y_test', 'exp_id', 'y', 'is_multiclass', 'data', 'gpu_param', 'X_train', 'USI', 'exp_name_log', 'fold_shuffle_param', 'X_test'}
2025-05-12 22:27:08,624:INFO:Checking environment
2025-05-12 22:27:08,624:INFO:python_version: 3.11.8
2025-05-12 22:27:08,624:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:27:08,624:INFO:machine: AMD64
2025-05-12 22:27:08,624:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:27:08,630:INFO:Memory: svmem(total=16907886592, available=2697539584, percent=84.0, used=14210347008, free=2697539584)
2025-05-12 22:27:08,630:INFO:Physical Core: 4
2025-05-12 22:27:08,631:INFO:Logical Core: 8
2025-05-12 22:27:08,631:INFO:Checking libraries
2025-05-12 22:27:08,631:INFO:System:
2025-05-12 22:27:08,631:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:27:08,631:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:27:08,631:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:27:08,631:INFO:PyCaret required dependencies:
2025-05-12 22:27:08,667:INFO:                 pip: 24.0
2025-05-12 22:27:08,667:INFO:          setuptools: 65.5.0
2025-05-12 22:27:08,667:INFO:             pycaret: 3.3.2
2025-05-12 22:27:08,668:INFO:             IPython: 9.2.0
2025-05-12 22:27:08,668:INFO:          ipywidgets: 8.1.7
2025-05-12 22:27:08,668:INFO:                tqdm: 4.67.1
2025-05-12 22:27:08,668:INFO:               numpy: 1.26.4
2025-05-12 22:27:08,668:INFO:              pandas: 2.1.4
2025-05-12 22:27:08,668:INFO:              jinja2: 3.1.6
2025-05-12 22:27:08,668:INFO:               scipy: 1.11.4
2025-05-12 22:27:08,668:INFO:              joblib: 1.3.2
2025-05-12 22:27:08,668:INFO:             sklearn: 1.4.2
2025-05-12 22:27:08,668:INFO:                pyod: 2.0.5
2025-05-12 22:27:08,668:INFO:            imblearn: 0.13.0
2025-05-12 22:27:08,668:INFO:   category_encoders: 2.7.0
2025-05-12 22:27:08,668:INFO:            lightgbm: 4.6.0
2025-05-12 22:27:08,668:INFO:               numba: 0.61.2
2025-05-12 22:27:08,668:INFO:            requests: 2.32.3
2025-05-12 22:27:08,668:INFO:          matplotlib: 3.7.5
2025-05-12 22:27:08,668:INFO:          scikitplot: 0.3.7
2025-05-12 22:27:08,668:INFO:         yellowbrick: 1.5
2025-05-12 22:27:08,668:INFO:              plotly: 5.24.1
2025-05-12 22:27:08,668:INFO:    plotly-resampler: Not installed
2025-05-12 22:27:08,668:INFO:             kaleido: 0.2.1
2025-05-12 22:27:08,668:INFO:           schemdraw: 0.15
2025-05-12 22:27:08,668:INFO:         statsmodels: 0.14.4
2025-05-12 22:27:08,669:INFO:              sktime: 0.26.0
2025-05-12 22:27:08,669:INFO:               tbats: 1.1.3
2025-05-12 22:27:08,669:INFO:            pmdarima: 2.0.4
2025-05-12 22:27:08,669:INFO:              psutil: 7.0.0
2025-05-12 22:27:08,669:INFO:          markupsafe: 3.0.2
2025-05-12 22:27:08,669:INFO:             pickle5: Not installed
2025-05-12 22:27:08,669:INFO:         cloudpickle: 3.1.1
2025-05-12 22:27:08,669:INFO:         deprecation: 2.1.0
2025-05-12 22:27:08,669:INFO:              xxhash: 3.5.0
2025-05-12 22:27:08,669:INFO:           wurlitzer: Not installed
2025-05-12 22:27:08,669:INFO:PyCaret optional dependencies:
2025-05-12 22:27:08,683:INFO:                shap: Not installed
2025-05-12 22:27:08,683:INFO:           interpret: Not installed
2025-05-12 22:27:08,683:INFO:                umap: Not installed
2025-05-12 22:27:08,683:INFO:     ydata_profiling: Not installed
2025-05-12 22:27:08,683:INFO:  explainerdashboard: Not installed
2025-05-12 22:27:08,683:INFO:             autoviz: Not installed
2025-05-12 22:27:08,683:INFO:           fairlearn: Not installed
2025-05-12 22:27:08,683:INFO:          deepchecks: Not installed
2025-05-12 22:27:08,683:INFO:             xgboost: Not installed
2025-05-12 22:27:08,683:INFO:            catboost: Not installed
2025-05-12 22:27:08,683:INFO:              kmodes: Not installed
2025-05-12 22:27:08,684:INFO:             mlxtend: Not installed
2025-05-12 22:27:08,684:INFO:       statsforecast: Not installed
2025-05-12 22:27:08,684:INFO:        tune_sklearn: Not installed
2025-05-12 22:27:08,684:INFO:                 ray: Not installed
2025-05-12 22:27:08,684:INFO:            hyperopt: Not installed
2025-05-12 22:27:08,684:INFO:              optuna: Not installed
2025-05-12 22:27:08,684:INFO:               skopt: Not installed
2025-05-12 22:27:08,684:INFO:              mlflow: Not installed
2025-05-12 22:27:08,684:INFO:              gradio: Not installed
2025-05-12 22:27:08,684:INFO:             fastapi: Not installed
2025-05-12 22:27:08,684:INFO:             uvicorn: Not installed
2025-05-12 22:27:08,684:INFO:              m2cgen: Not installed
2025-05-12 22:27:08,684:INFO:           evidently: Not installed
2025-05-12 22:27:08,684:INFO:               fugue: Not installed
2025-05-12 22:27:08,684:INFO:           streamlit: Not installed
2025-05-12 22:27:08,684:INFO:             prophet: Not installed
2025-05-12 22:27:08,684:INFO:None
2025-05-12 22:27:08,684:INFO:Set up data.
2025-05-12 22:27:08,691:INFO:Set up folding strategy.
2025-05-12 22:27:08,691:INFO:Set up train/test split.
2025-05-12 22:27:08,699:INFO:Set up index.
2025-05-12 22:27:08,699:INFO:Assigning column types.
2025-05-12 22:27:08,703:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:27:08,762:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:27:08,766:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:08,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:08,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:08,874:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:27:08,876:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:08,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:08,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:08,913:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:27:08,968:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:09,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,056:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:09,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,090:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-12 22:27:09,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,260:INFO:Preparing preprocessing pipeline...
2025-05-12 22:27:09,261:INFO:Set up simple imputation.
2025-05-12 22:27:09,263:INFO:Set up encoding of categorical features.
2025-05-12 22:27:09,263:INFO:Set up feature normalization.
2025-05-12 22:27:09,334:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:27:09,342:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:27:09,342:INFO:Creating final display dataframe.
2025-05-12 22:27:09,511:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              7ca3
2025-05-12 22:27:09,600:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,714:INFO:setup() successfully completed in 1.09s...............
2025-05-12 22:27:09,727:INFO:Initializing compare_models()
2025-05-12 22:27:09,728:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-12 22:27:09,728:INFO:Checking exceptions
2025-05-12 22:27:09,733:INFO:Preparing display monitor
2025-05-12 22:27:09,768:INFO:Initializing Logistic Regression
2025-05-12 22:27:09,768:INFO:Total runtime is 0.0 minutes
2025-05-12 22:27:09,775:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:09,776:INFO:Initializing create_model()
2025-05-12 22:27:09,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:09,776:INFO:Checking exceptions
2025-05-12 22:27:09,776:INFO:Importing libraries
2025-05-12 22:27:09,777:INFO:Copying training dataset
2025-05-12 22:27:09,783:INFO:Defining folds
2025-05-12 22:27:09,783:INFO:Declaring metric variables
2025-05-12 22:27:09,789:INFO:Importing untrained model
2025-05-12 22:27:09,796:INFO:Logistic Regression Imported successfully
2025-05-12 22:27:09,808:INFO:Starting cross validation
2025-05-12 22:27:09,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:19,048:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,069:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,219:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,267:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,362:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,447:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,558:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,588:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,714:INFO:Calculating mean and std
2025-05-12 22:27:19,716:INFO:Creating metrics dataframe
2025-05-12 22:27:19,719:INFO:Uploading results into container
2025-05-12 22:27:19,720:INFO:Uploading model into container now
2025-05-12 22:27:19,721:INFO:_master_model_container: 1
2025-05-12 22:27:19,721:INFO:_display_container: 2
2025-05-12 22:27:19,723:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-12 22:27:19,723:INFO:create_model() successfully completed......................................
2025-05-12 22:27:19,817:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:19,817:INFO:Creating metrics dataframe
2025-05-12 22:27:19,825:INFO:Initializing K Neighbors Classifier
2025-05-12 22:27:19,826:INFO:Total runtime is 0.1676392396291097 minutes
2025-05-12 22:27:19,831:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:19,831:INFO:Initializing create_model()
2025-05-12 22:27:19,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:19,832:INFO:Checking exceptions
2025-05-12 22:27:19,832:INFO:Importing libraries
2025-05-12 22:27:19,832:INFO:Copying training dataset
2025-05-12 22:27:19,839:INFO:Defining folds
2025-05-12 22:27:19,839:INFO:Declaring metric variables
2025-05-12 22:27:19,846:INFO:Importing untrained model
2025-05-12 22:27:19,852:INFO:K Neighbors Classifier Imported successfully
2025-05-12 22:27:19,863:INFO:Starting cross validation
2025-05-12 22:27:19,866:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:20,116:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,154:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,183:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,187:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,211:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,319:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,330:INFO:Calculating mean and std
2025-05-12 22:27:20,333:INFO:Creating metrics dataframe
2025-05-12 22:27:20,336:INFO:Uploading results into container
2025-05-12 22:27:20,337:INFO:Uploading model into container now
2025-05-12 22:27:20,337:INFO:_master_model_container: 2
2025-05-12 22:27:20,337:INFO:_display_container: 2
2025-05-12 22:27:20,339:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-12 22:27:20,339:INFO:create_model() successfully completed......................................
2025-05-12 22:27:20,423:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:20,423:INFO:Creating metrics dataframe
2025-05-12 22:27:20,436:INFO:Initializing Naive Bayes
2025-05-12 22:27:20,436:INFO:Total runtime is 0.17779157956441244 minutes
2025-05-12 22:27:20,443:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:20,443:INFO:Initializing create_model()
2025-05-12 22:27:20,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:20,443:INFO:Checking exceptions
2025-05-12 22:27:20,443:INFO:Importing libraries
2025-05-12 22:27:20,443:INFO:Copying training dataset
2025-05-12 22:27:20,448:INFO:Defining folds
2025-05-12 22:27:20,449:INFO:Declaring metric variables
2025-05-12 22:27:20,453:INFO:Importing untrained model
2025-05-12 22:27:20,460:INFO:Naive Bayes Imported successfully
2025-05-12 22:27:20,469:INFO:Starting cross validation
2025-05-12 22:27:20,472:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:20,673:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,676:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,684:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,819:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,830:INFO:Calculating mean and std
2025-05-12 22:27:20,831:INFO:Creating metrics dataframe
2025-05-12 22:27:20,835:INFO:Uploading results into container
2025-05-12 22:27:20,835:INFO:Uploading model into container now
2025-05-12 22:27:20,836:INFO:_master_model_container: 3
2025-05-12 22:27:20,836:INFO:_display_container: 2
2025-05-12 22:27:20,836:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-12 22:27:20,836:INFO:create_model() successfully completed......................................
2025-05-12 22:27:20,929:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:20,929:INFO:Creating metrics dataframe
2025-05-12 22:27:20,938:INFO:Initializing Decision Tree Classifier
2025-05-12 22:27:20,938:INFO:Total runtime is 0.18616087039311727 minutes
2025-05-12 22:27:20,944:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:20,945:INFO:Initializing create_model()
2025-05-12 22:27:20,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:20,946:INFO:Checking exceptions
2025-05-12 22:27:20,946:INFO:Importing libraries
2025-05-12 22:27:20,946:INFO:Copying training dataset
2025-05-12 22:27:20,953:INFO:Defining folds
2025-05-12 22:27:20,953:INFO:Declaring metric variables
2025-05-12 22:27:20,959:INFO:Importing untrained model
2025-05-12 22:27:20,967:INFO:Decision Tree Classifier Imported successfully
2025-05-12 22:27:20,979:INFO:Starting cross validation
2025-05-12 22:27:20,982:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:21,208:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:21,306:INFO:Calculating mean and std
2025-05-12 22:27:21,309:INFO:Creating metrics dataframe
2025-05-12 22:27:21,313:INFO:Uploading results into container
2025-05-12 22:27:21,314:INFO:Uploading model into container now
2025-05-12 22:27:21,314:INFO:_master_model_container: 4
2025-05-12 22:27:21,314:INFO:_display_container: 2
2025-05-12 22:27:21,315:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-12 22:27:21,315:INFO:create_model() successfully completed......................................
2025-05-12 22:27:21,406:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:21,407:INFO:Creating metrics dataframe
2025-05-12 22:27:21,416:INFO:Initializing SVM - Linear Kernel
2025-05-12 22:27:21,417:INFO:Total runtime is 0.19414552847544353 minutes
2025-05-12 22:27:21,421:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:21,421:INFO:Initializing create_model()
2025-05-12 22:27:21,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:21,421:INFO:Checking exceptions
2025-05-12 22:27:21,421:INFO:Importing libraries
2025-05-12 22:27:21,421:INFO:Copying training dataset
2025-05-12 22:27:21,430:INFO:Defining folds
2025-05-12 22:27:21,430:INFO:Declaring metric variables
2025-05-12 22:27:21,438:INFO:Importing untrained model
2025-05-12 22:27:21,447:INFO:SVM - Linear Kernel Imported successfully
2025-05-12 22:27:21,461:INFO:Starting cross validation
2025-05-12 22:27:21,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:21,715:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:21,804:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:21,973:INFO:Calculating mean and std
2025-05-12 22:27:21,975:INFO:Creating metrics dataframe
2025-05-12 22:27:21,978:INFO:Uploading results into container
2025-05-12 22:27:21,979:INFO:Uploading model into container now
2025-05-12 22:27:21,980:INFO:_master_model_container: 5
2025-05-12 22:27:21,980:INFO:_display_container: 2
2025-05-12 22:27:21,981:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-12 22:27:21,981:INFO:create_model() successfully completed......................................
2025-05-12 22:27:22,079:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:22,079:INFO:Creating metrics dataframe
2025-05-12 22:27:22,091:INFO:Initializing Ridge Classifier
2025-05-12 22:27:22,091:INFO:Total runtime is 0.2053900440533956 minutes
2025-05-12 22:27:22,098:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:22,099:INFO:Initializing create_model()
2025-05-12 22:27:22,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:22,099:INFO:Checking exceptions
2025-05-12 22:27:22,099:INFO:Importing libraries
2025-05-12 22:27:22,099:INFO:Copying training dataset
2025-05-12 22:27:22,105:INFO:Defining folds
2025-05-12 22:27:22,106:INFO:Declaring metric variables
2025-05-12 22:27:22,112:INFO:Importing untrained model
2025-05-12 22:27:22,119:INFO:Ridge Classifier Imported successfully
2025-05-12 22:27:22,129:INFO:Starting cross validation
2025-05-12 22:27:22,131:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:22,359:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,455:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,469:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,477:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,499:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,527:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,536:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,536:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,613:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,628:INFO:Calculating mean and std
2025-05-12 22:27:22,629:INFO:Creating metrics dataframe
2025-05-12 22:27:22,632:INFO:Uploading results into container
2025-05-12 22:27:22,633:INFO:Uploading model into container now
2025-05-12 22:27:22,633:INFO:_master_model_container: 6
2025-05-12 22:27:22,633:INFO:_display_container: 2
2025-05-12 22:27:22,634:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-12 22:27:22,634:INFO:create_model() successfully completed......................................
2025-05-12 22:27:22,723:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:22,723:INFO:Creating metrics dataframe
2025-05-12 22:27:22,733:INFO:Initializing Random Forest Classifier
2025-05-12 22:27:22,733:INFO:Total runtime is 0.21607719262441 minutes
2025-05-12 22:27:22,737:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:22,737:INFO:Initializing create_model()
2025-05-12 22:27:22,737:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:22,737:INFO:Checking exceptions
2025-05-12 22:27:22,737:INFO:Importing libraries
2025-05-12 22:27:22,739:INFO:Copying training dataset
2025-05-12 22:27:22,744:INFO:Defining folds
2025-05-12 22:27:22,744:INFO:Declaring metric variables
2025-05-12 22:27:22,749:INFO:Importing untrained model
2025-05-12 22:27:22,757:INFO:Random Forest Classifier Imported successfully
2025-05-12 22:27:22,767:INFO:Starting cross validation
2025-05-12 22:27:22,769:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:23,510:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:23,526:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:23,571:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:23,579:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:23,580:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:23,657:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:23,741:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:24,034:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:24,052:INFO:Calculating mean and std
2025-05-12 22:27:24,053:INFO:Creating metrics dataframe
2025-05-12 22:27:24,056:INFO:Uploading results into container
2025-05-12 22:27:24,057:INFO:Uploading model into container now
2025-05-12 22:27:24,057:INFO:_master_model_container: 7
2025-05-12 22:27:24,058:INFO:_display_container: 2
2025-05-12 22:27:24,058:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-12 22:27:24,058:INFO:create_model() successfully completed......................................
2025-05-12 22:27:24,141:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:24,142:INFO:Creating metrics dataframe
2025-05-12 22:27:24,151:INFO:Initializing Quadratic Discriminant Analysis
2025-05-12 22:27:24,151:INFO:Total runtime is 0.23971670071283976 minutes
2025-05-12 22:27:24,156:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:24,157:INFO:Initializing create_model()
2025-05-12 22:27:24,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:24,157:INFO:Checking exceptions
2025-05-12 22:27:24,157:INFO:Importing libraries
2025-05-12 22:27:24,157:INFO:Copying training dataset
2025-05-12 22:27:24,160:INFO:Defining folds
2025-05-12 22:27:24,160:INFO:Declaring metric variables
2025-05-12 22:27:24,164:INFO:Importing untrained model
2025-05-12 22:27:24,168:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-12 22:27:24,177:INFO:Starting cross validation
2025-05-12 22:27:24,180:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:24,275:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,276:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,279:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,284:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,300:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,300:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,306:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,309:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,336:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:24,413:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,419:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,476:INFO:Calculating mean and std
2025-05-12 22:27:24,477:INFO:Creating metrics dataframe
2025-05-12 22:27:24,480:INFO:Uploading results into container
2025-05-12 22:27:24,481:INFO:Uploading model into container now
2025-05-12 22:27:24,481:INFO:_master_model_container: 8
2025-05-12 22:27:24,481:INFO:_display_container: 2
2025-05-12 22:27:24,482:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-12 22:27:24,482:INFO:create_model() successfully completed......................................
2025-05-12 22:27:24,559:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:24,559:INFO:Creating metrics dataframe
2025-05-12 22:27:24,569:INFO:Initializing Ada Boost Classifier
2025-05-12 22:27:24,569:INFO:Total runtime is 0.2466849446296692 minutes
2025-05-12 22:27:24,576:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:24,576:INFO:Initializing create_model()
2025-05-12 22:27:24,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:24,576:INFO:Checking exceptions
2025-05-12 22:27:24,576:INFO:Importing libraries
2025-05-12 22:27:24,576:INFO:Copying training dataset
2025-05-12 22:27:24,583:INFO:Defining folds
2025-05-12 22:27:24,583:INFO:Declaring metric variables
2025-05-12 22:27:24,587:INFO:Importing untrained model
2025-05-12 22:27:24,593:INFO:Ada Boost Classifier Imported successfully
2025-05-12 22:27:24,601:INFO:Starting cross validation
2025-05-12 22:27:24,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:24,706:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:24,709:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:24,714:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:24,723:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:24,734:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:24,740:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:24,744:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:24,802:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:25,157:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:25,193:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:25,257:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:25,273:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:25,549:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:25,550:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:25,565:INFO:Calculating mean and std
2025-05-12 22:27:25,566:INFO:Creating metrics dataframe
2025-05-12 22:27:25,570:INFO:Uploading results into container
2025-05-12 22:27:25,571:INFO:Uploading model into container now
2025-05-12 22:27:25,572:INFO:_master_model_container: 9
2025-05-12 22:27:25,572:INFO:_display_container: 2
2025-05-12 22:27:25,573:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-12 22:27:25,573:INFO:create_model() successfully completed......................................
2025-05-12 22:27:25,673:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:25,673:INFO:Creating metrics dataframe
2025-05-12 22:27:25,690:INFO:Initializing Gradient Boosting Classifier
2025-05-12 22:27:25,691:INFO:Total runtime is 0.265375276406606 minutes
2025-05-12 22:27:25,696:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:25,697:INFO:Initializing create_model()
2025-05-12 22:27:25,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:25,697:INFO:Checking exceptions
2025-05-12 22:27:25,698:INFO:Importing libraries
2025-05-12 22:27:25,698:INFO:Copying training dataset
2025-05-12 22:27:25,706:INFO:Defining folds
2025-05-12 22:27:25,706:INFO:Declaring metric variables
2025-05-12 22:27:25,713:INFO:Importing untrained model
2025-05-12 22:27:25,720:INFO:Gradient Boosting Classifier Imported successfully
2025-05-12 22:27:25,732:INFO:Starting cross validation
2025-05-12 22:27:25,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:26,464:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:26,608:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:26,623:INFO:Calculating mean and std
2025-05-12 22:27:26,625:INFO:Creating metrics dataframe
2025-05-12 22:27:26,628:INFO:Uploading results into container
2025-05-12 22:27:26,629:INFO:Uploading model into container now
2025-05-12 22:27:26,630:INFO:_master_model_container: 10
2025-05-12 22:27:26,630:INFO:_display_container: 2
2025-05-12 22:27:26,631:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-12 22:27:26,631:INFO:create_model() successfully completed......................................
2025-05-12 22:27:26,707:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:26,707:INFO:Creating metrics dataframe
2025-05-12 22:27:26,721:INFO:Initializing Linear Discriminant Analysis
2025-05-12 22:27:26,723:INFO:Total runtime is 0.28257929881413774 minutes
2025-05-12 22:27:26,727:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:26,728:INFO:Initializing create_model()
2025-05-12 22:27:26,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:26,728:INFO:Checking exceptions
2025-05-12 22:27:26,728:INFO:Importing libraries
2025-05-12 22:27:26,728:INFO:Copying training dataset
2025-05-12 22:27:26,733:INFO:Defining folds
2025-05-12 22:27:26,733:INFO:Declaring metric variables
2025-05-12 22:27:26,740:INFO:Importing untrained model
2025-05-12 22:27:26,749:INFO:Linear Discriminant Analysis Imported successfully
2025-05-12 22:27:26,757:INFO:Starting cross validation
2025-05-12 22:27:26,761:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:26,931:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:26,939:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:26,966:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:26,979:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:26,980:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:27,068:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:27,081:INFO:Calculating mean and std
2025-05-12 22:27:27,081:INFO:Creating metrics dataframe
2025-05-12 22:27:27,086:INFO:Uploading results into container
2025-05-12 22:27:27,087:INFO:Uploading model into container now
2025-05-12 22:27:27,088:INFO:_master_model_container: 11
2025-05-12 22:27:27,088:INFO:_display_container: 2
2025-05-12 22:27:27,089:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-12 22:27:27,089:INFO:create_model() successfully completed......................................
2025-05-12 22:27:27,171:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:27,172:INFO:Creating metrics dataframe
2025-05-12 22:27:27,185:INFO:Initializing Extra Trees Classifier
2025-05-12 22:27:27,185:INFO:Total runtime is 0.2902848164240519 minutes
2025-05-12 22:27:27,190:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:27,191:INFO:Initializing create_model()
2025-05-12 22:27:27,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:27,191:INFO:Checking exceptions
2025-05-12 22:27:27,191:INFO:Importing libraries
2025-05-12 22:27:27,191:INFO:Copying training dataset
2025-05-12 22:27:27,196:INFO:Defining folds
2025-05-12 22:27:27,197:INFO:Declaring metric variables
2025-05-12 22:27:27,201:INFO:Importing untrained model
2025-05-12 22:27:27,208:INFO:Extra Trees Classifier Imported successfully
2025-05-12 22:27:27,217:INFO:Starting cross validation
2025-05-12 22:27:27,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:27,849:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:27,881:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:27,896:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:28,219:INFO:Calculating mean and std
2025-05-12 22:27:28,220:INFO:Creating metrics dataframe
2025-05-12 22:27:28,224:INFO:Uploading results into container
2025-05-12 22:27:28,224:INFO:Uploading model into container now
2025-05-12 22:27:28,225:INFO:_master_model_container: 12
2025-05-12 22:27:28,225:INFO:_display_container: 2
2025-05-12 22:27:28,226:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-12 22:27:28,226:INFO:create_model() successfully completed......................................
2025-05-12 22:27:28,306:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:28,306:INFO:Creating metrics dataframe
2025-05-12 22:27:28,317:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:27:28,318:INFO:Total runtime is 0.30916332403818764 minutes
2025-05-12 22:27:28,323:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:28,323:INFO:Initializing create_model()
2025-05-12 22:27:28,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:28,323:INFO:Checking exceptions
2025-05-12 22:27:28,323:INFO:Importing libraries
2025-05-12 22:27:28,323:INFO:Copying training dataset
2025-05-12 22:27:28,328:INFO:Defining folds
2025-05-12 22:27:28,329:INFO:Declaring metric variables
2025-05-12 22:27:28,333:INFO:Importing untrained model
2025-05-12 22:27:28,344:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:27:28,364:INFO:Starting cross validation
2025-05-12 22:27:28,376:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:28,792:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:28,803:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:28,961:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,005:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,104:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,263:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,289:INFO:Calculating mean and std
2025-05-12 22:27:29,291:INFO:Creating metrics dataframe
2025-05-12 22:27:29,298:INFO:Uploading results into container
2025-05-12 22:27:29,300:INFO:Uploading model into container now
2025-05-12 22:27:29,301:INFO:_master_model_container: 13
2025-05-12 22:27:29,302:INFO:_display_container: 2
2025-05-12 22:27:29,303:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:27:29,303:INFO:create_model() successfully completed......................................
2025-05-12 22:27:29,421:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:29,423:INFO:Creating metrics dataframe
2025-05-12 22:27:29,438:INFO:Initializing Dummy Classifier
2025-05-12 22:27:29,439:INFO:Total runtime is 0.3278443336486816 minutes
2025-05-12 22:27:29,444:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:29,444:INFO:Initializing create_model()
2025-05-12 22:27:29,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:29,444:INFO:Checking exceptions
2025-05-12 22:27:29,445:INFO:Importing libraries
2025-05-12 22:27:29,445:INFO:Copying training dataset
2025-05-12 22:27:29,450:INFO:Defining folds
2025-05-12 22:27:29,451:INFO:Declaring metric variables
2025-05-12 22:27:29,455:INFO:Importing untrained model
2025-05-12 22:27:29,461:INFO:Dummy Classifier Imported successfully
2025-05-12 22:27:29,473:INFO:Starting cross validation
2025-05-12 22:27:29,475:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:29,658:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,660:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,668:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,731:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,737:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,759:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,769:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,841:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,841:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,860:INFO:Calculating mean and std
2025-05-12 22:27:29,861:INFO:Creating metrics dataframe
2025-05-12 22:27:29,866:INFO:Uploading results into container
2025-05-12 22:27:29,867:INFO:Uploading model into container now
2025-05-12 22:27:29,869:INFO:_master_model_container: 14
2025-05-12 22:27:29,869:INFO:_display_container: 2
2025-05-12 22:27:29,869:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:27:29,870:INFO:create_model() successfully completed......................................
2025-05-12 22:27:29,970:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:29,970:INFO:Creating metrics dataframe
2025-05-12 22:27:29,993:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:27:30,007:INFO:Initializing create_model()
2025-05-12 22:27:30,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:30,009:INFO:Checking exceptions
2025-05-12 22:27:30,012:INFO:Importing libraries
2025-05-12 22:27:30,012:INFO:Copying training dataset
2025-05-12 22:27:30,017:INFO:Defining folds
2025-05-12 22:27:30,017:INFO:Declaring metric variables
2025-05-12 22:27:30,017:INFO:Importing untrained model
2025-05-12 22:27:30,017:INFO:Declaring custom model
2025-05-12 22:27:30,017:INFO:Dummy Classifier Imported successfully
2025-05-12 22:27:30,020:INFO:Cross validation set to False
2025-05-12 22:27:30,020:INFO:Fitting Model
2025-05-12 22:27:30,078:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:27:30,078:INFO:create_model() successfully completed......................................
2025-05-12 22:27:30,225:INFO:_master_model_container: 14
2025-05-12 22:27:30,225:INFO:_display_container: 2
2025-05-12 22:27:30,226:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:27:30,226:INFO:compare_models() successfully completed......................................
2025-05-12 22:27:30,254:INFO:Initializing create_model()
2025-05-12 22:27:30,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:30,254:INFO:Checking exceptions
2025-05-12 22:27:30,277:INFO:Importing libraries
2025-05-12 22:27:30,277:INFO:Copying training dataset
2025-05-12 22:27:30,284:INFO:Defining folds
2025-05-12 22:27:30,284:INFO:Declaring metric variables
2025-05-12 22:27:30,290:INFO:Importing untrained model
2025-05-12 22:27:30,297:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:27:30,308:INFO:Starting cross validation
2025-05-12 22:27:30,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:31,304:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:31,341:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:31,376:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:31,589:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:31,695:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:31,877:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:31,899:INFO:Calculating mean and std
2025-05-12 22:27:31,903:INFO:Creating metrics dataframe
2025-05-12 22:27:31,916:INFO:Finalizing model
2025-05-12 22:27:32,000:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:27:32,000:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.
2025-05-12 22:27:32,000:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-12 22:27:32,000:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-12 22:27:32,001:INFO:[LightGBM] [Info] Total Bins 117
2025-05-12 22:27:32,001:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:27:32,001:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:27:32,001:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:27:32,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,049:INFO:Uploading results into container
2025-05-12 22:27:32,051:INFO:Uploading model into container now
2025-05-12 22:27:32,073:INFO:_master_model_container: 15
2025-05-12 22:27:32,073:INFO:_display_container: 3
2025-05-12 22:27:32,074:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:27:32,074:INFO:create_model() successfully completed......................................
2025-05-12 22:27:32,208:INFO:Initializing tune_model()
2025-05-12 22:27:32,208:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:27:32,208:INFO:Checking exceptions
2025-05-12 22:27:32,231:INFO:Copying training dataset
2025-05-12 22:27:32,234:INFO:Checking base model
2025-05-12 22:27:32,234:INFO:Base model : Light Gradient Boosting Machine
2025-05-12 22:27:32,242:INFO:Declaring metric variables
2025-05-12 22:27:32,247:INFO:Defining Hyperparameters
2025-05-12 22:27:32,334:INFO:Tuning with n_jobs=-1
2025-05-12 22:27:32,334:INFO:Initializing RandomizedSearchCV
2025-05-12 22:27:41,274:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2025-05-12 22:27:41,277:INFO:Hyperparameter search completed
2025-05-12 22:27:41,277:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:41,279:INFO:Initializing create_model()
2025-05-12 22:27:41,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51214C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2025-05-12 22:27:41,279:INFO:Checking exceptions
2025-05-12 22:27:41,279:INFO:Importing libraries
2025-05-12 22:27:41,280:INFO:Copying training dataset
2025-05-12 22:27:41,287:INFO:Defining folds
2025-05-12 22:27:41,287:INFO:Declaring metric variables
2025-05-12 22:27:41,294:INFO:Importing untrained model
2025-05-12 22:27:41,294:INFO:Declaring custom model
2025-05-12 22:27:41,302:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:27:41,316:INFO:Starting cross validation
2025-05-12 22:27:41,319:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:41,611:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,612:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,630:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,647:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,713:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,729:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,821:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,845:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,889:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,899:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,917:INFO:Calculating mean and std
2025-05-12 22:27:41,923:INFO:Creating metrics dataframe
2025-05-12 22:27:41,933:INFO:Finalizing model
2025-05-12 22:27:42,007:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:27:42,007:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:27:42,008:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:27:42,008:INFO:[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.
2025-05-12 22:27:42,009:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:27:42,009:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:27:42,009:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:27:42,009:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:27:42,009:INFO:[LightGBM] [Info] Total Bins 0
2025-05-12 22:27:42,009:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 0
2025-05-12 22:27:42,009:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:27:42,009:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:27:42,009:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,009:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,009:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,020:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,020:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,039:INFO:Uploading results into container
2025-05-12 22:27:42,041:INFO:Uploading model into container now
2025-05-12 22:27:42,041:INFO:_master_model_container: 16
2025-05-12 22:27:42,043:INFO:_display_container: 4
2025-05-12 22:27:42,044:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:27:42,044:INFO:create_model() successfully completed......................................
2025-05-12 22:27:42,152:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:42,152:INFO:choose_better activated
2025-05-12 22:27:42,156:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:42,157:INFO:Initializing create_model()
2025-05-12 22:27:42,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:42,157:INFO:Checking exceptions
2025-05-12 22:27:42,159:INFO:Importing libraries
2025-05-12 22:27:42,160:INFO:Copying training dataset
2025-05-12 22:27:42,163:INFO:Defining folds
2025-05-12 22:27:42,163:INFO:Declaring metric variables
2025-05-12 22:27:42,164:INFO:Importing untrained model
2025-05-12 22:27:42,164:INFO:Declaring custom model
2025-05-12 22:27:42,166:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:27:42,166:INFO:Starting cross validation
2025-05-12 22:27:42,167:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:42,479:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:42,493:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:42,523:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:42,632:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:42,639:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:42,759:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:42,782:INFO:Calculating mean and std
2025-05-12 22:27:42,783:INFO:Creating metrics dataframe
2025-05-12 22:27:42,785:INFO:Finalizing model
2025-05-12 22:27:42,851:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:27:42,851:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.
2025-05-12 22:27:42,851:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-12 22:27:42,853:INFO:[LightGBM] [Info] Total Bins 117
2025-05-12 22:27:42,853:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:27:42,853:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:27:42,854:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:27:42,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,884:INFO:Uploading results into container
2025-05-12 22:27:42,885:INFO:Uploading model into container now
2025-05-12 22:27:42,885:INFO:_master_model_container: 17
2025-05-12 22:27:42,886:INFO:_display_container: 5
2025-05-12 22:27:42,887:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:27:42,887:INFO:create_model() successfully completed......................................
2025-05-12 22:27:42,988:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:42,989:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7891
2025-05-12 22:27:42,989:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8291
2025-05-12 22:27:42,990:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-12 22:27:42,990:INFO:choose_better completed
2025-05-12 22:27:43,003:INFO:_master_model_container: 17
2025-05-12 22:27:43,003:INFO:_display_container: 4
2025-05-12 22:27:43,004:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:27:43,004:INFO:tune_model() successfully completed......................................
2025-05-12 22:27:43,107:INFO:Initializing evaluate_model()
2025-05-12 22:27:43,108:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:27:43,119:INFO:Initializing plot_model()
2025-05-12 22:27:43,120:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:27:43,120:INFO:Checking exceptions
2025-05-12 22:27:43,124:INFO:Preloading libraries
2025-05-12 22:27:43,125:INFO:Copying training dataset
2025-05-12 22:27:43,125:INFO:Plot type: pipeline
2025-05-12 22:27:43,367:INFO:Visual Rendered Successfully
2025-05-12 22:27:43,448:INFO:plot_model() successfully completed......................................
2025-05-12 22:27:43,473:INFO:Initializing predict_model()
2025-05-12 22:27:43,473:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027D2DA511C0>)
2025-05-12 22:27:43,473:INFO:Checking exceptions
2025-05-12 22:27:43,473:INFO:Preloading libraries
2025-05-12 22:27:43,617:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:43,788:INFO:Initializing save_model()
2025-05-12 22:27:43,788:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-12 22:27:43,788:INFO:Adding model into prep_pipe
2025-05-12 22:27:43,803:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:27:43,823:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-12 22:27:43,823:INFO:save_model() successfully completed......................................
2025-05-12 22:27:50,877:INFO:PyCaret ClassificationExperiment
2025-05-12 22:27:50,877:INFO:Logging name: clf-default-name
2025-05-12 22:27:50,878:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-12 22:27:50,878:INFO:version 3.3.2
2025-05-12 22:27:50,878:INFO:Initializing setup()
2025-05-12 22:27:50,878:INFO:self.USI: 3347
2025-05-12 22:27:50,878:INFO:self._variable_keys: {'fold_groups_param', 'memory', 'n_jobs_param', 'fold_generator', 'X', 'seed', '_available_plots', '_ml_usecase', 'y_train', 'html_param', 'logging_param', 'target_param', 'idx', 'log_plots_param', 'pipeline', 'fix_imbalance', 'gpu_n_jobs_param', 'y_test', 'exp_id', 'y', 'is_multiclass', 'data', 'gpu_param', 'X_train', 'USI', 'exp_name_log', 'fold_shuffle_param', 'X_test'}
2025-05-12 22:27:50,878:INFO:Checking environment
2025-05-12 22:27:50,878:INFO:python_version: 3.11.8
2025-05-12 22:27:50,878:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:27:50,878:INFO:machine: AMD64
2025-05-12 22:27:50,878:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:27:50,882:INFO:Memory: svmem(total=16907886592, available=2438205440, percent=85.6, used=14469681152, free=2438205440)
2025-05-12 22:27:50,883:INFO:Physical Core: 4
2025-05-12 22:27:50,883:INFO:Logical Core: 8
2025-05-12 22:27:50,883:INFO:Checking libraries
2025-05-12 22:27:50,883:INFO:System:
2025-05-12 22:27:50,883:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:27:50,883:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:27:50,883:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:27:50,883:INFO:PyCaret required dependencies:
2025-05-12 22:27:50,883:INFO:                 pip: 24.0
2025-05-12 22:27:50,883:INFO:          setuptools: 65.5.0
2025-05-12 22:27:50,883:INFO:             pycaret: 3.3.2
2025-05-12 22:27:50,883:INFO:             IPython: 9.2.0
2025-05-12 22:27:50,883:INFO:          ipywidgets: 8.1.7
2025-05-12 22:27:50,883:INFO:                tqdm: 4.67.1
2025-05-12 22:27:50,883:INFO:               numpy: 1.26.4
2025-05-12 22:27:50,883:INFO:              pandas: 2.1.4
2025-05-12 22:27:50,883:INFO:              jinja2: 3.1.6
2025-05-12 22:27:50,883:INFO:               scipy: 1.11.4
2025-05-12 22:27:50,883:INFO:              joblib: 1.3.2
2025-05-12 22:27:50,883:INFO:             sklearn: 1.4.2
2025-05-12 22:27:50,883:INFO:                pyod: 2.0.5
2025-05-12 22:27:50,883:INFO:            imblearn: 0.13.0
2025-05-12 22:27:50,883:INFO:   category_encoders: 2.7.0
2025-05-12 22:27:50,883:INFO:            lightgbm: 4.6.0
2025-05-12 22:27:50,883:INFO:               numba: 0.61.2
2025-05-12 22:27:50,884:INFO:            requests: 2.32.3
2025-05-12 22:27:50,884:INFO:          matplotlib: 3.7.5
2025-05-12 22:27:50,884:INFO:          scikitplot: 0.3.7
2025-05-12 22:27:50,884:INFO:         yellowbrick: 1.5
2025-05-12 22:27:50,884:INFO:              plotly: 5.24.1
2025-05-12 22:27:50,884:INFO:    plotly-resampler: Not installed
2025-05-12 22:27:50,884:INFO:             kaleido: 0.2.1
2025-05-12 22:27:50,884:INFO:           schemdraw: 0.15
2025-05-12 22:27:50,884:INFO:         statsmodels: 0.14.4
2025-05-12 22:27:50,884:INFO:              sktime: 0.26.0
2025-05-12 22:27:50,884:INFO:               tbats: 1.1.3
2025-05-12 22:27:50,884:INFO:            pmdarima: 2.0.4
2025-05-12 22:27:50,884:INFO:              psutil: 7.0.0
2025-05-12 22:27:50,884:INFO:          markupsafe: 3.0.2
2025-05-12 22:27:50,884:INFO:             pickle5: Not installed
2025-05-12 22:27:50,884:INFO:         cloudpickle: 3.1.1
2025-05-12 22:27:50,884:INFO:         deprecation: 2.1.0
2025-05-12 22:27:50,884:INFO:              xxhash: 3.5.0
2025-05-12 22:27:50,884:INFO:           wurlitzer: Not installed
2025-05-12 22:27:50,884:INFO:PyCaret optional dependencies:
2025-05-12 22:27:50,884:INFO:                shap: Not installed
2025-05-12 22:27:50,884:INFO:           interpret: Not installed
2025-05-12 22:27:50,884:INFO:                umap: Not installed
2025-05-12 22:27:50,884:INFO:     ydata_profiling: Not installed
2025-05-12 22:27:50,884:INFO:  explainerdashboard: Not installed
2025-05-12 22:27:50,884:INFO:             autoviz: Not installed
2025-05-12 22:27:50,884:INFO:           fairlearn: Not installed
2025-05-12 22:27:50,884:INFO:          deepchecks: Not installed
2025-05-12 22:27:50,884:INFO:             xgboost: Not installed
2025-05-12 22:27:50,884:INFO:            catboost: Not installed
2025-05-12 22:27:50,884:INFO:              kmodes: Not installed
2025-05-12 22:27:50,884:INFO:             mlxtend: Not installed
2025-05-12 22:27:50,884:INFO:       statsforecast: Not installed
2025-05-12 22:27:50,884:INFO:        tune_sklearn: Not installed
2025-05-12 22:27:50,884:INFO:                 ray: Not installed
2025-05-12 22:27:50,885:INFO:            hyperopt: Not installed
2025-05-12 22:27:50,885:INFO:              optuna: Not installed
2025-05-12 22:27:50,885:INFO:               skopt: Not installed
2025-05-12 22:27:50,885:INFO:              mlflow: Not installed
2025-05-12 22:27:50,885:INFO:              gradio: Not installed
2025-05-12 22:27:50,885:INFO:             fastapi: Not installed
2025-05-12 22:27:50,885:INFO:             uvicorn: Not installed
2025-05-12 22:27:50,885:INFO:              m2cgen: Not installed
2025-05-12 22:27:50,885:INFO:           evidently: Not installed
2025-05-12 22:27:50,885:INFO:               fugue: Not installed
2025-05-12 22:27:50,885:INFO:           streamlit: Not installed
2025-05-12 22:27:50,885:INFO:             prophet: Not installed
2025-05-12 22:27:50,885:INFO:None
2025-05-12 22:27:50,885:INFO:Set up data.
2025-05-12 22:27:50,888:INFO:Set up folding strategy.
2025-05-12 22:27:50,888:INFO:Set up train/test split.
2025-05-12 22:27:50,892:INFO:Set up index.
2025-05-12 22:27:50,892:INFO:Assigning column types.
2025-05-12 22:27:50,894:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:27:50,980:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:27:50,981:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:51,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,013:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,049:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:27:51,050:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:51,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,071:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:27:51,107:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:51,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,162:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:51,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,183:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,184:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-12 22:27:51,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,293:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,294:INFO:Preparing preprocessing pipeline...
2025-05-12 22:27:51,294:INFO:Set up simple imputation.
2025-05-12 22:27:51,296:INFO:Set up encoding of categorical features.
2025-05-12 22:27:51,296:INFO:Set up feature normalization.
2025-05-12 22:27:51,343:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:27:51,347:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:27:51,347:INFO:Creating final display dataframe.
2025-05-12 22:27:51,471:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              3347
2025-05-12 22:27:51,536:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,536:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,593:INFO:setup() successfully completed in 0.72s...............
2025-05-12 22:27:51,609:INFO:Initializing compare_models()
2025-05-12 22:27:51,609:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-12 22:27:51,609:INFO:Checking exceptions
2025-05-12 22:27:51,611:INFO:Preparing display monitor
2025-05-12 22:27:51,633:INFO:Initializing Logistic Regression
2025-05-12 22:27:51,633:INFO:Total runtime is 0.0 minutes
2025-05-12 22:27:51,637:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:51,637:INFO:Initializing create_model()
2025-05-12 22:27:51,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:51,638:INFO:Checking exceptions
2025-05-12 22:27:51,638:INFO:Importing libraries
2025-05-12 22:27:51,638:INFO:Copying training dataset
2025-05-12 22:27:51,641:INFO:Defining folds
2025-05-12 22:27:51,641:INFO:Declaring metric variables
2025-05-12 22:27:51,646:INFO:Importing untrained model
2025-05-12 22:27:51,651:INFO:Logistic Regression Imported successfully
2025-05-12 22:27:51,660:INFO:Starting cross validation
2025-05-12 22:27:51,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:51,806:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,807:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,817:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,829:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,850:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,852:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,857:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,900:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,909:INFO:Calculating mean and std
2025-05-12 22:27:51,910:INFO:Creating metrics dataframe
2025-05-12 22:27:51,911:INFO:Uploading results into container
2025-05-12 22:27:51,911:INFO:Uploading model into container now
2025-05-12 22:27:51,913:INFO:_master_model_container: 1
2025-05-12 22:27:51,913:INFO:_display_container: 2
2025-05-12 22:27:51,913:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-12 22:27:51,913:INFO:create_model() successfully completed......................................
2025-05-12 22:27:51,983:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:51,983:INFO:Creating metrics dataframe
2025-05-12 22:27:51,991:INFO:Initializing K Neighbors Classifier
2025-05-12 22:27:51,991:INFO:Total runtime is 0.005974737803141276 minutes
2025-05-12 22:27:51,996:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:51,996:INFO:Initializing create_model()
2025-05-12 22:27:51,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:51,996:INFO:Checking exceptions
2025-05-12 22:27:51,996:INFO:Importing libraries
2025-05-12 22:27:51,996:INFO:Copying training dataset
2025-05-12 22:27:51,999:INFO:Defining folds
2025-05-12 22:27:51,999:INFO:Declaring metric variables
2025-05-12 22:27:52,002:INFO:Importing untrained model
2025-05-12 22:27:52,007:INFO:K Neighbors Classifier Imported successfully
2025-05-12 22:27:52,014:INFO:Starting cross validation
2025-05-12 22:27:52,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:52,157:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,157:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,171:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,175:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,187:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,257:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,265:INFO:Calculating mean and std
2025-05-12 22:27:52,265:INFO:Creating metrics dataframe
2025-05-12 22:27:52,266:INFO:Uploading results into container
2025-05-12 22:27:52,267:INFO:Uploading model into container now
2025-05-12 22:27:52,267:INFO:_master_model_container: 2
2025-05-12 22:27:52,267:INFO:_display_container: 2
2025-05-12 22:27:52,267:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-12 22:27:52,267:INFO:create_model() successfully completed......................................
2025-05-12 22:27:52,334:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:52,334:INFO:Creating metrics dataframe
2025-05-12 22:27:52,339:INFO:Initializing Naive Bayes
2025-05-12 22:27:52,339:INFO:Total runtime is 0.011779212951660156 minutes
2025-05-12 22:27:52,342:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:52,343:INFO:Initializing create_model()
2025-05-12 22:27:52,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:52,343:INFO:Checking exceptions
2025-05-12 22:27:52,343:INFO:Importing libraries
2025-05-12 22:27:52,343:INFO:Copying training dataset
2025-05-12 22:27:52,347:INFO:Defining folds
2025-05-12 22:27:52,347:INFO:Declaring metric variables
2025-05-12 22:27:52,350:INFO:Importing untrained model
2025-05-12 22:27:52,352:INFO:Naive Bayes Imported successfully
2025-05-12 22:27:52,359:INFO:Starting cross validation
2025-05-12 22:27:52,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:52,469:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,470:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,499:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,533:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,543:INFO:Calculating mean and std
2025-05-12 22:27:52,543:INFO:Creating metrics dataframe
2025-05-12 22:27:52,544:INFO:Uploading results into container
2025-05-12 22:27:52,544:INFO:Uploading model into container now
2025-05-12 22:27:52,546:INFO:_master_model_container: 3
2025-05-12 22:27:52,546:INFO:_display_container: 2
2025-05-12 22:27:52,546:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-12 22:27:52,546:INFO:create_model() successfully completed......................................
2025-05-12 22:27:52,609:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:52,609:INFO:Creating metrics dataframe
2025-05-12 22:27:52,615:INFO:Initializing Decision Tree Classifier
2025-05-12 22:27:52,615:INFO:Total runtime is 0.016368858019510903 minutes
2025-05-12 22:27:52,618:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:52,619:INFO:Initializing create_model()
2025-05-12 22:27:52,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:52,619:INFO:Checking exceptions
2025-05-12 22:27:52,619:INFO:Importing libraries
2025-05-12 22:27:52,619:INFO:Copying training dataset
2025-05-12 22:27:52,622:INFO:Defining folds
2025-05-12 22:27:52,622:INFO:Declaring metric variables
2025-05-12 22:27:52,625:INFO:Importing untrained model
2025-05-12 22:27:52,629:INFO:Decision Tree Classifier Imported successfully
2025-05-12 22:27:52,635:INFO:Starting cross validation
2025-05-12 22:27:52,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:52,767:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,827:INFO:Calculating mean and std
2025-05-12 22:27:52,827:INFO:Creating metrics dataframe
2025-05-12 22:27:52,830:INFO:Uploading results into container
2025-05-12 22:27:52,830:INFO:Uploading model into container now
2025-05-12 22:27:52,831:INFO:_master_model_container: 4
2025-05-12 22:27:52,831:INFO:_display_container: 2
2025-05-12 22:27:52,831:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-12 22:27:52,831:INFO:create_model() successfully completed......................................
2025-05-12 22:27:52,897:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:52,897:INFO:Creating metrics dataframe
2025-05-12 22:27:52,903:INFO:Initializing SVM - Linear Kernel
2025-05-12 22:27:52,903:INFO:Total runtime is 0.02116921345392863 minutes
2025-05-12 22:27:52,904:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:52,906:INFO:Initializing create_model()
2025-05-12 22:27:52,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:52,906:INFO:Checking exceptions
2025-05-12 22:27:52,906:INFO:Importing libraries
2025-05-12 22:27:52,906:INFO:Copying training dataset
2025-05-12 22:27:52,909:INFO:Defining folds
2025-05-12 22:27:52,909:INFO:Declaring metric variables
2025-05-12 22:27:52,912:INFO:Importing untrained model
2025-05-12 22:27:52,916:INFO:SVM - Linear Kernel Imported successfully
2025-05-12 22:27:52,922:INFO:Starting cross validation
2025-05-12 22:27:52,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:53,032:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,061:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,131:INFO:Calculating mean and std
2025-05-12 22:27:53,133:INFO:Creating metrics dataframe
2025-05-12 22:27:53,135:INFO:Uploading results into container
2025-05-12 22:27:53,135:INFO:Uploading model into container now
2025-05-12 22:27:53,136:INFO:_master_model_container: 5
2025-05-12 22:27:53,136:INFO:_display_container: 2
2025-05-12 22:27:53,136:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-12 22:27:53,136:INFO:create_model() successfully completed......................................
2025-05-12 22:27:53,206:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:53,207:INFO:Creating metrics dataframe
2025-05-12 22:27:53,215:INFO:Initializing Ridge Classifier
2025-05-12 22:27:53,215:INFO:Total runtime is 0.026364723841349285 minutes
2025-05-12 22:27:53,217:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:53,219:INFO:Initializing create_model()
2025-05-12 22:27:53,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:53,219:INFO:Checking exceptions
2025-05-12 22:27:53,219:INFO:Importing libraries
2025-05-12 22:27:53,219:INFO:Copying training dataset
2025-05-12 22:27:53,223:INFO:Defining folds
2025-05-12 22:27:53,223:INFO:Declaring metric variables
2025-05-12 22:27:53,226:INFO:Importing untrained model
2025-05-12 22:27:53,230:INFO:Ridge Classifier Imported successfully
2025-05-12 22:27:53,237:INFO:Starting cross validation
2025-05-12 22:27:53,239:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:53,374:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,381:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,381:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,389:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,394:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,397:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,399:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,476:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,480:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,494:INFO:Calculating mean and std
2025-05-12 22:27:53,494:INFO:Creating metrics dataframe
2025-05-12 22:27:53,497:INFO:Uploading results into container
2025-05-12 22:27:53,497:INFO:Uploading model into container now
2025-05-12 22:27:53,498:INFO:_master_model_container: 6
2025-05-12 22:27:53,498:INFO:_display_container: 2
2025-05-12 22:27:53,498:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-12 22:27:53,498:INFO:create_model() successfully completed......................................
2025-05-12 22:27:53,579:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:53,579:INFO:Creating metrics dataframe
2025-05-12 22:27:53,587:INFO:Initializing Random Forest Classifier
2025-05-12 22:27:53,587:INFO:Total runtime is 0.03256822427113851 minutes
2025-05-12 22:27:53,590:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:53,591:INFO:Initializing create_model()
2025-05-12 22:27:53,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:53,591:INFO:Checking exceptions
2025-05-12 22:27:53,591:INFO:Importing libraries
2025-05-12 22:27:53,591:INFO:Copying training dataset
2025-05-12 22:27:53,596:INFO:Defining folds
2025-05-12 22:27:53,596:INFO:Declaring metric variables
2025-05-12 22:27:53,600:INFO:Importing untrained model
2025-05-12 22:27:53,606:INFO:Random Forest Classifier Imported successfully
2025-05-12 22:27:53,615:INFO:Starting cross validation
2025-05-12 22:27:53,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:54,258:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,283:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,284:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,291:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,303:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,303:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,434:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,661:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,671:INFO:Calculating mean and std
2025-05-12 22:27:54,673:INFO:Creating metrics dataframe
2025-05-12 22:27:54,676:INFO:Uploading results into container
2025-05-12 22:27:54,677:INFO:Uploading model into container now
2025-05-12 22:27:54,678:INFO:_master_model_container: 7
2025-05-12 22:27:54,678:INFO:_display_container: 2
2025-05-12 22:27:54,679:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-12 22:27:54,679:INFO:create_model() successfully completed......................................
2025-05-12 22:27:54,756:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:54,756:INFO:Creating metrics dataframe
2025-05-12 22:27:54,764:INFO:Initializing Quadratic Discriminant Analysis
2025-05-12 22:27:54,764:INFO:Total runtime is 0.052192703882853186 minutes
2025-05-12 22:27:54,768:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:54,768:INFO:Initializing create_model()
2025-05-12 22:27:54,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:54,769:INFO:Checking exceptions
2025-05-12 22:27:54,769:INFO:Importing libraries
2025-05-12 22:27:54,769:INFO:Copying training dataset
2025-05-12 22:27:54,774:INFO:Defining folds
2025-05-12 22:27:54,774:INFO:Declaring metric variables
2025-05-12 22:27:54,779:INFO:Importing untrained model
2025-05-12 22:27:54,783:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-12 22:27:54,794:INFO:Starting cross validation
2025-05-12 22:27:54,796:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:54,892:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:54,893:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:54,893:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:54,893:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:54,907:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:54,908:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:54,911:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:54,949:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,951:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:55,020:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:55,026:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:55,070:INFO:Calculating mean and std
2025-05-12 22:27:55,071:INFO:Creating metrics dataframe
2025-05-12 22:27:55,073:INFO:Uploading results into container
2025-05-12 22:27:55,074:INFO:Uploading model into container now
2025-05-12 22:27:55,075:INFO:_master_model_container: 8
2025-05-12 22:27:55,075:INFO:_display_container: 2
2025-05-12 22:27:55,076:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-12 22:27:55,076:INFO:create_model() successfully completed......................................
2025-05-12 22:27:55,153:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:55,153:INFO:Creating metrics dataframe
2025-05-12 22:27:55,162:INFO:Initializing Ada Boost Classifier
2025-05-12 22:27:55,163:INFO:Total runtime is 0.05881415208180745 minutes
2025-05-12 22:27:55,166:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:55,167:INFO:Initializing create_model()
2025-05-12 22:27:55,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:55,167:INFO:Checking exceptions
2025-05-12 22:27:55,167:INFO:Importing libraries
2025-05-12 22:27:55,167:INFO:Copying training dataset
2025-05-12 22:27:55,171:INFO:Defining folds
2025-05-12 22:27:55,171:INFO:Declaring metric variables
2025-05-12 22:27:55,176:INFO:Importing untrained model
2025-05-12 22:27:55,180:INFO:Ada Boost Classifier Imported successfully
2025-05-12 22:27:55,187:INFO:Starting cross validation
2025-05-12 22:27:55,191:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:55,280:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,285:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,287:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,296:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,299:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,299:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,307:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,310:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,547:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:55,576:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:55,632:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,636:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,828:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:55,840:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:55,851:INFO:Calculating mean and std
2025-05-12 22:27:55,853:INFO:Creating metrics dataframe
2025-05-12 22:27:55,856:INFO:Uploading results into container
2025-05-12 22:27:55,858:INFO:Uploading model into container now
2025-05-12 22:27:55,859:INFO:_master_model_container: 9
2025-05-12 22:27:55,859:INFO:_display_container: 2
2025-05-12 22:27:55,860:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-12 22:27:55,860:INFO:create_model() successfully completed......................................
2025-05-12 22:27:55,962:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:55,962:INFO:Creating metrics dataframe
2025-05-12 22:27:55,973:INFO:Initializing Gradient Boosting Classifier
2025-05-12 22:27:55,973:INFO:Total runtime is 0.07234033346176147 minutes
2025-05-12 22:27:55,978:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:55,978:INFO:Initializing create_model()
2025-05-12 22:27:55,979:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:55,979:INFO:Checking exceptions
2025-05-12 22:27:55,979:INFO:Importing libraries
2025-05-12 22:27:55,979:INFO:Copying training dataset
2025-05-12 22:27:55,983:INFO:Defining folds
2025-05-12 22:27:55,983:INFO:Declaring metric variables
2025-05-12 22:27:55,989:INFO:Importing untrained model
2025-05-12 22:27:55,994:INFO:Gradient Boosting Classifier Imported successfully
2025-05-12 22:27:56,005:INFO:Starting cross validation
2025-05-12 22:27:56,007:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:56,432:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:56,699:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:56,711:INFO:Calculating mean and std
2025-05-12 22:27:56,713:INFO:Creating metrics dataframe
2025-05-12 22:27:56,714:INFO:Uploading results into container
2025-05-12 22:27:56,716:INFO:Uploading model into container now
2025-05-12 22:27:56,716:INFO:_master_model_container: 10
2025-05-12 22:27:56,716:INFO:_display_container: 2
2025-05-12 22:27:56,717:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-12 22:27:56,717:INFO:create_model() successfully completed......................................
2025-05-12 22:27:56,799:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:56,799:INFO:Creating metrics dataframe
2025-05-12 22:27:56,809:INFO:Initializing Linear Discriminant Analysis
2025-05-12 22:27:56,809:INFO:Total runtime is 0.08626944224039713 minutes
2025-05-12 22:27:56,814:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:56,814:INFO:Initializing create_model()
2025-05-12 22:27:56,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:56,814:INFO:Checking exceptions
2025-05-12 22:27:56,814:INFO:Importing libraries
2025-05-12 22:27:56,815:INFO:Copying training dataset
2025-05-12 22:27:56,820:INFO:Defining folds
2025-05-12 22:27:56,820:INFO:Declaring metric variables
2025-05-12 22:27:56,824:INFO:Importing untrained model
2025-05-12 22:27:56,830:INFO:Linear Discriminant Analysis Imported successfully
2025-05-12 22:27:56,841:INFO:Starting cross validation
2025-05-12 22:27:56,843:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:57,000:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,006:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,015:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,031:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,057:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,139:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,153:INFO:Calculating mean and std
2025-05-12 22:27:57,156:INFO:Creating metrics dataframe
2025-05-12 22:27:57,160:INFO:Uploading results into container
2025-05-12 22:27:57,160:INFO:Uploading model into container now
2025-05-12 22:27:57,162:INFO:_master_model_container: 11
2025-05-12 22:27:57,162:INFO:_display_container: 2
2025-05-12 22:27:57,163:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-12 22:27:57,163:INFO:create_model() successfully completed......................................
2025-05-12 22:27:57,246:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:57,246:INFO:Creating metrics dataframe
2025-05-12 22:27:57,257:INFO:Initializing Extra Trees Classifier
2025-05-12 22:27:57,257:INFO:Total runtime is 0.09373947779337564 minutes
2025-05-12 22:27:57,261:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:57,262:INFO:Initializing create_model()
2025-05-12 22:27:57,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:57,262:INFO:Checking exceptions
2025-05-12 22:27:57,262:INFO:Importing libraries
2025-05-12 22:27:57,262:INFO:Copying training dataset
2025-05-12 22:27:57,267:INFO:Defining folds
2025-05-12 22:27:57,267:INFO:Declaring metric variables
2025-05-12 22:27:57,272:INFO:Importing untrained model
2025-05-12 22:27:57,277:INFO:Extra Trees Classifier Imported successfully
2025-05-12 22:27:57,288:INFO:Starting cross validation
2025-05-12 22:27:57,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:57,872:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,890:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,955:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:58,242:INFO:Calculating mean and std
2025-05-12 22:27:58,243:INFO:Creating metrics dataframe
2025-05-12 22:27:58,244:INFO:Uploading results into container
2025-05-12 22:27:58,246:INFO:Uploading model into container now
2025-05-12 22:27:58,246:INFO:_master_model_container: 12
2025-05-12 22:27:58,246:INFO:_display_container: 2
2025-05-12 22:27:58,247:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-12 22:27:58,247:INFO:create_model() successfully completed......................................
2025-05-12 22:27:58,330:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:58,331:INFO:Creating metrics dataframe
2025-05-12 22:27:58,344:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:27:58,344:INFO:Total runtime is 0.11185899178187052 minutes
2025-05-12 22:27:58,348:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:58,348:INFO:Initializing create_model()
2025-05-12 22:27:58,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:58,349:INFO:Checking exceptions
2025-05-12 22:27:58,349:INFO:Importing libraries
2025-05-12 22:27:58,349:INFO:Copying training dataset
2025-05-12 22:27:58,357:INFO:Defining folds
2025-05-12 22:27:58,357:INFO:Declaring metric variables
2025-05-12 22:27:58,360:INFO:Importing untrained model
2025-05-12 22:27:58,364:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:27:58,373:INFO:Starting cross validation
2025-05-12 22:27:58,376:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:58,832:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:58,853:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:58,863:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,020:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,033:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,118:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,133:INFO:Calculating mean and std
2025-05-12 22:27:59,136:INFO:Creating metrics dataframe
2025-05-12 22:27:59,139:INFO:Uploading results into container
2025-05-12 22:27:59,139:INFO:Uploading model into container now
2025-05-12 22:27:59,140:INFO:_master_model_container: 13
2025-05-12 22:27:59,140:INFO:_display_container: 2
2025-05-12 22:27:59,141:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:27:59,143:INFO:create_model() successfully completed......................................
2025-05-12 22:27:59,240:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:59,240:INFO:Creating metrics dataframe
2025-05-12 22:27:59,251:INFO:Initializing Dummy Classifier
2025-05-12 22:27:59,251:INFO:Total runtime is 0.12696446975072223 minutes
2025-05-12 22:27:59,255:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:59,256:INFO:Initializing create_model()
2025-05-12 22:27:59,256:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:59,256:INFO:Checking exceptions
2025-05-12 22:27:59,256:INFO:Importing libraries
2025-05-12 22:27:59,256:INFO:Copying training dataset
2025-05-12 22:27:59,261:INFO:Defining folds
2025-05-12 22:27:59,261:INFO:Declaring metric variables
2025-05-12 22:27:59,265:INFO:Importing untrained model
2025-05-12 22:27:59,270:INFO:Dummy Classifier Imported successfully
2025-05-12 22:27:59,279:INFO:Starting cross validation
2025-05-12 22:27:59,281:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:59,443:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,445:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,459:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,467:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,470:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,472:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,477:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,497:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,565:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,566:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,582:INFO:Calculating mean and std
2025-05-12 22:27:59,584:INFO:Creating metrics dataframe
2025-05-12 22:27:59,586:INFO:Uploading results into container
2025-05-12 22:27:59,587:INFO:Uploading model into container now
2025-05-12 22:27:59,587:INFO:_master_model_container: 14
2025-05-12 22:27:59,588:INFO:_display_container: 2
2025-05-12 22:27:59,588:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:27:59,588:INFO:create_model() successfully completed......................................
2025-05-12 22:27:59,669:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:59,669:INFO:Creating metrics dataframe
2025-05-12 22:27:59,680:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:27:59,695:INFO:Initializing create_model()
2025-05-12 22:27:59,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:59,696:INFO:Checking exceptions
2025-05-12 22:27:59,698:INFO:Importing libraries
2025-05-12 22:27:59,698:INFO:Copying training dataset
2025-05-12 22:27:59,703:INFO:Defining folds
2025-05-12 22:27:59,704:INFO:Declaring metric variables
2025-05-12 22:27:59,704:INFO:Importing untrained model
2025-05-12 22:27:59,704:INFO:Declaring custom model
2025-05-12 22:27:59,704:INFO:Dummy Classifier Imported successfully
2025-05-12 22:27:59,706:INFO:Cross validation set to False
2025-05-12 22:27:59,706:INFO:Fitting Model
2025-05-12 22:27:59,749:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:27:59,749:INFO:create_model() successfully completed......................................
2025-05-12 22:27:59,849:INFO:_master_model_container: 14
2025-05-12 22:27:59,849:INFO:_display_container: 2
2025-05-12 22:27:59,849:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:27:59,849:INFO:compare_models() successfully completed......................................
2025-05-12 22:27:59,870:INFO:Initializing create_model()
2025-05-12 22:27:59,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:59,871:INFO:Checking exceptions
2025-05-12 22:27:59,895:INFO:Importing libraries
2025-05-12 22:27:59,895:INFO:Copying training dataset
2025-05-12 22:27:59,900:INFO:Defining folds
2025-05-12 22:27:59,900:INFO:Declaring metric variables
2025-05-12 22:27:59,906:INFO:Importing untrained model
2025-05-12 22:27:59,911:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:27:59,921:INFO:Starting cross validation
2025-05-12 22:27:59,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:00,327:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:00,332:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:00,363:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:00,533:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:00,566:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:00,676:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:00,694:INFO:Calculating mean and std
2025-05-12 22:28:00,694:INFO:Creating metrics dataframe
2025-05-12 22:28:00,704:INFO:Finalizing model
2025-05-12 22:28:00,779:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:28:00,779:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000074 seconds.
2025-05-12 22:28:00,779:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-12 22:28:00,779:INFO:[LightGBM] [Info] Total Bins 117
2025-05-12 22:28:00,779:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:28:00,779:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:28:00,779:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:28:00,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,815:INFO:Uploading results into container
2025-05-12 22:28:00,816:INFO:Uploading model into container now
2025-05-12 22:28:00,841:INFO:_master_model_container: 15
2025-05-12 22:28:00,841:INFO:_display_container: 3
2025-05-12 22:28:00,843:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:28:00,843:INFO:create_model() successfully completed......................................
2025-05-12 22:28:00,972:INFO:Initializing tune_model()
2025-05-12 22:28:00,972:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:28:00,972:INFO:Checking exceptions
2025-05-12 22:28:01,001:INFO:Copying training dataset
2025-05-12 22:28:01,010:INFO:Checking base model
2025-05-12 22:28:01,010:INFO:Base model : Light Gradient Boosting Machine
2025-05-12 22:28:01,022:INFO:Declaring metric variables
2025-05-12 22:28:01,029:INFO:Defining Hyperparameters
2025-05-12 22:28:01,147:INFO:Tuning with n_jobs=-1
2025-05-12 22:28:01,147:INFO:Initializing RandomizedSearchCV
2025-05-12 22:28:08,121:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2025-05-12 22:28:08,123:INFO:Hyperparameter search completed
2025-05-12 22:28:08,124:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:08,126:INFO:Initializing create_model()
2025-05-12 22:28:08,126:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D519ADD50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2025-05-12 22:28:08,126:INFO:Checking exceptions
2025-05-12 22:28:08,126:INFO:Importing libraries
2025-05-12 22:28:08,127:INFO:Copying training dataset
2025-05-12 22:28:08,135:INFO:Defining folds
2025-05-12 22:28:08,135:INFO:Declaring metric variables
2025-05-12 22:28:08,140:INFO:Importing untrained model
2025-05-12 22:28:08,141:INFO:Declaring custom model
2025-05-12 22:28:08,150:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:28:08,164:INFO:Starting cross validation
2025-05-12 22:28:08,166:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:08,487:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,488:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,491:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,519:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,547:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,550:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,647:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,689:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,731:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,733:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,749:INFO:Calculating mean and std
2025-05-12 22:28:08,751:INFO:Creating metrics dataframe
2025-05-12 22:28:08,761:INFO:Finalizing model
2025-05-12 22:28:08,831:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:28:08,831:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:28:08,831:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:28:08,833:INFO:[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.
2025-05-12 22:28:08,834:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:28:08,834:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:28:08,834:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:28:08,834:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:28:08,834:INFO:[LightGBM] [Info] Total Bins 0
2025-05-12 22:28:08,834:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 0
2025-05-12 22:28:08,835:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:28:08,835:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:28:08,835:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,835:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,835:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,835:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,853:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,853:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,866:INFO:Uploading results into container
2025-05-12 22:28:08,867:INFO:Uploading model into container now
2025-05-12 22:28:08,868:INFO:_master_model_container: 16
2025-05-12 22:28:08,868:INFO:_display_container: 4
2025-05-12 22:28:08,869:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:28:08,869:INFO:create_model() successfully completed......................................
2025-05-12 22:28:08,977:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:08,979:INFO:choose_better activated
2025-05-12 22:28:08,983:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:08,984:INFO:Initializing create_model()
2025-05-12 22:28:08,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:08,984:INFO:Checking exceptions
2025-05-12 22:28:08,986:INFO:Importing libraries
2025-05-12 22:28:08,986:INFO:Copying training dataset
2025-05-12 22:28:08,990:INFO:Defining folds
2025-05-12 22:28:08,990:INFO:Declaring metric variables
2025-05-12 22:28:08,990:INFO:Importing untrained model
2025-05-12 22:28:08,990:INFO:Declaring custom model
2025-05-12 22:28:08,991:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:28:08,993:INFO:Starting cross validation
2025-05-12 22:28:08,995:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:09,391:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:09,401:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:09,451:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:09,464:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:09,587:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:09,773:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:09,788:INFO:Calculating mean and std
2025-05-12 22:28:09,789:INFO:Creating metrics dataframe
2025-05-12 22:28:09,793:INFO:Finalizing model
2025-05-12 22:28:09,868:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:28:09,868:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000068 seconds.
2025-05-12 22:28:09,868:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-12 22:28:09,868:INFO:[LightGBM] [Info] Total Bins 117
2025-05-12 22:28:09,869:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:28:09,869:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:28:09,869:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:28:09,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,897:INFO:Uploading results into container
2025-05-12 22:28:09,898:INFO:Uploading model into container now
2025-05-12 22:28:09,899:INFO:_master_model_container: 17
2025-05-12 22:28:09,899:INFO:_display_container: 5
2025-05-12 22:28:09,899:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:28:09,899:INFO:create_model() successfully completed......................................
2025-05-12 22:28:10,008:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:10,009:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7891
2025-05-12 22:28:10,011:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8291
2025-05-12 22:28:10,012:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-12 22:28:10,013:INFO:choose_better completed
2025-05-12 22:28:10,028:INFO:_master_model_container: 17
2025-05-12 22:28:10,029:INFO:_display_container: 4
2025-05-12 22:28:10,029:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:28:10,030:INFO:tune_model() successfully completed......................................
2025-05-12 22:28:10,164:INFO:Initializing evaluate_model()
2025-05-12 22:28:10,164:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:28:10,178:INFO:Initializing plot_model()
2025-05-12 22:28:10,178:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:28:10,179:INFO:Checking exceptions
2025-05-12 22:28:10,181:INFO:Preloading libraries
2025-05-12 22:28:10,183:INFO:Copying training dataset
2025-05-12 22:28:10,183:INFO:Plot type: pipeline
2025-05-12 22:28:10,412:INFO:Visual Rendered Successfully
2025-05-12 22:28:10,488:INFO:plot_model() successfully completed......................................
2025-05-12 22:28:10,513:INFO:Initializing predict_model()
2025-05-12 22:28:10,513:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027D517ECD60>)
2025-05-12 22:28:10,513:INFO:Checking exceptions
2025-05-12 22:28:10,513:INFO:Preloading libraries
2025-05-12 22:28:10,631:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:10,785:INFO:Initializing save_model()
2025-05-12 22:28:10,785:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-12 22:28:10,785:INFO:Adding model into prep_pipe
2025-05-12 22:28:10,799:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:28:10,817:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-12 22:28:10,817:INFO:save_model() successfully completed......................................
2025-05-12 22:28:14,026:INFO:PyCaret ClassificationExperiment
2025-05-12 22:28:14,027:INFO:Logging name: clf-default-name
2025-05-12 22:28:14,027:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-12 22:28:14,027:INFO:version 3.3.2
2025-05-12 22:28:14,027:INFO:Initializing setup()
2025-05-12 22:28:14,027:INFO:self.USI: a35d
2025-05-12 22:28:14,027:INFO:self._variable_keys: {'fold_groups_param', 'memory', 'n_jobs_param', 'fold_generator', 'X', 'seed', '_available_plots', '_ml_usecase', 'y_train', 'html_param', 'logging_param', 'target_param', 'idx', 'log_plots_param', 'pipeline', 'fix_imbalance', 'gpu_n_jobs_param', 'y_test', 'exp_id', 'y', 'is_multiclass', 'data', 'gpu_param', 'X_train', 'USI', 'exp_name_log', 'fold_shuffle_param', 'X_test'}
2025-05-12 22:28:14,027:INFO:Checking environment
2025-05-12 22:28:14,027:INFO:python_version: 3.11.8
2025-05-12 22:28:14,027:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:28:14,027:INFO:machine: AMD64
2025-05-12 22:28:14,027:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:28:14,034:INFO:Memory: svmem(total=16907886592, available=2407600128, percent=85.8, used=14500286464, free=2407600128)
2025-05-12 22:28:14,034:INFO:Physical Core: 4
2025-05-12 22:28:14,034:INFO:Logical Core: 8
2025-05-12 22:28:14,034:INFO:Checking libraries
2025-05-12 22:28:14,034:INFO:System:
2025-05-12 22:28:14,035:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:28:14,035:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:28:14,035:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:28:14,035:INFO:PyCaret required dependencies:
2025-05-12 22:28:14,035:INFO:                 pip: 24.0
2025-05-12 22:28:14,035:INFO:          setuptools: 65.5.0
2025-05-12 22:28:14,035:INFO:             pycaret: 3.3.2
2025-05-12 22:28:14,035:INFO:             IPython: 9.2.0
2025-05-12 22:28:14,035:INFO:          ipywidgets: 8.1.7
2025-05-12 22:28:14,035:INFO:                tqdm: 4.67.1
2025-05-12 22:28:14,035:INFO:               numpy: 1.26.4
2025-05-12 22:28:14,035:INFO:              pandas: 2.1.4
2025-05-12 22:28:14,035:INFO:              jinja2: 3.1.6
2025-05-12 22:28:14,035:INFO:               scipy: 1.11.4
2025-05-12 22:28:14,035:INFO:              joblib: 1.3.2
2025-05-12 22:28:14,035:INFO:             sklearn: 1.4.2
2025-05-12 22:28:14,035:INFO:                pyod: 2.0.5
2025-05-12 22:28:14,035:INFO:            imblearn: 0.13.0
2025-05-12 22:28:14,036:INFO:   category_encoders: 2.7.0
2025-05-12 22:28:14,036:INFO:            lightgbm: 4.6.0
2025-05-12 22:28:14,036:INFO:               numba: 0.61.2
2025-05-12 22:28:14,036:INFO:            requests: 2.32.3
2025-05-12 22:28:14,036:INFO:          matplotlib: 3.7.5
2025-05-12 22:28:14,036:INFO:          scikitplot: 0.3.7
2025-05-12 22:28:14,036:INFO:         yellowbrick: 1.5
2025-05-12 22:28:14,036:INFO:              plotly: 5.24.1
2025-05-12 22:28:14,036:INFO:    plotly-resampler: Not installed
2025-05-12 22:28:14,036:INFO:             kaleido: 0.2.1
2025-05-12 22:28:14,036:INFO:           schemdraw: 0.15
2025-05-12 22:28:14,036:INFO:         statsmodels: 0.14.4
2025-05-12 22:28:14,036:INFO:              sktime: 0.26.0
2025-05-12 22:28:14,036:INFO:               tbats: 1.1.3
2025-05-12 22:28:14,036:INFO:            pmdarima: 2.0.4
2025-05-12 22:28:14,036:INFO:              psutil: 7.0.0
2025-05-12 22:28:14,036:INFO:          markupsafe: 3.0.2
2025-05-12 22:28:14,036:INFO:             pickle5: Not installed
2025-05-12 22:28:14,036:INFO:         cloudpickle: 3.1.1
2025-05-12 22:28:14,037:INFO:         deprecation: 2.1.0
2025-05-12 22:28:14,037:INFO:              xxhash: 3.5.0
2025-05-12 22:28:14,037:INFO:           wurlitzer: Not installed
2025-05-12 22:28:14,037:INFO:PyCaret optional dependencies:
2025-05-12 22:28:14,037:INFO:                shap: Not installed
2025-05-12 22:28:14,037:INFO:           interpret: Not installed
2025-05-12 22:28:14,037:INFO:                umap: Not installed
2025-05-12 22:28:14,037:INFO:     ydata_profiling: Not installed
2025-05-12 22:28:14,037:INFO:  explainerdashboard: Not installed
2025-05-12 22:28:14,037:INFO:             autoviz: Not installed
2025-05-12 22:28:14,037:INFO:           fairlearn: Not installed
2025-05-12 22:28:14,037:INFO:          deepchecks: Not installed
2025-05-12 22:28:14,037:INFO:             xgboost: Not installed
2025-05-12 22:28:14,037:INFO:            catboost: Not installed
2025-05-12 22:28:14,038:INFO:              kmodes: Not installed
2025-05-12 22:28:14,038:INFO:             mlxtend: Not installed
2025-05-12 22:28:14,038:INFO:       statsforecast: Not installed
2025-05-12 22:28:14,038:INFO:        tune_sklearn: Not installed
2025-05-12 22:28:14,038:INFO:                 ray: Not installed
2025-05-12 22:28:14,038:INFO:            hyperopt: Not installed
2025-05-12 22:28:14,038:INFO:              optuna: Not installed
2025-05-12 22:28:14,038:INFO:               skopt: Not installed
2025-05-12 22:28:14,038:INFO:              mlflow: Not installed
2025-05-12 22:28:14,038:INFO:              gradio: Not installed
2025-05-12 22:28:14,038:INFO:             fastapi: Not installed
2025-05-12 22:28:14,038:INFO:             uvicorn: Not installed
2025-05-12 22:28:14,038:INFO:              m2cgen: Not installed
2025-05-12 22:28:14,038:INFO:           evidently: Not installed
2025-05-12 22:28:14,038:INFO:               fugue: Not installed
2025-05-12 22:28:14,039:INFO:           streamlit: Not installed
2025-05-12 22:28:14,039:INFO:             prophet: Not installed
2025-05-12 22:28:14,039:INFO:None
2025-05-12 22:28:14,039:INFO:Set up data.
2025-05-12 22:28:14,043:INFO:Set up folding strategy.
2025-05-12 22:28:14,043:INFO:Set up train/test split.
2025-05-12 22:28:14,046:INFO:Set up index.
2025-05-12 22:28:14,047:INFO:Assigning column types.
2025-05-12 22:28:14,049:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:28:14,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:28:14,099:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:28:14,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,166:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:28:14,167:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:28:14,194:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,194:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,195:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:28:14,237:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:28:14,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,266:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,310:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:28:14,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,340:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-12 22:28:14,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,487:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,487:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,489:INFO:Preparing preprocessing pipeline...
2025-05-12 22:28:14,490:INFO:Set up simple imputation.
2025-05-12 22:28:14,491:INFO:Set up encoding of categorical features.
2025-05-12 22:28:14,491:INFO:Set up feature normalization.
2025-05-12 22:28:14,550:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:28:14,555:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:28:14,555:INFO:Creating final display dataframe.
2025-05-12 22:28:14,716:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              a35d
2025-05-12 22:28:14,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,864:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,865:INFO:setup() successfully completed in 0.84s...............
2025-05-12 22:28:14,881:INFO:Initializing compare_models()
2025-05-12 22:28:14,881:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-12 22:28:14,881:INFO:Checking exceptions
2025-05-12 22:28:14,884:INFO:Preparing display monitor
2025-05-12 22:28:14,913:INFO:Initializing Logistic Regression
2025-05-12 22:28:14,913:INFO:Total runtime is 0.0 minutes
2025-05-12 22:28:14,917:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:14,917:INFO:Initializing create_model()
2025-05-12 22:28:14,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:14,918:INFO:Checking exceptions
2025-05-12 22:28:14,918:INFO:Importing libraries
2025-05-12 22:28:14,918:INFO:Copying training dataset
2025-05-12 22:28:14,924:INFO:Defining folds
2025-05-12 22:28:14,924:INFO:Declaring metric variables
2025-05-12 22:28:14,930:INFO:Importing untrained model
2025-05-12 22:28:14,935:INFO:Logistic Regression Imported successfully
2025-05-12 22:28:14,945:INFO:Starting cross validation
2025-05-12 22:28:14,947:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:15,150:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,177:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,178:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,186:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,193:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,205:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,286:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,299:INFO:Calculating mean and std
2025-05-12 22:28:15,300:INFO:Creating metrics dataframe
2025-05-12 22:28:15,301:INFO:Uploading results into container
2025-05-12 22:28:15,303:INFO:Uploading model into container now
2025-05-12 22:28:15,303:INFO:_master_model_container: 1
2025-05-12 22:28:15,303:INFO:_display_container: 2
2025-05-12 22:28:15,304:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-12 22:28:15,304:INFO:create_model() successfully completed......................................
2025-05-12 22:28:15,387:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:15,387:INFO:Creating metrics dataframe
2025-05-12 22:28:15,395:INFO:Initializing K Neighbors Classifier
2025-05-12 22:28:15,395:INFO:Total runtime is 0.00803908109664917 minutes
2025-05-12 22:28:15,399:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:15,399:INFO:Initializing create_model()
2025-05-12 22:28:15,400:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:15,400:INFO:Checking exceptions
2025-05-12 22:28:15,400:INFO:Importing libraries
2025-05-12 22:28:15,400:INFO:Copying training dataset
2025-05-12 22:28:15,403:INFO:Defining folds
2025-05-12 22:28:15,403:INFO:Declaring metric variables
2025-05-12 22:28:15,408:INFO:Importing untrained model
2025-05-12 22:28:15,411:INFO:K Neighbors Classifier Imported successfully
2025-05-12 22:28:15,420:INFO:Starting cross validation
2025-05-12 22:28:15,423:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:15,642:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,647:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,681:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,687:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,689:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,807:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,823:INFO:Calculating mean and std
2025-05-12 22:28:15,823:INFO:Creating metrics dataframe
2025-05-12 22:28:15,825:INFO:Uploading results into container
2025-05-12 22:28:15,826:INFO:Uploading model into container now
2025-05-12 22:28:15,826:INFO:_master_model_container: 2
2025-05-12 22:28:15,826:INFO:_display_container: 2
2025-05-12 22:28:15,827:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-12 22:28:15,827:INFO:create_model() successfully completed......................................
2025-05-12 22:28:15,909:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:15,909:INFO:Creating metrics dataframe
2025-05-12 22:28:15,916:INFO:Initializing Naive Bayes
2025-05-12 22:28:15,916:INFO:Total runtime is 0.016720116138458252 minutes
2025-05-12 22:28:15,921:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:15,922:INFO:Initializing create_model()
2025-05-12 22:28:15,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:15,922:INFO:Checking exceptions
2025-05-12 22:28:15,922:INFO:Importing libraries
2025-05-12 22:28:15,922:INFO:Copying training dataset
2025-05-12 22:28:15,927:INFO:Defining folds
2025-05-12 22:28:15,927:INFO:Declaring metric variables
2025-05-12 22:28:15,930:INFO:Importing untrained model
2025-05-12 22:28:15,936:INFO:Naive Bayes Imported successfully
2025-05-12 22:28:15,947:INFO:Starting cross validation
2025-05-12 22:28:15,949:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:16,100:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:16,104:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:16,113:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:16,216:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:16,227:INFO:Calculating mean and std
2025-05-12 22:28:16,228:INFO:Creating metrics dataframe
2025-05-12 22:28:16,230:INFO:Uploading results into container
2025-05-12 22:28:16,231:INFO:Uploading model into container now
2025-05-12 22:28:16,231:INFO:_master_model_container: 3
2025-05-12 22:28:16,232:INFO:_display_container: 2
2025-05-12 22:28:16,232:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-12 22:28:16,232:INFO:create_model() successfully completed......................................
2025-05-12 22:28:16,313:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:16,313:INFO:Creating metrics dataframe
2025-05-12 22:28:16,321:INFO:Initializing Decision Tree Classifier
2025-05-12 22:28:16,321:INFO:Total runtime is 0.023478575547536212 minutes
2025-05-12 22:28:16,324:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:16,326:INFO:Initializing create_model()
2025-05-12 22:28:16,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:16,326:INFO:Checking exceptions
2025-05-12 22:28:16,326:INFO:Importing libraries
2025-05-12 22:28:16,326:INFO:Copying training dataset
2025-05-12 22:28:16,330:INFO:Defining folds
2025-05-12 22:28:16,330:INFO:Declaring metric variables
2025-05-12 22:28:16,334:INFO:Importing untrained model
2025-05-12 22:28:16,341:INFO:Decision Tree Classifier Imported successfully
2025-05-12 22:28:16,349:INFO:Starting cross validation
2025-05-12 22:28:16,351:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:16,507:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:16,617:INFO:Calculating mean and std
2025-05-12 22:28:16,618:INFO:Creating metrics dataframe
2025-05-12 22:28:16,621:INFO:Uploading results into container
2025-05-12 22:28:16,622:INFO:Uploading model into container now
2025-05-12 22:28:16,622:INFO:_master_model_container: 4
2025-05-12 22:28:16,622:INFO:_display_container: 2
2025-05-12 22:28:16,623:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-12 22:28:16,623:INFO:create_model() successfully completed......................................
2025-05-12 22:28:16,699:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:16,700:INFO:Creating metrics dataframe
2025-05-12 22:28:16,710:INFO:Initializing SVM - Linear Kernel
2025-05-12 22:28:16,710:INFO:Total runtime is 0.029951679706573486 minutes
2025-05-12 22:28:16,714:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:16,714:INFO:Initializing create_model()
2025-05-12 22:28:16,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:16,716:INFO:Checking exceptions
2025-05-12 22:28:16,716:INFO:Importing libraries
2025-05-12 22:28:16,716:INFO:Copying training dataset
2025-05-12 22:28:16,720:INFO:Defining folds
2025-05-12 22:28:16,720:INFO:Declaring metric variables
2025-05-12 22:28:16,724:INFO:Importing untrained model
2025-05-12 22:28:16,730:INFO:SVM - Linear Kernel Imported successfully
2025-05-12 22:28:16,741:INFO:Starting cross validation
2025-05-12 22:28:16,743:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:16,900:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:16,937:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,028:INFO:Calculating mean and std
2025-05-12 22:28:17,030:INFO:Creating metrics dataframe
2025-05-12 22:28:17,032:INFO:Uploading results into container
2025-05-12 22:28:17,033:INFO:Uploading model into container now
2025-05-12 22:28:17,033:INFO:_master_model_container: 5
2025-05-12 22:28:17,034:INFO:_display_container: 2
2025-05-12 22:28:17,034:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-12 22:28:17,034:INFO:create_model() successfully completed......................................
2025-05-12 22:28:17,143:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:17,144:INFO:Creating metrics dataframe
2025-05-12 22:28:17,157:INFO:Initializing Ridge Classifier
2025-05-12 22:28:17,159:INFO:Total runtime is 0.03743065992991129 minutes
2025-05-12 22:28:17,166:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:17,167:INFO:Initializing create_model()
2025-05-12 22:28:17,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:17,167:INFO:Checking exceptions
2025-05-12 22:28:17,167:INFO:Importing libraries
2025-05-12 22:28:17,167:INFO:Copying training dataset
2025-05-12 22:28:17,178:INFO:Defining folds
2025-05-12 22:28:17,178:INFO:Declaring metric variables
2025-05-12 22:28:17,185:INFO:Importing untrained model
2025-05-12 22:28:17,193:INFO:Ridge Classifier Imported successfully
2025-05-12 22:28:17,209:INFO:Starting cross validation
2025-05-12 22:28:17,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:17,395:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,398:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,436:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,440:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,463:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,471:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,546:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,547:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,565:INFO:Calculating mean and std
2025-05-12 22:28:17,566:INFO:Creating metrics dataframe
2025-05-12 22:28:17,569:INFO:Uploading results into container
2025-05-12 22:28:17,570:INFO:Uploading model into container now
2025-05-12 22:28:17,571:INFO:_master_model_container: 6
2025-05-12 22:28:17,571:INFO:_display_container: 2
2025-05-12 22:28:17,571:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-12 22:28:17,573:INFO:create_model() successfully completed......................................
2025-05-12 22:28:17,679:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:17,679:INFO:Creating metrics dataframe
2025-05-12 22:28:17,689:INFO:Initializing Random Forest Classifier
2025-05-12 22:28:17,689:INFO:Total runtime is 0.046272607644399 minutes
2025-05-12 22:28:17,694:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:17,694:INFO:Initializing create_model()
2025-05-12 22:28:17,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:17,694:INFO:Checking exceptions
2025-05-12 22:28:17,694:INFO:Importing libraries
2025-05-12 22:28:17,694:INFO:Copying training dataset
2025-05-12 22:28:17,701:INFO:Defining folds
2025-05-12 22:28:17,701:INFO:Declaring metric variables
2025-05-12 22:28:17,709:INFO:Importing untrained model
2025-05-12 22:28:17,714:INFO:Random Forest Classifier Imported successfully
2025-05-12 22:28:17,724:INFO:Starting cross validation
2025-05-12 22:28:17,727:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:18,455:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,455:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,461:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,479:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,484:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,515:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,636:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,865:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,873:INFO:Calculating mean and std
2025-05-12 22:28:18,875:INFO:Creating metrics dataframe
2025-05-12 22:28:18,877:INFO:Uploading results into container
2025-05-12 22:28:18,877:INFO:Uploading model into container now
2025-05-12 22:28:18,878:INFO:_master_model_container: 7
2025-05-12 22:28:18,878:INFO:_display_container: 2
2025-05-12 22:28:18,878:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-12 22:28:18,878:INFO:create_model() successfully completed......................................
2025-05-12 22:28:18,953:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:18,953:INFO:Creating metrics dataframe
2025-05-12 22:28:18,961:INFO:Initializing Quadratic Discriminant Analysis
2025-05-12 22:28:18,961:INFO:Total runtime is 0.06747546990712483 minutes
2025-05-12 22:28:18,970:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:18,970:INFO:Initializing create_model()
2025-05-12 22:28:18,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:18,971:INFO:Checking exceptions
2025-05-12 22:28:18,971:INFO:Importing libraries
2025-05-12 22:28:18,971:INFO:Copying training dataset
2025-05-12 22:28:18,991:INFO:Defining folds
2025-05-12 22:28:18,991:INFO:Declaring metric variables
2025-05-12 22:28:18,998:INFO:Importing untrained model
2025-05-12 22:28:19,007:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-12 22:28:19,016:INFO:Starting cross validation
2025-05-12 22:28:19,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:19,116:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,119:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,120:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,125:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,131:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,140:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,163:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:19,259:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,265:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,311:INFO:Calculating mean and std
2025-05-12 22:28:19,312:INFO:Creating metrics dataframe
2025-05-12 22:28:19,313:INFO:Uploading results into container
2025-05-12 22:28:19,315:INFO:Uploading model into container now
2025-05-12 22:28:19,316:INFO:_master_model_container: 8
2025-05-12 22:28:19,316:INFO:_display_container: 2
2025-05-12 22:28:19,316:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-12 22:28:19,316:INFO:create_model() successfully completed......................................
2025-05-12 22:28:19,398:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:19,398:INFO:Creating metrics dataframe
2025-05-12 22:28:19,409:INFO:Initializing Ada Boost Classifier
2025-05-12 22:28:19,409:INFO:Total runtime is 0.07493642965952554 minutes
2025-05-12 22:28:19,414:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:19,414:INFO:Initializing create_model()
2025-05-12 22:28:19,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:19,414:INFO:Checking exceptions
2025-05-12 22:28:19,414:INFO:Importing libraries
2025-05-12 22:28:19,414:INFO:Copying training dataset
2025-05-12 22:28:19,419:INFO:Defining folds
2025-05-12 22:28:19,419:INFO:Declaring metric variables
2025-05-12 22:28:19,424:INFO:Importing untrained model
2025-05-12 22:28:19,427:INFO:Ada Boost Classifier Imported successfully
2025-05-12 22:28:19,437:INFO:Starting cross validation
2025-05-12 22:28:19,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:19,536:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,539:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,542:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,544:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,545:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,547:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,564:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,626:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,837:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:19,956:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,960:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,981:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:20,134:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:20,136:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:20,146:INFO:Calculating mean and std
2025-05-12 22:28:20,147:INFO:Creating metrics dataframe
2025-05-12 22:28:20,149:INFO:Uploading results into container
2025-05-12 22:28:20,151:INFO:Uploading model into container now
2025-05-12 22:28:20,151:INFO:_master_model_container: 9
2025-05-12 22:28:20,151:INFO:_display_container: 2
2025-05-12 22:28:20,153:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-12 22:28:20,153:INFO:create_model() successfully completed......................................
2025-05-12 22:28:20,231:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:20,231:INFO:Creating metrics dataframe
2025-05-12 22:28:20,241:INFO:Initializing Gradient Boosting Classifier
2025-05-12 22:28:20,242:INFO:Total runtime is 0.08881661097208658 minutes
2025-05-12 22:28:20,245:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:20,245:INFO:Initializing create_model()
2025-05-12 22:28:20,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:20,245:INFO:Checking exceptions
2025-05-12 22:28:20,245:INFO:Importing libraries
2025-05-12 22:28:20,245:INFO:Copying training dataset
2025-05-12 22:28:20,251:INFO:Defining folds
2025-05-12 22:28:20,251:INFO:Declaring metric variables
2025-05-12 22:28:20,255:INFO:Importing untrained model
2025-05-12 22:28:20,260:INFO:Gradient Boosting Classifier Imported successfully
2025-05-12 22:28:20,269:INFO:Starting cross validation
2025-05-12 22:28:20,270:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:20,717:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:20,916:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:20,934:INFO:Calculating mean and std
2025-05-12 22:28:20,935:INFO:Creating metrics dataframe
2025-05-12 22:28:20,937:INFO:Uploading results into container
2025-05-12 22:28:20,937:INFO:Uploading model into container now
2025-05-12 22:28:20,937:INFO:_master_model_container: 10
2025-05-12 22:28:20,937:INFO:_display_container: 2
2025-05-12 22:28:20,939:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-12 22:28:20,939:INFO:create_model() successfully completed......................................
2025-05-12 22:28:21,015:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:21,015:INFO:Creating metrics dataframe
2025-05-12 22:28:21,026:INFO:Initializing Linear Discriminant Analysis
2025-05-12 22:28:21,026:INFO:Total runtime is 0.10188523133595784 minutes
2025-05-12 22:28:21,029:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:21,029:INFO:Initializing create_model()
2025-05-12 22:28:21,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:21,030:INFO:Checking exceptions
2025-05-12 22:28:21,030:INFO:Importing libraries
2025-05-12 22:28:21,030:INFO:Copying training dataset
2025-05-12 22:28:21,036:INFO:Defining folds
2025-05-12 22:28:21,036:INFO:Declaring metric variables
2025-05-12 22:28:21,041:INFO:Importing untrained model
2025-05-12 22:28:21,044:INFO:Linear Discriminant Analysis Imported successfully
2025-05-12 22:28:21,053:INFO:Starting cross validation
2025-05-12 22:28:21,055:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:21,206:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:21,207:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:21,229:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:21,230:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:21,245:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:21,323:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:21,330:INFO:Calculating mean and std
2025-05-12 22:28:21,331:INFO:Creating metrics dataframe
2025-05-12 22:28:21,333:INFO:Uploading results into container
2025-05-12 22:28:21,334:INFO:Uploading model into container now
2025-05-12 22:28:21,334:INFO:_master_model_container: 11
2025-05-12 22:28:21,334:INFO:_display_container: 2
2025-05-12 22:28:21,336:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-12 22:28:21,336:INFO:create_model() successfully completed......................................
2025-05-12 22:28:21,417:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:21,417:INFO:Creating metrics dataframe
2025-05-12 22:28:21,427:INFO:Initializing Extra Trees Classifier
2025-05-12 22:28:21,427:INFO:Total runtime is 0.10856681664784748 minutes
2025-05-12 22:28:21,430:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:21,431:INFO:Initializing create_model()
2025-05-12 22:28:21,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:21,431:INFO:Checking exceptions
2025-05-12 22:28:21,431:INFO:Importing libraries
2025-05-12 22:28:21,431:INFO:Copying training dataset
2025-05-12 22:28:21,437:INFO:Defining folds
2025-05-12 22:28:21,437:INFO:Declaring metric variables
2025-05-12 22:28:21,440:INFO:Importing untrained model
2025-05-12 22:28:21,444:INFO:Extra Trees Classifier Imported successfully
2025-05-12 22:28:21,454:INFO:Starting cross validation
2025-05-12 22:28:21,455:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:22,098:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:22,147:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:22,198:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:22,459:INFO:Calculating mean and std
2025-05-12 22:28:22,461:INFO:Creating metrics dataframe
2025-05-12 22:28:22,463:INFO:Uploading results into container
2025-05-12 22:28:22,464:INFO:Uploading model into container now
2025-05-12 22:28:22,466:INFO:_master_model_container: 12
2025-05-12 22:28:22,466:INFO:_display_container: 2
2025-05-12 22:28:22,466:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-12 22:28:22,466:INFO:create_model() successfully completed......................................
2025-05-12 22:28:22,544:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:22,544:INFO:Creating metrics dataframe
2025-05-12 22:28:22,554:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:28:22,554:INFO:Total runtime is 0.1273613731066386 minutes
2025-05-12 22:28:22,558:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:22,559:INFO:Initializing create_model()
2025-05-12 22:28:22,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:22,559:INFO:Checking exceptions
2025-05-12 22:28:22,559:INFO:Importing libraries
2025-05-12 22:28:22,559:INFO:Copying training dataset
2025-05-12 22:28:22,565:INFO:Defining folds
2025-05-12 22:28:22,565:INFO:Declaring metric variables
2025-05-12 22:28:22,569:INFO:Importing untrained model
2025-05-12 22:28:22,575:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:28:22,584:INFO:Starting cross validation
2025-05-12 22:28:22,587:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:22,917:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:22,944:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:22,948:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,046:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,068:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,228:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,253:INFO:Calculating mean and std
2025-05-12 22:28:23,255:INFO:Creating metrics dataframe
2025-05-12 22:28:23,259:INFO:Uploading results into container
2025-05-12 22:28:23,260:INFO:Uploading model into container now
2025-05-12 22:28:23,261:INFO:_master_model_container: 13
2025-05-12 22:28:23,261:INFO:_display_container: 2
2025-05-12 22:28:23,265:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:28:23,265:INFO:create_model() successfully completed......................................
2025-05-12 22:28:23,372:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:23,372:INFO:Creating metrics dataframe
2025-05-12 22:28:23,386:INFO:Initializing Dummy Classifier
2025-05-12 22:28:23,386:INFO:Total runtime is 0.14121649265289307 minutes
2025-05-12 22:28:23,390:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:23,391:INFO:Initializing create_model()
2025-05-12 22:28:23,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:23,391:INFO:Checking exceptions
2025-05-12 22:28:23,391:INFO:Importing libraries
2025-05-12 22:28:23,391:INFO:Copying training dataset
2025-05-12 22:28:23,397:INFO:Defining folds
2025-05-12 22:28:23,397:INFO:Declaring metric variables
2025-05-12 22:28:23,401:INFO:Importing untrained model
2025-05-12 22:28:23,408:INFO:Dummy Classifier Imported successfully
2025-05-12 22:28:23,419:INFO:Starting cross validation
2025-05-12 22:28:23,421:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:23,594:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,600:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,607:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,624:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,637:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,657:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,659:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,660:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,776:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,786:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,799:INFO:Calculating mean and std
2025-05-12 22:28:23,802:INFO:Creating metrics dataframe
2025-05-12 22:28:23,806:INFO:Uploading results into container
2025-05-12 22:28:23,808:INFO:Uploading model into container now
2025-05-12 22:28:23,808:INFO:_master_model_container: 14
2025-05-12 22:28:23,809:INFO:_display_container: 2
2025-05-12 22:28:23,809:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:28:23,809:INFO:create_model() successfully completed......................................
2025-05-12 22:28:23,920:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:23,921:INFO:Creating metrics dataframe
2025-05-12 22:28:23,936:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:28:23,949:INFO:Initializing create_model()
2025-05-12 22:28:23,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:23,949:INFO:Checking exceptions
2025-05-12 22:28:23,951:INFO:Importing libraries
2025-05-12 22:28:23,951:INFO:Copying training dataset
2025-05-12 22:28:23,956:INFO:Defining folds
2025-05-12 22:28:23,956:INFO:Declaring metric variables
2025-05-12 22:28:23,956:INFO:Importing untrained model
2025-05-12 22:28:23,957:INFO:Declaring custom model
2025-05-12 22:28:23,957:INFO:Dummy Classifier Imported successfully
2025-05-12 22:28:23,958:INFO:Cross validation set to False
2025-05-12 22:28:23,958:INFO:Fitting Model
2025-05-12 22:28:24,039:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:28:24,040:INFO:create_model() successfully completed......................................
2025-05-12 22:28:24,156:INFO:_master_model_container: 14
2025-05-12 22:28:24,156:INFO:_display_container: 2
2025-05-12 22:28:24,156:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:28:24,156:INFO:compare_models() successfully completed......................................
2025-05-12 22:28:24,184:INFO:Initializing create_model()
2025-05-12 22:28:24,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=dummy, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:24,186:INFO:Checking exceptions
2025-05-12 22:28:24,206:INFO:Importing libraries
2025-05-12 22:28:24,207:INFO:Copying training dataset
2025-05-12 22:28:24,214:INFO:Defining folds
2025-05-12 22:28:24,214:INFO:Declaring metric variables
2025-05-12 22:28:24,219:INFO:Importing untrained model
2025-05-12 22:28:24,224:INFO:Dummy Classifier Imported successfully
2025-05-12 22:28:24,237:INFO:Starting cross validation
2025-05-12 22:28:24,239:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:24,407:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,416:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,435:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,449:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,461:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,476:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,481:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,483:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,532:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,539:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,552:INFO:Calculating mean and std
2025-05-12 22:28:24,552:INFO:Creating metrics dataframe
2025-05-12 22:28:24,559:INFO:Finalizing model
2025-05-12 22:28:24,613:INFO:Uploading results into container
2025-05-12 22:28:24,615:INFO:Uploading model into container now
2025-05-12 22:28:24,627:INFO:_master_model_container: 15
2025-05-12 22:28:24,627:INFO:_display_container: 3
2025-05-12 22:28:24,627:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:28:24,627:INFO:create_model() successfully completed......................................
2025-05-12 22:28:24,839:INFO:Initializing tune_model()
2025-05-12 22:28:24,839:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:28:24,839:INFO:Checking exceptions
2025-05-12 22:28:24,864:INFO:Copying training dataset
2025-05-12 22:28:24,869:INFO:Checking base model
2025-05-12 22:28:24,869:INFO:Base model : Dummy Classifier
2025-05-12 22:28:24,874:INFO:Declaring metric variables
2025-05-12 22:28:24,881:INFO:Defining Hyperparameters
2025-05-12 22:28:24,881:INFO:10 is bigger than total combinations 4, setting search algorithm to grid
2025-05-12 22:28:24,968:INFO:Tuning with n_jobs=-1
2025-05-12 22:28:24,968:INFO:Initializing GridSearchCV
2025-05-12 22:28:25,921:INFO:best_params: {'actual_estimator__strategy': 'most_frequent'}
2025-05-12 22:28:25,923:INFO:Hyperparameter search completed
2025-05-12 22:28:25,923:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:25,924:INFO:Initializing create_model()
2025-05-12 22:28:25,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51BFCB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'strategy': 'most_frequent'})
2025-05-12 22:28:25,924:INFO:Checking exceptions
2025-05-12 22:28:25,924:INFO:Importing libraries
2025-05-12 22:28:25,924:INFO:Copying training dataset
2025-05-12 22:28:25,931:INFO:Defining folds
2025-05-12 22:28:25,933:INFO:Declaring metric variables
2025-05-12 22:28:25,937:INFO:Importing untrained model
2025-05-12 22:28:25,937:INFO:Declaring custom model
2025-05-12 22:28:25,943:INFO:Dummy Classifier Imported successfully
2025-05-12 22:28:25,955:INFO:Starting cross validation
2025-05-12 22:28:25,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:26,124:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,129:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,133:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,136:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,136:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,154:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,162:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,169:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,235:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,240:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,253:INFO:Calculating mean and std
2025-05-12 22:28:26,254:INFO:Creating metrics dataframe
2025-05-12 22:28:26,261:INFO:Finalizing model
2025-05-12 22:28:26,311:INFO:Uploading results into container
2025-05-12 22:28:26,313:INFO:Uploading model into container now
2025-05-12 22:28:26,313:INFO:_master_model_container: 16
2025-05-12 22:28:26,313:INFO:_display_container: 4
2025-05-12 22:28:26,313:INFO:DummyClassifier(constant=None, random_state=123, strategy='most_frequent')
2025-05-12 22:28:26,313:INFO:create_model() successfully completed......................................
2025-05-12 22:28:26,389:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:26,390:INFO:choose_better activated
2025-05-12 22:28:26,393:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:26,394:INFO:Initializing create_model()
2025-05-12 22:28:26,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:26,394:INFO:Checking exceptions
2025-05-12 22:28:26,396:INFO:Importing libraries
2025-05-12 22:28:26,396:INFO:Copying training dataset
2025-05-12 22:28:26,400:INFO:Defining folds
2025-05-12 22:28:26,400:INFO:Declaring metric variables
2025-05-12 22:28:26,401:INFO:Importing untrained model
2025-05-12 22:28:26,401:INFO:Declaring custom model
2025-05-12 22:28:26,401:INFO:Dummy Classifier Imported successfully
2025-05-12 22:28:26,401:INFO:Starting cross validation
2025-05-12 22:28:26,403:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:26,546:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,551:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,551:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,553:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,565:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,568:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,581:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,661:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,663:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,679:INFO:Calculating mean and std
2025-05-12 22:28:26,679:INFO:Creating metrics dataframe
2025-05-12 22:28:26,682:INFO:Finalizing model
2025-05-12 22:28:26,724:INFO:Uploading results into container
2025-05-12 22:28:26,724:INFO:Uploading model into container now
2025-05-12 22:28:26,726:INFO:_master_model_container: 17
2025-05-12 22:28:26,726:INFO:_display_container: 5
2025-05-12 22:28:26,726:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:28:26,726:INFO:create_model() successfully completed......................................
2025-05-12 22:28:26,810:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:26,810:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior') result for Accuracy is 0.8291
2025-05-12 22:28:26,811:INFO:DummyClassifier(constant=None, random_state=123, strategy='most_frequent') result for Accuracy is 0.8291
2025-05-12 22:28:26,811:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior') is best model
2025-05-12 22:28:26,811:INFO:choose_better completed
2025-05-12 22:28:26,811:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:28:26,822:INFO:_master_model_container: 17
2025-05-12 22:28:26,822:INFO:_display_container: 4
2025-05-12 22:28:26,822:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:28:26,822:INFO:tune_model() successfully completed......................................
2025-05-12 22:28:26,914:INFO:Initializing evaluate_model()
2025-05-12 22:28:26,914:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:28:26,927:INFO:Initializing plot_model()
2025-05-12 22:28:26,928:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:28:26,928:INFO:Checking exceptions
2025-05-12 22:28:26,930:INFO:Preloading libraries
2025-05-12 22:28:26,930:INFO:Copying training dataset
2025-05-12 22:28:26,930:INFO:Plot type: pipeline
2025-05-12 22:28:27,056:INFO:Visual Rendered Successfully
2025-05-12 22:28:27,141:INFO:plot_model() successfully completed......................................
2025-05-12 22:28:27,163:INFO:Initializing predict_model()
2025-05-12 22:28:27,164:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027D51A91B20>)
2025-05-12 22:28:27,164:INFO:Checking exceptions
2025-05-12 22:28:27,164:INFO:Preloading libraries
2025-05-12 22:28:27,276:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:27,391:INFO:Initializing save_model()
2025-05-12 22:28:27,391:INFO:save_model(model=DummyClassifier(constant=None, random_state=123, strategy='prior'), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-12 22:28:27,391:INFO:Adding model into prep_pipe
2025-05-12 22:28:27,399:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:28:27,405:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 DummyClassifier(constant=None, random_state=123,
                                 strategy='prior'))],
         verbose=False)
2025-05-12 22:28:27,405:INFO:save_model() successfully completed......................................
2025-05-12 22:29:48,072:INFO:Initializing predict_model()
2025-05-12 22:29:48,072:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027D51A90220>)
2025-05-12 22:29:48,072:INFO:Checking exceptions
2025-05-12 22:29:48,072:INFO:Preloading libraries
2025-05-12 22:29:48,154:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:29:48,307:INFO:Initializing save_model()
2025-05-12 22:29:48,307:INFO:save_model(model=DummyClassifier(constant=None, random_state=123, strategy='prior'), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-12 22:29:48,307:INFO:Adding model into prep_pipe
2025-05-12 22:29:48,319:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:29:48,327:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 DummyClassifier(constant=None, random_state=123,
                                 strategy='prior'))],
         verbose=False)
2025-05-12 22:29:48,327:INFO:save_model() successfully completed......................................
2025-05-12 22:30:54,335:INFO:PyCaret RegressionExperiment
2025-05-12 22:30:54,335:INFO:Logging name: reg-default-name
2025-05-12 22:30:54,335:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:30:54,335:INFO:version 3.3.2
2025-05-12 22:30:54,335:INFO:Initializing setup()
2025-05-12 22:30:54,335:INFO:self.USI: 19b1
2025-05-12 22:30:54,335:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'transform_target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:30:54,335:INFO:Checking environment
2025-05-12 22:30:54,335:INFO:python_version: 3.11.8
2025-05-12 22:30:54,335:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:30:54,335:INFO:machine: AMD64
2025-05-12 22:30:54,335:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:30:54,340:INFO:Memory: svmem(total=16907886592, available=2868690944, percent=83.0, used=14039195648, free=2868690944)
2025-05-12 22:30:54,340:INFO:Physical Core: 4
2025-05-12 22:30:54,340:INFO:Logical Core: 8
2025-05-12 22:30:54,340:INFO:Checking libraries
2025-05-12 22:30:54,340:INFO:System:
2025-05-12 22:30:54,340:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:30:54,340:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:30:54,340:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:30:54,340:INFO:PyCaret required dependencies:
2025-05-12 22:30:54,341:INFO:                 pip: 24.0
2025-05-12 22:30:54,341:INFO:          setuptools: 65.5.0
2025-05-12 22:30:54,341:INFO:             pycaret: 3.3.2
2025-05-12 22:30:54,341:INFO:             IPython: 9.2.0
2025-05-12 22:30:54,341:INFO:          ipywidgets: 8.1.7
2025-05-12 22:30:54,341:INFO:                tqdm: 4.67.1
2025-05-12 22:30:54,341:INFO:               numpy: 1.26.4
2025-05-12 22:30:54,341:INFO:              pandas: 2.1.4
2025-05-12 22:30:54,341:INFO:              jinja2: 3.1.6
2025-05-12 22:30:54,341:INFO:               scipy: 1.11.4
2025-05-12 22:30:54,341:INFO:              joblib: 1.3.2
2025-05-12 22:30:54,341:INFO:             sklearn: 1.4.2
2025-05-12 22:30:54,341:INFO:                pyod: 2.0.5
2025-05-12 22:30:54,341:INFO:            imblearn: 0.13.0
2025-05-12 22:30:54,341:INFO:   category_encoders: 2.7.0
2025-05-12 22:30:54,341:INFO:            lightgbm: 4.6.0
2025-05-12 22:30:54,341:INFO:               numba: 0.61.2
2025-05-12 22:30:54,341:INFO:            requests: 2.32.3
2025-05-12 22:30:54,341:INFO:          matplotlib: 3.7.5
2025-05-12 22:30:54,341:INFO:          scikitplot: 0.3.7
2025-05-12 22:30:54,341:INFO:         yellowbrick: 1.5
2025-05-12 22:30:54,341:INFO:              plotly: 5.24.1
2025-05-12 22:30:54,341:INFO:    plotly-resampler: Not installed
2025-05-12 22:30:54,341:INFO:             kaleido: 0.2.1
2025-05-12 22:30:54,341:INFO:           schemdraw: 0.15
2025-05-12 22:30:54,341:INFO:         statsmodels: 0.14.4
2025-05-12 22:30:54,341:INFO:              sktime: 0.26.0
2025-05-12 22:30:54,341:INFO:               tbats: 1.1.3
2025-05-12 22:30:54,341:INFO:            pmdarima: 2.0.4
2025-05-12 22:30:54,341:INFO:              psutil: 7.0.0
2025-05-12 22:30:54,341:INFO:          markupsafe: 3.0.2
2025-05-12 22:30:54,341:INFO:             pickle5: Not installed
2025-05-12 22:30:54,341:INFO:         cloudpickle: 3.1.1
2025-05-12 22:30:54,341:INFO:         deprecation: 2.1.0
2025-05-12 22:30:54,341:INFO:              xxhash: 3.5.0
2025-05-12 22:30:54,341:INFO:           wurlitzer: Not installed
2025-05-12 22:30:54,341:INFO:PyCaret optional dependencies:
2025-05-12 22:30:54,341:INFO:                shap: Not installed
2025-05-12 22:30:54,341:INFO:           interpret: Not installed
2025-05-12 22:30:54,341:INFO:                umap: Not installed
2025-05-12 22:30:54,341:INFO:     ydata_profiling: Not installed
2025-05-12 22:30:54,341:INFO:  explainerdashboard: Not installed
2025-05-12 22:30:54,341:INFO:             autoviz: Not installed
2025-05-12 22:30:54,341:INFO:           fairlearn: Not installed
2025-05-12 22:30:54,341:INFO:          deepchecks: Not installed
2025-05-12 22:30:54,341:INFO:             xgboost: Not installed
2025-05-12 22:30:54,341:INFO:            catboost: Not installed
2025-05-12 22:30:54,341:INFO:              kmodes: Not installed
2025-05-12 22:30:54,341:INFO:             mlxtend: Not installed
2025-05-12 22:30:54,341:INFO:       statsforecast: Not installed
2025-05-12 22:30:54,341:INFO:        tune_sklearn: Not installed
2025-05-12 22:30:54,341:INFO:                 ray: Not installed
2025-05-12 22:30:54,343:INFO:            hyperopt: Not installed
2025-05-12 22:30:54,343:INFO:              optuna: Not installed
2025-05-12 22:30:54,343:INFO:               skopt: Not installed
2025-05-12 22:30:54,343:INFO:              mlflow: Not installed
2025-05-12 22:30:54,343:INFO:              gradio: Not installed
2025-05-12 22:30:54,343:INFO:             fastapi: Not installed
2025-05-12 22:30:54,343:INFO:             uvicorn: Not installed
2025-05-12 22:30:54,343:INFO:              m2cgen: Not installed
2025-05-12 22:30:54,343:INFO:           evidently: Not installed
2025-05-12 22:30:54,343:INFO:               fugue: Not installed
2025-05-12 22:30:54,343:INFO:           streamlit: Not installed
2025-05-12 22:30:54,343:INFO:             prophet: Not installed
2025-05-12 22:30:54,343:INFO:None
2025-05-12 22:30:54,343:INFO:Set up data.
2025-05-12 22:30:54,347:INFO:Set up folding strategy.
2025-05-12 22:30:54,347:INFO:Set up train/test split.
2025-05-12 22:30:54,351:INFO:Set up index.
2025-05-12 22:30:54,351:INFO:Assigning column types.
2025-05-12 22:30:54,355:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:30:54,356:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,360:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,363:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,415:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,453:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,454:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,454:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,459:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,461:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,510:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,546:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,547:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:30:54,553:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,559:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,615:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,652:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,657:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,660:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,716:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,754:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,755:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,756:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:30:54,766:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,813:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,850:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,851:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,851:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,860:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,907:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,953:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,954:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:30:55,017:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:55,056:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:55,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,131:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:55,169:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:55,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,170:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,170:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:30:55,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:55,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,331:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:55,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,385:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:30:55,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,571:INFO:Preparing preprocessing pipeline...
2025-05-12 22:30:55,571:INFO:Set up simple imputation.
2025-05-12 22:30:55,573:INFO:Set up encoding of categorical features.
2025-05-12 22:30:55,573:INFO:Set up feature normalization.
2025-05-12 22:30:55,629:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:30:55,637:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:30:55,637:INFO:Creating final display dataframe.
2025-05-12 22:30:55,775:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type        Regression
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              19b1
2025-05-12 22:30:55,870:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,961:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,961:INFO:setup() successfully completed in 1.63s...............
2025-05-12 22:30:55,974:INFO:Initializing compare_models()
2025-05-12 22:30:55,974:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 22:30:55,974:INFO:Checking exceptions
2025-05-12 22:30:55,976:INFO:Preparing display monitor
2025-05-12 22:30:55,997:INFO:Initializing Linear Regression
2025-05-12 22:30:55,998:INFO:Total runtime is 1.6709168752034504e-05 minutes
2025-05-12 22:30:56,000:INFO:SubProcess create_model() called ==================================
2025-05-12 22:30:56,000:INFO:Initializing create_model()
2025-05-12 22:30:56,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:30:56,000:INFO:Checking exceptions
2025-05-12 22:30:56,000:INFO:Importing libraries
2025-05-12 22:30:56,000:INFO:Copying training dataset
2025-05-12 22:30:56,004:INFO:Defining folds
2025-05-12 22:30:56,005:INFO:Declaring metric variables
2025-05-12 22:30:56,008:INFO:Importing untrained model
2025-05-12 22:30:56,010:INFO:Linear Regression Imported successfully
2025-05-12 22:30:56,018:INFO:Starting cross validation
2025-05-12 22:30:56,020:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
