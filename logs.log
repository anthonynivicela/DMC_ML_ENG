2025-05-12 20:59:51,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 20:59:51,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 20:59:51,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 20:59:51,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:01:56,179:INFO:PyCaret RegressionExperiment
2025-05-12 21:01:56,179:INFO:Logging name: reg-default-name
2025-05-12 21:01:56,179:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 21:01:56,180:INFO:version 3.3.2
2025-05-12 21:01:56,180:INFO:Initializing setup()
2025-05-12 21:01:56,180:INFO:self.USI: c989
2025-05-12 21:01:56,180:INFO:self._variable_keys: {'exp_id', 'transform_target_param', 'X_test', 'X_train', 'y_train', 'memory', 'log_plots_param', 'X', 'y', 'target_param', 'gpu_param', 'html_param', 'exp_name_log', 'USI', 'data', 'pipeline', 'y_test', '_ml_usecase', 'seed', '_available_plots', 'fold_groups_param', 'idx', 'fold_shuffle_param', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'logging_param'}
2025-05-12 21:01:56,180:INFO:Checking environment
2025-05-12 21:01:56,180:INFO:python_version: 3.11.8
2025-05-12 21:01:56,180:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 21:01:56,180:INFO:machine: AMD64
2025-05-12 21:01:56,180:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 21:01:56,189:INFO:Memory: svmem(total=16907886592, available=3690487808, percent=78.2, used=13217398784, free=3690487808)
2025-05-12 21:01:56,189:INFO:Physical Core: 4
2025-05-12 21:01:56,190:INFO:Logical Core: 8
2025-05-12 21:01:56,190:INFO:Checking libraries
2025-05-12 21:01:56,190:INFO:System:
2025-05-12 21:01:56,190:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 21:01:56,190:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 21:01:56,190:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 21:01:56,190:INFO:PyCaret required dependencies:
2025-05-12 21:01:56,297:INFO:                 pip: 24.0
2025-05-12 21:01:56,297:INFO:          setuptools: 65.5.0
2025-05-12 21:01:56,297:INFO:             pycaret: 3.3.2
2025-05-12 21:01:56,297:INFO:             IPython: 9.2.0
2025-05-12 21:01:56,297:INFO:          ipywidgets: 8.1.7
2025-05-12 21:01:56,297:INFO:                tqdm: 4.67.1
2025-05-12 21:01:56,297:INFO:               numpy: 1.26.4
2025-05-12 21:01:56,297:INFO:              pandas: 2.1.4
2025-05-12 21:01:56,297:INFO:              jinja2: 3.1.6
2025-05-12 21:01:56,297:INFO:               scipy: 1.11.4
2025-05-12 21:01:56,297:INFO:              joblib: 1.3.2
2025-05-12 21:01:56,297:INFO:             sklearn: 1.4.2
2025-05-12 21:01:56,297:INFO:                pyod: 2.0.5
2025-05-12 21:01:56,297:INFO:            imblearn: 0.13.0
2025-05-12 21:01:56,297:INFO:   category_encoders: 2.7.0
2025-05-12 21:01:56,297:INFO:            lightgbm: 4.6.0
2025-05-12 21:01:56,297:INFO:               numba: 0.61.2
2025-05-12 21:01:56,297:INFO:            requests: 2.32.3
2025-05-12 21:01:56,298:INFO:          matplotlib: 3.7.5
2025-05-12 21:01:56,298:INFO:          scikitplot: 0.3.7
2025-05-12 21:01:56,298:INFO:         yellowbrick: 1.5
2025-05-12 21:01:56,298:INFO:              plotly: 5.24.1
2025-05-12 21:01:56,298:INFO:    plotly-resampler: Not installed
2025-05-12 21:01:56,298:INFO:             kaleido: 0.2.1
2025-05-12 21:01:56,298:INFO:           schemdraw: 0.15
2025-05-12 21:01:56,298:INFO:         statsmodels: 0.14.4
2025-05-12 21:01:56,298:INFO:              sktime: 0.26.0
2025-05-12 21:01:56,298:INFO:               tbats: 1.1.3
2025-05-12 21:01:56,298:INFO:            pmdarima: 2.0.4
2025-05-12 21:01:56,298:INFO:              psutil: 7.0.0
2025-05-12 21:01:56,298:INFO:          markupsafe: 3.0.2
2025-05-12 21:01:56,298:INFO:             pickle5: Not installed
2025-05-12 21:01:56,298:INFO:         cloudpickle: 3.1.1
2025-05-12 21:01:56,298:INFO:         deprecation: 2.1.0
2025-05-12 21:01:56,298:INFO:              xxhash: 3.5.0
2025-05-12 21:01:56,298:INFO:           wurlitzer: Not installed
2025-05-12 21:01:56,298:INFO:PyCaret optional dependencies:
2025-05-12 21:01:56,312:INFO:                shap: Not installed
2025-05-12 21:01:56,312:INFO:           interpret: Not installed
2025-05-12 21:01:56,312:INFO:                umap: Not installed
2025-05-12 21:01:56,312:INFO:     ydata_profiling: Not installed
2025-05-12 21:01:56,312:INFO:  explainerdashboard: Not installed
2025-05-12 21:01:56,312:INFO:             autoviz: Not installed
2025-05-12 21:01:56,312:INFO:           fairlearn: Not installed
2025-05-12 21:01:56,312:INFO:          deepchecks: Not installed
2025-05-12 21:01:56,312:INFO:             xgboost: Not installed
2025-05-12 21:01:56,312:INFO:            catboost: Not installed
2025-05-12 21:01:56,312:INFO:              kmodes: Not installed
2025-05-12 21:01:56,312:INFO:             mlxtend: Not installed
2025-05-12 21:01:56,312:INFO:       statsforecast: Not installed
2025-05-12 21:01:56,312:INFO:        tune_sklearn: Not installed
2025-05-12 21:01:56,312:INFO:                 ray: Not installed
2025-05-12 21:01:56,312:INFO:            hyperopt: Not installed
2025-05-12 21:01:56,312:INFO:              optuna: Not installed
2025-05-12 21:01:56,312:INFO:               skopt: Not installed
2025-05-12 21:01:56,312:INFO:              mlflow: Not installed
2025-05-12 21:01:56,312:INFO:              gradio: Not installed
2025-05-12 21:01:56,312:INFO:             fastapi: Not installed
2025-05-12 21:01:56,312:INFO:             uvicorn: Not installed
2025-05-12 21:01:56,312:INFO:              m2cgen: Not installed
2025-05-12 21:01:56,312:INFO:           evidently: Not installed
2025-05-12 21:01:56,312:INFO:               fugue: Not installed
2025-05-12 21:01:56,312:INFO:           streamlit: Not installed
2025-05-12 21:01:56,312:INFO:             prophet: Not installed
2025-05-12 21:01:56,312:INFO:None
2025-05-12 21:01:56,312:INFO:Set up data.
2025-05-12 21:01:56,318:INFO:Set up folding strategy.
2025-05-12 21:01:56,319:INFO:Set up train/test split.
2025-05-12 21:01:56,372:INFO:Set up index.
2025-05-12 21:01:56,372:INFO:Assigning column types.
2025-05-12 21:01:56,376:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 21:01:56,377:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,380:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,385:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,480:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,481:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,481:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,485:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,490:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,545:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,591:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,592:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 21:01:56,597:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,600:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,651:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,699:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,704:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,756:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,797:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 21:01:56,806:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,856:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,896:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,904:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:56,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:56,998:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 21:01:57,056:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:57,096:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:57,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,097:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,154:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:57,195:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:01:57,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,198:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 21:01:57,254:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:57,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,352:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:01:57,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,391:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,392:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 21:01:57,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,594:INFO:Preparing preprocessing pipeline...
2025-05-12 21:01:57,594:INFO:Set up simple imputation.
2025-05-12 21:01:57,595:INFO:Set up encoding of categorical features.
2025-05-12 21:01:57,595:INFO:Set up feature normalization.
2025-05-12 21:01:57,641:INFO:Finished creating preprocessing pipeline.
2025-05-12 21:01:57,648:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 21:01:57,648:INFO:Creating final display dataframe.
2025-05-12 21:01:57,771:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            precio
2                   Target type        Regression
3           Original data shape          (100, 7)
4        Transformed data shape         (100, 10)
5   Transformed train set shape          (70, 10)
6    Transformed test set shape          (30, 10)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              c989
2025-05-12 21:01:57,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:57,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:58,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:58,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:01:58,002:INFO:setup() successfully completed in 1.83s...............
2025-05-12 21:07:08,707:INFO:Initializing compare_models()
2025-05-12 21:07:08,707:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 21:07:08,707:INFO:Checking exceptions
2025-05-12 21:07:08,711:INFO:Preparing display monitor
2025-05-12 21:07:08,755:INFO:Initializing Linear Regression
2025-05-12 21:07:08,756:INFO:Total runtime is 1.663366953531901e-05 minutes
2025-05-12 21:07:08,759:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:08,760:INFO:Initializing create_model()
2025-05-12 21:07:08,760:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:08,760:INFO:Checking exceptions
2025-05-12 21:07:08,761:INFO:Importing libraries
2025-05-12 21:07:08,761:INFO:Copying training dataset
2025-05-12 21:07:08,767:INFO:Defining folds
2025-05-12 21:07:08,767:INFO:Declaring metric variables
2025-05-12 21:07:08,771:INFO:Importing untrained model
2025-05-12 21:07:08,777:INFO:Linear Regression Imported successfully
2025-05-12 21:07:08,788:INFO:Starting cross validation
2025-05-12 21:07:08,800:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:17,461:INFO:Calculating mean and std
2025-05-12 21:07:17,462:INFO:Creating metrics dataframe
2025-05-12 21:07:17,465:INFO:Uploading results into container
2025-05-12 21:07:17,465:INFO:Uploading model into container now
2025-05-12 21:07:17,465:INFO:_master_model_container: 1
2025-05-12 21:07:17,467:INFO:_display_container: 2
2025-05-12 21:07:17,467:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:07:17,467:INFO:create_model() successfully completed......................................
2025-05-12 21:07:17,562:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:17,562:INFO:Creating metrics dataframe
2025-05-12 21:07:17,570:INFO:Initializing Lasso Regression
2025-05-12 21:07:17,570:INFO:Total runtime is 0.14691134293874106 minutes
2025-05-12 21:07:17,572:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:17,573:INFO:Initializing create_model()
2025-05-12 21:07:17,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:17,573:INFO:Checking exceptions
2025-05-12 21:07:17,573:INFO:Importing libraries
2025-05-12 21:07:17,573:INFO:Copying training dataset
2025-05-12 21:07:17,579:INFO:Defining folds
2025-05-12 21:07:17,579:INFO:Declaring metric variables
2025-05-12 21:07:17,584:INFO:Importing untrained model
2025-05-12 21:07:17,588:INFO:Lasso Regression Imported successfully
2025-05-12 21:07:17,598:INFO:Starting cross validation
2025-05-12 21:07:17,599:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:17,796:INFO:Calculating mean and std
2025-05-12 21:07:17,797:INFO:Creating metrics dataframe
2025-05-12 21:07:17,800:INFO:Uploading results into container
2025-05-12 21:07:17,801:INFO:Uploading model into container now
2025-05-12 21:07:17,801:INFO:_master_model_container: 2
2025-05-12 21:07:17,801:INFO:_display_container: 2
2025-05-12 21:07:17,801:INFO:Lasso(random_state=123)
2025-05-12 21:07:17,801:INFO:create_model() successfully completed......................................
2025-05-12 21:07:17,884:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:17,885:INFO:Creating metrics dataframe
2025-05-12 21:07:17,894:INFO:Initializing Ridge Regression
2025-05-12 21:07:17,894:INFO:Total runtime is 0.15231239000956218 minutes
2025-05-12 21:07:17,898:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:17,898:INFO:Initializing create_model()
2025-05-12 21:07:17,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:17,898:INFO:Checking exceptions
2025-05-12 21:07:17,898:INFO:Importing libraries
2025-05-12 21:07:17,898:INFO:Copying training dataset
2025-05-12 21:07:17,901:INFO:Defining folds
2025-05-12 21:07:17,902:INFO:Declaring metric variables
2025-05-12 21:07:17,908:INFO:Importing untrained model
2025-05-12 21:07:17,914:INFO:Ridge Regression Imported successfully
2025-05-12 21:07:17,923:INFO:Starting cross validation
2025-05-12 21:07:17,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:18,128:INFO:Calculating mean and std
2025-05-12 21:07:18,130:INFO:Creating metrics dataframe
2025-05-12 21:07:18,131:INFO:Uploading results into container
2025-05-12 21:07:18,132:INFO:Uploading model into container now
2025-05-12 21:07:18,133:INFO:_master_model_container: 3
2025-05-12 21:07:18,133:INFO:_display_container: 2
2025-05-12 21:07:18,133:INFO:Ridge(random_state=123)
2025-05-12 21:07:18,133:INFO:create_model() successfully completed......................................
2025-05-12 21:07:18,216:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:18,216:INFO:Creating metrics dataframe
2025-05-12 21:07:18,224:INFO:Initializing Elastic Net
2025-05-12 21:07:18,224:INFO:Total runtime is 0.15782576402028403 minutes
2025-05-12 21:07:18,228:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:18,229:INFO:Initializing create_model()
2025-05-12 21:07:18,229:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:18,229:INFO:Checking exceptions
2025-05-12 21:07:18,229:INFO:Importing libraries
2025-05-12 21:07:18,229:INFO:Copying training dataset
2025-05-12 21:07:18,233:INFO:Defining folds
2025-05-12 21:07:18,233:INFO:Declaring metric variables
2025-05-12 21:07:18,237:INFO:Importing untrained model
2025-05-12 21:07:18,241:INFO:Elastic Net Imported successfully
2025-05-12 21:07:18,251:INFO:Starting cross validation
2025-05-12 21:07:18,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:18,443:INFO:Calculating mean and std
2025-05-12 21:07:18,444:INFO:Creating metrics dataframe
2025-05-12 21:07:18,447:INFO:Uploading results into container
2025-05-12 21:07:18,447:INFO:Uploading model into container now
2025-05-12 21:07:18,448:INFO:_master_model_container: 4
2025-05-12 21:07:18,448:INFO:_display_container: 2
2025-05-12 21:07:18,448:INFO:ElasticNet(random_state=123)
2025-05-12 21:07:18,449:INFO:create_model() successfully completed......................................
2025-05-12 21:07:18,530:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:18,531:INFO:Creating metrics dataframe
2025-05-12 21:07:18,538:INFO:Initializing Least Angle Regression
2025-05-12 21:07:18,538:INFO:Total runtime is 0.16304643154144288 minutes
2025-05-12 21:07:18,542:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:18,543:INFO:Initializing create_model()
2025-05-12 21:07:18,543:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:18,543:INFO:Checking exceptions
2025-05-12 21:07:18,543:INFO:Importing libraries
2025-05-12 21:07:18,543:INFO:Copying training dataset
2025-05-12 21:07:18,548:INFO:Defining folds
2025-05-12 21:07:18,548:INFO:Declaring metric variables
2025-05-12 21:07:18,551:INFO:Importing untrained model
2025-05-12 21:07:18,555:INFO:Least Angle Regression Imported successfully
2025-05-12 21:07:18,565:INFO:Starting cross validation
2025-05-12 21:07:18,566:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:18,790:INFO:Calculating mean and std
2025-05-12 21:07:18,792:INFO:Creating metrics dataframe
2025-05-12 21:07:18,794:INFO:Uploading results into container
2025-05-12 21:07:18,794:INFO:Uploading model into container now
2025-05-12 21:07:18,795:INFO:_master_model_container: 5
2025-05-12 21:07:18,795:INFO:_display_container: 2
2025-05-12 21:07:18,795:INFO:Lars(random_state=123)
2025-05-12 21:07:18,795:INFO:create_model() successfully completed......................................
2025-05-12 21:07:18,882:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:18,882:INFO:Creating metrics dataframe
2025-05-12 21:07:18,892:INFO:Initializing Lasso Least Angle Regression
2025-05-12 21:07:18,892:INFO:Total runtime is 0.16894732316335043 minutes
2025-05-12 21:07:18,896:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:18,896:INFO:Initializing create_model()
2025-05-12 21:07:18,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:18,896:INFO:Checking exceptions
2025-05-12 21:07:18,897:INFO:Importing libraries
2025-05-12 21:07:18,897:INFO:Copying training dataset
2025-05-12 21:07:18,902:INFO:Defining folds
2025-05-12 21:07:18,902:INFO:Declaring metric variables
2025-05-12 21:07:18,907:INFO:Importing untrained model
2025-05-12 21:07:18,912:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 21:07:18,919:INFO:Starting cross validation
2025-05-12 21:07:18,922:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:19,146:INFO:Calculating mean and std
2025-05-12 21:07:19,147:INFO:Creating metrics dataframe
2025-05-12 21:07:19,149:INFO:Uploading results into container
2025-05-12 21:07:19,150:INFO:Uploading model into container now
2025-05-12 21:07:19,150:INFO:_master_model_container: 6
2025-05-12 21:07:19,150:INFO:_display_container: 2
2025-05-12 21:07:19,151:INFO:LassoLars(random_state=123)
2025-05-12 21:07:19,151:INFO:create_model() successfully completed......................................
2025-05-12 21:07:19,238:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:19,238:INFO:Creating metrics dataframe
2025-05-12 21:07:19,247:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 21:07:19,247:INFO:Total runtime is 0.17486355702082315 minutes
2025-05-12 21:07:19,250:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:19,251:INFO:Initializing create_model()
2025-05-12 21:07:19,251:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:19,251:INFO:Checking exceptions
2025-05-12 21:07:19,251:INFO:Importing libraries
2025-05-12 21:07:19,251:INFO:Copying training dataset
2025-05-12 21:07:19,255:INFO:Defining folds
2025-05-12 21:07:19,255:INFO:Declaring metric variables
2025-05-12 21:07:19,259:INFO:Importing untrained model
2025-05-12 21:07:19,261:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 21:07:19,270:INFO:Starting cross validation
2025-05-12 21:07:19,271:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:19,460:INFO:Calculating mean and std
2025-05-12 21:07:19,462:INFO:Creating metrics dataframe
2025-05-12 21:07:19,464:INFO:Uploading results into container
2025-05-12 21:07:19,464:INFO:Uploading model into container now
2025-05-12 21:07:19,465:INFO:_master_model_container: 7
2025-05-12 21:07:19,465:INFO:_display_container: 2
2025-05-12 21:07:19,465:INFO:OrthogonalMatchingPursuit()
2025-05-12 21:07:19,465:INFO:create_model() successfully completed......................................
2025-05-12 21:07:19,546:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:19,546:INFO:Creating metrics dataframe
2025-05-12 21:07:19,555:INFO:Initializing Bayesian Ridge
2025-05-12 21:07:19,556:INFO:Total runtime is 0.18001383145650227 minutes
2025-05-12 21:07:19,560:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:19,560:INFO:Initializing create_model()
2025-05-12 21:07:19,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:19,560:INFO:Checking exceptions
2025-05-12 21:07:19,560:INFO:Importing libraries
2025-05-12 21:07:19,560:INFO:Copying training dataset
2025-05-12 21:07:19,564:INFO:Defining folds
2025-05-12 21:07:19,565:INFO:Declaring metric variables
2025-05-12 21:07:19,568:INFO:Importing untrained model
2025-05-12 21:07:19,572:INFO:Bayesian Ridge Imported successfully
2025-05-12 21:07:19,581:INFO:Starting cross validation
2025-05-12 21:07:19,582:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:19,788:INFO:Calculating mean and std
2025-05-12 21:07:19,790:INFO:Creating metrics dataframe
2025-05-12 21:07:19,792:INFO:Uploading results into container
2025-05-12 21:07:19,793:INFO:Uploading model into container now
2025-05-12 21:07:19,793:INFO:_master_model_container: 8
2025-05-12 21:07:19,793:INFO:_display_container: 2
2025-05-12 21:07:19,793:INFO:BayesianRidge()
2025-05-12 21:07:19,793:INFO:create_model() successfully completed......................................
2025-05-12 21:07:19,873:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:19,874:INFO:Creating metrics dataframe
2025-05-12 21:07:19,882:INFO:Initializing Passive Aggressive Regressor
2025-05-12 21:07:19,884:INFO:Total runtime is 0.1854825735092163 minutes
2025-05-12 21:07:19,886:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:19,888:INFO:Initializing create_model()
2025-05-12 21:07:19,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:19,888:INFO:Checking exceptions
2025-05-12 21:07:19,888:INFO:Importing libraries
2025-05-12 21:07:19,888:INFO:Copying training dataset
2025-05-12 21:07:19,892:INFO:Defining folds
2025-05-12 21:07:19,892:INFO:Declaring metric variables
2025-05-12 21:07:19,895:INFO:Importing untrained model
2025-05-12 21:07:19,899:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 21:07:19,907:INFO:Starting cross validation
2025-05-12 21:07:19,908:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:19,988:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:19,990:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:19,993:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:19,998:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:20,009:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:20,018:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:20,018:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:20,022:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:20,087:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:20,090:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:07:20,123:INFO:Calculating mean and std
2025-05-12 21:07:20,125:INFO:Creating metrics dataframe
2025-05-12 21:07:20,126:INFO:Uploading results into container
2025-05-12 21:07:20,128:INFO:Uploading model into container now
2025-05-12 21:07:20,128:INFO:_master_model_container: 9
2025-05-12 21:07:20,128:INFO:_display_container: 2
2025-05-12 21:07:20,128:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 21:07:20,129:INFO:create_model() successfully completed......................................
2025-05-12 21:07:20,210:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:20,211:INFO:Creating metrics dataframe
2025-05-12 21:07:20,220:INFO:Initializing Huber Regressor
2025-05-12 21:07:20,220:INFO:Total runtime is 0.19107828934987384 minutes
2025-05-12 21:07:20,224:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:20,225:INFO:Initializing create_model()
2025-05-12 21:07:20,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:20,225:INFO:Checking exceptions
2025-05-12 21:07:20,225:INFO:Importing libraries
2025-05-12 21:07:20,225:INFO:Copying training dataset
2025-05-12 21:07:20,228:INFO:Defining folds
2025-05-12 21:07:20,228:INFO:Declaring metric variables
2025-05-12 21:07:20,233:INFO:Importing untrained model
2025-05-12 21:07:20,235:INFO:Huber Regressor Imported successfully
2025-05-12 21:07:20,245:INFO:Starting cross validation
2025-05-12 21:07:20,246:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:20,458:INFO:Calculating mean and std
2025-05-12 21:07:20,459:INFO:Creating metrics dataframe
2025-05-12 21:07:20,461:INFO:Uploading results into container
2025-05-12 21:07:20,461:INFO:Uploading model into container now
2025-05-12 21:07:20,463:INFO:_master_model_container: 10
2025-05-12 21:07:20,463:INFO:_display_container: 2
2025-05-12 21:07:20,463:INFO:HuberRegressor()
2025-05-12 21:07:20,463:INFO:create_model() successfully completed......................................
2025-05-12 21:07:20,546:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:20,546:INFO:Creating metrics dataframe
2025-05-12 21:07:20,555:INFO:Initializing K Neighbors Regressor
2025-05-12 21:07:20,555:INFO:Total runtime is 0.19666815996170042 minutes
2025-05-12 21:07:20,560:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:20,560:INFO:Initializing create_model()
2025-05-12 21:07:20,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:20,560:INFO:Checking exceptions
2025-05-12 21:07:20,560:INFO:Importing libraries
2025-05-12 21:07:20,561:INFO:Copying training dataset
2025-05-12 21:07:20,564:INFO:Defining folds
2025-05-12 21:07:20,564:INFO:Declaring metric variables
2025-05-12 21:07:20,569:INFO:Importing untrained model
2025-05-12 21:07:20,572:INFO:K Neighbors Regressor Imported successfully
2025-05-12 21:07:20,582:INFO:Starting cross validation
2025-05-12 21:07:20,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:20,887:INFO:Calculating mean and std
2025-05-12 21:07:20,888:INFO:Creating metrics dataframe
2025-05-12 21:07:20,892:INFO:Uploading results into container
2025-05-12 21:07:20,893:INFO:Uploading model into container now
2025-05-12 21:07:20,893:INFO:_master_model_container: 11
2025-05-12 21:07:20,893:INFO:_display_container: 2
2025-05-12 21:07:20,894:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 21:07:20,894:INFO:create_model() successfully completed......................................
2025-05-12 21:07:20,974:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:20,974:INFO:Creating metrics dataframe
2025-05-12 21:07:20,984:INFO:Initializing Decision Tree Regressor
2025-05-12 21:07:20,984:INFO:Total runtime is 0.2038112163543701 minutes
2025-05-12 21:07:20,989:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:20,989:INFO:Initializing create_model()
2025-05-12 21:07:20,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:20,989:INFO:Checking exceptions
2025-05-12 21:07:20,989:INFO:Importing libraries
2025-05-12 21:07:20,989:INFO:Copying training dataset
2025-05-12 21:07:20,994:INFO:Defining folds
2025-05-12 21:07:20,994:INFO:Declaring metric variables
2025-05-12 21:07:20,997:INFO:Importing untrained model
2025-05-12 21:07:21,001:INFO:Decision Tree Regressor Imported successfully
2025-05-12 21:07:21,011:INFO:Starting cross validation
2025-05-12 21:07:21,014:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:21,224:INFO:Calculating mean and std
2025-05-12 21:07:21,225:INFO:Creating metrics dataframe
2025-05-12 21:07:21,227:INFO:Uploading results into container
2025-05-12 21:07:21,228:INFO:Uploading model into container now
2025-05-12 21:07:21,228:INFO:_master_model_container: 12
2025-05-12 21:07:21,228:INFO:_display_container: 2
2025-05-12 21:07:21,228:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 21:07:21,228:INFO:create_model() successfully completed......................................
2025-05-12 21:07:21,308:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:21,308:INFO:Creating metrics dataframe
2025-05-12 21:07:21,319:INFO:Initializing Random Forest Regressor
2025-05-12 21:07:21,319:INFO:Total runtime is 0.20939798355102537 minutes
2025-05-12 21:07:21,322:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:21,322:INFO:Initializing create_model()
2025-05-12 21:07:21,322:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:21,322:INFO:Checking exceptions
2025-05-12 21:07:21,324:INFO:Importing libraries
2025-05-12 21:07:21,324:INFO:Copying training dataset
2025-05-12 21:07:21,327:INFO:Defining folds
2025-05-12 21:07:21,327:INFO:Declaring metric variables
2025-05-12 21:07:21,332:INFO:Importing untrained model
2025-05-12 21:07:21,335:INFO:Random Forest Regressor Imported successfully
2025-05-12 21:07:21,342:INFO:Starting cross validation
2025-05-12 21:07:21,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:22,119:INFO:Calculating mean and std
2025-05-12 21:07:22,120:INFO:Creating metrics dataframe
2025-05-12 21:07:22,122:INFO:Uploading results into container
2025-05-12 21:07:22,123:INFO:Uploading model into container now
2025-05-12 21:07:22,123:INFO:_master_model_container: 13
2025-05-12 21:07:22,123:INFO:_display_container: 2
2025-05-12 21:07:22,125:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:07:22,125:INFO:create_model() successfully completed......................................
2025-05-12 21:07:22,207:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:22,207:INFO:Creating metrics dataframe
2025-05-12 21:07:22,218:INFO:Initializing Extra Trees Regressor
2025-05-12 21:07:22,218:INFO:Total runtime is 0.22437867323557534 minutes
2025-05-12 21:07:22,222:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:22,222:INFO:Initializing create_model()
2025-05-12 21:07:22,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:22,222:INFO:Checking exceptions
2025-05-12 21:07:22,222:INFO:Importing libraries
2025-05-12 21:07:22,222:INFO:Copying training dataset
2025-05-12 21:07:22,225:INFO:Defining folds
2025-05-12 21:07:22,226:INFO:Declaring metric variables
2025-05-12 21:07:22,230:INFO:Importing untrained model
2025-05-12 21:07:22,232:INFO:Extra Trees Regressor Imported successfully
2025-05-12 21:07:22,240:INFO:Starting cross validation
2025-05-12 21:07:22,242:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:22,976:INFO:Calculating mean and std
2025-05-12 21:07:22,978:INFO:Creating metrics dataframe
2025-05-12 21:07:22,979:INFO:Uploading results into container
2025-05-12 21:07:22,981:INFO:Uploading model into container now
2025-05-12 21:07:22,982:INFO:_master_model_container: 14
2025-05-12 21:07:22,982:INFO:_display_container: 2
2025-05-12 21:07:22,983:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:07:22,983:INFO:create_model() successfully completed......................................
2025-05-12 21:07:23,069:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:23,069:INFO:Creating metrics dataframe
2025-05-12 21:07:23,080:INFO:Initializing AdaBoost Regressor
2025-05-12 21:07:23,080:INFO:Total runtime is 0.23874803781509396 minutes
2025-05-12 21:07:23,083:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:23,083:INFO:Initializing create_model()
2025-05-12 21:07:23,083:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:23,083:INFO:Checking exceptions
2025-05-12 21:07:23,083:INFO:Importing libraries
2025-05-12 21:07:23,083:INFO:Copying training dataset
2025-05-12 21:07:23,089:INFO:Defining folds
2025-05-12 21:07:23,089:INFO:Declaring metric variables
2025-05-12 21:07:23,092:INFO:Importing untrained model
2025-05-12 21:07:23,097:INFO:AdaBoost Regressor Imported successfully
2025-05-12 21:07:23,105:INFO:Starting cross validation
2025-05-12 21:07:23,106:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:23,569:INFO:Calculating mean and std
2025-05-12 21:07:23,570:INFO:Creating metrics dataframe
2025-05-12 21:07:23,572:INFO:Uploading results into container
2025-05-12 21:07:23,572:INFO:Uploading model into container now
2025-05-12 21:07:23,572:INFO:_master_model_container: 15
2025-05-12 21:07:23,574:INFO:_display_container: 2
2025-05-12 21:07:23,574:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 21:07:23,574:INFO:create_model() successfully completed......................................
2025-05-12 21:07:23,659:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:23,659:INFO:Creating metrics dataframe
2025-05-12 21:07:23,671:INFO:Initializing Gradient Boosting Regressor
2025-05-12 21:07:23,671:INFO:Total runtime is 0.24859412511189774 minutes
2025-05-12 21:07:23,673:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:23,673:INFO:Initializing create_model()
2025-05-12 21:07:23,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:23,673:INFO:Checking exceptions
2025-05-12 21:07:23,673:INFO:Importing libraries
2025-05-12 21:07:23,673:INFO:Copying training dataset
2025-05-12 21:07:23,678:INFO:Defining folds
2025-05-12 21:07:23,679:INFO:Declaring metric variables
2025-05-12 21:07:23,682:INFO:Importing untrained model
2025-05-12 21:07:23,686:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 21:07:23,693:INFO:Starting cross validation
2025-05-12 21:07:23,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:24,060:INFO:Calculating mean and std
2025-05-12 21:07:24,061:INFO:Creating metrics dataframe
2025-05-12 21:07:24,062:INFO:Uploading results into container
2025-05-12 21:07:24,064:INFO:Uploading model into container now
2025-05-12 21:07:24,065:INFO:_master_model_container: 16
2025-05-12 21:07:24,065:INFO:_display_container: 2
2025-05-12 21:07:24,065:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 21:07:24,065:INFO:create_model() successfully completed......................................
2025-05-12 21:07:24,146:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:24,146:INFO:Creating metrics dataframe
2025-05-12 21:07:24,157:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 21:07:24,157:INFO:Total runtime is 0.2566994190216064 minutes
2025-05-12 21:07:24,159:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:24,160:INFO:Initializing create_model()
2025-05-12 21:07:24,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:24,160:INFO:Checking exceptions
2025-05-12 21:07:24,160:INFO:Importing libraries
2025-05-12 21:07:24,160:INFO:Copying training dataset
2025-05-12 21:07:24,164:INFO:Defining folds
2025-05-12 21:07:24,164:INFO:Declaring metric variables
2025-05-12 21:07:24,167:INFO:Importing untrained model
2025-05-12 21:07:24,172:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 21:07:24,181:INFO:Starting cross validation
2025-05-12 21:07:24,182:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:24,650:INFO:Calculating mean and std
2025-05-12 21:07:24,654:INFO:Creating metrics dataframe
2025-05-12 21:07:24,658:INFO:Uploading results into container
2025-05-12 21:07:24,659:INFO:Uploading model into container now
2025-05-12 21:07:24,660:INFO:_master_model_container: 17
2025-05-12 21:07:24,660:INFO:_display_container: 2
2025-05-12 21:07:24,661:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:07:24,662:INFO:create_model() successfully completed......................................
2025-05-12 21:07:24,780:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:24,780:INFO:Creating metrics dataframe
2025-05-12 21:07:24,795:INFO:Initializing Dummy Regressor
2025-05-12 21:07:24,795:INFO:Total runtime is 0.26733943223953244 minutes
2025-05-12 21:07:24,798:INFO:SubProcess create_model() called ==================================
2025-05-12 21:07:24,799:INFO:Initializing create_model()
2025-05-12 21:07:24,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FAE402D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:24,799:INFO:Checking exceptions
2025-05-12 21:07:24,799:INFO:Importing libraries
2025-05-12 21:07:24,799:INFO:Copying training dataset
2025-05-12 21:07:24,805:INFO:Defining folds
2025-05-12 21:07:24,805:INFO:Declaring metric variables
2025-05-12 21:07:24,810:INFO:Importing untrained model
2025-05-12 21:07:24,816:INFO:Dummy Regressor Imported successfully
2025-05-12 21:07:24,824:INFO:Starting cross validation
2025-05-12 21:07:24,827:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:07:25,043:INFO:Calculating mean and std
2025-05-12 21:07:25,045:INFO:Creating metrics dataframe
2025-05-12 21:07:25,047:INFO:Uploading results into container
2025-05-12 21:07:25,048:INFO:Uploading model into container now
2025-05-12 21:07:25,049:INFO:_master_model_container: 18
2025-05-12 21:07:25,049:INFO:_display_container: 2
2025-05-12 21:07:25,050:INFO:DummyRegressor()
2025-05-12 21:07:25,050:INFO:create_model() successfully completed......................................
2025-05-12 21:07:25,135:INFO:SubProcess create_model() end ==================================
2025-05-12 21:07:25,135:INFO:Creating metrics dataframe
2025-05-12 21:07:25,149:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 21:07:25,158:INFO:Initializing create_model()
2025-05-12 21:07:25,158:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:07:25,158:INFO:Checking exceptions
2025-05-12 21:07:25,160:INFO:Importing libraries
2025-05-12 21:07:25,160:INFO:Copying training dataset
2025-05-12 21:07:25,165:INFO:Defining folds
2025-05-12 21:07:25,165:INFO:Declaring metric variables
2025-05-12 21:07:25,165:INFO:Importing untrained model
2025-05-12 21:07:25,165:INFO:Declaring custom model
2025-05-12 21:07:25,165:INFO:Linear Regression Imported successfully
2025-05-12 21:07:25,167:INFO:Cross validation set to False
2025-05-12 21:07:25,168:INFO:Fitting Model
2025-05-12 21:07:25,206:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:07:25,206:INFO:create_model() successfully completed......................................
2025-05-12 21:07:25,319:INFO:_master_model_container: 18
2025-05-12 21:07:25,319:INFO:_display_container: 2
2025-05-12 21:07:25,319:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:07:25,319:INFO:compare_models() successfully completed......................................
2025-05-12 21:20:31,144:INFO:Initializing create_model()
2025-05-12 21:20:31,144:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:20:31,144:INFO:Checking exceptions
2025-05-12 21:20:31,159:INFO:Importing libraries
2025-05-12 21:20:31,159:INFO:Copying training dataset
2025-05-12 21:20:31,166:INFO:Defining folds
2025-05-12 21:20:31,167:INFO:Declaring metric variables
2025-05-12 21:20:31,171:INFO:Importing untrained model
2025-05-12 21:20:31,176:INFO:Linear Regression Imported successfully
2025-05-12 21:20:31,182:INFO:Starting cross validation
2025-05-12 21:20:31,184:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:20:40,263:INFO:Calculating mean and std
2025-05-12 21:20:40,265:INFO:Creating metrics dataframe
2025-05-12 21:20:40,279:INFO:Finalizing model
2025-05-12 21:20:40,355:INFO:Uploading results into container
2025-05-12 21:20:40,357:INFO:Uploading model into container now
2025-05-12 21:20:40,370:INFO:_master_model_container: 19
2025-05-12 21:20:40,370:INFO:_display_container: 3
2025-05-12 21:20:40,370:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:20:40,370:INFO:create_model() successfully completed......................................
2025-05-12 21:24:48,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:24:48,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:24:48,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:24:48,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 21:24:49,252:INFO:PyCaret RegressionExperiment
2025-05-12 21:24:49,253:INFO:Logging name: reg-default-name
2025-05-12 21:24:49,253:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 21:24:49,253:INFO:version 3.3.2
2025-05-12 21:24:49,253:INFO:Initializing setup()
2025-05-12 21:24:49,253:INFO:self.USI: afdb
2025-05-12 21:24:49,253:INFO:self._variable_keys: {'X_test', 'logging_param', 'exp_name_log', '_ml_usecase', '_available_plots', 'y_test', 'X_train', 'seed', 'X', 'idx', 'USI', 'y', 'data', 'memory', 'exp_id', 'n_jobs_param', 'pipeline', 'html_param', 'y_train', 'transform_target_param', 'fold_shuffle_param', 'target_param', 'gpu_n_jobs_param', 'fold_generator', 'gpu_param', 'log_plots_param', 'fold_groups_param'}
2025-05-12 21:24:49,253:INFO:Checking environment
2025-05-12 21:24:49,254:INFO:python_version: 3.11.8
2025-05-12 21:24:49,254:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 21:24:49,254:INFO:machine: AMD64
2025-05-12 21:24:49,254:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 21:24:49,259:INFO:Memory: svmem(total=16907886592, available=2661965824, percent=84.3, used=14245920768, free=2661965824)
2025-05-12 21:24:49,259:INFO:Physical Core: 4
2025-05-12 21:24:49,259:INFO:Logical Core: 8
2025-05-12 21:24:49,259:INFO:Checking libraries
2025-05-12 21:24:49,259:INFO:System:
2025-05-12 21:24:49,259:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 21:24:49,259:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 21:24:49,259:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 21:24:49,259:INFO:PyCaret required dependencies:
2025-05-12 21:24:49,292:INFO:                 pip: 24.0
2025-05-12 21:24:49,292:INFO:          setuptools: 65.5.0
2025-05-12 21:24:49,292:INFO:             pycaret: 3.3.2
2025-05-12 21:24:49,292:INFO:             IPython: 9.2.0
2025-05-12 21:24:49,292:INFO:          ipywidgets: 8.1.7
2025-05-12 21:24:49,292:INFO:                tqdm: 4.67.1
2025-05-12 21:24:49,292:INFO:               numpy: 1.26.4
2025-05-12 21:24:49,292:INFO:              pandas: 2.1.4
2025-05-12 21:24:49,292:INFO:              jinja2: 3.1.6
2025-05-12 21:24:49,292:INFO:               scipy: 1.11.4
2025-05-12 21:24:49,292:INFO:              joblib: 1.3.2
2025-05-12 21:24:49,292:INFO:             sklearn: 1.4.2
2025-05-12 21:24:49,292:INFO:                pyod: 2.0.5
2025-05-12 21:24:49,292:INFO:            imblearn: 0.13.0
2025-05-12 21:24:49,292:INFO:   category_encoders: 2.7.0
2025-05-12 21:24:49,292:INFO:            lightgbm: 4.6.0
2025-05-12 21:24:49,292:INFO:               numba: 0.61.2
2025-05-12 21:24:49,292:INFO:            requests: 2.32.3
2025-05-12 21:24:49,292:INFO:          matplotlib: 3.7.5
2025-05-12 21:24:49,292:INFO:          scikitplot: 0.3.7
2025-05-12 21:24:49,292:INFO:         yellowbrick: 1.5
2025-05-12 21:24:49,292:INFO:              plotly: 5.24.1
2025-05-12 21:24:49,292:INFO:    plotly-resampler: Not installed
2025-05-12 21:24:49,292:INFO:             kaleido: 0.2.1
2025-05-12 21:24:49,292:INFO:           schemdraw: 0.15
2025-05-12 21:24:49,292:INFO:         statsmodels: 0.14.4
2025-05-12 21:24:49,292:INFO:              sktime: 0.26.0
2025-05-12 21:24:49,292:INFO:               tbats: 1.1.3
2025-05-12 21:24:49,292:INFO:            pmdarima: 2.0.4
2025-05-12 21:24:49,292:INFO:              psutil: 7.0.0
2025-05-12 21:24:49,292:INFO:          markupsafe: 3.0.2
2025-05-12 21:24:49,292:INFO:             pickle5: Not installed
2025-05-12 21:24:49,292:INFO:         cloudpickle: 3.1.1
2025-05-12 21:24:49,292:INFO:         deprecation: 2.1.0
2025-05-12 21:24:49,292:INFO:              xxhash: 3.5.0
2025-05-12 21:24:49,292:INFO:           wurlitzer: Not installed
2025-05-12 21:24:49,294:INFO:PyCaret optional dependencies:
2025-05-12 21:24:49,308:INFO:                shap: Not installed
2025-05-12 21:24:49,308:INFO:           interpret: Not installed
2025-05-12 21:24:49,308:INFO:                umap: Not installed
2025-05-12 21:24:49,308:INFO:     ydata_profiling: Not installed
2025-05-12 21:24:49,308:INFO:  explainerdashboard: Not installed
2025-05-12 21:24:49,309:INFO:             autoviz: Not installed
2025-05-12 21:24:49,309:INFO:           fairlearn: Not installed
2025-05-12 21:24:49,309:INFO:          deepchecks: Not installed
2025-05-12 21:24:49,309:INFO:             xgboost: Not installed
2025-05-12 21:24:49,309:INFO:            catboost: Not installed
2025-05-12 21:24:49,309:INFO:              kmodes: Not installed
2025-05-12 21:24:49,310:INFO:             mlxtend: Not installed
2025-05-12 21:24:49,310:INFO:       statsforecast: Not installed
2025-05-12 21:24:49,310:INFO:        tune_sklearn: Not installed
2025-05-12 21:24:49,310:INFO:                 ray: Not installed
2025-05-12 21:24:49,310:INFO:            hyperopt: Not installed
2025-05-12 21:24:49,310:INFO:              optuna: Not installed
2025-05-12 21:24:49,310:INFO:               skopt: Not installed
2025-05-12 21:24:49,310:INFO:              mlflow: Not installed
2025-05-12 21:24:49,310:INFO:              gradio: Not installed
2025-05-12 21:24:49,310:INFO:             fastapi: Not installed
2025-05-12 21:24:49,310:INFO:             uvicorn: Not installed
2025-05-12 21:24:49,310:INFO:              m2cgen: Not installed
2025-05-12 21:24:49,310:INFO:           evidently: Not installed
2025-05-12 21:24:49,310:INFO:               fugue: Not installed
2025-05-12 21:24:49,310:INFO:           streamlit: Not installed
2025-05-12 21:24:49,310:INFO:             prophet: Not installed
2025-05-12 21:24:49,310:INFO:None
2025-05-12 21:24:49,310:INFO:Set up data.
2025-05-12 21:24:49,317:INFO:Set up folding strategy.
2025-05-12 21:24:49,317:INFO:Set up train/test split.
2025-05-12 21:24:49,322:INFO:Set up index.
2025-05-12 21:24:49,324:INFO:Assigning column types.
2025-05-12 21:24:49,327:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 21:24:49,327:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,332:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,339:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,456:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,457:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,462:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,468:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,526:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,571:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,572:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 21:24:49,575:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,581:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,636:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,684:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,688:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,743:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,786:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,788:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,788:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 21:24:49,797:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,850:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,894:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:49,905:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:24:49,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,002:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,002:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,002:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 21:24:50,070:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,114:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,180:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,228:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 21:24:50,311:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:24:50,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,505:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 21:24:50,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:50,746:INFO:Preparing preprocessing pipeline...
2025-05-12 21:24:50,746:INFO:Set up simple imputation.
2025-05-12 21:24:50,748:INFO:Set up encoding of categorical features.
2025-05-12 21:24:50,748:INFO:Set up feature normalization.
2025-05-12 21:24:50,841:INFO:Finished creating preprocessing pipeline.
2025-05-12 21:24:50,849:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 21:24:50,849:INFO:Creating final display dataframe.
2025-05-12 21:24:51,003:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            precio
2                   Target type        Regression
3           Original data shape          (100, 7)
4        Transformed data shape         (100, 10)
5   Transformed train set shape          (70, 10)
6    Transformed test set shape          (30, 10)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              afdb
2025-05-12 21:24:51,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:51,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:51,225:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:51,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:24:51,226:INFO:setup() successfully completed in 1.98s...............
2025-05-12 21:24:51,235:INFO:Initializing compare_models()
2025-05-12 21:24:51,235:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 21:24:51,235:INFO:Checking exceptions
2025-05-12 21:24:51,237:INFO:Preparing display monitor
2025-05-12 21:24:51,270:INFO:Initializing Linear Regression
2025-05-12 21:24:51,270:INFO:Total runtime is 0.0 minutes
2025-05-12 21:24:51,275:INFO:SubProcess create_model() called ==================================
2025-05-12 21:24:51,275:INFO:Initializing create_model()
2025-05-12 21:24:51,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:24:51,275:INFO:Checking exceptions
2025-05-12 21:24:51,275:INFO:Importing libraries
2025-05-12 21:24:51,276:INFO:Copying training dataset
2025-05-12 21:24:51,281:INFO:Defining folds
2025-05-12 21:24:51,281:INFO:Declaring metric variables
2025-05-12 21:24:51,285:INFO:Importing untrained model
2025-05-12 21:24:51,289:INFO:Linear Regression Imported successfully
2025-05-12 21:24:51,298:INFO:Starting cross validation
2025-05-12 21:24:51,307:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:00,960:INFO:Calculating mean and std
2025-05-12 21:25:00,961:INFO:Creating metrics dataframe
2025-05-12 21:25:00,962:INFO:Uploading results into container
2025-05-12 21:25:00,964:INFO:Uploading model into container now
2025-05-12 21:25:00,964:INFO:_master_model_container: 1
2025-05-12 21:25:00,964:INFO:_display_container: 2
2025-05-12 21:25:00,965:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:25:00,965:INFO:create_model() successfully completed......................................
2025-05-12 21:25:01,041:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:01,041:INFO:Creating metrics dataframe
2025-05-12 21:25:01,047:INFO:Initializing Lasso Regression
2025-05-12 21:25:01,047:INFO:Total runtime is 0.1629357973734538 minutes
2025-05-12 21:25:01,051:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:01,052:INFO:Initializing create_model()
2025-05-12 21:25:01,052:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:01,052:INFO:Checking exceptions
2025-05-12 21:25:01,052:INFO:Importing libraries
2025-05-12 21:25:01,052:INFO:Copying training dataset
2025-05-12 21:25:01,056:INFO:Defining folds
2025-05-12 21:25:01,056:INFO:Declaring metric variables
2025-05-12 21:25:01,059:INFO:Importing untrained model
2025-05-12 21:25:01,062:INFO:Lasso Regression Imported successfully
2025-05-12 21:25:01,072:INFO:Starting cross validation
2025-05-12 21:25:01,074:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:01,259:INFO:Calculating mean and std
2025-05-12 21:25:01,259:INFO:Creating metrics dataframe
2025-05-12 21:25:01,262:INFO:Uploading results into container
2025-05-12 21:25:01,263:INFO:Uploading model into container now
2025-05-12 21:25:01,263:INFO:_master_model_container: 2
2025-05-12 21:25:01,263:INFO:_display_container: 2
2025-05-12 21:25:01,263:INFO:Lasso(random_state=123)
2025-05-12 21:25:01,263:INFO:create_model() successfully completed......................................
2025-05-12 21:25:01,335:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:01,335:INFO:Creating metrics dataframe
2025-05-12 21:25:01,343:INFO:Initializing Ridge Regression
2025-05-12 21:25:01,343:INFO:Total runtime is 0.1678742567698161 minutes
2025-05-12 21:25:01,347:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:01,347:INFO:Initializing create_model()
2025-05-12 21:25:01,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:01,347:INFO:Checking exceptions
2025-05-12 21:25:01,347:INFO:Importing libraries
2025-05-12 21:25:01,347:INFO:Copying training dataset
2025-05-12 21:25:01,352:INFO:Defining folds
2025-05-12 21:25:01,353:INFO:Declaring metric variables
2025-05-12 21:25:01,355:INFO:Importing untrained model
2025-05-12 21:25:01,360:INFO:Ridge Regression Imported successfully
2025-05-12 21:25:01,369:INFO:Starting cross validation
2025-05-12 21:25:01,370:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:01,543:INFO:Calculating mean and std
2025-05-12 21:25:01,543:INFO:Creating metrics dataframe
2025-05-12 21:25:01,546:INFO:Uploading results into container
2025-05-12 21:25:01,546:INFO:Uploading model into container now
2025-05-12 21:25:01,547:INFO:_master_model_container: 3
2025-05-12 21:25:01,547:INFO:_display_container: 2
2025-05-12 21:25:01,548:INFO:Ridge(random_state=123)
2025-05-12 21:25:01,548:INFO:create_model() successfully completed......................................
2025-05-12 21:25:01,622:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:01,623:INFO:Creating metrics dataframe
2025-05-12 21:25:01,629:INFO:Initializing Elastic Net
2025-05-12 21:25:01,629:INFO:Total runtime is 0.17265101671218874 minutes
2025-05-12 21:25:01,632:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:01,634:INFO:Initializing create_model()
2025-05-12 21:25:01,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:01,634:INFO:Checking exceptions
2025-05-12 21:25:01,634:INFO:Importing libraries
2025-05-12 21:25:01,634:INFO:Copying training dataset
2025-05-12 21:25:01,638:INFO:Defining folds
2025-05-12 21:25:01,639:INFO:Declaring metric variables
2025-05-12 21:25:01,641:INFO:Importing untrained model
2025-05-12 21:25:01,645:INFO:Elastic Net Imported successfully
2025-05-12 21:25:01,653:INFO:Starting cross validation
2025-05-12 21:25:01,655:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:01,829:INFO:Calculating mean and std
2025-05-12 21:25:01,831:INFO:Creating metrics dataframe
2025-05-12 21:25:01,832:INFO:Uploading results into container
2025-05-12 21:25:01,833:INFO:Uploading model into container now
2025-05-12 21:25:01,834:INFO:_master_model_container: 4
2025-05-12 21:25:01,834:INFO:_display_container: 2
2025-05-12 21:25:01,834:INFO:ElasticNet(random_state=123)
2025-05-12 21:25:01,834:INFO:create_model() successfully completed......................................
2025-05-12 21:25:01,910:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:01,910:INFO:Creating metrics dataframe
2025-05-12 21:25:01,917:INFO:Initializing Least Angle Regression
2025-05-12 21:25:01,917:INFO:Total runtime is 0.1774511019388835 minutes
2025-05-12 21:25:01,922:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:01,922:INFO:Initializing create_model()
2025-05-12 21:25:01,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:01,922:INFO:Checking exceptions
2025-05-12 21:25:01,922:INFO:Importing libraries
2025-05-12 21:25:01,923:INFO:Copying training dataset
2025-05-12 21:25:01,926:INFO:Defining folds
2025-05-12 21:25:01,927:INFO:Declaring metric variables
2025-05-12 21:25:01,930:INFO:Importing untrained model
2025-05-12 21:25:01,934:INFO:Least Angle Regression Imported successfully
2025-05-12 21:25:01,943:INFO:Starting cross validation
2025-05-12 21:25:01,944:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:02,125:INFO:Calculating mean and std
2025-05-12 21:25:02,125:INFO:Creating metrics dataframe
2025-05-12 21:25:02,127:INFO:Uploading results into container
2025-05-12 21:25:02,128:INFO:Uploading model into container now
2025-05-12 21:25:02,128:INFO:_master_model_container: 5
2025-05-12 21:25:02,128:INFO:_display_container: 2
2025-05-12 21:25:02,129:INFO:Lars(random_state=123)
2025-05-12 21:25:02,129:INFO:create_model() successfully completed......................................
2025-05-12 21:25:02,202:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:02,202:INFO:Creating metrics dataframe
2025-05-12 21:25:02,210:INFO:Initializing Lasso Least Angle Regression
2025-05-12 21:25:02,210:INFO:Total runtime is 0.18232665459314987 minutes
2025-05-12 21:25:02,215:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:02,216:INFO:Initializing create_model()
2025-05-12 21:25:02,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:02,216:INFO:Checking exceptions
2025-05-12 21:25:02,216:INFO:Importing libraries
2025-05-12 21:25:02,216:INFO:Copying training dataset
2025-05-12 21:25:02,219:INFO:Defining folds
2025-05-12 21:25:02,219:INFO:Declaring metric variables
2025-05-12 21:25:02,222:INFO:Importing untrained model
2025-05-12 21:25:02,225:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 21:25:02,234:INFO:Starting cross validation
2025-05-12 21:25:02,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:02,422:INFO:Calculating mean and std
2025-05-12 21:25:02,423:INFO:Creating metrics dataframe
2025-05-12 21:25:02,425:INFO:Uploading results into container
2025-05-12 21:25:02,425:INFO:Uploading model into container now
2025-05-12 21:25:02,425:INFO:_master_model_container: 6
2025-05-12 21:25:02,425:INFO:_display_container: 2
2025-05-12 21:25:02,427:INFO:LassoLars(random_state=123)
2025-05-12 21:25:02,427:INFO:create_model() successfully completed......................................
2025-05-12 21:25:02,499:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:02,499:INFO:Creating metrics dataframe
2025-05-12 21:25:02,506:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 21:25:02,506:INFO:Total runtime is 0.187268344561259 minutes
2025-05-12 21:25:02,509:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:02,509:INFO:Initializing create_model()
2025-05-12 21:25:02,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:02,511:INFO:Checking exceptions
2025-05-12 21:25:02,511:INFO:Importing libraries
2025-05-12 21:25:02,511:INFO:Copying training dataset
2025-05-12 21:25:02,514:INFO:Defining folds
2025-05-12 21:25:02,514:INFO:Declaring metric variables
2025-05-12 21:25:02,517:INFO:Importing untrained model
2025-05-12 21:25:02,521:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 21:25:02,529:INFO:Starting cross validation
2025-05-12 21:25:02,530:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:02,721:INFO:Calculating mean and std
2025-05-12 21:25:02,727:INFO:Creating metrics dataframe
2025-05-12 21:25:02,730:INFO:Uploading results into container
2025-05-12 21:25:02,731:INFO:Uploading model into container now
2025-05-12 21:25:02,731:INFO:_master_model_container: 7
2025-05-12 21:25:02,732:INFO:_display_container: 2
2025-05-12 21:25:02,732:INFO:OrthogonalMatchingPursuit()
2025-05-12 21:25:02,732:INFO:create_model() successfully completed......................................
2025-05-12 21:25:02,852:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:02,852:INFO:Creating metrics dataframe
2025-05-12 21:25:02,861:INFO:Initializing Bayesian Ridge
2025-05-12 21:25:02,861:INFO:Total runtime is 0.1931766788164775 minutes
2025-05-12 21:25:02,867:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:02,867:INFO:Initializing create_model()
2025-05-12 21:25:02,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:02,867:INFO:Checking exceptions
2025-05-12 21:25:02,867:INFO:Importing libraries
2025-05-12 21:25:02,867:INFO:Copying training dataset
2025-05-12 21:25:02,873:INFO:Defining folds
2025-05-12 21:25:02,874:INFO:Declaring metric variables
2025-05-12 21:25:02,879:INFO:Importing untrained model
2025-05-12 21:25:02,884:INFO:Bayesian Ridge Imported successfully
2025-05-12 21:25:02,892:INFO:Starting cross validation
2025-05-12 21:25:02,894:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:03,104:INFO:Calculating mean and std
2025-05-12 21:25:03,105:INFO:Creating metrics dataframe
2025-05-12 21:25:03,108:INFO:Uploading results into container
2025-05-12 21:25:03,109:INFO:Uploading model into container now
2025-05-12 21:25:03,109:INFO:_master_model_container: 8
2025-05-12 21:25:03,109:INFO:_display_container: 2
2025-05-12 21:25:03,111:INFO:BayesianRidge()
2025-05-12 21:25:03,111:INFO:create_model() successfully completed......................................
2025-05-12 21:25:03,184:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:03,184:INFO:Creating metrics dataframe
2025-05-12 21:25:03,192:INFO:Initializing Passive Aggressive Regressor
2025-05-12 21:25:03,192:INFO:Total runtime is 0.1987003842989604 minutes
2025-05-12 21:25:03,195:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:03,196:INFO:Initializing create_model()
2025-05-12 21:25:03,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:03,196:INFO:Checking exceptions
2025-05-12 21:25:03,196:INFO:Importing libraries
2025-05-12 21:25:03,196:INFO:Copying training dataset
2025-05-12 21:25:03,201:INFO:Defining folds
2025-05-12 21:25:03,202:INFO:Declaring metric variables
2025-05-12 21:25:03,205:INFO:Importing untrained model
2025-05-12 21:25:03,208:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 21:25:03,219:INFO:Starting cross validation
2025-05-12 21:25:03,220:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:03,295:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,303:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,309:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,312:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,314:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,315:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,321:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,346:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,388:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,394:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:25:03,423:INFO:Calculating mean and std
2025-05-12 21:25:03,423:INFO:Creating metrics dataframe
2025-05-12 21:25:03,426:INFO:Uploading results into container
2025-05-12 21:25:03,427:INFO:Uploading model into container now
2025-05-12 21:25:03,428:INFO:_master_model_container: 9
2025-05-12 21:25:03,428:INFO:_display_container: 2
2025-05-12 21:25:03,428:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 21:25:03,429:INFO:create_model() successfully completed......................................
2025-05-12 21:25:03,543:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:03,543:INFO:Creating metrics dataframe
2025-05-12 21:25:03,563:INFO:Initializing Huber Regressor
2025-05-12 21:25:03,563:INFO:Total runtime is 0.20488003889719647 minutes
2025-05-12 21:25:03,568:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:03,569:INFO:Initializing create_model()
2025-05-12 21:25:03,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:03,569:INFO:Checking exceptions
2025-05-12 21:25:03,569:INFO:Importing libraries
2025-05-12 21:25:03,569:INFO:Copying training dataset
2025-05-12 21:25:03,572:INFO:Defining folds
2025-05-12 21:25:03,573:INFO:Declaring metric variables
2025-05-12 21:25:03,577:INFO:Importing untrained model
2025-05-12 21:25:03,581:INFO:Huber Regressor Imported successfully
2025-05-12 21:25:03,592:INFO:Starting cross validation
2025-05-12 21:25:03,593:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:03,809:INFO:Calculating mean and std
2025-05-12 21:25:03,809:INFO:Creating metrics dataframe
2025-05-12 21:25:03,812:INFO:Uploading results into container
2025-05-12 21:25:03,813:INFO:Uploading model into container now
2025-05-12 21:25:03,814:INFO:_master_model_container: 10
2025-05-12 21:25:03,814:INFO:_display_container: 2
2025-05-12 21:25:03,814:INFO:HuberRegressor()
2025-05-12 21:25:03,814:INFO:create_model() successfully completed......................................
2025-05-12 21:25:03,883:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:03,883:INFO:Creating metrics dataframe
2025-05-12 21:25:03,892:INFO:Initializing K Neighbors Regressor
2025-05-12 21:25:03,892:INFO:Total runtime is 0.21035494804382326 minutes
2025-05-12 21:25:03,896:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:03,897:INFO:Initializing create_model()
2025-05-12 21:25:03,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:03,897:INFO:Checking exceptions
2025-05-12 21:25:03,898:INFO:Importing libraries
2025-05-12 21:25:03,898:INFO:Copying training dataset
2025-05-12 21:25:03,901:INFO:Defining folds
2025-05-12 21:25:03,902:INFO:Declaring metric variables
2025-05-12 21:25:03,904:INFO:Importing untrained model
2025-05-12 21:25:03,908:INFO:K Neighbors Regressor Imported successfully
2025-05-12 21:25:03,916:INFO:Starting cross validation
2025-05-12 21:25:03,917:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:04,142:INFO:Calculating mean and std
2025-05-12 21:25:04,144:INFO:Creating metrics dataframe
2025-05-12 21:25:04,146:INFO:Uploading results into container
2025-05-12 21:25:04,146:INFO:Uploading model into container now
2025-05-12 21:25:04,147:INFO:_master_model_container: 11
2025-05-12 21:25:04,147:INFO:_display_container: 2
2025-05-12 21:25:04,147:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 21:25:04,148:INFO:create_model() successfully completed......................................
2025-05-12 21:25:04,217:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:04,217:INFO:Creating metrics dataframe
2025-05-12 21:25:04,225:INFO:Initializing Decision Tree Regressor
2025-05-12 21:25:04,226:INFO:Total runtime is 0.21593229770660402 minutes
2025-05-12 21:25:04,229:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:04,229:INFO:Initializing create_model()
2025-05-12 21:25:04,229:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:04,229:INFO:Checking exceptions
2025-05-12 21:25:04,229:INFO:Importing libraries
2025-05-12 21:25:04,231:INFO:Copying training dataset
2025-05-12 21:25:04,235:INFO:Defining folds
2025-05-12 21:25:04,235:INFO:Declaring metric variables
2025-05-12 21:25:04,238:INFO:Importing untrained model
2025-05-12 21:25:04,241:INFO:Decision Tree Regressor Imported successfully
2025-05-12 21:25:04,248:INFO:Starting cross validation
2025-05-12 21:25:04,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:04,430:INFO:Calculating mean and std
2025-05-12 21:25:04,432:INFO:Creating metrics dataframe
2025-05-12 21:25:04,435:INFO:Uploading results into container
2025-05-12 21:25:04,436:INFO:Uploading model into container now
2025-05-12 21:25:04,436:INFO:_master_model_container: 12
2025-05-12 21:25:04,437:INFO:_display_container: 2
2025-05-12 21:25:04,437:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 21:25:04,437:INFO:create_model() successfully completed......................................
2025-05-12 21:25:04,508:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:04,508:INFO:Creating metrics dataframe
2025-05-12 21:25:04,519:INFO:Initializing Random Forest Regressor
2025-05-12 21:25:04,519:INFO:Total runtime is 0.22080289522806806 minutes
2025-05-12 21:25:04,523:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:04,523:INFO:Initializing create_model()
2025-05-12 21:25:04,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:04,523:INFO:Checking exceptions
2025-05-12 21:25:04,523:INFO:Importing libraries
2025-05-12 21:25:04,524:INFO:Copying training dataset
2025-05-12 21:25:04,527:INFO:Defining folds
2025-05-12 21:25:04,527:INFO:Declaring metric variables
2025-05-12 21:25:04,530:INFO:Importing untrained model
2025-05-12 21:25:04,535:INFO:Random Forest Regressor Imported successfully
2025-05-12 21:25:04,549:INFO:Starting cross validation
2025-05-12 21:25:04,551:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:05,409:INFO:Calculating mean and std
2025-05-12 21:25:05,409:INFO:Creating metrics dataframe
2025-05-12 21:25:05,411:INFO:Uploading results into container
2025-05-12 21:25:05,412:INFO:Uploading model into container now
2025-05-12 21:25:05,413:INFO:_master_model_container: 13
2025-05-12 21:25:05,413:INFO:_display_container: 2
2025-05-12 21:25:05,414:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:25:05,414:INFO:create_model() successfully completed......................................
2025-05-12 21:25:05,486:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:05,486:INFO:Creating metrics dataframe
2025-05-12 21:25:05,496:INFO:Initializing Extra Trees Regressor
2025-05-12 21:25:05,496:INFO:Total runtime is 0.2371017456054688 minutes
2025-05-12 21:25:05,501:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:05,502:INFO:Initializing create_model()
2025-05-12 21:25:05,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:05,502:INFO:Checking exceptions
2025-05-12 21:25:05,502:INFO:Importing libraries
2025-05-12 21:25:05,502:INFO:Copying training dataset
2025-05-12 21:25:05,506:INFO:Defining folds
2025-05-12 21:25:05,506:INFO:Declaring metric variables
2025-05-12 21:25:05,509:INFO:Importing untrained model
2025-05-12 21:25:05,513:INFO:Extra Trees Regressor Imported successfully
2025-05-12 21:25:05,521:INFO:Starting cross validation
2025-05-12 21:25:05,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:06,141:INFO:Calculating mean and std
2025-05-12 21:25:06,141:INFO:Creating metrics dataframe
2025-05-12 21:25:06,144:INFO:Uploading results into container
2025-05-12 21:25:06,145:INFO:Uploading model into container now
2025-05-12 21:25:06,146:INFO:_master_model_container: 14
2025-05-12 21:25:06,146:INFO:_display_container: 2
2025-05-12 21:25:06,147:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:25:06,147:INFO:create_model() successfully completed......................................
2025-05-12 21:25:06,218:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:06,218:INFO:Creating metrics dataframe
2025-05-12 21:25:06,228:INFO:Initializing AdaBoost Regressor
2025-05-12 21:25:06,228:INFO:Total runtime is 0.24929802417755131 minutes
2025-05-12 21:25:06,232:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:06,232:INFO:Initializing create_model()
2025-05-12 21:25:06,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:06,232:INFO:Checking exceptions
2025-05-12 21:25:06,232:INFO:Importing libraries
2025-05-12 21:25:06,233:INFO:Copying training dataset
2025-05-12 21:25:06,236:INFO:Defining folds
2025-05-12 21:25:06,236:INFO:Declaring metric variables
2025-05-12 21:25:06,239:INFO:Importing untrained model
2025-05-12 21:25:06,243:INFO:AdaBoost Regressor Imported successfully
2025-05-12 21:25:06,253:INFO:Starting cross validation
2025-05-12 21:25:06,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:06,685:INFO:Calculating mean and std
2025-05-12 21:25:06,686:INFO:Creating metrics dataframe
2025-05-12 21:25:06,689:INFO:Uploading results into container
2025-05-12 21:25:06,689:INFO:Uploading model into container now
2025-05-12 21:25:06,691:INFO:_master_model_container: 15
2025-05-12 21:25:06,691:INFO:_display_container: 2
2025-05-12 21:25:06,692:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 21:25:06,692:INFO:create_model() successfully completed......................................
2025-05-12 21:25:06,767:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:06,767:INFO:Creating metrics dataframe
2025-05-12 21:25:06,778:INFO:Initializing Gradient Boosting Regressor
2025-05-12 21:25:06,778:INFO:Total runtime is 0.2584522485733033 minutes
2025-05-12 21:25:06,782:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:06,782:INFO:Initializing create_model()
2025-05-12 21:25:06,782:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:06,782:INFO:Checking exceptions
2025-05-12 21:25:06,782:INFO:Importing libraries
2025-05-12 21:25:06,782:INFO:Copying training dataset
2025-05-12 21:25:06,787:INFO:Defining folds
2025-05-12 21:25:06,787:INFO:Declaring metric variables
2025-05-12 21:25:06,789:INFO:Importing untrained model
2025-05-12 21:25:06,795:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 21:25:06,805:INFO:Starting cross validation
2025-05-12 21:25:06,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:07,153:INFO:Calculating mean and std
2025-05-12 21:25:07,155:INFO:Creating metrics dataframe
2025-05-12 21:25:07,156:INFO:Uploading results into container
2025-05-12 21:25:07,157:INFO:Uploading model into container now
2025-05-12 21:25:07,157:INFO:_master_model_container: 16
2025-05-12 21:25:07,157:INFO:_display_container: 2
2025-05-12 21:25:07,158:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 21:25:07,158:INFO:create_model() successfully completed......................................
2025-05-12 21:25:07,228:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:07,228:INFO:Creating metrics dataframe
2025-05-12 21:25:07,239:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 21:25:07,239:INFO:Total runtime is 0.2661504745483399 minutes
2025-05-12 21:25:07,242:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:07,242:INFO:Initializing create_model()
2025-05-12 21:25:07,242:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:07,242:INFO:Checking exceptions
2025-05-12 21:25:07,242:INFO:Importing libraries
2025-05-12 21:25:07,243:INFO:Copying training dataset
2025-05-12 21:25:07,248:INFO:Defining folds
2025-05-12 21:25:07,248:INFO:Declaring metric variables
2025-05-12 21:25:07,250:INFO:Importing untrained model
2025-05-12 21:25:07,254:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 21:25:07,262:INFO:Starting cross validation
2025-05-12 21:25:07,265:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:07,776:INFO:Calculating mean and std
2025-05-12 21:25:07,776:INFO:Creating metrics dataframe
2025-05-12 21:25:07,781:INFO:Uploading results into container
2025-05-12 21:25:07,782:INFO:Uploading model into container now
2025-05-12 21:25:07,783:INFO:_master_model_container: 17
2025-05-12 21:25:07,783:INFO:_display_container: 2
2025-05-12 21:25:07,785:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:25:07,785:INFO:create_model() successfully completed......................................
2025-05-12 21:25:07,885:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:07,885:INFO:Creating metrics dataframe
2025-05-12 21:25:07,897:INFO:Initializing Dummy Regressor
2025-05-12 21:25:07,897:INFO:Total runtime is 0.2771038134892782 minutes
2025-05-12 21:25:07,901:INFO:SubProcess create_model() called ==================================
2025-05-12 21:25:07,901:INFO:Initializing create_model()
2025-05-12 21:25:07,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023360113510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:07,902:INFO:Checking exceptions
2025-05-12 21:25:07,902:INFO:Importing libraries
2025-05-12 21:25:07,902:INFO:Copying training dataset
2025-05-12 21:25:07,906:INFO:Defining folds
2025-05-12 21:25:07,906:INFO:Declaring metric variables
2025-05-12 21:25:07,910:INFO:Importing untrained model
2025-05-12 21:25:07,915:INFO:Dummy Regressor Imported successfully
2025-05-12 21:25:07,925:INFO:Starting cross validation
2025-05-12 21:25:07,928:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:08,119:INFO:Calculating mean and std
2025-05-12 21:25:08,120:INFO:Creating metrics dataframe
2025-05-12 21:25:08,122:INFO:Uploading results into container
2025-05-12 21:25:08,123:INFO:Uploading model into container now
2025-05-12 21:25:08,123:INFO:_master_model_container: 18
2025-05-12 21:25:08,124:INFO:_display_container: 2
2025-05-12 21:25:08,124:INFO:DummyRegressor()
2025-05-12 21:25:08,124:INFO:create_model() successfully completed......................................
2025-05-12 21:25:08,198:INFO:SubProcess create_model() end ==================================
2025-05-12 21:25:08,199:INFO:Creating metrics dataframe
2025-05-12 21:25:08,210:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 21:25:08,220:INFO:Initializing create_model()
2025-05-12 21:25:08,220:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:08,220:INFO:Checking exceptions
2025-05-12 21:25:08,222:INFO:Importing libraries
2025-05-12 21:25:08,222:INFO:Copying training dataset
2025-05-12 21:25:08,225:INFO:Defining folds
2025-05-12 21:25:08,225:INFO:Declaring metric variables
2025-05-12 21:25:08,225:INFO:Importing untrained model
2025-05-12 21:25:08,226:INFO:Declaring custom model
2025-05-12 21:25:08,226:INFO:Linear Regression Imported successfully
2025-05-12 21:25:08,227:INFO:Cross validation set to False
2025-05-12 21:25:08,227:INFO:Fitting Model
2025-05-12 21:25:08,255:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:25:08,255:INFO:create_model() successfully completed......................................
2025-05-12 21:25:08,350:INFO:_master_model_container: 18
2025-05-12 21:25:08,350:INFO:_display_container: 2
2025-05-12 21:25:08,351:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:25:08,351:INFO:compare_models() successfully completed......................................
2025-05-12 21:25:08,379:INFO:Initializing create_model()
2025-05-12 21:25:08,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002333BFA7510>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:25:08,380:INFO:Checking exceptions
2025-05-12 21:25:08,398:INFO:Importing libraries
2025-05-12 21:25:08,398:INFO:Copying training dataset
2025-05-12 21:25:08,404:INFO:Defining folds
2025-05-12 21:25:08,404:INFO:Declaring metric variables
2025-05-12 21:25:08,408:INFO:Importing untrained model
2025-05-12 21:25:08,412:INFO:Linear Regression Imported successfully
2025-05-12 21:25:08,422:INFO:Starting cross validation
2025-05-12 21:25:08,423:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:25:08,622:INFO:Calculating mean and std
2025-05-12 21:25:08,623:INFO:Creating metrics dataframe
2025-05-12 21:25:08,628:INFO:Finalizing model
2025-05-12 21:25:08,668:INFO:Uploading results into container
2025-05-12 21:25:08,669:INFO:Uploading model into container now
2025-05-12 21:25:08,680:INFO:_master_model_container: 19
2025-05-12 21:25:08,680:INFO:_display_container: 3
2025-05-12 21:25:08,681:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:25:08,681:INFO:create_model() successfully completed......................................
2025-05-12 21:40:17,014:INFO:Initializing tune_model()
2025-05-12 21:40:17,015:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 21:40:17,015:INFO:Checking exceptions
2025-05-12 21:40:17,033:INFO:Copying training dataset
2025-05-12 21:40:17,037:INFO:Checking base model
2025-05-12 21:40:17,037:INFO:Base model : Linear Regression
2025-05-12 21:40:17,042:INFO:Declaring metric variables
2025-05-12 21:40:17,045:INFO:Defining Hyperparameters
2025-05-12 21:40:17,045:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-05-12 21:40:17,133:INFO:Tuning with n_jobs=-1
2025-05-12 21:40:17,133:INFO:Initializing GridSearchCV
2025-05-12 21:40:28,451:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-05-12 21:40:28,453:INFO:Hyperparameter search completed
2025-05-12 21:40:28,453:INFO:SubProcess create_model() called ==================================
2025-05-12 21:40:28,455:INFO:Initializing create_model()
2025-05-12 21:40:28,455:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FA59B850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True})
2025-05-12 21:40:28,456:INFO:Checking exceptions
2025-05-12 21:40:28,456:INFO:Importing libraries
2025-05-12 21:40:28,456:INFO:Copying training dataset
2025-05-12 21:40:28,462:INFO:Defining folds
2025-05-12 21:40:28,462:INFO:Declaring metric variables
2025-05-12 21:40:28,466:INFO:Importing untrained model
2025-05-12 21:40:28,466:INFO:Declaring custom model
2025-05-12 21:40:28,472:INFO:Linear Regression Imported successfully
2025-05-12 21:40:28,485:INFO:Starting cross validation
2025-05-12 21:40:28,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:40:28,888:INFO:Calculating mean and std
2025-05-12 21:40:28,890:INFO:Creating metrics dataframe
2025-05-12 21:40:28,903:INFO:Finalizing model
2025-05-12 21:40:28,990:INFO:Uploading results into container
2025-05-12 21:40:28,992:INFO:Uploading model into container now
2025-05-12 21:40:28,993:INFO:_master_model_container: 20
2025-05-12 21:40:28,993:INFO:_display_container: 4
2025-05-12 21:40:28,994:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:40:28,994:INFO:create_model() successfully completed......................................
2025-05-12 21:40:29,128:INFO:SubProcess create_model() end ==================================
2025-05-12 21:40:29,128:INFO:choose_better activated
2025-05-12 21:40:29,135:INFO:SubProcess create_model() called ==================================
2025-05-12 21:40:29,136:INFO:Initializing create_model()
2025-05-12 21:40:29,136:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:40:29,136:INFO:Checking exceptions
2025-05-12 21:40:29,141:INFO:Importing libraries
2025-05-12 21:40:29,141:INFO:Copying training dataset
2025-05-12 21:40:29,146:INFO:Defining folds
2025-05-12 21:40:29,148:INFO:Declaring metric variables
2025-05-12 21:40:29,148:INFO:Importing untrained model
2025-05-12 21:40:29,148:INFO:Declaring custom model
2025-05-12 21:40:29,148:INFO:Linear Regression Imported successfully
2025-05-12 21:40:29,149:INFO:Starting cross validation
2025-05-12 21:40:29,151:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:40:29,432:INFO:Calculating mean and std
2025-05-12 21:40:29,432:INFO:Creating metrics dataframe
2025-05-12 21:40:29,435:INFO:Finalizing model
2025-05-12 21:40:29,502:INFO:Uploading results into container
2025-05-12 21:40:29,502:INFO:Uploading model into container now
2025-05-12 21:40:29,503:INFO:_master_model_container: 21
2025-05-12 21:40:29,503:INFO:_display_container: 5
2025-05-12 21:40:29,504:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:40:29,504:INFO:create_model() successfully completed......................................
2025-05-12 21:40:29,618:INFO:SubProcess create_model() end ==================================
2025-05-12 21:40:29,620:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9592
2025-05-12 21:40:29,620:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9592
2025-05-12 21:40:29,620:INFO:LinearRegression(n_jobs=-1) is best model
2025-05-12 21:40:29,621:INFO:choose_better completed
2025-05-12 21:40:29,621:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 21:40:29,638:INFO:_master_model_container: 21
2025-05-12 21:40:29,638:INFO:_display_container: 4
2025-05-12 21:40:29,640:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:40:29,640:INFO:tune_model() successfully completed......................................
2025-05-12 21:42:56,784:INFO:Initializing evaluate_model()
2025-05-12 21:42:56,784:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 21:42:56,792:INFO:Initializing plot_model()
2025-05-12 21:42:56,792:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 21:42:56,792:INFO:Checking exceptions
2025-05-12 21:42:56,795:INFO:Preloading libraries
2025-05-12 21:42:56,795:INFO:Copying training dataset
2025-05-12 21:42:56,795:INFO:Plot type: pipeline
2025-05-12 21:42:57,042:INFO:Visual Rendered Successfully
2025-05-12 21:42:57,117:INFO:plot_model() successfully completed......................................
2025-05-12 21:43:20,345:INFO:Initializing evaluate_model()
2025-05-12 21:43:20,345:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 21:43:20,354:INFO:Initializing plot_model()
2025-05-12 21:43:20,355:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 21:43:20,355:INFO:Checking exceptions
2025-05-12 21:43:20,356:INFO:Preloading libraries
2025-05-12 21:43:20,356:INFO:Copying training dataset
2025-05-12 21:43:20,358:INFO:Plot type: pipeline
2025-05-12 21:43:20,498:INFO:Visual Rendered Successfully
2025-05-12 21:43:20,576:INFO:plot_model() successfully completed......................................
2025-05-12 21:46:03,300:INFO:Initializing predict_model()
2025-05-12 21:46:03,301:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000180FAA37CE0>)
2025-05-12 21:46:03,301:INFO:Checking exceptions
2025-05-12 21:46:03,301:INFO:Preloading libraries
2025-05-12 21:46:03,388:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 21:49:11,672:INFO:Initializing predict_model()
2025-05-12 21:49:11,672:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA5A4B10>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000180FABE40E0>)
2025-05-12 21:49:11,672:INFO:Checking exceptions
2025-05-12 21:49:11,672:INFO:Preloading libraries
2025-05-12 21:49:11,750:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 21:58:43,369:INFO:PyCaret RegressionExperiment
2025-05-12 21:58:43,369:INFO:Logging name: reg-default-name
2025-05-12 21:58:43,369:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 21:58:43,369:INFO:version 3.3.2
2025-05-12 21:58:43,370:INFO:Initializing setup()
2025-05-12 21:58:43,370:INFO:self.USI: ae80
2025-05-12 21:58:43,370:INFO:self._variable_keys: {'exp_id', 'transform_target_param', 'X_test', 'X_train', 'y_train', 'memory', 'log_plots_param', 'X', 'y', 'target_param', 'gpu_param', 'html_param', 'exp_name_log', 'USI', 'data', 'pipeline', 'y_test', '_ml_usecase', 'seed', '_available_plots', 'fold_groups_param', 'idx', 'fold_shuffle_param', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'logging_param'}
2025-05-12 21:58:43,370:INFO:Checking environment
2025-05-12 21:58:43,370:INFO:python_version: 3.11.8
2025-05-12 21:58:43,370:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 21:58:43,370:INFO:machine: AMD64
2025-05-12 21:58:43,370:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 21:58:43,384:INFO:Memory: svmem(total=16907886592, available=4335013888, percent=74.4, used=12572872704, free=4335013888)
2025-05-12 21:58:43,385:INFO:Physical Core: 4
2025-05-12 21:58:43,385:INFO:Logical Core: 8
2025-05-12 21:58:43,385:INFO:Checking libraries
2025-05-12 21:58:43,385:INFO:System:
2025-05-12 21:58:43,385:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 21:58:43,385:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 21:58:43,385:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 21:58:43,385:INFO:PyCaret required dependencies:
2025-05-12 21:58:43,385:INFO:                 pip: 24.0
2025-05-12 21:58:43,385:INFO:          setuptools: 65.5.0
2025-05-12 21:58:43,386:INFO:             pycaret: 3.3.2
2025-05-12 21:58:43,386:INFO:             IPython: 9.2.0
2025-05-12 21:58:43,386:INFO:          ipywidgets: 8.1.7
2025-05-12 21:58:43,386:INFO:                tqdm: 4.67.1
2025-05-12 21:58:43,386:INFO:               numpy: 1.26.4
2025-05-12 21:58:43,386:INFO:              pandas: 2.1.4
2025-05-12 21:58:43,386:INFO:              jinja2: 3.1.6
2025-05-12 21:58:43,386:INFO:               scipy: 1.11.4
2025-05-12 21:58:43,386:INFO:              joblib: 1.3.2
2025-05-12 21:58:43,386:INFO:             sklearn: 1.4.2
2025-05-12 21:58:43,386:INFO:                pyod: 2.0.5
2025-05-12 21:58:43,386:INFO:            imblearn: 0.13.0
2025-05-12 21:58:43,386:INFO:   category_encoders: 2.7.0
2025-05-12 21:58:43,386:INFO:            lightgbm: 4.6.0
2025-05-12 21:58:43,386:INFO:               numba: 0.61.2
2025-05-12 21:58:43,386:INFO:            requests: 2.32.3
2025-05-12 21:58:43,387:INFO:          matplotlib: 3.7.5
2025-05-12 21:58:43,387:INFO:          scikitplot: 0.3.7
2025-05-12 21:58:43,387:INFO:         yellowbrick: 1.5
2025-05-12 21:58:43,387:INFO:              plotly: 5.24.1
2025-05-12 21:58:43,387:INFO:    plotly-resampler: Not installed
2025-05-12 21:58:43,388:INFO:             kaleido: 0.2.1
2025-05-12 21:58:43,388:INFO:           schemdraw: 0.15
2025-05-12 21:58:43,388:INFO:         statsmodels: 0.14.4
2025-05-12 21:58:43,388:INFO:              sktime: 0.26.0
2025-05-12 21:58:43,388:INFO:               tbats: 1.1.3
2025-05-12 21:58:43,388:INFO:            pmdarima: 2.0.4
2025-05-12 21:58:43,388:INFO:              psutil: 7.0.0
2025-05-12 21:58:43,389:INFO:          markupsafe: 3.0.2
2025-05-12 21:58:43,389:INFO:             pickle5: Not installed
2025-05-12 21:58:43,389:INFO:         cloudpickle: 3.1.1
2025-05-12 21:58:43,389:INFO:         deprecation: 2.1.0
2025-05-12 21:58:43,389:INFO:              xxhash: 3.5.0
2025-05-12 21:58:43,389:INFO:           wurlitzer: Not installed
2025-05-12 21:58:43,390:INFO:PyCaret optional dependencies:
2025-05-12 21:58:43,390:INFO:                shap: Not installed
2025-05-12 21:58:43,390:INFO:           interpret: Not installed
2025-05-12 21:58:43,390:INFO:                umap: Not installed
2025-05-12 21:58:43,390:INFO:     ydata_profiling: Not installed
2025-05-12 21:58:43,390:INFO:  explainerdashboard: Not installed
2025-05-12 21:58:43,391:INFO:             autoviz: Not installed
2025-05-12 21:58:43,391:INFO:           fairlearn: Not installed
2025-05-12 21:58:43,391:INFO:          deepchecks: Not installed
2025-05-12 21:58:43,391:INFO:             xgboost: Not installed
2025-05-12 21:58:43,391:INFO:            catboost: Not installed
2025-05-12 21:58:43,391:INFO:              kmodes: Not installed
2025-05-12 21:58:43,391:INFO:             mlxtend: Not installed
2025-05-12 21:58:43,391:INFO:       statsforecast: Not installed
2025-05-12 21:58:43,391:INFO:        tune_sklearn: Not installed
2025-05-12 21:58:43,391:INFO:                 ray: Not installed
2025-05-12 21:58:43,391:INFO:            hyperopt: Not installed
2025-05-12 21:58:43,392:INFO:              optuna: Not installed
2025-05-12 21:58:43,392:INFO:               skopt: Not installed
2025-05-12 21:58:43,392:INFO:              mlflow: Not installed
2025-05-12 21:58:43,392:INFO:              gradio: Not installed
2025-05-12 21:58:43,392:INFO:             fastapi: Not installed
2025-05-12 21:58:43,392:INFO:             uvicorn: Not installed
2025-05-12 21:58:43,392:INFO:              m2cgen: Not installed
2025-05-12 21:58:43,392:INFO:           evidently: Not installed
2025-05-12 21:58:43,392:INFO:               fugue: Not installed
2025-05-12 21:58:43,392:INFO:           streamlit: Not installed
2025-05-12 21:58:43,392:INFO:             prophet: Not installed
2025-05-12 21:58:43,392:INFO:None
2025-05-12 21:58:43,393:INFO:Set up data.
2025-05-12 21:58:43,400:INFO:Set up folding strategy.
2025-05-12 21:58:43,400:INFO:Set up train/test split.
2025-05-12 21:58:43,404:INFO:Set up index.
2025-05-12 21:58:43,406:INFO:Assigning column types.
2025-05-12 21:58:43,410:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 21:58:43,411:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,419:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,427:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,486:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,531:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,534:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,540:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,544:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,597:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,641:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 21:58:43,645:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,649:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,744:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,745:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,749:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,752:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,809:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,850:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,850:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,850:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,851:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 21:58:43,859:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,922:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,962:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:43,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:43,971:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,075:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,076:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,077:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 21:58:44,147:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,198:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,198:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,283:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,338:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,339:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 21:58:44,431:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,499:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,500:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,589:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:58:44,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,674:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,674:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 21:58:44,866:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:44,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:45,076:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:45,076:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:45,077:INFO:Preparing preprocessing pipeline...
2025-05-12 21:58:45,078:INFO:Set up simple imputation.
2025-05-12 21:58:45,079:INFO:Set up encoding of categorical features.
2025-05-12 21:58:45,081:INFO:Set up feature normalization.
2025-05-12 21:58:45,163:INFO:Finished creating preprocessing pipeline.
2025-05-12 21:58:45,176:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 21:58:45,176:INFO:Creating final display dataframe.
2025-05-12 21:58:45,447:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            precio
2                   Target type        Regression
3           Original data shape          (100, 7)
4        Transformed data shape         (100, 10)
5   Transformed train set shape          (70, 10)
6    Transformed test set shape          (30, 10)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              ae80
2025-05-12 21:58:45,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:45,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:45,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:45,843:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:58:45,844:INFO:setup() successfully completed in 2.48s...............
2025-05-12 21:58:45,853:INFO:Initializing compare_models()
2025-05-12 21:58:45,853:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA902250>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000180FA902250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 21:58:45,854:INFO:Checking exceptions
2025-05-12 21:58:45,858:INFO:Preparing display monitor
2025-05-12 21:58:45,889:INFO:Initializing Linear Regression
2025-05-12 21:58:45,890:INFO:Total runtime is 1.7495950063069663e-05 minutes
2025-05-12 21:58:45,895:INFO:SubProcess create_model() called ==================================
2025-05-12 21:58:45,896:INFO:Initializing create_model()
2025-05-12 21:58:45,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA902250>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FE375690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:58:45,896:INFO:Checking exceptions
2025-05-12 21:58:45,896:INFO:Importing libraries
2025-05-12 21:58:45,896:INFO:Copying training dataset
2025-05-12 21:58:45,901:INFO:Defining folds
2025-05-12 21:58:45,902:INFO:Declaring metric variables
2025-05-12 21:58:45,907:INFO:Importing untrained model
2025-05-12 21:58:45,913:INFO:Linear Regression Imported successfully
2025-05-12 21:58:45,924:INFO:Starting cross validation
2025-05-12 21:58:45,927:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:07,488:INFO:PyCaret RegressionExperiment
2025-05-12 21:59:07,488:INFO:Logging name: reg-default-name
2025-05-12 21:59:07,488:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 21:59:07,489:INFO:version 3.3.2
2025-05-12 21:59:07,489:INFO:Initializing setup()
2025-05-12 21:59:07,489:INFO:self.USI: 192c
2025-05-12 21:59:07,489:INFO:self._variable_keys: {'exp_id', 'transform_target_param', 'X_test', 'X_train', 'y_train', 'memory', 'log_plots_param', 'X', 'y', 'target_param', 'gpu_param', 'html_param', 'exp_name_log', 'USI', 'data', 'pipeline', 'y_test', '_ml_usecase', 'seed', '_available_plots', 'fold_groups_param', 'idx', 'fold_shuffle_param', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'logging_param'}
2025-05-12 21:59:07,489:INFO:Checking environment
2025-05-12 21:59:07,489:INFO:python_version: 3.11.8
2025-05-12 21:59:07,489:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 21:59:07,489:INFO:machine: AMD64
2025-05-12 21:59:07,490:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 21:59:07,496:INFO:Memory: svmem(total=16907886592, available=4224679936, percent=75.0, used=12683206656, free=4224679936)
2025-05-12 21:59:07,496:INFO:Physical Core: 4
2025-05-12 21:59:07,496:INFO:Logical Core: 8
2025-05-12 21:59:07,497:INFO:Checking libraries
2025-05-12 21:59:07,497:INFO:System:
2025-05-12 21:59:07,497:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 21:59:07,497:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 21:59:07,497:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 21:59:07,497:INFO:PyCaret required dependencies:
2025-05-12 21:59:07,497:INFO:                 pip: 24.0
2025-05-12 21:59:07,497:INFO:          setuptools: 65.5.0
2025-05-12 21:59:07,497:INFO:             pycaret: 3.3.2
2025-05-12 21:59:07,497:INFO:             IPython: 9.2.0
2025-05-12 21:59:07,497:INFO:          ipywidgets: 8.1.7
2025-05-12 21:59:07,498:INFO:                tqdm: 4.67.1
2025-05-12 21:59:07,498:INFO:               numpy: 1.26.4
2025-05-12 21:59:07,498:INFO:              pandas: 2.1.4
2025-05-12 21:59:07,498:INFO:              jinja2: 3.1.6
2025-05-12 21:59:07,498:INFO:               scipy: 1.11.4
2025-05-12 21:59:07,498:INFO:              joblib: 1.3.2
2025-05-12 21:59:07,498:INFO:             sklearn: 1.4.2
2025-05-12 21:59:07,498:INFO:                pyod: 2.0.5
2025-05-12 21:59:07,498:INFO:            imblearn: 0.13.0
2025-05-12 21:59:07,498:INFO:   category_encoders: 2.7.0
2025-05-12 21:59:07,498:INFO:            lightgbm: 4.6.0
2025-05-12 21:59:07,498:INFO:               numba: 0.61.2
2025-05-12 21:59:07,498:INFO:            requests: 2.32.3
2025-05-12 21:59:07,498:INFO:          matplotlib: 3.7.5
2025-05-12 21:59:07,499:INFO:          scikitplot: 0.3.7
2025-05-12 21:59:07,499:INFO:         yellowbrick: 1.5
2025-05-12 21:59:07,499:INFO:              plotly: 5.24.1
2025-05-12 21:59:07,499:INFO:    plotly-resampler: Not installed
2025-05-12 21:59:07,499:INFO:             kaleido: 0.2.1
2025-05-12 21:59:07,499:INFO:           schemdraw: 0.15
2025-05-12 21:59:07,499:INFO:         statsmodels: 0.14.4
2025-05-12 21:59:07,499:INFO:              sktime: 0.26.0
2025-05-12 21:59:07,499:INFO:               tbats: 1.1.3
2025-05-12 21:59:07,499:INFO:            pmdarima: 2.0.4
2025-05-12 21:59:07,500:INFO:              psutil: 7.0.0
2025-05-12 21:59:07,500:INFO:          markupsafe: 3.0.2
2025-05-12 21:59:07,500:INFO:             pickle5: Not installed
2025-05-12 21:59:07,500:INFO:         cloudpickle: 3.1.1
2025-05-12 21:59:07,500:INFO:         deprecation: 2.1.0
2025-05-12 21:59:07,500:INFO:              xxhash: 3.5.0
2025-05-12 21:59:07,500:INFO:           wurlitzer: Not installed
2025-05-12 21:59:07,500:INFO:PyCaret optional dependencies:
2025-05-12 21:59:07,500:INFO:                shap: Not installed
2025-05-12 21:59:07,500:INFO:           interpret: Not installed
2025-05-12 21:59:07,500:INFO:                umap: Not installed
2025-05-12 21:59:07,500:INFO:     ydata_profiling: Not installed
2025-05-12 21:59:07,501:INFO:  explainerdashboard: Not installed
2025-05-12 21:59:07,501:INFO:             autoviz: Not installed
2025-05-12 21:59:07,501:INFO:           fairlearn: Not installed
2025-05-12 21:59:07,501:INFO:          deepchecks: Not installed
2025-05-12 21:59:07,501:INFO:             xgboost: Not installed
2025-05-12 21:59:07,501:INFO:            catboost: Not installed
2025-05-12 21:59:07,501:INFO:              kmodes: Not installed
2025-05-12 21:59:07,501:INFO:             mlxtend: Not installed
2025-05-12 21:59:07,501:INFO:       statsforecast: Not installed
2025-05-12 21:59:07,501:INFO:        tune_sklearn: Not installed
2025-05-12 21:59:07,501:INFO:                 ray: Not installed
2025-05-12 21:59:07,501:INFO:            hyperopt: Not installed
2025-05-12 21:59:07,501:INFO:              optuna: Not installed
2025-05-12 21:59:07,501:INFO:               skopt: Not installed
2025-05-12 21:59:07,501:INFO:              mlflow: Not installed
2025-05-12 21:59:07,501:INFO:              gradio: Not installed
2025-05-12 21:59:07,501:INFO:             fastapi: Not installed
2025-05-12 21:59:07,501:INFO:             uvicorn: Not installed
2025-05-12 21:59:07,503:INFO:              m2cgen: Not installed
2025-05-12 21:59:07,503:INFO:           evidently: Not installed
2025-05-12 21:59:07,503:INFO:               fugue: Not installed
2025-05-12 21:59:07,503:INFO:           streamlit: Not installed
2025-05-12 21:59:07,503:INFO:             prophet: Not installed
2025-05-12 21:59:07,503:INFO:None
2025-05-12 21:59:07,503:INFO:Set up data.
2025-05-12 21:59:07,509:INFO:Set up folding strategy.
2025-05-12 21:59:07,509:INFO:Set up train/test split.
2025-05-12 21:59:07,515:INFO:Set up index.
2025-05-12 21:59:07,516:INFO:Assigning column types.
2025-05-12 21:59:07,521:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 21:59:07,521:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:59:07,532:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:59:07,545:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:59:07,737:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:07,856:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:07,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:07,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:07,858:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 21:59:07,869:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:59:07,878:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,137:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,138:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,139:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 21:59:08,144:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,151:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,227:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,293:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,293:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,302:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,308:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,392:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,454:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,455:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 21:59:08,469:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,555:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,626:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,627:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,642:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,747:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,818:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 21:59:08,922:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,982:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:08,982:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:08,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,063:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:09,112:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 21:59:09,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,113:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 21:59:09,187:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:09,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,297:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 21:59:09,342:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,342:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 21:59:09,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,589:INFO:Preparing preprocessing pipeline...
2025-05-12 21:59:09,589:INFO:Set up simple imputation.
2025-05-12 21:59:09,591:INFO:Set up encoding of categorical features.
2025-05-12 21:59:09,591:INFO:Set up feature normalization.
2025-05-12 21:59:09,647:INFO:Finished creating preprocessing pipeline.
2025-05-12 21:59:09,657:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 21:59:09,657:INFO:Creating final display dataframe.
2025-05-12 21:59:09,836:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            precio
2                   Target type        Regression
3           Original data shape          (100, 7)
4        Transformed data shape         (100, 10)
5   Transformed train set shape          (70, 10)
6    Transformed test set shape          (30, 10)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              192c
2025-05-12 21:59:09,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:09,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:10,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:10,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 21:59:10,126:INFO:setup() successfully completed in 2.64s...............
2025-05-12 21:59:10,137:INFO:Initializing compare_models()
2025-05-12 21:59:10,137:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 21:59:10,137:INFO:Checking exceptions
2025-05-12 21:59:10,141:INFO:Preparing display monitor
2025-05-12 21:59:10,176:INFO:Initializing Linear Regression
2025-05-12 21:59:10,176:INFO:Total runtime is 0.0 minutes
2025-05-12 21:59:10,184:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:10,185:INFO:Initializing create_model()
2025-05-12 21:59:10,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:10,185:INFO:Checking exceptions
2025-05-12 21:59:10,185:INFO:Importing libraries
2025-05-12 21:59:10,185:INFO:Copying training dataset
2025-05-12 21:59:10,190:INFO:Defining folds
2025-05-12 21:59:10,190:INFO:Declaring metric variables
2025-05-12 21:59:10,196:INFO:Importing untrained model
2025-05-12 21:59:10,201:INFO:Linear Regression Imported successfully
2025-05-12 21:59:10,211:INFO:Starting cross validation
2025-05-12 21:59:10,214:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:37,276:INFO:Calculating mean and std
2025-05-12 21:59:37,278:INFO:Creating metrics dataframe
2025-05-12 21:59:37,282:INFO:Uploading results into container
2025-05-12 21:59:37,283:INFO:Uploading model into container now
2025-05-12 21:59:37,284:INFO:_master_model_container: 1
2025-05-12 21:59:37,284:INFO:_display_container: 2
2025-05-12 21:59:37,285:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:59:37,285:INFO:create_model() successfully completed......................................
2025-05-12 21:59:37,428:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:37,428:INFO:Creating metrics dataframe
2025-05-12 21:59:37,436:INFO:Initializing Lasso Regression
2025-05-12 21:59:37,437:INFO:Total runtime is 0.45435139338175456 minutes
2025-05-12 21:59:37,443:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:37,444:INFO:Initializing create_model()
2025-05-12 21:59:37,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:37,444:INFO:Checking exceptions
2025-05-12 21:59:37,445:INFO:Importing libraries
2025-05-12 21:59:37,445:INFO:Copying training dataset
2025-05-12 21:59:37,450:INFO:Defining folds
2025-05-12 21:59:37,451:INFO:Declaring metric variables
2025-05-12 21:59:37,459:INFO:Importing untrained model
2025-05-12 21:59:37,466:INFO:Lasso Regression Imported successfully
2025-05-12 21:59:37,479:INFO:Starting cross validation
2025-05-12 21:59:37,482:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:37,767:INFO:Calculating mean and std
2025-05-12 21:59:37,771:INFO:Creating metrics dataframe
2025-05-12 21:59:37,773:INFO:Uploading results into container
2025-05-12 21:59:37,774:INFO:Uploading model into container now
2025-05-12 21:59:37,774:INFO:_master_model_container: 2
2025-05-12 21:59:37,776:INFO:_display_container: 2
2025-05-12 21:59:37,776:INFO:Lasso(random_state=123)
2025-05-12 21:59:37,777:INFO:create_model() successfully completed......................................
2025-05-12 21:59:37,921:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:37,921:INFO:Creating metrics dataframe
2025-05-12 21:59:37,931:INFO:Initializing Ridge Regression
2025-05-12 21:59:37,932:INFO:Total runtime is 0.46260168552398684 minutes
2025-05-12 21:59:37,938:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:37,938:INFO:Initializing create_model()
2025-05-12 21:59:37,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:37,938:INFO:Checking exceptions
2025-05-12 21:59:37,938:INFO:Importing libraries
2025-05-12 21:59:37,938:INFO:Copying training dataset
2025-05-12 21:59:37,947:INFO:Defining folds
2025-05-12 21:59:37,947:INFO:Declaring metric variables
2025-05-12 21:59:37,954:INFO:Importing untrained model
2025-05-12 21:59:37,961:INFO:Ridge Regression Imported successfully
2025-05-12 21:59:37,973:INFO:Starting cross validation
2025-05-12 21:59:37,976:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:38,236:INFO:Calculating mean and std
2025-05-12 21:59:38,237:INFO:Creating metrics dataframe
2025-05-12 21:59:38,241:INFO:Uploading results into container
2025-05-12 21:59:38,242:INFO:Uploading model into container now
2025-05-12 21:59:38,242:INFO:_master_model_container: 3
2025-05-12 21:59:38,242:INFO:_display_container: 2
2025-05-12 21:59:38,243:INFO:Ridge(random_state=123)
2025-05-12 21:59:38,244:INFO:create_model() successfully completed......................................
2025-05-12 21:59:38,373:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:38,373:INFO:Creating metrics dataframe
2025-05-12 21:59:38,382:INFO:Initializing Elastic Net
2025-05-12 21:59:38,382:INFO:Total runtime is 0.47009887297948205 minutes
2025-05-12 21:59:38,388:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:38,389:INFO:Initializing create_model()
2025-05-12 21:59:38,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:38,389:INFO:Checking exceptions
2025-05-12 21:59:38,389:INFO:Importing libraries
2025-05-12 21:59:38,389:INFO:Copying training dataset
2025-05-12 21:59:38,396:INFO:Defining folds
2025-05-12 21:59:38,396:INFO:Declaring metric variables
2025-05-12 21:59:38,401:INFO:Importing untrained model
2025-05-12 21:59:38,409:INFO:Elastic Net Imported successfully
2025-05-12 21:59:38,422:INFO:Starting cross validation
2025-05-12 21:59:38,423:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:38,663:INFO:Calculating mean and std
2025-05-12 21:59:38,665:INFO:Creating metrics dataframe
2025-05-12 21:59:38,667:INFO:Uploading results into container
2025-05-12 21:59:38,668:INFO:Uploading model into container now
2025-05-12 21:59:38,668:INFO:_master_model_container: 4
2025-05-12 21:59:38,669:INFO:_display_container: 2
2025-05-12 21:59:38,669:INFO:ElasticNet(random_state=123)
2025-05-12 21:59:38,669:INFO:create_model() successfully completed......................................
2025-05-12 21:59:38,787:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:38,787:INFO:Creating metrics dataframe
2025-05-12 21:59:38,799:INFO:Initializing Least Angle Regression
2025-05-12 21:59:38,800:INFO:Total runtime is 0.4770725727081299 minutes
2025-05-12 21:59:38,806:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:38,806:INFO:Initializing create_model()
2025-05-12 21:59:38,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:38,806:INFO:Checking exceptions
2025-05-12 21:59:38,806:INFO:Importing libraries
2025-05-12 21:59:38,806:INFO:Copying training dataset
2025-05-12 21:59:38,812:INFO:Defining folds
2025-05-12 21:59:38,812:INFO:Declaring metric variables
2025-05-12 21:59:38,818:INFO:Importing untrained model
2025-05-12 21:59:38,824:INFO:Least Angle Regression Imported successfully
2025-05-12 21:59:38,834:INFO:Starting cross validation
2025-05-12 21:59:38,836:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:39,037:INFO:Calculating mean and std
2025-05-12 21:59:39,039:INFO:Creating metrics dataframe
2025-05-12 21:59:39,041:INFO:Uploading results into container
2025-05-12 21:59:39,041:INFO:Uploading model into container now
2025-05-12 21:59:39,042:INFO:_master_model_container: 5
2025-05-12 21:59:39,042:INFO:_display_container: 2
2025-05-12 21:59:39,042:INFO:Lars(random_state=123)
2025-05-12 21:59:39,042:INFO:create_model() successfully completed......................................
2025-05-12 21:59:39,192:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:39,192:INFO:Creating metrics dataframe
2025-05-12 21:59:39,202:INFO:Initializing Lasso Least Angle Regression
2025-05-12 21:59:39,202:INFO:Total runtime is 0.4837677836418152 minutes
2025-05-12 21:59:39,207:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:39,208:INFO:Initializing create_model()
2025-05-12 21:59:39,208:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:39,208:INFO:Checking exceptions
2025-05-12 21:59:39,208:INFO:Importing libraries
2025-05-12 21:59:39,208:INFO:Copying training dataset
2025-05-12 21:59:39,213:INFO:Defining folds
2025-05-12 21:59:39,214:INFO:Declaring metric variables
2025-05-12 21:59:39,220:INFO:Importing untrained model
2025-05-12 21:59:39,226:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 21:59:39,234:INFO:Starting cross validation
2025-05-12 21:59:39,237:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:39,449:INFO:Calculating mean and std
2025-05-12 21:59:39,450:INFO:Creating metrics dataframe
2025-05-12 21:59:39,453:INFO:Uploading results into container
2025-05-12 21:59:39,453:INFO:Uploading model into container now
2025-05-12 21:59:39,455:INFO:_master_model_container: 6
2025-05-12 21:59:39,455:INFO:_display_container: 2
2025-05-12 21:59:39,456:INFO:LassoLars(random_state=123)
2025-05-12 21:59:39,456:INFO:create_model() successfully completed......................................
2025-05-12 21:59:39,566:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:39,566:INFO:Creating metrics dataframe
2025-05-12 21:59:39,574:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 21:59:39,575:INFO:Total runtime is 0.4899897654851278 minutes
2025-05-12 21:59:39,578:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:39,578:INFO:Initializing create_model()
2025-05-12 21:59:39,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:39,579:INFO:Checking exceptions
2025-05-12 21:59:39,579:INFO:Importing libraries
2025-05-12 21:59:39,579:INFO:Copying training dataset
2025-05-12 21:59:39,584:INFO:Defining folds
2025-05-12 21:59:39,584:INFO:Declaring metric variables
2025-05-12 21:59:39,591:INFO:Importing untrained model
2025-05-12 21:59:39,596:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 21:59:39,607:INFO:Starting cross validation
2025-05-12 21:59:39,609:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:39,869:INFO:Calculating mean and std
2025-05-12 21:59:39,870:INFO:Creating metrics dataframe
2025-05-12 21:59:39,873:INFO:Uploading results into container
2025-05-12 21:59:39,874:INFO:Uploading model into container now
2025-05-12 21:59:39,874:INFO:_master_model_container: 7
2025-05-12 21:59:39,875:INFO:_display_container: 2
2025-05-12 21:59:39,875:INFO:OrthogonalMatchingPursuit()
2025-05-12 21:59:39,875:INFO:create_model() successfully completed......................................
2025-05-12 21:59:40,007:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:40,008:INFO:Creating metrics dataframe
2025-05-12 21:59:40,024:INFO:Initializing Bayesian Ridge
2025-05-12 21:59:40,025:INFO:Total runtime is 0.4974802374839783 minutes
2025-05-12 21:59:40,030:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:40,031:INFO:Initializing create_model()
2025-05-12 21:59:40,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:40,031:INFO:Checking exceptions
2025-05-12 21:59:40,031:INFO:Importing libraries
2025-05-12 21:59:40,031:INFO:Copying training dataset
2025-05-12 21:59:40,040:INFO:Defining folds
2025-05-12 21:59:40,040:INFO:Declaring metric variables
2025-05-12 21:59:40,043:INFO:Importing untrained model
2025-05-12 21:59:40,054:INFO:Bayesian Ridge Imported successfully
2025-05-12 21:59:40,064:INFO:Starting cross validation
2025-05-12 21:59:40,070:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:40,353:INFO:Calculating mean and std
2025-05-12 21:59:40,355:INFO:Creating metrics dataframe
2025-05-12 21:59:40,357:INFO:Uploading results into container
2025-05-12 21:59:40,358:INFO:Uploading model into container now
2025-05-12 21:59:40,359:INFO:_master_model_container: 8
2025-05-12 21:59:40,359:INFO:_display_container: 2
2025-05-12 21:59:40,359:INFO:BayesianRidge()
2025-05-12 21:59:40,361:INFO:create_model() successfully completed......................................
2025-05-12 21:59:40,488:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:40,488:INFO:Creating metrics dataframe
2025-05-12 21:59:40,499:INFO:Initializing Passive Aggressive Regressor
2025-05-12 21:59:40,499:INFO:Total runtime is 0.5053914825121562 minutes
2025-05-12 21:59:40,506:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:40,506:INFO:Initializing create_model()
2025-05-12 21:59:40,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:40,506:INFO:Checking exceptions
2025-05-12 21:59:40,506:INFO:Importing libraries
2025-05-12 21:59:40,506:INFO:Copying training dataset
2025-05-12 21:59:40,513:INFO:Defining folds
2025-05-12 21:59:40,514:INFO:Declaring metric variables
2025-05-12 21:59:40,558:INFO:Importing untrained model
2025-05-12 21:59:40,565:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 21:59:40,582:INFO:Starting cross validation
2025-05-12 21:59:40,584:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:40,794:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,794:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,794:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,794:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,797:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,807:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,828:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,913:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,925:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-12 21:59:40,953:INFO:Calculating mean and std
2025-05-12 21:59:40,955:INFO:Creating metrics dataframe
2025-05-12 21:59:40,958:INFO:Uploading results into container
2025-05-12 21:59:40,959:INFO:Uploading model into container now
2025-05-12 21:59:40,959:INFO:_master_model_container: 9
2025-05-12 21:59:40,959:INFO:_display_container: 2
2025-05-12 21:59:40,960:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 21:59:40,960:INFO:create_model() successfully completed......................................
2025-05-12 21:59:41,077:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:41,077:INFO:Creating metrics dataframe
2025-05-12 21:59:41,088:INFO:Initializing Huber Regressor
2025-05-12 21:59:41,088:INFO:Total runtime is 0.5152082641919454 minutes
2025-05-12 21:59:41,091:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:41,092:INFO:Initializing create_model()
2025-05-12 21:59:41,092:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:41,092:INFO:Checking exceptions
2025-05-12 21:59:41,093:INFO:Importing libraries
2025-05-12 21:59:41,093:INFO:Copying training dataset
2025-05-12 21:59:41,100:INFO:Defining folds
2025-05-12 21:59:41,100:INFO:Declaring metric variables
2025-05-12 21:59:41,106:INFO:Importing untrained model
2025-05-12 21:59:41,112:INFO:Huber Regressor Imported successfully
2025-05-12 21:59:41,122:INFO:Starting cross validation
2025-05-12 21:59:41,124:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:41,380:INFO:Calculating mean and std
2025-05-12 21:59:41,382:INFO:Creating metrics dataframe
2025-05-12 21:59:41,383:INFO:Uploading results into container
2025-05-12 21:59:41,385:INFO:Uploading model into container now
2025-05-12 21:59:41,386:INFO:_master_model_container: 10
2025-05-12 21:59:41,387:INFO:_display_container: 2
2025-05-12 21:59:41,387:INFO:HuberRegressor()
2025-05-12 21:59:41,387:INFO:create_model() successfully completed......................................
2025-05-12 21:59:41,500:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:41,501:INFO:Creating metrics dataframe
2025-05-12 21:59:41,511:INFO:Initializing K Neighbors Regressor
2025-05-12 21:59:41,511:INFO:Total runtime is 0.5222517967224122 minutes
2025-05-12 21:59:41,516:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:41,517:INFO:Initializing create_model()
2025-05-12 21:59:41,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:41,517:INFO:Checking exceptions
2025-05-12 21:59:41,517:INFO:Importing libraries
2025-05-12 21:59:41,517:INFO:Copying training dataset
2025-05-12 21:59:41,521:INFO:Defining folds
2025-05-12 21:59:41,521:INFO:Declaring metric variables
2025-05-12 21:59:41,528:INFO:Importing untrained model
2025-05-12 21:59:41,534:INFO:K Neighbors Regressor Imported successfully
2025-05-12 21:59:41,541:INFO:Starting cross validation
2025-05-12 21:59:41,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:41,838:INFO:Calculating mean and std
2025-05-12 21:59:41,839:INFO:Creating metrics dataframe
2025-05-12 21:59:41,841:INFO:Uploading results into container
2025-05-12 21:59:41,842:INFO:Uploading model into container now
2025-05-12 21:59:41,843:INFO:_master_model_container: 11
2025-05-12 21:59:41,843:INFO:_display_container: 2
2025-05-12 21:59:41,843:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 21:59:41,844:INFO:create_model() successfully completed......................................
2025-05-12 21:59:41,957:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:41,957:INFO:Creating metrics dataframe
2025-05-12 21:59:41,967:INFO:Initializing Decision Tree Regressor
2025-05-12 21:59:41,967:INFO:Total runtime is 0.5298539320627849 minutes
2025-05-12 21:59:41,971:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:41,972:INFO:Initializing create_model()
2025-05-12 21:59:41,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:41,972:INFO:Checking exceptions
2025-05-12 21:59:41,972:INFO:Importing libraries
2025-05-12 21:59:41,973:INFO:Copying training dataset
2025-05-12 21:59:41,978:INFO:Defining folds
2025-05-12 21:59:41,978:INFO:Declaring metric variables
2025-05-12 21:59:41,984:INFO:Importing untrained model
2025-05-12 21:59:41,990:INFO:Decision Tree Regressor Imported successfully
2025-05-12 21:59:41,998:INFO:Starting cross validation
2025-05-12 21:59:42,001:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:42,212:INFO:Calculating mean and std
2025-05-12 21:59:42,213:INFO:Creating metrics dataframe
2025-05-12 21:59:42,217:INFO:Uploading results into container
2025-05-12 21:59:42,217:INFO:Uploading model into container now
2025-05-12 21:59:42,219:INFO:_master_model_container: 12
2025-05-12 21:59:42,219:INFO:_display_container: 2
2025-05-12 21:59:42,220:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 21:59:42,220:INFO:create_model() successfully completed......................................
2025-05-12 21:59:42,336:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:42,337:INFO:Creating metrics dataframe
2025-05-12 21:59:42,349:INFO:Initializing Random Forest Regressor
2025-05-12 21:59:42,349:INFO:Total runtime is 0.5362255096435548 minutes
2025-05-12 21:59:42,354:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:42,356:INFO:Initializing create_model()
2025-05-12 21:59:42,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:42,356:INFO:Checking exceptions
2025-05-12 21:59:42,356:INFO:Importing libraries
2025-05-12 21:59:42,356:INFO:Copying training dataset
2025-05-12 21:59:42,361:INFO:Defining folds
2025-05-12 21:59:42,361:INFO:Declaring metric variables
2025-05-12 21:59:42,369:INFO:Importing untrained model
2025-05-12 21:59:42,376:INFO:Random Forest Regressor Imported successfully
2025-05-12 21:59:42,386:INFO:Starting cross validation
2025-05-12 21:59:42,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:43,218:INFO:Calculating mean and std
2025-05-12 21:59:43,219:INFO:Creating metrics dataframe
2025-05-12 21:59:43,222:INFO:Uploading results into container
2025-05-12 21:59:43,222:INFO:Uploading model into container now
2025-05-12 21:59:43,223:INFO:_master_model_container: 13
2025-05-12 21:59:43,223:INFO:_display_container: 2
2025-05-12 21:59:43,224:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:59:43,224:INFO:create_model() successfully completed......................................
2025-05-12 21:59:43,329:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:43,329:INFO:Creating metrics dataframe
2025-05-12 21:59:43,339:INFO:Initializing Extra Trees Regressor
2025-05-12 21:59:43,339:INFO:Total runtime is 0.5527250568072002 minutes
2025-05-12 21:59:43,343:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:43,343:INFO:Initializing create_model()
2025-05-12 21:59:43,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:43,343:INFO:Checking exceptions
2025-05-12 21:59:43,343:INFO:Importing libraries
2025-05-12 21:59:43,343:INFO:Copying training dataset
2025-05-12 21:59:43,350:INFO:Defining folds
2025-05-12 21:59:43,350:INFO:Declaring metric variables
2025-05-12 21:59:43,354:INFO:Importing untrained model
2025-05-12 21:59:43,359:INFO:Extra Trees Regressor Imported successfully
2025-05-12 21:59:43,369:INFO:Starting cross validation
2025-05-12 21:59:43,371:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:44,132:INFO:Calculating mean and std
2025-05-12 21:59:44,133:INFO:Creating metrics dataframe
2025-05-12 21:59:44,136:INFO:Uploading results into container
2025-05-12 21:59:44,137:INFO:Uploading model into container now
2025-05-12 21:59:44,139:INFO:_master_model_container: 14
2025-05-12 21:59:44,139:INFO:_display_container: 2
2025-05-12 21:59:44,140:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:59:44,140:INFO:create_model() successfully completed......................................
2025-05-12 21:59:44,253:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:44,253:INFO:Creating metrics dataframe
2025-05-12 21:59:44,264:INFO:Initializing AdaBoost Regressor
2025-05-12 21:59:44,264:INFO:Total runtime is 0.5681455413500469 minutes
2025-05-12 21:59:44,270:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:44,271:INFO:Initializing create_model()
2025-05-12 21:59:44,271:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:44,271:INFO:Checking exceptions
2025-05-12 21:59:44,271:INFO:Importing libraries
2025-05-12 21:59:44,271:INFO:Copying training dataset
2025-05-12 21:59:44,276:INFO:Defining folds
2025-05-12 21:59:44,276:INFO:Declaring metric variables
2025-05-12 21:59:44,282:INFO:Importing untrained model
2025-05-12 21:59:44,287:INFO:AdaBoost Regressor Imported successfully
2025-05-12 21:59:44,297:INFO:Starting cross validation
2025-05-12 21:59:44,300:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:44,801:INFO:Calculating mean and std
2025-05-12 21:59:44,803:INFO:Creating metrics dataframe
2025-05-12 21:59:44,805:INFO:Uploading results into container
2025-05-12 21:59:44,806:INFO:Uploading model into container now
2025-05-12 21:59:44,807:INFO:_master_model_container: 15
2025-05-12 21:59:44,807:INFO:_display_container: 2
2025-05-12 21:59:44,807:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 21:59:44,808:INFO:create_model() successfully completed......................................
2025-05-12 21:59:44,927:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:44,927:INFO:Creating metrics dataframe
2025-05-12 21:59:44,942:INFO:Initializing Gradient Boosting Regressor
2025-05-12 21:59:44,942:INFO:Total runtime is 0.5794375061988831 minutes
2025-05-12 21:59:44,947:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:44,947:INFO:Initializing create_model()
2025-05-12 21:59:44,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:44,947:INFO:Checking exceptions
2025-05-12 21:59:44,948:INFO:Importing libraries
2025-05-12 21:59:44,948:INFO:Copying training dataset
2025-05-12 21:59:44,955:INFO:Defining folds
2025-05-12 21:59:44,955:INFO:Declaring metric variables
2025-05-12 21:59:44,962:INFO:Importing untrained model
2025-05-12 21:59:44,979:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 21:59:45,009:INFO:Starting cross validation
2025-05-12 21:59:45,011:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:45,605:INFO:Calculating mean and std
2025-05-12 21:59:45,607:INFO:Creating metrics dataframe
2025-05-12 21:59:45,613:INFO:Uploading results into container
2025-05-12 21:59:45,614:INFO:Uploading model into container now
2025-05-12 21:59:45,615:INFO:_master_model_container: 16
2025-05-12 21:59:45,615:INFO:_display_container: 2
2025-05-12 21:59:45,617:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 21:59:45,617:INFO:create_model() successfully completed......................................
2025-05-12 21:59:45,789:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:45,790:INFO:Creating metrics dataframe
2025-05-12 21:59:45,808:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 21:59:45,808:INFO:Total runtime is 0.5938732743263245 minutes
2025-05-12 21:59:45,816:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:45,817:INFO:Initializing create_model()
2025-05-12 21:59:45,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:45,817:INFO:Checking exceptions
2025-05-12 21:59:45,817:INFO:Importing libraries
2025-05-12 21:59:45,817:INFO:Copying training dataset
2025-05-12 21:59:45,829:INFO:Defining folds
2025-05-12 21:59:45,829:INFO:Declaring metric variables
2025-05-12 21:59:45,840:INFO:Importing untrained model
2025-05-12 21:59:45,850:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 21:59:45,866:INFO:Starting cross validation
2025-05-12 21:59:45,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:46,652:INFO:Calculating mean and std
2025-05-12 21:59:46,655:INFO:Creating metrics dataframe
2025-05-12 21:59:46,657:INFO:Uploading results into container
2025-05-12 21:59:46,660:INFO:Uploading model into container now
2025-05-12 21:59:46,661:INFO:_master_model_container: 17
2025-05-12 21:59:46,661:INFO:_display_container: 2
2025-05-12 21:59:46,662:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 21:59:46,663:INFO:create_model() successfully completed......................................
2025-05-12 21:59:46,809:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:46,809:INFO:Creating metrics dataframe
2025-05-12 21:59:46,823:INFO:Initializing Dummy Regressor
2025-05-12 21:59:46,823:INFO:Total runtime is 0.6107922116915385 minutes
2025-05-12 21:59:46,830:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:46,830:INFO:Initializing create_model()
2025-05-12 21:59:46,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF4D76D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:46,831:INFO:Checking exceptions
2025-05-12 21:59:46,831:INFO:Importing libraries
2025-05-12 21:59:46,831:INFO:Copying training dataset
2025-05-12 21:59:46,837:INFO:Defining folds
2025-05-12 21:59:46,838:INFO:Declaring metric variables
2025-05-12 21:59:46,845:INFO:Importing untrained model
2025-05-12 21:59:46,852:INFO:Dummy Regressor Imported successfully
2025-05-12 21:59:46,861:INFO:Starting cross validation
2025-05-12 21:59:46,864:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:47,089:INFO:Calculating mean and std
2025-05-12 21:59:47,090:INFO:Creating metrics dataframe
2025-05-12 21:59:47,094:INFO:Uploading results into container
2025-05-12 21:59:47,095:INFO:Uploading model into container now
2025-05-12 21:59:47,096:INFO:_master_model_container: 18
2025-05-12 21:59:47,096:INFO:_display_container: 2
2025-05-12 21:59:47,097:INFO:DummyRegressor()
2025-05-12 21:59:47,097:INFO:create_model() successfully completed......................................
2025-05-12 21:59:47,219:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:47,219:INFO:Creating metrics dataframe
2025-05-12 21:59:47,236:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 21:59:47,262:INFO:Initializing create_model()
2025-05-12 21:59:47,262:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:47,262:INFO:Checking exceptions
2025-05-12 21:59:47,265:INFO:Importing libraries
2025-05-12 21:59:47,265:INFO:Copying training dataset
2025-05-12 21:59:47,270:INFO:Defining folds
2025-05-12 21:59:47,270:INFO:Declaring metric variables
2025-05-12 21:59:47,270:INFO:Importing untrained model
2025-05-12 21:59:47,270:INFO:Declaring custom model
2025-05-12 21:59:47,271:INFO:Linear Regression Imported successfully
2025-05-12 21:59:47,272:INFO:Cross validation set to False
2025-05-12 21:59:47,272:INFO:Fitting Model
2025-05-12 21:59:47,308:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:59:47,308:INFO:create_model() successfully completed......................................
2025-05-12 21:59:47,474:INFO:_master_model_container: 18
2025-05-12 21:59:47,474:INFO:_display_container: 2
2025-05-12 21:59:47,474:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:59:47,475:INFO:compare_models() successfully completed......................................
2025-05-12 21:59:47,505:INFO:Initializing create_model()
2025-05-12 21:59:47,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:47,505:INFO:Checking exceptions
2025-05-12 21:59:47,531:INFO:Importing libraries
2025-05-12 21:59:47,531:INFO:Copying training dataset
2025-05-12 21:59:47,552:INFO:Defining folds
2025-05-12 21:59:47,552:INFO:Declaring metric variables
2025-05-12 21:59:47,561:INFO:Importing untrained model
2025-05-12 21:59:47,567:INFO:Linear Regression Imported successfully
2025-05-12 21:59:47,580:INFO:Starting cross validation
2025-05-12 21:59:47,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:47,830:INFO:Calculating mean and std
2025-05-12 21:59:47,831:INFO:Creating metrics dataframe
2025-05-12 21:59:47,836:INFO:Finalizing model
2025-05-12 21:59:47,880:INFO:Uploading results into container
2025-05-12 21:59:47,881:INFO:Uploading model into container now
2025-05-12 21:59:47,896:INFO:_master_model_container: 19
2025-05-12 21:59:47,896:INFO:_display_container: 3
2025-05-12 21:59:47,896:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:59:47,898:INFO:create_model() successfully completed......................................
2025-05-12 21:59:48,022:INFO:Initializing tune_model()
2025-05-12 21:59:48,022:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 21:59:48,022:INFO:Checking exceptions
2025-05-12 21:59:48,044:INFO:Copying training dataset
2025-05-12 21:59:48,050:INFO:Checking base model
2025-05-12 21:59:48,050:INFO:Base model : Linear Regression
2025-05-12 21:59:48,057:INFO:Declaring metric variables
2025-05-12 21:59:48,068:INFO:Defining Hyperparameters
2025-05-12 21:59:48,068:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-05-12 21:59:48,204:INFO:Tuning with n_jobs=-1
2025-05-12 21:59:48,204:INFO:Initializing GridSearchCV
2025-05-12 21:59:48,632:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-05-12 21:59:48,633:INFO:Hyperparameter search completed
2025-05-12 21:59:48,633:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:48,633:INFO:Initializing create_model()
2025-05-12 21:59:48,633:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000180FF3B2AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True})
2025-05-12 21:59:48,633:INFO:Checking exceptions
2025-05-12 21:59:48,635:INFO:Importing libraries
2025-05-12 21:59:48,635:INFO:Copying training dataset
2025-05-12 21:59:48,639:INFO:Defining folds
2025-05-12 21:59:48,639:INFO:Declaring metric variables
2025-05-12 21:59:48,644:INFO:Importing untrained model
2025-05-12 21:59:48,644:INFO:Declaring custom model
2025-05-12 21:59:48,652:INFO:Linear Regression Imported successfully
2025-05-12 21:59:48,667:INFO:Starting cross validation
2025-05-12 21:59:48,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:48,955:INFO:Calculating mean and std
2025-05-12 21:59:48,956:INFO:Creating metrics dataframe
2025-05-12 21:59:48,963:INFO:Finalizing model
2025-05-12 21:59:49,018:INFO:Uploading results into container
2025-05-12 21:59:49,020:INFO:Uploading model into container now
2025-05-12 21:59:49,020:INFO:_master_model_container: 20
2025-05-12 21:59:49,021:INFO:_display_container: 4
2025-05-12 21:59:49,021:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:59:49,021:INFO:create_model() successfully completed......................................
2025-05-12 21:59:49,156:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:49,156:INFO:choose_better activated
2025-05-12 21:59:49,161:INFO:SubProcess create_model() called ==================================
2025-05-12 21:59:49,161:INFO:Initializing create_model()
2025-05-12 21:59:49,162:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 21:59:49,162:INFO:Checking exceptions
2025-05-12 21:59:49,166:INFO:Importing libraries
2025-05-12 21:59:49,167:INFO:Copying training dataset
2025-05-12 21:59:49,170:INFO:Defining folds
2025-05-12 21:59:49,170:INFO:Declaring metric variables
2025-05-12 21:59:49,171:INFO:Importing untrained model
2025-05-12 21:59:49,171:INFO:Declaring custom model
2025-05-12 21:59:49,171:INFO:Linear Regression Imported successfully
2025-05-12 21:59:49,171:INFO:Starting cross validation
2025-05-12 21:59:49,173:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 21:59:49,411:INFO:Calculating mean and std
2025-05-12 21:59:49,412:INFO:Creating metrics dataframe
2025-05-12 21:59:49,413:INFO:Finalizing model
2025-05-12 21:59:49,454:INFO:Uploading results into container
2025-05-12 21:59:49,456:INFO:Uploading model into container now
2025-05-12 21:59:49,456:INFO:_master_model_container: 21
2025-05-12 21:59:49,456:INFO:_display_container: 5
2025-05-12 21:59:49,457:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:59:49,457:INFO:create_model() successfully completed......................................
2025-05-12 21:59:49,576:INFO:SubProcess create_model() end ==================================
2025-05-12 21:59:49,576:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9592
2025-05-12 21:59:49,576:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9592
2025-05-12 21:59:49,577:INFO:LinearRegression(n_jobs=-1) is best model
2025-05-12 21:59:49,577:INFO:choose_better completed
2025-05-12 21:59:49,577:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 21:59:49,590:INFO:_master_model_container: 21
2025-05-12 21:59:49,591:INFO:_display_container: 4
2025-05-12 21:59:49,591:INFO:LinearRegression(n_jobs=-1)
2025-05-12 21:59:49,591:INFO:tune_model() successfully completed......................................
2025-05-12 21:59:49,728:INFO:Initializing evaluate_model()
2025-05-12 21:59:49,729:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 21:59:49,739:INFO:Initializing plot_model()
2025-05-12 21:59:49,739:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=LinearRegression(n_jobs=-1), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 21:59:49,739:INFO:Checking exceptions
2025-05-12 21:59:49,743:INFO:Preloading libraries
2025-05-12 21:59:49,743:INFO:Copying training dataset
2025-05-12 21:59:49,743:INFO:Plot type: pipeline
2025-05-12 21:59:49,987:INFO:Visual Rendered Successfully
2025-05-12 21:59:50,121:INFO:plot_model() successfully completed......................................
2025-05-12 21:59:50,157:INFO:Initializing predict_model()
2025-05-12 21:59:50,158:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000180FA521C50>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000180FAFCE480>)
2025-05-12 21:59:50,158:INFO:Checking exceptions
2025-05-12 21:59:50,158:INFO:Preloading libraries
2025-05-12 21:59:50,287:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:02:05,675:INFO:Initializing save_model()
2025-05-12 22:02:05,675:INFO:save_model(model=LinearRegression(n_jobs=-1), model_name=modelo_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-12 22:02:05,675:INFO:Adding model into prep_pipe
2025-05-12 22:02:05,691:INFO:modelo_final.pkl saved in current working directory
2025-05-12 22:02:05,702:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', LinearRegression(n_jobs=-1))])
2025-05-12 22:02:05,703:INFO:save_model() successfully completed......................................
2025-05-12 22:08:39,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:08:39,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:08:39,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:08:39,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:10:18,846:INFO:PyCaret RegressionExperiment
2025-05-12 22:10:18,846:INFO:Logging name: reg-default-name
2025-05-12 22:10:18,847:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:10:18,847:INFO:version 3.3.2
2025-05-12 22:10:18,847:INFO:Initializing setup()
2025-05-12 22:10:18,847:INFO:self.USI: 2b1f
2025-05-12 22:10:18,847:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'transform_target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:10:18,847:INFO:Checking environment
2025-05-12 22:10:18,847:INFO:python_version: 3.11.8
2025-05-12 22:10:18,847:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:10:18,847:INFO:machine: AMD64
2025-05-12 22:10:18,847:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:10:18,854:INFO:Memory: svmem(total=16907886592, available=3919495168, percent=76.8, used=12988391424, free=3919495168)
2025-05-12 22:10:18,854:INFO:Physical Core: 4
2025-05-12 22:10:18,855:INFO:Logical Core: 8
2025-05-12 22:10:18,855:INFO:Checking libraries
2025-05-12 22:10:18,855:INFO:System:
2025-05-12 22:10:18,855:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:10:18,855:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:10:18,855:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:10:18,855:INFO:PyCaret required dependencies:
2025-05-12 22:10:18,885:INFO:                 pip: 24.0
2025-05-12 22:10:18,885:INFO:          setuptools: 65.5.0
2025-05-12 22:10:18,885:INFO:             pycaret: 3.3.2
2025-05-12 22:10:18,885:INFO:             IPython: 9.2.0
2025-05-12 22:10:18,885:INFO:          ipywidgets: 8.1.7
2025-05-12 22:10:18,885:INFO:                tqdm: 4.67.1
2025-05-12 22:10:18,885:INFO:               numpy: 1.26.4
2025-05-12 22:10:18,885:INFO:              pandas: 2.1.4
2025-05-12 22:10:18,885:INFO:              jinja2: 3.1.6
2025-05-12 22:10:18,885:INFO:               scipy: 1.11.4
2025-05-12 22:10:18,885:INFO:              joblib: 1.3.2
2025-05-12 22:10:18,885:INFO:             sklearn: 1.4.2
2025-05-12 22:10:18,885:INFO:                pyod: 2.0.5
2025-05-12 22:10:18,886:INFO:            imblearn: 0.13.0
2025-05-12 22:10:18,886:INFO:   category_encoders: 2.7.0
2025-05-12 22:10:18,886:INFO:            lightgbm: 4.6.0
2025-05-12 22:10:18,886:INFO:               numba: 0.61.2
2025-05-12 22:10:18,886:INFO:            requests: 2.32.3
2025-05-12 22:10:18,886:INFO:          matplotlib: 3.7.5
2025-05-12 22:10:18,886:INFO:          scikitplot: 0.3.7
2025-05-12 22:10:18,886:INFO:         yellowbrick: 1.5
2025-05-12 22:10:18,886:INFO:              plotly: 5.24.1
2025-05-12 22:10:18,886:INFO:    plotly-resampler: Not installed
2025-05-12 22:10:18,886:INFO:             kaleido: 0.2.1
2025-05-12 22:10:18,886:INFO:           schemdraw: 0.15
2025-05-12 22:10:18,886:INFO:         statsmodels: 0.14.4
2025-05-12 22:10:18,886:INFO:              sktime: 0.26.0
2025-05-12 22:10:18,886:INFO:               tbats: 1.1.3
2025-05-12 22:10:18,886:INFO:            pmdarima: 2.0.4
2025-05-12 22:10:18,886:INFO:              psutil: 7.0.0
2025-05-12 22:10:18,886:INFO:          markupsafe: 3.0.2
2025-05-12 22:10:18,886:INFO:             pickle5: Not installed
2025-05-12 22:10:18,886:INFO:         cloudpickle: 3.1.1
2025-05-12 22:10:18,886:INFO:         deprecation: 2.1.0
2025-05-12 22:10:18,886:INFO:              xxhash: 3.5.0
2025-05-12 22:10:18,886:INFO:           wurlitzer: Not installed
2025-05-12 22:10:18,886:INFO:PyCaret optional dependencies:
2025-05-12 22:10:18,896:INFO:                shap: Not installed
2025-05-12 22:10:18,896:INFO:           interpret: Not installed
2025-05-12 22:10:18,896:INFO:                umap: Not installed
2025-05-12 22:10:18,896:INFO:     ydata_profiling: Not installed
2025-05-12 22:10:18,896:INFO:  explainerdashboard: Not installed
2025-05-12 22:10:18,896:INFO:             autoviz: Not installed
2025-05-12 22:10:18,896:INFO:           fairlearn: Not installed
2025-05-12 22:10:18,896:INFO:          deepchecks: Not installed
2025-05-12 22:10:18,896:INFO:             xgboost: Not installed
2025-05-12 22:10:18,896:INFO:            catboost: Not installed
2025-05-12 22:10:18,896:INFO:              kmodes: Not installed
2025-05-12 22:10:18,896:INFO:             mlxtend: Not installed
2025-05-12 22:10:18,896:INFO:       statsforecast: Not installed
2025-05-12 22:10:18,896:INFO:        tune_sklearn: Not installed
2025-05-12 22:10:18,896:INFO:                 ray: Not installed
2025-05-12 22:10:18,896:INFO:            hyperopt: Not installed
2025-05-12 22:10:18,896:INFO:              optuna: Not installed
2025-05-12 22:10:18,896:INFO:               skopt: Not installed
2025-05-12 22:10:18,896:INFO:              mlflow: Not installed
2025-05-12 22:10:18,896:INFO:              gradio: Not installed
2025-05-12 22:10:18,896:INFO:             fastapi: Not installed
2025-05-12 22:10:18,896:INFO:             uvicorn: Not installed
2025-05-12 22:10:18,897:INFO:              m2cgen: Not installed
2025-05-12 22:10:18,897:INFO:           evidently: Not installed
2025-05-12 22:10:18,897:INFO:               fugue: Not installed
2025-05-12 22:10:18,897:INFO:           streamlit: Not installed
2025-05-12 22:10:18,897:INFO:             prophet: Not installed
2025-05-12 22:10:18,897:INFO:None
2025-05-12 22:10:18,897:INFO:Set up data.
2025-05-12 22:10:52,323:INFO:PyCaret RegressionExperiment
2025-05-12 22:10:52,324:INFO:Logging name: reg-default-name
2025-05-12 22:10:52,324:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:10:52,324:INFO:version 3.3.2
2025-05-12 22:10:52,324:INFO:Initializing setup()
2025-05-12 22:10:52,324:INFO:self.USI: 9623
2025-05-12 22:10:52,324:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'transform_target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:10:52,324:INFO:Checking environment
2025-05-12 22:10:52,324:INFO:python_version: 3.11.8
2025-05-12 22:10:52,324:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:10:52,324:INFO:machine: AMD64
2025-05-12 22:10:52,324:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:10:52,330:INFO:Memory: svmem(total=16907886592, available=4026912768, percent=76.2, used=12880973824, free=4026912768)
2025-05-12 22:10:52,330:INFO:Physical Core: 4
2025-05-12 22:10:52,330:INFO:Logical Core: 8
2025-05-12 22:10:52,330:INFO:Checking libraries
2025-05-12 22:10:52,330:INFO:System:
2025-05-12 22:10:52,330:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:10:52,330:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:10:52,330:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:10:52,330:INFO:PyCaret required dependencies:
2025-05-12 22:10:52,330:INFO:                 pip: 24.0
2025-05-12 22:10:52,330:INFO:          setuptools: 65.5.0
2025-05-12 22:10:52,330:INFO:             pycaret: 3.3.2
2025-05-12 22:10:52,330:INFO:             IPython: 9.2.0
2025-05-12 22:10:52,330:INFO:          ipywidgets: 8.1.7
2025-05-12 22:10:52,330:INFO:                tqdm: 4.67.1
2025-05-12 22:10:52,330:INFO:               numpy: 1.26.4
2025-05-12 22:10:52,330:INFO:              pandas: 2.1.4
2025-05-12 22:10:52,330:INFO:              jinja2: 3.1.6
2025-05-12 22:10:52,330:INFO:               scipy: 1.11.4
2025-05-12 22:10:52,330:INFO:              joblib: 1.3.2
2025-05-12 22:10:52,330:INFO:             sklearn: 1.4.2
2025-05-12 22:10:52,330:INFO:                pyod: 2.0.5
2025-05-12 22:10:52,330:INFO:            imblearn: 0.13.0
2025-05-12 22:10:52,331:INFO:   category_encoders: 2.7.0
2025-05-12 22:10:52,331:INFO:            lightgbm: 4.6.0
2025-05-12 22:10:52,331:INFO:               numba: 0.61.2
2025-05-12 22:10:52,331:INFO:            requests: 2.32.3
2025-05-12 22:10:52,331:INFO:          matplotlib: 3.7.5
2025-05-12 22:10:52,331:INFO:          scikitplot: 0.3.7
2025-05-12 22:10:52,331:INFO:         yellowbrick: 1.5
2025-05-12 22:10:52,331:INFO:              plotly: 5.24.1
2025-05-12 22:10:52,331:INFO:    plotly-resampler: Not installed
2025-05-12 22:10:52,331:INFO:             kaleido: 0.2.1
2025-05-12 22:10:52,331:INFO:           schemdraw: 0.15
2025-05-12 22:10:52,331:INFO:         statsmodels: 0.14.4
2025-05-12 22:10:52,331:INFO:              sktime: 0.26.0
2025-05-12 22:10:52,331:INFO:               tbats: 1.1.3
2025-05-12 22:10:52,331:INFO:            pmdarima: 2.0.4
2025-05-12 22:10:52,331:INFO:              psutil: 7.0.0
2025-05-12 22:10:52,331:INFO:          markupsafe: 3.0.2
2025-05-12 22:10:52,331:INFO:             pickle5: Not installed
2025-05-12 22:10:52,331:INFO:         cloudpickle: 3.1.1
2025-05-12 22:10:52,331:INFO:         deprecation: 2.1.0
2025-05-12 22:10:52,331:INFO:              xxhash: 3.5.0
2025-05-12 22:10:52,331:INFO:           wurlitzer: Not installed
2025-05-12 22:10:52,331:INFO:PyCaret optional dependencies:
2025-05-12 22:10:52,331:INFO:                shap: Not installed
2025-05-12 22:10:52,331:INFO:           interpret: Not installed
2025-05-12 22:10:52,331:INFO:                umap: Not installed
2025-05-12 22:10:52,331:INFO:     ydata_profiling: Not installed
2025-05-12 22:10:52,332:INFO:  explainerdashboard: Not installed
2025-05-12 22:10:52,332:INFO:             autoviz: Not installed
2025-05-12 22:10:52,332:INFO:           fairlearn: Not installed
2025-05-12 22:10:52,332:INFO:          deepchecks: Not installed
2025-05-12 22:10:52,332:INFO:             xgboost: Not installed
2025-05-12 22:10:52,332:INFO:            catboost: Not installed
2025-05-12 22:10:52,332:INFO:              kmodes: Not installed
2025-05-12 22:10:52,332:INFO:             mlxtend: Not installed
2025-05-12 22:10:52,332:INFO:       statsforecast: Not installed
2025-05-12 22:10:52,332:INFO:        tune_sklearn: Not installed
2025-05-12 22:10:52,332:INFO:                 ray: Not installed
2025-05-12 22:10:52,332:INFO:            hyperopt: Not installed
2025-05-12 22:10:52,332:INFO:              optuna: Not installed
2025-05-12 22:10:52,332:INFO:               skopt: Not installed
2025-05-12 22:10:52,332:INFO:              mlflow: Not installed
2025-05-12 22:10:52,332:INFO:              gradio: Not installed
2025-05-12 22:10:52,332:INFO:             fastapi: Not installed
2025-05-12 22:10:52,332:INFO:             uvicorn: Not installed
2025-05-12 22:10:52,332:INFO:              m2cgen: Not installed
2025-05-12 22:10:52,332:INFO:           evidently: Not installed
2025-05-12 22:10:52,332:INFO:               fugue: Not installed
2025-05-12 22:10:52,332:INFO:           streamlit: Not installed
2025-05-12 22:10:52,332:INFO:             prophet: Not installed
2025-05-12 22:10:52,332:INFO:None
2025-05-12 22:10:52,332:INFO:Set up data.
2025-05-12 22:10:52,339:INFO:Set up folding strategy.
2025-05-12 22:10:52,339:INFO:Set up train/test split.
2025-05-12 22:10:52,374:INFO:Set up index.
2025-05-12 22:10:52,374:INFO:Assigning column types.
2025-05-12 22:10:52,377:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:10:52,377:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,381:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,384:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,479:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,520:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,521:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,525:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,529:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,580:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,616:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,617:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:10:52,621:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,625:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,671:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,705:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,705:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,711:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,715:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,759:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,793:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:10:52,800:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,846:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,880:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,888:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,968:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:52,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:52,969:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:10:53,019:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:53,054:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:53,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,106:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:53,141:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:10:53,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,142:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,142:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:10:53,193:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:53,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,285:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:10:53,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,321:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:10:53,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,519:INFO:Preparing preprocessing pipeline...
2025-05-12 22:10:53,519:INFO:Set up simple imputation.
2025-05-12 22:10:53,520:INFO:Set up encoding of categorical features.
2025-05-12 22:10:53,520:INFO:Set up feature normalization.
2025-05-12 22:10:53,585:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:10:53,592:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 22:10:53,592:INFO:Creating final display dataframe.
2025-05-12 22:10:53,742:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type        Regression
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              9623
2025-05-12 22:10:53,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:53,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:54,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:54,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:10:54,048:INFO:setup() successfully completed in 1.73s...............
2025-05-12 22:11:08,125:INFO:Initializing compare_models()
2025-05-12 22:11:08,125:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 22:11:08,125:INFO:Checking exceptions
2025-05-12 22:11:08,127:INFO:Preparing display monitor
2025-05-12 22:11:08,160:INFO:Initializing Linear Regression
2025-05-12 22:11:08,160:INFO:Total runtime is 0.0 minutes
2025-05-12 22:11:08,169:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:08,170:INFO:Initializing create_model()
2025-05-12 22:11:08,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:08,170:INFO:Checking exceptions
2025-05-12 22:11:08,170:INFO:Importing libraries
2025-05-12 22:11:08,170:INFO:Copying training dataset
2025-05-12 22:11:08,175:INFO:Defining folds
2025-05-12 22:11:08,176:INFO:Declaring metric variables
2025-05-12 22:11:08,181:INFO:Importing untrained model
2025-05-12 22:11:08,185:INFO:Linear Regression Imported successfully
2025-05-12 22:11:08,195:INFO:Starting cross validation
2025-05-12 22:11:08,204:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:19,594:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:19,632:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:19,972:INFO:Calculating mean and std
2025-05-12 22:11:19,974:INFO:Creating metrics dataframe
2025-05-12 22:11:19,979:INFO:Uploading results into container
2025-05-12 22:11:19,981:INFO:Uploading model into container now
2025-05-12 22:11:19,982:INFO:_master_model_container: 1
2025-05-12 22:11:19,983:INFO:_display_container: 2
2025-05-12 22:11:19,983:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:11:19,983:INFO:create_model() successfully completed......................................
2025-05-12 22:11:20,098:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:20,098:INFO:Creating metrics dataframe
2025-05-12 22:11:20,107:INFO:Initializing Lasso Regression
2025-05-12 22:11:20,107:INFO:Total runtime is 0.19912593364715575 minutes
2025-05-12 22:11:20,113:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:20,114:INFO:Initializing create_model()
2025-05-12 22:11:20,114:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:20,114:INFO:Checking exceptions
2025-05-12 22:11:20,114:INFO:Importing libraries
2025-05-12 22:11:20,114:INFO:Copying training dataset
2025-05-12 22:11:20,120:INFO:Defining folds
2025-05-12 22:11:20,121:INFO:Declaring metric variables
2025-05-12 22:11:20,126:INFO:Importing untrained model
2025-05-12 22:11:20,133:INFO:Lasso Regression Imported successfully
2025-05-12 22:11:20,145:INFO:Starting cross validation
2025-05-12 22:11:20,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:20,560:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:20,561:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:20,563:INFO:Calculating mean and std
2025-05-12 22:11:20,567:INFO:Creating metrics dataframe
2025-05-12 22:11:20,570:INFO:Uploading results into container
2025-05-12 22:11:20,570:INFO:Uploading model into container now
2025-05-12 22:11:20,571:INFO:_master_model_container: 2
2025-05-12 22:11:20,571:INFO:_display_container: 2
2025-05-12 22:11:20,571:INFO:Lasso(random_state=123)
2025-05-12 22:11:20,571:INFO:create_model() successfully completed......................................
2025-05-12 22:11:20,675:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:20,675:INFO:Creating metrics dataframe
2025-05-12 22:11:20,684:INFO:Initializing Ridge Regression
2025-05-12 22:11:20,684:INFO:Total runtime is 0.20874226093292236 minutes
2025-05-12 22:11:20,689:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:20,689:INFO:Initializing create_model()
2025-05-12 22:11:20,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:20,690:INFO:Checking exceptions
2025-05-12 22:11:20,690:INFO:Importing libraries
2025-05-12 22:11:20,690:INFO:Copying training dataset
2025-05-12 22:11:20,696:INFO:Defining folds
2025-05-12 22:11:20,696:INFO:Declaring metric variables
2025-05-12 22:11:20,701:INFO:Importing untrained model
2025-05-12 22:11:20,707:INFO:Ridge Regression Imported successfully
2025-05-12 22:11:20,719:INFO:Starting cross validation
2025-05-12 22:11:20,721:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:20,981:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:20,981:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:20,990:INFO:Calculating mean and std
2025-05-12 22:11:20,991:INFO:Creating metrics dataframe
2025-05-12 22:11:20,992:INFO:Uploading results into container
2025-05-12 22:11:20,993:INFO:Uploading model into container now
2025-05-12 22:11:20,993:INFO:_master_model_container: 3
2025-05-12 22:11:20,994:INFO:_display_container: 2
2025-05-12 22:11:20,994:INFO:Ridge(random_state=123)
2025-05-12 22:11:20,994:INFO:create_model() successfully completed......................................
2025-05-12 22:11:21,081:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:21,081:INFO:Creating metrics dataframe
2025-05-12 22:11:21,091:INFO:Initializing Elastic Net
2025-05-12 22:11:21,091:INFO:Total runtime is 0.21550976037979125 minutes
2025-05-12 22:11:21,094:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:21,094:INFO:Initializing create_model()
2025-05-12 22:11:21,094:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:21,095:INFO:Checking exceptions
2025-05-12 22:11:21,095:INFO:Importing libraries
2025-05-12 22:11:21,095:INFO:Copying training dataset
2025-05-12 22:11:21,100:INFO:Defining folds
2025-05-12 22:11:21,100:INFO:Declaring metric variables
2025-05-12 22:11:21,105:INFO:Importing untrained model
2025-05-12 22:11:21,111:INFO:Elastic Net Imported successfully
2025-05-12 22:11:21,120:INFO:Starting cross validation
2025-05-12 22:11:21,121:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:21,430:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:21,431:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:21,436:INFO:Calculating mean and std
2025-05-12 22:11:21,438:INFO:Creating metrics dataframe
2025-05-12 22:11:21,441:INFO:Uploading results into container
2025-05-12 22:11:21,441:INFO:Uploading model into container now
2025-05-12 22:11:21,443:INFO:_master_model_container: 4
2025-05-12 22:11:21,443:INFO:_display_container: 2
2025-05-12 22:11:21,444:INFO:ElasticNet(random_state=123)
2025-05-12 22:11:21,444:INFO:create_model() successfully completed......................................
2025-05-12 22:11:21,537:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:21,537:INFO:Creating metrics dataframe
2025-05-12 22:11:21,545:INFO:Initializing Least Angle Regression
2025-05-12 22:11:21,545:INFO:Total runtime is 0.22307785749435424 minutes
2025-05-12 22:11:21,550:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:21,550:INFO:Initializing create_model()
2025-05-12 22:11:21,550:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:21,550:INFO:Checking exceptions
2025-05-12 22:11:21,550:INFO:Importing libraries
2025-05-12 22:11:21,550:INFO:Copying training dataset
2025-05-12 22:11:21,557:INFO:Defining folds
2025-05-12 22:11:21,558:INFO:Declaring metric variables
2025-05-12 22:11:21,563:INFO:Importing untrained model
2025-05-12 22:11:21,568:INFO:Least Angle Regression Imported successfully
2025-05-12 22:11:21,578:INFO:Starting cross validation
2025-05-12 22:11:21,580:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:21,946:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:21,947:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:21,957:INFO:Calculating mean and std
2025-05-12 22:11:21,959:INFO:Creating metrics dataframe
2025-05-12 22:11:21,962:INFO:Uploading results into container
2025-05-12 22:11:21,963:INFO:Uploading model into container now
2025-05-12 22:11:21,963:INFO:_master_model_container: 5
2025-05-12 22:11:21,964:INFO:_display_container: 2
2025-05-12 22:11:21,964:INFO:Lars(random_state=123)
2025-05-12 22:11:21,964:INFO:create_model() successfully completed......................................
2025-05-12 22:11:22,074:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:22,074:INFO:Creating metrics dataframe
2025-05-12 22:11:22,084:INFO:Initializing Lasso Least Angle Regression
2025-05-12 22:11:22,084:INFO:Total runtime is 0.23206319014231364 minutes
2025-05-12 22:11:22,089:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:22,090:INFO:Initializing create_model()
2025-05-12 22:11:22,090:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:22,090:INFO:Checking exceptions
2025-05-12 22:11:22,090:INFO:Importing libraries
2025-05-12 22:11:22,091:INFO:Copying training dataset
2025-05-12 22:11:22,097:INFO:Defining folds
2025-05-12 22:11:22,097:INFO:Declaring metric variables
2025-05-12 22:11:22,102:INFO:Importing untrained model
2025-05-12 22:11:22,109:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:11:22,119:INFO:Starting cross validation
2025-05-12 22:11:22,121:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:22,389:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:22,389:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:22,398:INFO:Calculating mean and std
2025-05-12 22:11:22,400:INFO:Creating metrics dataframe
2025-05-12 22:11:22,404:INFO:Uploading results into container
2025-05-12 22:11:22,404:INFO:Uploading model into container now
2025-05-12 22:11:22,406:INFO:_master_model_container: 6
2025-05-12 22:11:22,406:INFO:_display_container: 2
2025-05-12 22:11:22,407:INFO:LassoLars(random_state=123)
2025-05-12 22:11:22,408:INFO:create_model() successfully completed......................................
2025-05-12 22:11:22,514:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:22,514:INFO:Creating metrics dataframe
2025-05-12 22:11:22,524:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 22:11:22,524:INFO:Total runtime is 0.23940389951070148 minutes
2025-05-12 22:11:22,529:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:22,529:INFO:Initializing create_model()
2025-05-12 22:11:22,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:22,530:INFO:Checking exceptions
2025-05-12 22:11:22,530:INFO:Importing libraries
2025-05-12 22:11:22,530:INFO:Copying training dataset
2025-05-12 22:11:22,536:INFO:Defining folds
2025-05-12 22:11:22,537:INFO:Declaring metric variables
2025-05-12 22:11:22,542:INFO:Importing untrained model
2025-05-12 22:11:22,549:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 22:11:22,560:INFO:Starting cross validation
2025-05-12 22:11:22,563:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:22,856:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:22,856:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:22,864:INFO:Calculating mean and std
2025-05-12 22:11:22,866:INFO:Creating metrics dataframe
2025-05-12 22:11:22,868:INFO:Uploading results into container
2025-05-12 22:11:22,868:INFO:Uploading model into container now
2025-05-12 22:11:22,869:INFO:_master_model_container: 7
2025-05-12 22:11:22,869:INFO:_display_container: 2
2025-05-12 22:11:22,870:INFO:OrthogonalMatchingPursuit()
2025-05-12 22:11:22,870:INFO:create_model() successfully completed......................................
2025-05-12 22:11:22,966:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:22,967:INFO:Creating metrics dataframe
2025-05-12 22:11:22,976:INFO:Initializing Bayesian Ridge
2025-05-12 22:11:22,976:INFO:Total runtime is 0.2469269871711731 minutes
2025-05-12 22:11:22,981:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:22,981:INFO:Initializing create_model()
2025-05-12 22:11:22,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:22,981:INFO:Checking exceptions
2025-05-12 22:11:22,981:INFO:Importing libraries
2025-05-12 22:11:22,981:INFO:Copying training dataset
2025-05-12 22:11:22,986:INFO:Defining folds
2025-05-12 22:11:22,986:INFO:Declaring metric variables
2025-05-12 22:11:22,991:INFO:Importing untrained model
2025-05-12 22:11:22,999:INFO:Bayesian Ridge Imported successfully
2025-05-12 22:11:23,009:INFO:Starting cross validation
2025-05-12 22:11:23,012:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:23,358:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:23,358:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:23,371:INFO:Calculating mean and std
2025-05-12 22:11:23,373:INFO:Creating metrics dataframe
2025-05-12 22:11:23,377:INFO:Uploading results into container
2025-05-12 22:11:23,378:INFO:Uploading model into container now
2025-05-12 22:11:23,378:INFO:_master_model_container: 8
2025-05-12 22:11:23,379:INFO:_display_container: 2
2025-05-12 22:11:23,380:INFO:BayesianRidge()
2025-05-12 22:11:23,380:INFO:create_model() successfully completed......................................
2025-05-12 22:11:23,483:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:23,483:INFO:Creating metrics dataframe
2025-05-12 22:11:23,493:INFO:Initializing Passive Aggressive Regressor
2025-05-12 22:11:23,493:INFO:Total runtime is 0.25555330912272134 minutes
2025-05-12 22:11:23,498:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:23,498:INFO:Initializing create_model()
2025-05-12 22:11:23,498:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:23,498:INFO:Checking exceptions
2025-05-12 22:11:23,499:INFO:Importing libraries
2025-05-12 22:11:23,499:INFO:Copying training dataset
2025-05-12 22:11:23,504:INFO:Defining folds
2025-05-12 22:11:23,504:INFO:Declaring metric variables
2025-05-12 22:11:23,511:INFO:Importing untrained model
2025-05-12 22:11:23,517:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 22:11:23,525:INFO:Starting cross validation
2025-05-12 22:11:23,529:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:23,837:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:23,837:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:23,847:INFO:Calculating mean and std
2025-05-12 22:11:23,849:INFO:Creating metrics dataframe
2025-05-12 22:11:23,852:INFO:Uploading results into container
2025-05-12 22:11:23,853:INFO:Uploading model into container now
2025-05-12 22:11:23,853:INFO:_master_model_container: 9
2025-05-12 22:11:23,853:INFO:_display_container: 2
2025-05-12 22:11:23,854:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 22:11:23,854:INFO:create_model() successfully completed......................................
2025-05-12 22:11:23,963:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:23,963:INFO:Creating metrics dataframe
2025-05-12 22:11:23,979:INFO:Initializing Huber Regressor
2025-05-12 22:11:23,979:INFO:Total runtime is 0.2636478384335836 minutes
2025-05-12 22:11:23,986:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:23,986:INFO:Initializing create_model()
2025-05-12 22:11:23,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:23,987:INFO:Checking exceptions
2025-05-12 22:11:23,987:INFO:Importing libraries
2025-05-12 22:11:23,987:INFO:Copying training dataset
2025-05-12 22:11:23,993:INFO:Defining folds
2025-05-12 22:11:23,993:INFO:Declaring metric variables
2025-05-12 22:11:24,002:INFO:Importing untrained model
2025-05-12 22:11:24,009:INFO:Huber Regressor Imported successfully
2025-05-12 22:11:24,023:INFO:Starting cross validation
2025-05-12 22:11:24,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:24,470:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:24,470:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:24,477:INFO:Calculating mean and std
2025-05-12 22:11:24,479:INFO:Creating metrics dataframe
2025-05-12 22:11:24,482:INFO:Uploading results into container
2025-05-12 22:11:24,484:INFO:Uploading model into container now
2025-05-12 22:11:24,484:INFO:_master_model_container: 10
2025-05-12 22:11:24,485:INFO:_display_container: 2
2025-05-12 22:11:24,485:INFO:HuberRegressor()
2025-05-12 22:11:24,486:INFO:create_model() successfully completed......................................
2025-05-12 22:11:24,581:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:24,582:INFO:Creating metrics dataframe
2025-05-12 22:11:24,594:INFO:Initializing K Neighbors Regressor
2025-05-12 22:11:24,595:INFO:Total runtime is 0.2739195187886556 minutes
2025-05-12 22:11:24,600:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:24,601:INFO:Initializing create_model()
2025-05-12 22:11:24,601:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:24,601:INFO:Checking exceptions
2025-05-12 22:11:24,601:INFO:Importing libraries
2025-05-12 22:11:24,601:INFO:Copying training dataset
2025-05-12 22:11:24,607:INFO:Defining folds
2025-05-12 22:11:24,607:INFO:Declaring metric variables
2025-05-12 22:11:24,615:INFO:Importing untrained model
2025-05-12 22:11:24,619:INFO:K Neighbors Regressor Imported successfully
2025-05-12 22:11:24,627:INFO:Starting cross validation
2025-05-12 22:11:24,629:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:24,953:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:24,953:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:24,956:INFO:Calculating mean and std
2025-05-12 22:11:24,958:INFO:Creating metrics dataframe
2025-05-12 22:11:24,960:INFO:Uploading results into container
2025-05-12 22:11:24,961:INFO:Uploading model into container now
2025-05-12 22:11:24,962:INFO:_master_model_container: 11
2025-05-12 22:11:24,962:INFO:_display_container: 2
2025-05-12 22:11:24,963:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 22:11:24,963:INFO:create_model() successfully completed......................................
2025-05-12 22:11:25,069:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:25,069:INFO:Creating metrics dataframe
2025-05-12 22:11:25,083:INFO:Initializing Decision Tree Regressor
2025-05-12 22:11:25,083:INFO:Total runtime is 0.28204752604166666 minutes
2025-05-12 22:11:25,088:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:25,089:INFO:Initializing create_model()
2025-05-12 22:11:25,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:25,089:INFO:Checking exceptions
2025-05-12 22:11:25,089:INFO:Importing libraries
2025-05-12 22:11:25,089:INFO:Copying training dataset
2025-05-12 22:11:25,097:INFO:Defining folds
2025-05-12 22:11:25,097:INFO:Declaring metric variables
2025-05-12 22:11:25,104:INFO:Importing untrained model
2025-05-12 22:11:25,111:INFO:Decision Tree Regressor Imported successfully
2025-05-12 22:11:25,140:INFO:Starting cross validation
2025-05-12 22:11:25,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:25,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:25,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:25,626:INFO:Calculating mean and std
2025-05-12 22:11:25,630:INFO:Creating metrics dataframe
2025-05-12 22:11:25,632:INFO:Uploading results into container
2025-05-12 22:11:25,634:INFO:Uploading model into container now
2025-05-12 22:11:25,635:INFO:_master_model_container: 12
2025-05-12 22:11:25,635:INFO:_display_container: 2
2025-05-12 22:11:25,636:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 22:11:25,636:INFO:create_model() successfully completed......................................
2025-05-12 22:11:25,765:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:25,765:INFO:Creating metrics dataframe
2025-05-12 22:11:25,779:INFO:Initializing Random Forest Regressor
2025-05-12 22:11:25,779:INFO:Total runtime is 0.2936530113220215 minutes
2025-05-12 22:11:25,785:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:25,786:INFO:Initializing create_model()
2025-05-12 22:11:25,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:25,786:INFO:Checking exceptions
2025-05-12 22:11:25,786:INFO:Importing libraries
2025-05-12 22:11:25,786:INFO:Copying training dataset
2025-05-12 22:11:25,795:INFO:Defining folds
2025-05-12 22:11:25,795:INFO:Declaring metric variables
2025-05-12 22:11:25,800:INFO:Importing untrained model
2025-05-12 22:11:25,808:INFO:Random Forest Regressor Imported successfully
2025-05-12 22:11:25,822:INFO:Starting cross validation
2025-05-12 22:11:25,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:26,795:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:26,795:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:26,805:INFO:Calculating mean and std
2025-05-12 22:11:26,807:INFO:Creating metrics dataframe
2025-05-12 22:11:26,810:INFO:Uploading results into container
2025-05-12 22:11:26,811:INFO:Uploading model into container now
2025-05-12 22:11:26,813:INFO:_master_model_container: 13
2025-05-12 22:11:26,813:INFO:_display_container: 2
2025-05-12 22:11:26,814:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:11:26,815:INFO:create_model() successfully completed......................................
2025-05-12 22:11:26,919:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:26,920:INFO:Creating metrics dataframe
2025-05-12 22:11:26,933:INFO:Initializing Extra Trees Regressor
2025-05-12 22:11:26,933:INFO:Total runtime is 0.3128852486610413 minutes
2025-05-12 22:11:26,938:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:26,938:INFO:Initializing create_model()
2025-05-12 22:11:26,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:26,939:INFO:Checking exceptions
2025-05-12 22:11:26,939:INFO:Importing libraries
2025-05-12 22:11:26,939:INFO:Copying training dataset
2025-05-12 22:11:26,945:INFO:Defining folds
2025-05-12 22:11:26,946:INFO:Declaring metric variables
2025-05-12 22:11:26,953:INFO:Importing untrained model
2025-05-12 22:11:26,959:INFO:Extra Trees Regressor Imported successfully
2025-05-12 22:11:26,971:INFO:Starting cross validation
2025-05-12 22:11:26,976:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:27,938:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:27,939:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:27,951:INFO:Calculating mean and std
2025-05-12 22:11:27,953:INFO:Creating metrics dataframe
2025-05-12 22:11:27,956:INFO:Uploading results into container
2025-05-12 22:11:27,956:INFO:Uploading model into container now
2025-05-12 22:11:27,957:INFO:_master_model_container: 14
2025-05-12 22:11:27,957:INFO:_display_container: 2
2025-05-12 22:11:27,959:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:11:27,959:INFO:create_model() successfully completed......................................
2025-05-12 22:11:28,112:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:28,112:INFO:Creating metrics dataframe
2025-05-12 22:11:28,135:INFO:Initializing AdaBoost Regressor
2025-05-12 22:11:28,135:INFO:Total runtime is 0.3329196174939474 minutes
2025-05-12 22:11:28,145:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:28,146:INFO:Initializing create_model()
2025-05-12 22:11:28,146:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:28,146:INFO:Checking exceptions
2025-05-12 22:11:28,146:INFO:Importing libraries
2025-05-12 22:11:28,147:INFO:Copying training dataset
2025-05-12 22:11:28,158:INFO:Defining folds
2025-05-12 22:11:28,158:INFO:Declaring metric variables
2025-05-12 22:11:28,166:INFO:Importing untrained model
2025-05-12 22:11:28,175:INFO:AdaBoost Regressor Imported successfully
2025-05-12 22:11:28,216:INFO:Starting cross validation
2025-05-12 22:11:28,222:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:28,815:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:28,815:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:28,824:INFO:Calculating mean and std
2025-05-12 22:11:28,825:INFO:Creating metrics dataframe
2025-05-12 22:11:28,827:INFO:Uploading results into container
2025-05-12 22:11:28,827:INFO:Uploading model into container now
2025-05-12 22:11:28,827:INFO:_master_model_container: 15
2025-05-12 22:11:28,828:INFO:_display_container: 2
2025-05-12 22:11:28,828:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 22:11:28,829:INFO:create_model() successfully completed......................................
2025-05-12 22:11:28,915:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:28,916:INFO:Creating metrics dataframe
2025-05-12 22:11:28,927:INFO:Initializing Gradient Boosting Regressor
2025-05-12 22:11:28,927:INFO:Total runtime is 0.34611835082372033 minutes
2025-05-12 22:11:28,931:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:28,931:INFO:Initializing create_model()
2025-05-12 22:11:28,931:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:28,931:INFO:Checking exceptions
2025-05-12 22:11:28,931:INFO:Importing libraries
2025-05-12 22:11:28,931:INFO:Copying training dataset
2025-05-12 22:11:28,936:INFO:Defining folds
2025-05-12 22:11:28,936:INFO:Declaring metric variables
2025-05-12 22:11:28,940:INFO:Importing untrained model
2025-05-12 22:11:28,946:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 22:11:28,954:INFO:Starting cross validation
2025-05-12 22:11:28,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:29,586:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:29,586:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:29,591:INFO:Calculating mean and std
2025-05-12 22:11:29,593:INFO:Creating metrics dataframe
2025-05-12 22:11:29,596:INFO:Uploading results into container
2025-05-12 22:11:29,597:INFO:Uploading model into container now
2025-05-12 22:11:29,598:INFO:_master_model_container: 16
2025-05-12 22:11:29,599:INFO:_display_container: 2
2025-05-12 22:11:29,600:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 22:11:29,600:INFO:create_model() successfully completed......................................
2025-05-12 22:11:29,706:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:29,706:INFO:Creating metrics dataframe
2025-05-12 22:11:29,720:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:11:29,721:INFO:Total runtime is 0.3593586881955465 minutes
2025-05-12 22:11:29,728:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:29,728:INFO:Initializing create_model()
2025-05-12 22:11:29,728:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:29,729:INFO:Checking exceptions
2025-05-12 22:11:29,729:INFO:Importing libraries
2025-05-12 22:11:29,729:INFO:Copying training dataset
2025-05-12 22:11:29,734:INFO:Defining folds
2025-05-12 22:11:29,734:INFO:Declaring metric variables
2025-05-12 22:11:29,745:INFO:Importing untrained model
2025-05-12 22:11:29,751:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:11:29,769:INFO:Starting cross validation
2025-05-12 22:11:29,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:30,516:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:30,516:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:30,529:INFO:Calculating mean and std
2025-05-12 22:11:30,531:INFO:Creating metrics dataframe
2025-05-12 22:11:30,536:INFO:Uploading results into container
2025-05-12 22:11:30,536:INFO:Uploading model into container now
2025-05-12 22:11:30,538:INFO:_master_model_container: 17
2025-05-12 22:11:30,538:INFO:_display_container: 2
2025-05-12 22:11:30,539:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:11:30,540:INFO:create_model() successfully completed......................................
2025-05-12 22:11:30,657:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:30,657:INFO:Creating metrics dataframe
2025-05-12 22:11:30,670:INFO:Initializing Dummy Regressor
2025-05-12 22:11:30,670:INFO:Total runtime is 0.37517590522766114 minutes
2025-05-12 22:11:30,675:INFO:SubProcess create_model() called ==================================
2025-05-12 22:11:30,675:INFO:Initializing create_model()
2025-05-12 22:11:30,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78A27D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:30,676:INFO:Checking exceptions
2025-05-12 22:11:30,676:INFO:Importing libraries
2025-05-12 22:11:30,676:INFO:Copying training dataset
2025-05-12 22:11:30,681:INFO:Defining folds
2025-05-12 22:11:30,681:INFO:Declaring metric variables
2025-05-12 22:11:30,687:INFO:Importing untrained model
2025-05-12 22:11:30,693:INFO:Dummy Regressor Imported successfully
2025-05-12 22:11:30,702:INFO:Starting cross validation
2025-05-12 22:11:30,704:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:31,008:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:31,008:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:31,011:INFO:Calculating mean and std
2025-05-12 22:11:31,012:INFO:Creating metrics dataframe
2025-05-12 22:11:31,015:INFO:Uploading results into container
2025-05-12 22:11:31,016:INFO:Uploading model into container now
2025-05-12 22:11:31,017:INFO:_master_model_container: 18
2025-05-12 22:11:31,017:INFO:_display_container: 2
2025-05-12 22:11:31,018:INFO:DummyRegressor()
2025-05-12 22:11:31,018:INFO:create_model() successfully completed......................................
2025-05-12 22:11:31,117:INFO:SubProcess create_model() end ==================================
2025-05-12 22:11:31,118:INFO:Creating metrics dataframe
2025-05-12 22:11:31,134:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:11:31,150:INFO:Initializing create_model()
2025-05-12 22:11:31,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:31,151:INFO:Checking exceptions
2025-05-12 22:11:31,156:INFO:Importing libraries
2025-05-12 22:11:31,156:INFO:Copying training dataset
2025-05-12 22:11:31,161:INFO:Defining folds
2025-05-12 22:11:31,161:INFO:Declaring metric variables
2025-05-12 22:11:31,161:INFO:Importing untrained model
2025-05-12 22:11:31,161:INFO:Declaring custom model
2025-05-12 22:11:31,163:INFO:Lasso Regression Imported successfully
2025-05-12 22:11:31,164:INFO:Cross validation set to False
2025-05-12 22:11:31,164:INFO:Fitting Model
2025-05-12 22:11:31,240:INFO:Lasso(random_state=123)
2025-05-12 22:11:31,240:INFO:create_model() successfully completed......................................
2025-05-12 22:11:31,394:INFO:_master_model_container: 18
2025-05-12 22:11:31,395:INFO:_display_container: 2
2025-05-12 22:11:31,395:INFO:Lasso(random_state=123)
2025-05-12 22:11:31,395:INFO:compare_models() successfully completed......................................
2025-05-12 22:11:59,653:INFO:Initializing create_model()
2025-05-12 22:11:59,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=lasso, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:11:59,653:INFO:Checking exceptions
2025-05-12 22:11:59,669:INFO:Importing libraries
2025-05-12 22:11:59,670:INFO:Copying training dataset
2025-05-12 22:11:59,676:INFO:Defining folds
2025-05-12 22:11:59,676:INFO:Declaring metric variables
2025-05-12 22:11:59,681:INFO:Importing untrained model
2025-05-12 22:11:59,687:INFO:Lasso Regression Imported successfully
2025-05-12 22:11:59,698:INFO:Starting cross validation
2025-05-12 22:11:59,700:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:11:59,899:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:11:59,899:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:11:59,904:INFO:Calculating mean and std
2025-05-12 22:11:59,904:INFO:Creating metrics dataframe
2025-05-12 22:11:59,908:INFO:Finalizing model
2025-05-12 22:11:59,941:INFO:Uploading results into container
2025-05-12 22:11:59,942:INFO:Uploading model into container now
2025-05-12 22:11:59,950:INFO:_master_model_container: 19
2025-05-12 22:11:59,951:INFO:_display_container: 3
2025-05-12 22:11:59,951:INFO:Lasso(random_state=123)
2025-05-12 22:11:59,951:INFO:create_model() successfully completed......................................
2025-05-12 22:12:19,541:INFO:Initializing create_model()
2025-05-12 22:12:19,541:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=lasso, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:12:19,541:INFO:Checking exceptions
2025-05-12 22:12:19,558:INFO:Importing libraries
2025-05-12 22:12:19,558:INFO:Copying training dataset
2025-05-12 22:12:19,564:INFO:Defining folds
2025-05-12 22:12:19,564:INFO:Declaring metric variables
2025-05-12 22:12:19,567:INFO:Importing untrained model
2025-05-12 22:12:19,572:INFO:Lasso Regression Imported successfully
2025-05-12 22:12:19,580:INFO:Starting cross validation
2025-05-12 22:12:19,582:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:12:19,869:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:12:19,869:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:12:19,879:INFO:Calculating mean and std
2025-05-12 22:12:19,879:INFO:Creating metrics dataframe
2025-05-12 22:12:19,883:INFO:Finalizing model
2025-05-12 22:12:19,921:INFO:Uploading results into container
2025-05-12 22:12:19,921:INFO:Uploading model into container now
2025-05-12 22:12:19,930:INFO:_master_model_container: 20
2025-05-12 22:12:19,931:INFO:_display_container: 4
2025-05-12 22:12:19,931:INFO:Lasso(random_state=123)
2025-05-12 22:12:19,931:INFO:create_model() successfully completed......................................
2025-05-12 22:12:37,058:INFO:Initializing tune_model()
2025-05-12 22:12:37,058:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=Lasso(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:12:37,058:INFO:Checking exceptions
2025-05-12 22:12:37,076:INFO:Copying training dataset
2025-05-12 22:12:37,079:INFO:Checking base model
2025-05-12 22:12:37,080:INFO:Base model : Lasso Regression
2025-05-12 22:12:37,085:INFO:Declaring metric variables
2025-05-12 22:12:37,089:INFO:Defining Hyperparameters
2025-05-12 22:12:37,251:INFO:Tuning with n_jobs=-1
2025-05-12 22:12:37,251:INFO:Initializing RandomizedSearchCV
2025-05-12 22:12:39,647:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 5.62}
2025-05-12 22:12:39,649:INFO:Hyperparameter search completed
2025-05-12 22:12:39,649:INFO:SubProcess create_model() called ==================================
2025-05-12 22:12:39,651:INFO:Initializing create_model()
2025-05-12 22:12:39,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7AC73D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'alpha': 5.62})
2025-05-12 22:12:39,653:INFO:Checking exceptions
2025-05-12 22:12:39,653:INFO:Importing libraries
2025-05-12 22:12:39,653:INFO:Copying training dataset
2025-05-12 22:12:39,669:INFO:Defining folds
2025-05-12 22:12:39,669:INFO:Declaring metric variables
2025-05-12 22:12:39,676:INFO:Importing untrained model
2025-05-12 22:12:39,676:INFO:Declaring custom model
2025-05-12 22:12:39,683:INFO:Lasso Regression Imported successfully
2025-05-12 22:12:39,699:INFO:Starting cross validation
2025-05-12 22:12:39,701:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:12:40,124:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:12:40,124:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:12:40,126:INFO:Calculating mean and std
2025-05-12 22:12:40,127:INFO:Creating metrics dataframe
2025-05-12 22:12:40,137:INFO:Finalizing model
2025-05-12 22:12:40,228:INFO:Uploading results into container
2025-05-12 22:12:40,230:INFO:Uploading model into container now
2025-05-12 22:12:40,230:INFO:_master_model_container: 21
2025-05-12 22:12:40,230:INFO:_display_container: 5
2025-05-12 22:12:40,231:INFO:Lasso(alpha=5.62, random_state=123)
2025-05-12 22:12:40,231:INFO:create_model() successfully completed......................................
2025-05-12 22:12:40,361:INFO:SubProcess create_model() end ==================================
2025-05-12 22:12:40,361:INFO:choose_better activated
2025-05-12 22:12:40,366:INFO:SubProcess create_model() called ==================================
2025-05-12 22:12:40,367:INFO:Initializing create_model()
2025-05-12 22:12:40,368:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:12:40,368:INFO:Checking exceptions
2025-05-12 22:12:40,371:INFO:Importing libraries
2025-05-12 22:12:40,371:INFO:Copying training dataset
2025-05-12 22:12:40,381:INFO:Defining folds
2025-05-12 22:12:40,382:INFO:Declaring metric variables
2025-05-12 22:12:40,382:INFO:Importing untrained model
2025-05-12 22:12:40,382:INFO:Declaring custom model
2025-05-12 22:12:40,383:INFO:Lasso Regression Imported successfully
2025-05-12 22:12:40,383:INFO:Starting cross validation
2025-05-12 22:12:40,406:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:12:40,864:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:12:40,866:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:12:40,875:INFO:Calculating mean and std
2025-05-12 22:12:40,876:INFO:Creating metrics dataframe
2025-05-12 22:12:40,880:INFO:Finalizing model
2025-05-12 22:12:40,949:INFO:Uploading results into container
2025-05-12 22:12:40,950:INFO:Uploading model into container now
2025-05-12 22:12:40,951:INFO:_master_model_container: 22
2025-05-12 22:12:40,951:INFO:_display_container: 6
2025-05-12 22:12:40,951:INFO:Lasso(random_state=123)
2025-05-12 22:12:40,951:INFO:create_model() successfully completed......................................
2025-05-12 22:12:41,081:INFO:SubProcess create_model() end ==================================
2025-05-12 22:12:41,081:INFO:Lasso(random_state=123) result for R2 is -0.0421
2025-05-12 22:12:41,082:INFO:Lasso(alpha=5.62, random_state=123) result for R2 is -0.0421
2025-05-12 22:12:41,082:INFO:Lasso(random_state=123) is best model
2025-05-12 22:12:41,082:INFO:choose_better completed
2025-05-12 22:12:41,082:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:12:41,097:INFO:_master_model_container: 22
2025-05-12 22:12:41,097:INFO:_display_container: 5
2025-05-12 22:12:41,098:INFO:Lasso(random_state=123)
2025-05-12 22:12:41,098:INFO:tune_model() successfully completed......................................
2025-05-12 22:13:02,146:INFO:Initializing evaluate_model()
2025-05-12 22:13:02,146:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=Lasso(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:13:02,154:INFO:Initializing plot_model()
2025-05-12 22:13:02,155:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=Lasso(random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:13:02,155:INFO:Checking exceptions
2025-05-12 22:13:02,157:INFO:Preloading libraries
2025-05-12 22:13:02,158:INFO:Copying training dataset
2025-05-12 22:13:02,158:INFO:Plot type: pipeline
2025-05-12 22:13:02,322:INFO:Visual Rendered Successfully
2025-05-12 22:13:02,446:INFO:plot_model() successfully completed......................................
2025-05-12 22:13:23,735:INFO:Initializing predict_model()
2025-05-12 22:13:23,735:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA77178750>, estimator=Lasso(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EA7AD94E00>)
2025-05-12 22:13:23,736:INFO:Checking exceptions
2025-05-12 22:13:23,736:INFO:Preloading libraries
2025-05-12 22:13:23,869:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:18:27,340:INFO:PyCaret RegressionExperiment
2025-05-12 22:18:27,341:INFO:Logging name: reg-default-name
2025-05-12 22:18:27,341:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:18:27,341:INFO:version 3.3.2
2025-05-12 22:18:27,341:INFO:Initializing setup()
2025-05-12 22:18:27,341:INFO:self.USI: a4a7
2025-05-12 22:18:27,341:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'transform_target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:18:27,341:INFO:Checking environment
2025-05-12 22:18:27,341:INFO:python_version: 3.11.8
2025-05-12 22:18:27,341:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:18:27,341:INFO:machine: AMD64
2025-05-12 22:18:27,341:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:18:27,347:INFO:Memory: svmem(total=16907886592, available=4068175872, percent=75.9, used=12839710720, free=4068175872)
2025-05-12 22:18:27,348:INFO:Physical Core: 4
2025-05-12 22:18:27,348:INFO:Logical Core: 8
2025-05-12 22:18:27,348:INFO:Checking libraries
2025-05-12 22:18:27,348:INFO:System:
2025-05-12 22:18:27,348:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:18:27,348:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:18:27,348:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:18:27,348:INFO:PyCaret required dependencies:
2025-05-12 22:18:27,348:INFO:                 pip: 24.0
2025-05-12 22:18:27,348:INFO:          setuptools: 65.5.0
2025-05-12 22:18:27,348:INFO:             pycaret: 3.3.2
2025-05-12 22:18:27,348:INFO:             IPython: 9.2.0
2025-05-12 22:18:27,348:INFO:          ipywidgets: 8.1.7
2025-05-12 22:18:27,348:INFO:                tqdm: 4.67.1
2025-05-12 22:18:27,348:INFO:               numpy: 1.26.4
2025-05-12 22:18:27,348:INFO:              pandas: 2.1.4
2025-05-12 22:18:27,348:INFO:              jinja2: 3.1.6
2025-05-12 22:18:27,348:INFO:               scipy: 1.11.4
2025-05-12 22:18:27,348:INFO:              joblib: 1.3.2
2025-05-12 22:18:27,348:INFO:             sklearn: 1.4.2
2025-05-12 22:18:27,348:INFO:                pyod: 2.0.5
2025-05-12 22:18:27,348:INFO:            imblearn: 0.13.0
2025-05-12 22:18:27,349:INFO:   category_encoders: 2.7.0
2025-05-12 22:18:27,349:INFO:            lightgbm: 4.6.0
2025-05-12 22:18:27,349:INFO:               numba: 0.61.2
2025-05-12 22:18:27,349:INFO:            requests: 2.32.3
2025-05-12 22:18:27,349:INFO:          matplotlib: 3.7.5
2025-05-12 22:18:27,349:INFO:          scikitplot: 0.3.7
2025-05-12 22:18:27,349:INFO:         yellowbrick: 1.5
2025-05-12 22:18:27,349:INFO:              plotly: 5.24.1
2025-05-12 22:18:27,349:INFO:    plotly-resampler: Not installed
2025-05-12 22:18:27,349:INFO:             kaleido: 0.2.1
2025-05-12 22:18:27,349:INFO:           schemdraw: 0.15
2025-05-12 22:18:27,349:INFO:         statsmodels: 0.14.4
2025-05-12 22:18:27,349:INFO:              sktime: 0.26.0
2025-05-12 22:18:27,349:INFO:               tbats: 1.1.3
2025-05-12 22:18:27,349:INFO:            pmdarima: 2.0.4
2025-05-12 22:18:27,349:INFO:              psutil: 7.0.0
2025-05-12 22:18:27,349:INFO:          markupsafe: 3.0.2
2025-05-12 22:18:27,350:INFO:             pickle5: Not installed
2025-05-12 22:18:27,350:INFO:         cloudpickle: 3.1.1
2025-05-12 22:18:27,350:INFO:         deprecation: 2.1.0
2025-05-12 22:18:27,350:INFO:              xxhash: 3.5.0
2025-05-12 22:18:27,350:INFO:           wurlitzer: Not installed
2025-05-12 22:18:27,350:INFO:PyCaret optional dependencies:
2025-05-12 22:18:27,350:INFO:                shap: Not installed
2025-05-12 22:18:27,350:INFO:           interpret: Not installed
2025-05-12 22:18:27,350:INFO:                umap: Not installed
2025-05-12 22:18:27,350:INFO:     ydata_profiling: Not installed
2025-05-12 22:18:27,350:INFO:  explainerdashboard: Not installed
2025-05-12 22:18:27,350:INFO:             autoviz: Not installed
2025-05-12 22:18:27,350:INFO:           fairlearn: Not installed
2025-05-12 22:18:27,350:INFO:          deepchecks: Not installed
2025-05-12 22:18:27,350:INFO:             xgboost: Not installed
2025-05-12 22:18:27,351:INFO:            catboost: Not installed
2025-05-12 22:18:27,351:INFO:              kmodes: Not installed
2025-05-12 22:18:27,351:INFO:             mlxtend: Not installed
2025-05-12 22:18:27,351:INFO:       statsforecast: Not installed
2025-05-12 22:18:27,351:INFO:        tune_sklearn: Not installed
2025-05-12 22:18:27,351:INFO:                 ray: Not installed
2025-05-12 22:18:27,351:INFO:            hyperopt: Not installed
2025-05-12 22:18:27,351:INFO:              optuna: Not installed
2025-05-12 22:18:27,351:INFO:               skopt: Not installed
2025-05-12 22:18:27,351:INFO:              mlflow: Not installed
2025-05-12 22:18:27,351:INFO:              gradio: Not installed
2025-05-12 22:18:27,352:INFO:             fastapi: Not installed
2025-05-12 22:18:27,352:INFO:             uvicorn: Not installed
2025-05-12 22:18:27,352:INFO:              m2cgen: Not installed
2025-05-12 22:18:27,352:INFO:           evidently: Not installed
2025-05-12 22:18:27,352:INFO:               fugue: Not installed
2025-05-12 22:18:27,352:INFO:           streamlit: Not installed
2025-05-12 22:18:27,352:INFO:             prophet: Not installed
2025-05-12 22:18:27,352:INFO:None
2025-05-12 22:18:27,352:INFO:Set up data.
2025-05-12 22:18:27,358:INFO:Set up folding strategy.
2025-05-12 22:18:27,358:INFO:Set up train/test split.
2025-05-12 22:18:27,367:INFO:Set up index.
2025-05-12 22:18:27,367:INFO:Assigning column types.
2025-05-12 22:18:27,371:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:18:27,371:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,380:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,389:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,451:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,487:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,487:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,488:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,492:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,544:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,585:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,586:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,586:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:18:27,590:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,593:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,643:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,683:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,687:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,691:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,737:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,771:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,773:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:18:27,781:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,823:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,858:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,859:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,867:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,913:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,950:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:27,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:27,950:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:18:28,005:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:28,043:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:28,044:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:28,129:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:18:28,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,130:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:18:28,181:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:28,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,270:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:18:28,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,309:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,309:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:18:28,408:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,498:INFO:Preparing preprocessing pipeline...
2025-05-12 22:18:28,498:INFO:Set up simple imputation.
2025-05-12 22:18:28,500:INFO:Set up encoding of categorical features.
2025-05-12 22:18:28,500:INFO:Set up feature normalization.
2025-05-12 22:18:28,549:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:18:28,554:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 22:18:28,554:INFO:Creating final display dataframe.
2025-05-12 22:18:28,693:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type        Regression
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              a4a7
2025-05-12 22:18:28,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:18:28,913:INFO:setup() successfully completed in 1.57s...............
2025-05-12 22:18:28,928:INFO:Initializing compare_models()
2025-05-12 22:18:28,929:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 22:18:28,929:INFO:Checking exceptions
2025-05-12 22:18:28,930:INFO:Preparing display monitor
2025-05-12 22:18:28,954:INFO:Initializing Linear Regression
2025-05-12 22:18:28,954:INFO:Total runtime is 0.0 minutes
2025-05-12 22:18:28,959:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:28,959:INFO:Initializing create_model()
2025-05-12 22:18:28,960:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:28,960:INFO:Checking exceptions
2025-05-12 22:18:28,960:INFO:Importing libraries
2025-05-12 22:18:28,960:INFO:Copying training dataset
2025-05-12 22:18:28,966:INFO:Defining folds
2025-05-12 22:18:28,966:INFO:Declaring metric variables
2025-05-12 22:18:28,971:INFO:Importing untrained model
2025-05-12 22:18:28,974:INFO:Linear Regression Imported successfully
2025-05-12 22:18:28,983:INFO:Starting cross validation
2025-05-12 22:18:28,984:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:38,439:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:38,441:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:38,696:INFO:Calculating mean and std
2025-05-12 22:18:38,697:INFO:Creating metrics dataframe
2025-05-12 22:18:38,701:INFO:Uploading results into container
2025-05-12 22:18:38,703:INFO:Uploading model into container now
2025-05-12 22:18:38,703:INFO:_master_model_container: 1
2025-05-12 22:18:38,705:INFO:_display_container: 2
2025-05-12 22:18:38,706:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:18:38,706:INFO:create_model() successfully completed......................................
2025-05-12 22:18:38,826:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:38,827:INFO:Creating metrics dataframe
2025-05-12 22:18:38,834:INFO:Initializing Lasso Regression
2025-05-12 22:18:38,834:INFO:Total runtime is 0.16466412941614786 minutes
2025-05-12 22:18:38,839:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:38,839:INFO:Initializing create_model()
2025-05-12 22:18:38,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:38,839:INFO:Checking exceptions
2025-05-12 22:18:38,839:INFO:Importing libraries
2025-05-12 22:18:38,839:INFO:Copying training dataset
2025-05-12 22:18:38,844:INFO:Defining folds
2025-05-12 22:18:38,844:INFO:Declaring metric variables
2025-05-12 22:18:38,849:INFO:Importing untrained model
2025-05-12 22:18:38,857:INFO:Lasso Regression Imported successfully
2025-05-12 22:18:38,866:INFO:Starting cross validation
2025-05-12 22:18:38,868:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:39,174:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:39,175:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:39,185:INFO:Calculating mean and std
2025-05-12 22:18:39,187:INFO:Creating metrics dataframe
2025-05-12 22:18:39,190:INFO:Uploading results into container
2025-05-12 22:18:39,191:INFO:Uploading model into container now
2025-05-12 22:18:39,191:INFO:_master_model_container: 2
2025-05-12 22:18:39,191:INFO:_display_container: 2
2025-05-12 22:18:39,191:INFO:Lasso(random_state=123)
2025-05-12 22:18:39,192:INFO:create_model() successfully completed......................................
2025-05-12 22:18:39,282:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:39,282:INFO:Creating metrics dataframe
2025-05-12 22:18:39,292:INFO:Initializing Ridge Regression
2025-05-12 22:18:39,292:INFO:Total runtime is 0.1722898761431376 minutes
2025-05-12 22:18:39,297:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:39,297:INFO:Initializing create_model()
2025-05-12 22:18:39,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:39,297:INFO:Checking exceptions
2025-05-12 22:18:39,297:INFO:Importing libraries
2025-05-12 22:18:39,298:INFO:Copying training dataset
2025-05-12 22:18:39,303:INFO:Defining folds
2025-05-12 22:18:39,304:INFO:Declaring metric variables
2025-05-12 22:18:39,309:INFO:Importing untrained model
2025-05-12 22:18:39,313:INFO:Ridge Regression Imported successfully
2025-05-12 22:18:39,324:INFO:Starting cross validation
2025-05-12 22:18:39,328:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:39,573:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:39,574:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:39,579:INFO:Calculating mean and std
2025-05-12 22:18:39,581:INFO:Creating metrics dataframe
2025-05-12 22:18:39,582:INFO:Uploading results into container
2025-05-12 22:18:39,584:INFO:Uploading model into container now
2025-05-12 22:18:39,584:INFO:_master_model_container: 3
2025-05-12 22:18:39,584:INFO:_display_container: 2
2025-05-12 22:18:39,585:INFO:Ridge(random_state=123)
2025-05-12 22:18:39,585:INFO:create_model() successfully completed......................................
2025-05-12 22:18:39,680:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:39,681:INFO:Creating metrics dataframe
2025-05-12 22:18:39,688:INFO:Initializing Elastic Net
2025-05-12 22:18:39,688:INFO:Total runtime is 0.17889271179835 minutes
2025-05-12 22:18:39,691:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:39,691:INFO:Initializing create_model()
2025-05-12 22:18:39,691:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:39,693:INFO:Checking exceptions
2025-05-12 22:18:39,693:INFO:Importing libraries
2025-05-12 22:18:39,693:INFO:Copying training dataset
2025-05-12 22:18:39,697:INFO:Defining folds
2025-05-12 22:18:39,698:INFO:Declaring metric variables
2025-05-12 22:18:39,701:INFO:Importing untrained model
2025-05-12 22:18:39,713:INFO:Elastic Net Imported successfully
2025-05-12 22:18:39,753:INFO:Starting cross validation
2025-05-12 22:18:39,756:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:40,058:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:40,059:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:40,062:INFO:Calculating mean and std
2025-05-12 22:18:40,063:INFO:Creating metrics dataframe
2025-05-12 22:18:40,066:INFO:Uploading results into container
2025-05-12 22:18:40,067:INFO:Uploading model into container now
2025-05-12 22:18:40,068:INFO:_master_model_container: 4
2025-05-12 22:18:40,069:INFO:_display_container: 2
2025-05-12 22:18:40,070:INFO:ElasticNet(random_state=123)
2025-05-12 22:18:40,070:INFO:create_model() successfully completed......................................
2025-05-12 22:18:40,163:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:40,163:INFO:Creating metrics dataframe
2025-05-12 22:18:40,170:INFO:Initializing Least Angle Regression
2025-05-12 22:18:40,170:INFO:Total runtime is 0.18693626721700032 minutes
2025-05-12 22:18:40,174:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:40,174:INFO:Initializing create_model()
2025-05-12 22:18:40,174:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:40,174:INFO:Checking exceptions
2025-05-12 22:18:40,174:INFO:Importing libraries
2025-05-12 22:18:40,174:INFO:Copying training dataset
2025-05-12 22:18:40,179:INFO:Defining folds
2025-05-12 22:18:40,179:INFO:Declaring metric variables
2025-05-12 22:18:40,184:INFO:Importing untrained model
2025-05-12 22:18:40,191:INFO:Least Angle Regression Imported successfully
2025-05-12 22:18:40,200:INFO:Starting cross validation
2025-05-12 22:18:40,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:40,449:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:40,450:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:40,459:INFO:Calculating mean and std
2025-05-12 22:18:40,460:INFO:Creating metrics dataframe
2025-05-12 22:18:40,463:INFO:Uploading results into container
2025-05-12 22:18:40,463:INFO:Uploading model into container now
2025-05-12 22:18:40,464:INFO:_master_model_container: 5
2025-05-12 22:18:40,464:INFO:_display_container: 2
2025-05-12 22:18:40,464:INFO:Lars(random_state=123)
2025-05-12 22:18:40,464:INFO:create_model() successfully completed......................................
2025-05-12 22:18:40,555:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:40,555:INFO:Creating metrics dataframe
2025-05-12 22:18:40,564:INFO:Initializing Lasso Least Angle Regression
2025-05-12 22:18:40,564:INFO:Total runtime is 0.1934968630472819 minutes
2025-05-12 22:18:40,569:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:40,570:INFO:Initializing create_model()
2025-05-12 22:18:40,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:40,570:INFO:Checking exceptions
2025-05-12 22:18:40,571:INFO:Importing libraries
2025-05-12 22:18:40,571:INFO:Copying training dataset
2025-05-12 22:18:40,575:INFO:Defining folds
2025-05-12 22:18:40,576:INFO:Declaring metric variables
2025-05-12 22:18:40,580:INFO:Importing untrained model
2025-05-12 22:18:40,583:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:18:40,594:INFO:Starting cross validation
2025-05-12 22:18:40,596:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:40,887:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:40,887:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:40,896:INFO:Calculating mean and std
2025-05-12 22:18:40,897:INFO:Creating metrics dataframe
2025-05-12 22:18:40,899:INFO:Uploading results into container
2025-05-12 22:18:40,900:INFO:Uploading model into container now
2025-05-12 22:18:40,901:INFO:_master_model_container: 6
2025-05-12 22:18:40,901:INFO:_display_container: 2
2025-05-12 22:18:40,901:INFO:LassoLars(random_state=123)
2025-05-12 22:18:40,902:INFO:create_model() successfully completed......................................
2025-05-12 22:18:40,994:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:40,994:INFO:Creating metrics dataframe
2025-05-12 22:18:41,004:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 22:18:41,004:INFO:Total runtime is 0.2008352518081665 minutes
2025-05-12 22:18:41,009:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:41,009:INFO:Initializing create_model()
2025-05-12 22:18:41,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:41,009:INFO:Checking exceptions
2025-05-12 22:18:41,009:INFO:Importing libraries
2025-05-12 22:18:41,009:INFO:Copying training dataset
2025-05-12 22:18:41,014:INFO:Defining folds
2025-05-12 22:18:41,015:INFO:Declaring metric variables
2025-05-12 22:18:41,019:INFO:Importing untrained model
2025-05-12 22:18:41,026:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 22:18:41,034:INFO:Starting cross validation
2025-05-12 22:18:41,037:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:41,279:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:41,279:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:41,281:INFO:Calculating mean and std
2025-05-12 22:18:41,283:INFO:Creating metrics dataframe
2025-05-12 22:18:41,286:INFO:Uploading results into container
2025-05-12 22:18:41,287:INFO:Uploading model into container now
2025-05-12 22:18:41,287:INFO:_master_model_container: 7
2025-05-12 22:18:41,287:INFO:_display_container: 2
2025-05-12 22:18:41,288:INFO:OrthogonalMatchingPursuit()
2025-05-12 22:18:41,288:INFO:create_model() successfully completed......................................
2025-05-12 22:18:41,379:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:41,379:INFO:Creating metrics dataframe
2025-05-12 22:18:41,389:INFO:Initializing Bayesian Ridge
2025-05-12 22:18:41,389:INFO:Total runtime is 0.2072447975476583 minutes
2025-05-12 22:18:41,393:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:41,393:INFO:Initializing create_model()
2025-05-12 22:18:41,393:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:41,393:INFO:Checking exceptions
2025-05-12 22:18:41,394:INFO:Importing libraries
2025-05-12 22:18:41,394:INFO:Copying training dataset
2025-05-12 22:18:41,398:INFO:Defining folds
2025-05-12 22:18:41,398:INFO:Declaring metric variables
2025-05-12 22:18:41,403:INFO:Importing untrained model
2025-05-12 22:18:41,408:INFO:Bayesian Ridge Imported successfully
2025-05-12 22:18:41,415:INFO:Starting cross validation
2025-05-12 22:18:41,417:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:41,658:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:41,659:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:41,669:INFO:Calculating mean and std
2025-05-12 22:18:41,671:INFO:Creating metrics dataframe
2025-05-12 22:18:41,674:INFO:Uploading results into container
2025-05-12 22:18:41,676:INFO:Uploading model into container now
2025-05-12 22:18:41,676:INFO:_master_model_container: 8
2025-05-12 22:18:41,676:INFO:_display_container: 2
2025-05-12 22:18:41,677:INFO:BayesianRidge()
2025-05-12 22:18:41,677:INFO:create_model() successfully completed......................................
2025-05-12 22:18:41,767:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:41,768:INFO:Creating metrics dataframe
2025-05-12 22:18:41,776:INFO:Initializing Passive Aggressive Regressor
2025-05-12 22:18:41,776:INFO:Total runtime is 0.21370112895965576 minutes
2025-05-12 22:18:41,780:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:41,780:INFO:Initializing create_model()
2025-05-12 22:18:41,780:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:41,780:INFO:Checking exceptions
2025-05-12 22:18:41,780:INFO:Importing libraries
2025-05-12 22:18:41,780:INFO:Copying training dataset
2025-05-12 22:18:41,785:INFO:Defining folds
2025-05-12 22:18:41,786:INFO:Declaring metric variables
2025-05-12 22:18:41,789:INFO:Importing untrained model
2025-05-12 22:18:41,795:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 22:18:41,804:INFO:Starting cross validation
2025-05-12 22:18:41,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:42,047:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:42,047:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:42,049:INFO:Calculating mean and std
2025-05-12 22:18:42,050:INFO:Creating metrics dataframe
2025-05-12 22:18:42,053:INFO:Uploading results into container
2025-05-12 22:18:42,054:INFO:Uploading model into container now
2025-05-12 22:18:42,055:INFO:_master_model_container: 9
2025-05-12 22:18:42,055:INFO:_display_container: 2
2025-05-12 22:18:42,056:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 22:18:42,056:INFO:create_model() successfully completed......................................
2025-05-12 22:18:42,152:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:42,152:INFO:Creating metrics dataframe
2025-05-12 22:18:42,161:INFO:Initializing Huber Regressor
2025-05-12 22:18:42,161:INFO:Total runtime is 0.220106303691864 minutes
2025-05-12 22:18:42,166:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:42,166:INFO:Initializing create_model()
2025-05-12 22:18:42,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:42,166:INFO:Checking exceptions
2025-05-12 22:18:42,167:INFO:Importing libraries
2025-05-12 22:18:42,167:INFO:Copying training dataset
2025-05-12 22:18:42,171:INFO:Defining folds
2025-05-12 22:18:42,172:INFO:Declaring metric variables
2025-05-12 22:18:42,176:INFO:Importing untrained model
2025-05-12 22:18:42,183:INFO:Huber Regressor Imported successfully
2025-05-12 22:18:42,193:INFO:Starting cross validation
2025-05-12 22:18:42,196:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:42,561:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:42,561:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:42,573:INFO:Calculating mean and std
2025-05-12 22:18:42,574:INFO:Creating metrics dataframe
2025-05-12 22:18:42,577:INFO:Uploading results into container
2025-05-12 22:18:42,577:INFO:Uploading model into container now
2025-05-12 22:18:42,578:INFO:_master_model_container: 10
2025-05-12 22:18:42,578:INFO:_display_container: 2
2025-05-12 22:18:42,578:INFO:HuberRegressor()
2025-05-12 22:18:42,578:INFO:create_model() successfully completed......................................
2025-05-12 22:18:42,676:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:42,676:INFO:Creating metrics dataframe
2025-05-12 22:18:42,687:INFO:Initializing K Neighbors Regressor
2025-05-12 22:18:42,688:INFO:Total runtime is 0.2288930098215739 minutes
2025-05-12 22:18:42,693:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:42,693:INFO:Initializing create_model()
2025-05-12 22:18:42,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:42,693:INFO:Checking exceptions
2025-05-12 22:18:42,693:INFO:Importing libraries
2025-05-12 22:18:42,693:INFO:Copying training dataset
2025-05-12 22:18:42,698:INFO:Defining folds
2025-05-12 22:18:42,698:INFO:Declaring metric variables
2025-05-12 22:18:42,704:INFO:Importing untrained model
2025-05-12 22:18:42,707:INFO:K Neighbors Regressor Imported successfully
2025-05-12 22:18:42,718:INFO:Starting cross validation
2025-05-12 22:18:42,720:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:43,006:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:43,006:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:43,011:INFO:Calculating mean and std
2025-05-12 22:18:43,011:INFO:Creating metrics dataframe
2025-05-12 22:18:43,016:INFO:Uploading results into container
2025-05-12 22:18:43,017:INFO:Uploading model into container now
2025-05-12 22:18:43,017:INFO:_master_model_container: 11
2025-05-12 22:18:43,017:INFO:_display_container: 2
2025-05-12 22:18:43,019:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 22:18:43,019:INFO:create_model() successfully completed......................................
2025-05-12 22:18:43,108:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:43,108:INFO:Creating metrics dataframe
2025-05-12 22:18:43,117:INFO:Initializing Decision Tree Regressor
2025-05-12 22:18:43,118:INFO:Total runtime is 0.23605743646621705 minutes
2025-05-12 22:18:43,120:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:43,121:INFO:Initializing create_model()
2025-05-12 22:18:43,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:43,121:INFO:Checking exceptions
2025-05-12 22:18:43,121:INFO:Importing libraries
2025-05-12 22:18:43,121:INFO:Copying training dataset
2025-05-12 22:18:43,126:INFO:Defining folds
2025-05-12 22:18:43,127:INFO:Declaring metric variables
2025-05-12 22:18:43,131:INFO:Importing untrained model
2025-05-12 22:18:43,136:INFO:Decision Tree Regressor Imported successfully
2025-05-12 22:18:43,146:INFO:Starting cross validation
2025-05-12 22:18:43,148:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:43,420:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:43,421:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:43,428:INFO:Calculating mean and std
2025-05-12 22:18:43,430:INFO:Creating metrics dataframe
2025-05-12 22:18:43,433:INFO:Uploading results into container
2025-05-12 22:18:43,434:INFO:Uploading model into container now
2025-05-12 22:18:43,434:INFO:_master_model_container: 12
2025-05-12 22:18:43,434:INFO:_display_container: 2
2025-05-12 22:18:43,436:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 22:18:43,436:INFO:create_model() successfully completed......................................
2025-05-12 22:18:43,535:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:43,535:INFO:Creating metrics dataframe
2025-05-12 22:18:43,551:INFO:Initializing Random Forest Regressor
2025-05-12 22:18:43,551:INFO:Total runtime is 0.24327282508214315 minutes
2025-05-12 22:18:43,556:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:43,557:INFO:Initializing create_model()
2025-05-12 22:18:43,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:43,557:INFO:Checking exceptions
2025-05-12 22:18:43,557:INFO:Importing libraries
2025-05-12 22:18:43,557:INFO:Copying training dataset
2025-05-12 22:18:43,563:INFO:Defining folds
2025-05-12 22:18:43,563:INFO:Declaring metric variables
2025-05-12 22:18:43,569:INFO:Importing untrained model
2025-05-12 22:18:43,573:INFO:Random Forest Regressor Imported successfully
2025-05-12 22:18:43,584:INFO:Starting cross validation
2025-05-12 22:18:43,587:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:44,795:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:44,796:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:44,813:INFO:Calculating mean and std
2025-05-12 22:18:44,814:INFO:Creating metrics dataframe
2025-05-12 22:18:44,818:INFO:Uploading results into container
2025-05-12 22:18:44,818:INFO:Uploading model into container now
2025-05-12 22:18:44,819:INFO:_master_model_container: 13
2025-05-12 22:18:44,819:INFO:_display_container: 2
2025-05-12 22:18:44,819:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:18:44,820:INFO:create_model() successfully completed......................................
2025-05-12 22:18:44,909:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:44,910:INFO:Creating metrics dataframe
2025-05-12 22:18:44,920:INFO:Initializing Extra Trees Regressor
2025-05-12 22:18:44,920:INFO:Total runtime is 0.2661035100618998 minutes
2025-05-12 22:18:44,924:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:44,924:INFO:Initializing create_model()
2025-05-12 22:18:44,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:44,925:INFO:Checking exceptions
2025-05-12 22:18:44,925:INFO:Importing libraries
2025-05-12 22:18:44,925:INFO:Copying training dataset
2025-05-12 22:18:44,930:INFO:Defining folds
2025-05-12 22:18:44,931:INFO:Declaring metric variables
2025-05-12 22:18:44,935:INFO:Importing untrained model
2025-05-12 22:18:44,940:INFO:Extra Trees Regressor Imported successfully
2025-05-12 22:18:44,961:INFO:Starting cross validation
2025-05-12 22:18:44,965:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:45,646:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:45,647:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:45,651:INFO:Calculating mean and std
2025-05-12 22:18:45,652:INFO:Creating metrics dataframe
2025-05-12 22:18:45,654:INFO:Uploading results into container
2025-05-12 22:18:45,655:INFO:Uploading model into container now
2025-05-12 22:18:45,655:INFO:_master_model_container: 14
2025-05-12 22:18:45,655:INFO:_display_container: 2
2025-05-12 22:18:45,656:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:18:45,656:INFO:create_model() successfully completed......................................
2025-05-12 22:18:45,760:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:45,761:INFO:Creating metrics dataframe
2025-05-12 22:18:45,781:INFO:Initializing AdaBoost Regressor
2025-05-12 22:18:45,781:INFO:Total runtime is 0.2804393212000529 minutes
2025-05-12 22:18:45,788:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:45,788:INFO:Initializing create_model()
2025-05-12 22:18:45,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:45,788:INFO:Checking exceptions
2025-05-12 22:18:45,788:INFO:Importing libraries
2025-05-12 22:18:45,788:INFO:Copying training dataset
2025-05-12 22:18:45,795:INFO:Defining folds
2025-05-12 22:18:45,795:INFO:Declaring metric variables
2025-05-12 22:18:45,803:INFO:Importing untrained model
2025-05-12 22:18:45,808:INFO:AdaBoost Regressor Imported successfully
2025-05-12 22:18:45,821:INFO:Starting cross validation
2025-05-12 22:18:45,825:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:46,377:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:46,378:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:46,381:INFO:Calculating mean and std
2025-05-12 22:18:46,382:INFO:Creating metrics dataframe
2025-05-12 22:18:46,386:INFO:Uploading results into container
2025-05-12 22:18:46,387:INFO:Uploading model into container now
2025-05-12 22:18:46,387:INFO:_master_model_container: 15
2025-05-12 22:18:46,387:INFO:_display_container: 2
2025-05-12 22:18:46,388:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 22:18:46,388:INFO:create_model() successfully completed......................................
2025-05-12 22:18:46,483:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:46,483:INFO:Creating metrics dataframe
2025-05-12 22:18:46,494:INFO:Initializing Gradient Boosting Regressor
2025-05-12 22:18:46,494:INFO:Total runtime is 0.29232976833979285 minutes
2025-05-12 22:18:46,499:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:46,499:INFO:Initializing create_model()
2025-05-12 22:18:46,499:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:46,499:INFO:Checking exceptions
2025-05-12 22:18:46,499:INFO:Importing libraries
2025-05-12 22:18:46,499:INFO:Copying training dataset
2025-05-12 22:18:46,504:INFO:Defining folds
2025-05-12 22:18:46,504:INFO:Declaring metric variables
2025-05-12 22:18:46,509:INFO:Importing untrained model
2025-05-12 22:18:46,515:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 22:18:46,524:INFO:Starting cross validation
2025-05-12 22:18:46,528:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:47,078:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:47,079:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:47,080:INFO:Calculating mean and std
2025-05-12 22:18:47,081:INFO:Creating metrics dataframe
2025-05-12 22:18:47,083:INFO:Uploading results into container
2025-05-12 22:18:47,084:INFO:Uploading model into container now
2025-05-12 22:18:47,085:INFO:_master_model_container: 16
2025-05-12 22:18:47,085:INFO:_display_container: 2
2025-05-12 22:18:47,086:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 22:18:47,086:INFO:create_model() successfully completed......................................
2025-05-12 22:18:47,181:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:47,181:INFO:Creating metrics dataframe
2025-05-12 22:18:47,191:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:18:47,191:INFO:Total runtime is 0.30394897063573195 minutes
2025-05-12 22:18:47,195:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:47,196:INFO:Initializing create_model()
2025-05-12 22:18:47,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:47,196:INFO:Checking exceptions
2025-05-12 22:18:47,196:INFO:Importing libraries
2025-05-12 22:18:47,196:INFO:Copying training dataset
2025-05-12 22:18:47,200:INFO:Defining folds
2025-05-12 22:18:47,200:INFO:Declaring metric variables
2025-05-12 22:18:47,204:INFO:Importing untrained model
2025-05-12 22:18:47,210:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:18:47,218:INFO:Starting cross validation
2025-05-12 22:18:47,220:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:47,815:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:47,815:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:47,817:INFO:Calculating mean and std
2025-05-12 22:18:47,819:INFO:Creating metrics dataframe
2025-05-12 22:18:47,822:INFO:Uploading results into container
2025-05-12 22:18:47,824:INFO:Uploading model into container now
2025-05-12 22:18:47,824:INFO:_master_model_container: 17
2025-05-12 22:18:47,825:INFO:_display_container: 2
2025-05-12 22:18:47,826:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:18:47,827:INFO:create_model() successfully completed......................................
2025-05-12 22:18:47,947:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:47,947:INFO:Creating metrics dataframe
2025-05-12 22:18:47,959:INFO:Initializing Dummy Regressor
2025-05-12 22:18:47,959:INFO:Total runtime is 0.3167533874511718 minutes
2025-05-12 22:18:47,964:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:47,964:INFO:Initializing create_model()
2025-05-12 22:18:47,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B069AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:47,964:INFO:Checking exceptions
2025-05-12 22:18:47,964:INFO:Importing libraries
2025-05-12 22:18:47,964:INFO:Copying training dataset
2025-05-12 22:18:47,970:INFO:Defining folds
2025-05-12 22:18:47,970:INFO:Declaring metric variables
2025-05-12 22:18:47,975:INFO:Importing untrained model
2025-05-12 22:18:47,983:INFO:Dummy Regressor Imported successfully
2025-05-12 22:18:47,991:INFO:Starting cross validation
2025-05-12 22:18:47,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:48,238:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:48,239:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:48,246:INFO:Calculating mean and std
2025-05-12 22:18:48,247:INFO:Creating metrics dataframe
2025-05-12 22:18:48,249:INFO:Uploading results into container
2025-05-12 22:18:48,249:INFO:Uploading model into container now
2025-05-12 22:18:48,250:INFO:_master_model_container: 18
2025-05-12 22:18:48,250:INFO:_display_container: 2
2025-05-12 22:18:48,251:INFO:DummyRegressor()
2025-05-12 22:18:48,251:INFO:create_model() successfully completed......................................
2025-05-12 22:18:48,346:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:48,346:INFO:Creating metrics dataframe
2025-05-12 22:18:48,358:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:18:48,369:INFO:Initializing create_model()
2025-05-12 22:18:48,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:48,369:INFO:Checking exceptions
2025-05-12 22:18:48,371:INFO:Importing libraries
2025-05-12 22:18:48,371:INFO:Copying training dataset
2025-05-12 22:18:48,374:INFO:Defining folds
2025-05-12 22:18:48,375:INFO:Declaring metric variables
2025-05-12 22:18:48,375:INFO:Importing untrained model
2025-05-12 22:18:48,376:INFO:Declaring custom model
2025-05-12 22:18:48,377:INFO:Lasso Regression Imported successfully
2025-05-12 22:18:48,379:INFO:Cross validation set to False
2025-05-12 22:18:48,379:INFO:Fitting Model
2025-05-12 22:18:48,426:INFO:Lasso(random_state=123)
2025-05-12 22:18:48,426:INFO:create_model() successfully completed......................................
2025-05-12 22:18:48,606:INFO:_master_model_container: 18
2025-05-12 22:18:48,606:INFO:_display_container: 2
2025-05-12 22:18:48,607:INFO:Lasso(random_state=123)
2025-05-12 22:18:48,607:INFO:compare_models() successfully completed......................................
2025-05-12 22:18:48,664:INFO:Initializing create_model()
2025-05-12 22:18:48,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=en, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:48,664:INFO:Checking exceptions
2025-05-12 22:18:48,685:INFO:Importing libraries
2025-05-12 22:18:48,686:INFO:Copying training dataset
2025-05-12 22:18:48,692:INFO:Defining folds
2025-05-12 22:18:48,692:INFO:Declaring metric variables
2025-05-12 22:18:48,698:INFO:Importing untrained model
2025-05-12 22:18:48,721:INFO:Elastic Net Imported successfully
2025-05-12 22:18:48,738:INFO:Starting cross validation
2025-05-12 22:18:48,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:49,009:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:49,009:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:49,020:INFO:Calculating mean and std
2025-05-12 22:18:49,021:INFO:Creating metrics dataframe
2025-05-12 22:18:49,027:INFO:Finalizing model
2025-05-12 22:18:49,076:INFO:Uploading results into container
2025-05-12 22:18:49,077:INFO:Uploading model into container now
2025-05-12 22:18:49,087:INFO:_master_model_container: 19
2025-05-12 22:18:49,088:INFO:_display_container: 3
2025-05-12 22:18:49,088:INFO:ElasticNet(random_state=123)
2025-05-12 22:18:49,088:INFO:create_model() successfully completed......................................
2025-05-12 22:18:49,191:INFO:Initializing tune_model()
2025-05-12 22:18:49,191:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ElasticNet(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:18:49,192:INFO:Checking exceptions
2025-05-12 22:18:49,211:INFO:Copying training dataset
2025-05-12 22:18:49,215:INFO:Checking base model
2025-05-12 22:18:49,215:INFO:Base model : Elastic Net
2025-05-12 22:18:49,219:INFO:Declaring metric variables
2025-05-12 22:18:49,223:INFO:Defining Hyperparameters
2025-05-12 22:18:49,313:INFO:Tuning with n_jobs=-1
2025-05-12 22:18:49,313:INFO:Initializing RandomizedSearchCV
2025-05-12 22:18:51,893:INFO:best_params: {'actual_estimator__l1_ratio': 0.664, 'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 9.88}
2025-05-12 22:18:51,894:INFO:Hyperparameter search completed
2025-05-12 22:18:51,894:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:51,896:INFO:Initializing create_model()
2025-05-12 22:18:51,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ElasticNet(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA785CCED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'l1_ratio': 0.664, 'fit_intercept': True, 'alpha': 9.88})
2025-05-12 22:18:51,897:INFO:Checking exceptions
2025-05-12 22:18:51,898:INFO:Importing libraries
2025-05-12 22:18:51,898:INFO:Copying training dataset
2025-05-12 22:18:51,904:INFO:Defining folds
2025-05-12 22:18:51,904:INFO:Declaring metric variables
2025-05-12 22:18:51,911:INFO:Importing untrained model
2025-05-12 22:18:51,911:INFO:Declaring custom model
2025-05-12 22:18:51,921:INFO:Elastic Net Imported successfully
2025-05-12 22:18:51,945:INFO:Starting cross validation
2025-05-12 22:18:51,949:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:52,347:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:52,347:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:52,357:INFO:Calculating mean and std
2025-05-12 22:18:52,358:INFO:Creating metrics dataframe
2025-05-12 22:18:52,364:INFO:Finalizing model
2025-05-12 22:18:52,424:INFO:Uploading results into container
2025-05-12 22:18:52,424:INFO:Uploading model into container now
2025-05-12 22:18:52,426:INFO:_master_model_container: 20
2025-05-12 22:18:52,426:INFO:_display_container: 4
2025-05-12 22:18:52,426:INFO:ElasticNet(alpha=9.88, l1_ratio=0.664, random_state=123)
2025-05-12 22:18:52,426:INFO:create_model() successfully completed......................................
2025-05-12 22:18:52,519:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:52,519:INFO:choose_better activated
2025-05-12 22:18:52,523:INFO:SubProcess create_model() called ==================================
2025-05-12 22:18:52,523:INFO:Initializing create_model()
2025-05-12 22:18:52,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ElasticNet(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:18:52,523:INFO:Checking exceptions
2025-05-12 22:18:52,525:INFO:Importing libraries
2025-05-12 22:18:52,525:INFO:Copying training dataset
2025-05-12 22:18:52,529:INFO:Defining folds
2025-05-12 22:18:52,530:INFO:Declaring metric variables
2025-05-12 22:18:52,530:INFO:Importing untrained model
2025-05-12 22:18:52,530:INFO:Declaring custom model
2025-05-12 22:18:52,530:INFO:Elastic Net Imported successfully
2025-05-12 22:18:52,531:INFO:Starting cross validation
2025-05-12 22:18:52,533:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:18:52,851:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:18:52,851:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:18:52,853:INFO:Calculating mean and std
2025-05-12 22:18:52,854:INFO:Creating metrics dataframe
2025-05-12 22:18:52,857:INFO:Finalizing model
2025-05-12 22:18:52,905:INFO:Uploading results into container
2025-05-12 22:18:52,906:INFO:Uploading model into container now
2025-05-12 22:18:52,906:INFO:_master_model_container: 21
2025-05-12 22:18:52,906:INFO:_display_container: 5
2025-05-12 22:18:52,907:INFO:ElasticNet(random_state=123)
2025-05-12 22:18:52,907:INFO:create_model() successfully completed......................................
2025-05-12 22:18:53,000:INFO:SubProcess create_model() end ==================================
2025-05-12 22:18:53,000:INFO:ElasticNet(random_state=123) result for R2 is -0.0421
2025-05-12 22:18:53,001:INFO:ElasticNet(alpha=9.88, l1_ratio=0.664, random_state=123) result for R2 is -0.0421
2025-05-12 22:18:53,001:INFO:ElasticNet(random_state=123) is best model
2025-05-12 22:18:53,001:INFO:choose_better completed
2025-05-12 22:18:53,001:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:18:53,011:INFO:_master_model_container: 21
2025-05-12 22:18:53,011:INFO:_display_container: 4
2025-05-12 22:18:53,011:INFO:ElasticNet(random_state=123)
2025-05-12 22:18:53,011:INFO:tune_model() successfully completed......................................
2025-05-12 22:18:53,107:INFO:Initializing evaluate_model()
2025-05-12 22:18:53,107:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ElasticNet(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:18:53,117:INFO:Initializing plot_model()
2025-05-12 22:18:53,117:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ElasticNet(random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:18:53,117:INFO:Checking exceptions
2025-05-12 22:18:53,119:INFO:Preloading libraries
2025-05-12 22:18:53,119:INFO:Copying training dataset
2025-05-12 22:18:53,119:INFO:Plot type: pipeline
2025-05-12 22:18:53,231:INFO:Visual Rendered Successfully
2025-05-12 22:18:53,312:INFO:plot_model() successfully completed......................................
2025-05-12 22:18:53,329:INFO:Initializing predict_model()
2025-05-12 22:18:53,329:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7B211810>, estimator=ElasticNet(random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EA7AEA2E80>)
2025-05-12 22:18:53,329:INFO:Checking exceptions
2025-05-12 22:18:53,329:INFO:Preloading libraries
2025-05-12 22:18:53,426:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:18:53,534:INFO:Initializing save_model()
2025-05-12 22:18:53,534:INFO:save_model(model=ElasticNet(random_state=123), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-12 22:18:53,534:INFO:Adding model into prep_pipe
2025-05-12 22:18:53,543:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:18:53,549:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', ElasticNet(random_state=123))])
2025-05-12 22:18:53,549:INFO:save_model() successfully completed......................................
2025-05-12 22:22:50,033:INFO:PyCaret RegressionExperiment
2025-05-12 22:22:50,033:INFO:Logging name: reg-default-name
2025-05-12 22:22:50,033:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:22:50,033:INFO:version 3.3.2
2025-05-12 22:22:50,033:INFO:Initializing setup()
2025-05-12 22:22:50,033:INFO:self.USI: e29e
2025-05-12 22:22:50,034:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'transform_target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:22:50,034:INFO:Checking environment
2025-05-12 22:22:50,034:INFO:python_version: 3.11.8
2025-05-12 22:22:50,034:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:22:50,034:INFO:machine: AMD64
2025-05-12 22:22:50,034:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:22:50,038:INFO:Memory: svmem(total=16907886592, available=3052384256, percent=81.9, used=13855502336, free=3052384256)
2025-05-12 22:22:50,039:INFO:Physical Core: 4
2025-05-12 22:22:50,039:INFO:Logical Core: 8
2025-05-12 22:22:50,039:INFO:Checking libraries
2025-05-12 22:22:50,039:INFO:System:
2025-05-12 22:22:50,039:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:22:50,039:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:22:50,039:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:22:50,039:INFO:PyCaret required dependencies:
2025-05-12 22:22:50,039:INFO:                 pip: 24.0
2025-05-12 22:22:50,039:INFO:          setuptools: 65.5.0
2025-05-12 22:22:50,039:INFO:             pycaret: 3.3.2
2025-05-12 22:22:50,039:INFO:             IPython: 9.2.0
2025-05-12 22:22:50,039:INFO:          ipywidgets: 8.1.7
2025-05-12 22:22:50,039:INFO:                tqdm: 4.67.1
2025-05-12 22:22:50,039:INFO:               numpy: 1.26.4
2025-05-12 22:22:50,039:INFO:              pandas: 2.1.4
2025-05-12 22:22:50,039:INFO:              jinja2: 3.1.6
2025-05-12 22:22:50,039:INFO:               scipy: 1.11.4
2025-05-12 22:22:50,039:INFO:              joblib: 1.3.2
2025-05-12 22:22:50,039:INFO:             sklearn: 1.4.2
2025-05-12 22:22:50,039:INFO:                pyod: 2.0.5
2025-05-12 22:22:50,039:INFO:            imblearn: 0.13.0
2025-05-12 22:22:50,039:INFO:   category_encoders: 2.7.0
2025-05-12 22:22:50,039:INFO:            lightgbm: 4.6.0
2025-05-12 22:22:50,039:INFO:               numba: 0.61.2
2025-05-12 22:22:50,039:INFO:            requests: 2.32.3
2025-05-12 22:22:50,039:INFO:          matplotlib: 3.7.5
2025-05-12 22:22:50,039:INFO:          scikitplot: 0.3.7
2025-05-12 22:22:50,039:INFO:         yellowbrick: 1.5
2025-05-12 22:22:50,039:INFO:              plotly: 5.24.1
2025-05-12 22:22:50,039:INFO:    plotly-resampler: Not installed
2025-05-12 22:22:50,039:INFO:             kaleido: 0.2.1
2025-05-12 22:22:50,039:INFO:           schemdraw: 0.15
2025-05-12 22:22:50,039:INFO:         statsmodels: 0.14.4
2025-05-12 22:22:50,039:INFO:              sktime: 0.26.0
2025-05-12 22:22:50,039:INFO:               tbats: 1.1.3
2025-05-12 22:22:50,039:INFO:            pmdarima: 2.0.4
2025-05-12 22:22:50,039:INFO:              psutil: 7.0.0
2025-05-12 22:22:50,039:INFO:          markupsafe: 3.0.2
2025-05-12 22:22:50,039:INFO:             pickle5: Not installed
2025-05-12 22:22:50,039:INFO:         cloudpickle: 3.1.1
2025-05-12 22:22:50,039:INFO:         deprecation: 2.1.0
2025-05-12 22:22:50,040:INFO:              xxhash: 3.5.0
2025-05-12 22:22:50,040:INFO:           wurlitzer: Not installed
2025-05-12 22:22:50,040:INFO:PyCaret optional dependencies:
2025-05-12 22:22:50,040:INFO:                shap: Not installed
2025-05-12 22:22:50,040:INFO:           interpret: Not installed
2025-05-12 22:22:50,040:INFO:                umap: Not installed
2025-05-12 22:22:50,040:INFO:     ydata_profiling: Not installed
2025-05-12 22:22:50,040:INFO:  explainerdashboard: Not installed
2025-05-12 22:22:50,040:INFO:             autoviz: Not installed
2025-05-12 22:22:50,040:INFO:           fairlearn: Not installed
2025-05-12 22:22:50,040:INFO:          deepchecks: Not installed
2025-05-12 22:22:50,040:INFO:             xgboost: Not installed
2025-05-12 22:22:50,040:INFO:            catboost: Not installed
2025-05-12 22:22:50,040:INFO:              kmodes: Not installed
2025-05-12 22:22:50,040:INFO:             mlxtend: Not installed
2025-05-12 22:22:50,040:INFO:       statsforecast: Not installed
2025-05-12 22:22:50,040:INFO:        tune_sklearn: Not installed
2025-05-12 22:22:50,040:INFO:                 ray: Not installed
2025-05-12 22:22:50,040:INFO:            hyperopt: Not installed
2025-05-12 22:22:50,040:INFO:              optuna: Not installed
2025-05-12 22:22:50,040:INFO:               skopt: Not installed
2025-05-12 22:22:50,040:INFO:              mlflow: Not installed
2025-05-12 22:22:50,040:INFO:              gradio: Not installed
2025-05-12 22:22:50,040:INFO:             fastapi: Not installed
2025-05-12 22:22:50,040:INFO:             uvicorn: Not installed
2025-05-12 22:22:50,040:INFO:              m2cgen: Not installed
2025-05-12 22:22:50,040:INFO:           evidently: Not installed
2025-05-12 22:22:50,040:INFO:               fugue: Not installed
2025-05-12 22:22:50,040:INFO:           streamlit: Not installed
2025-05-12 22:22:50,040:INFO:             prophet: Not installed
2025-05-12 22:22:50,040:INFO:None
2025-05-12 22:22:50,040:INFO:Set up data.
2025-05-12 22:22:50,044:INFO:Set up folding strategy.
2025-05-12 22:22:50,044:INFO:Set up train/test split.
2025-05-12 22:22:50,046:INFO:Set up index.
2025-05-12 22:22:50,046:INFO:Assigning column types.
2025-05-12 22:22:50,048:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:22:50,048:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,052:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,056:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,145:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,186:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,187:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,187:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,191:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,194:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,240:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,276:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,277:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:22:50,280:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,284:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,329:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,363:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,364:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,368:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,372:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,419:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,457:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,458:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:22:50,465:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,514:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,549:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,549:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,557:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,599:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,633:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,634:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:22:50,685:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,770:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,804:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:22:50,858:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,960:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:22:50,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:50,999:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:22:51,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,203:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,203:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,204:INFO:Preparing preprocessing pipeline...
2025-05-12 22:22:51,204:INFO:Set up simple imputation.
2025-05-12 22:22:51,207:INFO:Set up encoding of categorical features.
2025-05-12 22:22:51,207:INFO:Set up feature normalization.
2025-05-12 22:22:51,261:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:22:51,267:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-12 22:22:51,267:INFO:Creating final display dataframe.
2025-05-12 22:22:51,421:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type        Regression
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              e29e
2025-05-12 22:22:51,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:22:51,652:INFO:setup() successfully completed in 1.62s...............
2025-05-12 22:22:51,671:INFO:Initializing compare_models()
2025-05-12 22:22:51,671:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 22:22:51,671:INFO:Checking exceptions
2025-05-12 22:22:51,674:INFO:Preparing display monitor
2025-05-12 22:22:51,694:INFO:Initializing Linear Regression
2025-05-12 22:22:51,695:INFO:Total runtime is 1.666545867919922e-05 minutes
2025-05-12 22:22:51,698:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:51,700:INFO:Initializing create_model()
2025-05-12 22:22:51,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:51,700:INFO:Checking exceptions
2025-05-12 22:22:51,700:INFO:Importing libraries
2025-05-12 22:22:51,700:INFO:Copying training dataset
2025-05-12 22:22:51,704:INFO:Defining folds
2025-05-12 22:22:51,704:INFO:Declaring metric variables
2025-05-12 22:22:51,708:INFO:Importing untrained model
2025-05-12 22:22:51,712:INFO:Linear Regression Imported successfully
2025-05-12 22:22:51,720:INFO:Starting cross validation
2025-05-12 22:22:51,721:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:51,927:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:51,927:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:51,931:INFO:Calculating mean and std
2025-05-12 22:22:51,931:INFO:Creating metrics dataframe
2025-05-12 22:22:51,933:INFO:Uploading results into container
2025-05-12 22:22:51,933:INFO:Uploading model into container now
2025-05-12 22:22:51,933:INFO:_master_model_container: 1
2025-05-12 22:22:51,933:INFO:_display_container: 2
2025-05-12 22:22:51,933:INFO:LinearRegression(n_jobs=-1)
2025-05-12 22:22:51,933:INFO:create_model() successfully completed......................................
2025-05-12 22:22:52,018:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:52,018:INFO:Creating metrics dataframe
2025-05-12 22:22:52,024:INFO:Initializing Lasso Regression
2025-05-12 22:22:52,024:INFO:Total runtime is 0.0054997642834981285 minutes
2025-05-12 22:22:52,028:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:52,028:INFO:Initializing create_model()
2025-05-12 22:22:52,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:52,028:INFO:Checking exceptions
2025-05-12 22:22:52,028:INFO:Importing libraries
2025-05-12 22:22:52,028:INFO:Copying training dataset
2025-05-12 22:22:52,031:INFO:Defining folds
2025-05-12 22:22:52,031:INFO:Declaring metric variables
2025-05-12 22:22:52,034:INFO:Importing untrained model
2025-05-12 22:22:52,037:INFO:Lasso Regression Imported successfully
2025-05-12 22:22:52,044:INFO:Starting cross validation
2025-05-12 22:22:52,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:52,209:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:52,210:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:52,216:INFO:Calculating mean and std
2025-05-12 22:22:52,216:INFO:Creating metrics dataframe
2025-05-12 22:22:52,217:INFO:Uploading results into container
2025-05-12 22:22:52,218:INFO:Uploading model into container now
2025-05-12 22:22:52,218:INFO:_master_model_container: 2
2025-05-12 22:22:52,218:INFO:_display_container: 2
2025-05-12 22:22:52,218:INFO:Lasso(random_state=123)
2025-05-12 22:22:52,218:INFO:create_model() successfully completed......................................
2025-05-12 22:22:52,291:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:52,291:INFO:Creating metrics dataframe
2025-05-12 22:22:52,297:INFO:Initializing Ridge Regression
2025-05-12 22:22:52,297:INFO:Total runtime is 0.010042277971903484 minutes
2025-05-12 22:22:52,299:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:52,299:INFO:Initializing create_model()
2025-05-12 22:22:52,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:52,299:INFO:Checking exceptions
2025-05-12 22:22:52,299:INFO:Importing libraries
2025-05-12 22:22:52,299:INFO:Copying training dataset
2025-05-12 22:22:52,301:INFO:Defining folds
2025-05-12 22:22:52,303:INFO:Declaring metric variables
2025-05-12 22:22:52,306:INFO:Importing untrained model
2025-05-12 22:22:52,309:INFO:Ridge Regression Imported successfully
2025-05-12 22:22:52,314:INFO:Starting cross validation
2025-05-12 22:22:52,314:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:52,478:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:52,479:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:52,488:INFO:Calculating mean and std
2025-05-12 22:22:52,488:INFO:Creating metrics dataframe
2025-05-12 22:22:52,489:INFO:Uploading results into container
2025-05-12 22:22:52,490:INFO:Uploading model into container now
2025-05-12 22:22:52,490:INFO:_master_model_container: 3
2025-05-12 22:22:52,490:INFO:_display_container: 2
2025-05-12 22:22:52,490:INFO:Ridge(random_state=123)
2025-05-12 22:22:52,490:INFO:create_model() successfully completed......................................
2025-05-12 22:22:52,567:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:52,568:INFO:Creating metrics dataframe
2025-05-12 22:22:52,574:INFO:Initializing Elastic Net
2025-05-12 22:22:52,574:INFO:Total runtime is 0.014663692315419516 minutes
2025-05-12 22:22:52,577:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:52,578:INFO:Initializing create_model()
2025-05-12 22:22:52,578:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:52,578:INFO:Checking exceptions
2025-05-12 22:22:52,578:INFO:Importing libraries
2025-05-12 22:22:52,578:INFO:Copying training dataset
2025-05-12 22:22:52,581:INFO:Defining folds
2025-05-12 22:22:52,581:INFO:Declaring metric variables
2025-05-12 22:22:52,584:INFO:Importing untrained model
2025-05-12 22:22:52,587:INFO:Elastic Net Imported successfully
2025-05-12 22:22:52,594:INFO:Starting cross validation
2025-05-12 22:22:52,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:52,769:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:52,769:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:52,775:INFO:Calculating mean and std
2025-05-12 22:22:52,776:INFO:Creating metrics dataframe
2025-05-12 22:22:52,777:INFO:Uploading results into container
2025-05-12 22:22:52,777:INFO:Uploading model into container now
2025-05-12 22:22:52,777:INFO:_master_model_container: 4
2025-05-12 22:22:52,777:INFO:_display_container: 2
2025-05-12 22:22:52,779:INFO:ElasticNet(random_state=123)
2025-05-12 22:22:52,779:INFO:create_model() successfully completed......................................
2025-05-12 22:22:52,854:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:52,856:INFO:Creating metrics dataframe
2025-05-12 22:22:52,861:INFO:Initializing Least Angle Regression
2025-05-12 22:22:52,861:INFO:Total runtime is 0.019452619552612307 minutes
2025-05-12 22:22:52,864:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:52,866:INFO:Initializing create_model()
2025-05-12 22:22:52,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:52,866:INFO:Checking exceptions
2025-05-12 22:22:52,866:INFO:Importing libraries
2025-05-12 22:22:52,866:INFO:Copying training dataset
2025-05-12 22:22:52,868:INFO:Defining folds
2025-05-12 22:22:52,868:INFO:Declaring metric variables
2025-05-12 22:22:52,871:INFO:Importing untrained model
2025-05-12 22:22:52,874:INFO:Least Angle Regression Imported successfully
2025-05-12 22:22:52,879:INFO:Starting cross validation
2025-05-12 22:22:52,880:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:53,051:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:53,053:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:53,055:INFO:Calculating mean and std
2025-05-12 22:22:53,056:INFO:Creating metrics dataframe
2025-05-12 22:22:53,057:INFO:Uploading results into container
2025-05-12 22:22:53,057:INFO:Uploading model into container now
2025-05-12 22:22:53,057:INFO:_master_model_container: 5
2025-05-12 22:22:53,057:INFO:_display_container: 2
2025-05-12 22:22:53,059:INFO:Lars(random_state=123)
2025-05-12 22:22:53,059:INFO:create_model() successfully completed......................................
2025-05-12 22:22:53,137:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:53,137:INFO:Creating metrics dataframe
2025-05-12 22:22:53,147:INFO:Initializing Lasso Least Angle Regression
2025-05-12 22:22:53,147:INFO:Total runtime is 0.02421023448308309 minutes
2025-05-12 22:22:53,168:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:53,168:INFO:Initializing create_model()
2025-05-12 22:22:53,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:53,168:INFO:Checking exceptions
2025-05-12 22:22:53,169:INFO:Importing libraries
2025-05-12 22:22:53,169:INFO:Copying training dataset
2025-05-12 22:22:53,179:INFO:Defining folds
2025-05-12 22:22:53,179:INFO:Declaring metric variables
2025-05-12 22:22:53,184:INFO:Importing untrained model
2025-05-12 22:22:53,190:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:22:53,213:INFO:Starting cross validation
2025-05-12 22:22:53,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:53,467:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:53,467:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:53,473:INFO:Calculating mean and std
2025-05-12 22:22:53,474:INFO:Creating metrics dataframe
2025-05-12 22:22:53,476:INFO:Uploading results into container
2025-05-12 22:22:53,477:INFO:Uploading model into container now
2025-05-12 22:22:53,478:INFO:_master_model_container: 6
2025-05-12 22:22:53,478:INFO:_display_container: 2
2025-05-12 22:22:53,479:INFO:LassoLars(random_state=123)
2025-05-12 22:22:53,479:INFO:create_model() successfully completed......................................
2025-05-12 22:22:53,574:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:53,574:INFO:Creating metrics dataframe
2025-05-12 22:22:53,582:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 22:22:53,582:INFO:Total runtime is 0.031459403038024907 minutes
2025-05-12 22:22:53,588:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:53,588:INFO:Initializing create_model()
2025-05-12 22:22:53,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:53,589:INFO:Checking exceptions
2025-05-12 22:22:53,589:INFO:Importing libraries
2025-05-12 22:22:53,589:INFO:Copying training dataset
2025-05-12 22:22:53,593:INFO:Defining folds
2025-05-12 22:22:53,593:INFO:Declaring metric variables
2025-05-12 22:22:53,596:INFO:Importing untrained model
2025-05-12 22:22:53,601:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 22:22:53,611:INFO:Starting cross validation
2025-05-12 22:22:53,613:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:53,950:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:53,950:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:53,955:INFO:Calculating mean and std
2025-05-12 22:22:53,956:INFO:Creating metrics dataframe
2025-05-12 22:22:53,959:INFO:Uploading results into container
2025-05-12 22:22:53,960:INFO:Uploading model into container now
2025-05-12 22:22:53,961:INFO:_master_model_container: 7
2025-05-12 22:22:53,961:INFO:_display_container: 2
2025-05-12 22:22:53,961:INFO:OrthogonalMatchingPursuit()
2025-05-12 22:22:53,961:INFO:create_model() successfully completed......................................
2025-05-12 22:22:54,061:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:54,061:INFO:Creating metrics dataframe
2025-05-12 22:22:54,072:INFO:Initializing Bayesian Ridge
2025-05-12 22:22:54,073:INFO:Total runtime is 0.0396315097808838 minutes
2025-05-12 22:22:54,076:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:54,077:INFO:Initializing create_model()
2025-05-12 22:22:54,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:54,077:INFO:Checking exceptions
2025-05-12 22:22:54,077:INFO:Importing libraries
2025-05-12 22:22:54,077:INFO:Copying training dataset
2025-05-12 22:22:54,082:INFO:Defining folds
2025-05-12 22:22:54,083:INFO:Declaring metric variables
2025-05-12 22:22:54,088:INFO:Importing untrained model
2025-05-12 22:22:54,092:INFO:Bayesian Ridge Imported successfully
2025-05-12 22:22:54,099:INFO:Starting cross validation
2025-05-12 22:22:54,102:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:54,333:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:54,333:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:54,339:INFO:Calculating mean and std
2025-05-12 22:22:54,340:INFO:Creating metrics dataframe
2025-05-12 22:22:54,343:INFO:Uploading results into container
2025-05-12 22:22:54,343:INFO:Uploading model into container now
2025-05-12 22:22:54,344:INFO:_master_model_container: 8
2025-05-12 22:22:54,344:INFO:_display_container: 2
2025-05-12 22:22:54,344:INFO:BayesianRidge()
2025-05-12 22:22:54,344:INFO:create_model() successfully completed......................................
2025-05-12 22:22:54,436:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:54,436:INFO:Creating metrics dataframe
2025-05-12 22:22:54,444:INFO:Initializing Passive Aggressive Regressor
2025-05-12 22:22:54,446:INFO:Total runtime is 0.04586352109909059 minutes
2025-05-12 22:22:54,449:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:54,449:INFO:Initializing create_model()
2025-05-12 22:22:54,450:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:54,450:INFO:Checking exceptions
2025-05-12 22:22:54,450:INFO:Importing libraries
2025-05-12 22:22:54,450:INFO:Copying training dataset
2025-05-12 22:22:54,457:INFO:Defining folds
2025-05-12 22:22:54,457:INFO:Declaring metric variables
2025-05-12 22:22:54,464:INFO:Importing untrained model
2025-05-12 22:22:54,469:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 22:22:54,478:INFO:Starting cross validation
2025-05-12 22:22:54,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:54,713:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:54,713:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:54,719:INFO:Calculating mean and std
2025-05-12 22:22:54,721:INFO:Creating metrics dataframe
2025-05-12 22:22:54,723:INFO:Uploading results into container
2025-05-12 22:22:54,724:INFO:Uploading model into container now
2025-05-12 22:22:54,724:INFO:_master_model_container: 9
2025-05-12 22:22:54,724:INFO:_display_container: 2
2025-05-12 22:22:54,724:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-12 22:22:54,724:INFO:create_model() successfully completed......................................
2025-05-12 22:22:54,817:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:54,819:INFO:Creating metrics dataframe
2025-05-12 22:22:54,827:INFO:Initializing Huber Regressor
2025-05-12 22:22:54,827:INFO:Total runtime is 0.052217296759287525 minutes
2025-05-12 22:22:54,831:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:54,832:INFO:Initializing create_model()
2025-05-12 22:22:54,832:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:54,832:INFO:Checking exceptions
2025-05-12 22:22:54,832:INFO:Importing libraries
2025-05-12 22:22:54,832:INFO:Copying training dataset
2025-05-12 22:22:54,839:INFO:Defining folds
2025-05-12 22:22:54,839:INFO:Declaring metric variables
2025-05-12 22:22:54,843:INFO:Importing untrained model
2025-05-12 22:22:54,849:INFO:Huber Regressor Imported successfully
2025-05-12 22:22:54,857:INFO:Starting cross validation
2025-05-12 22:22:54,859:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:55,169:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:55,169:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:55,179:INFO:Calculating mean and std
2025-05-12 22:22:55,180:INFO:Creating metrics dataframe
2025-05-12 22:22:55,182:INFO:Uploading results into container
2025-05-12 22:22:55,183:INFO:Uploading model into container now
2025-05-12 22:22:55,183:INFO:_master_model_container: 10
2025-05-12 22:22:55,183:INFO:_display_container: 2
2025-05-12 22:22:55,184:INFO:HuberRegressor()
2025-05-12 22:22:55,184:INFO:create_model() successfully completed......................................
2025-05-12 22:22:55,273:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:55,274:INFO:Creating metrics dataframe
2025-05-12 22:22:55,283:INFO:Initializing K Neighbors Regressor
2025-05-12 22:22:55,283:INFO:Total runtime is 0.05981308221817017 minutes
2025-05-12 22:22:55,287:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:55,287:INFO:Initializing create_model()
2025-05-12 22:22:55,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:55,287:INFO:Checking exceptions
2025-05-12 22:22:55,287:INFO:Importing libraries
2025-05-12 22:22:55,287:INFO:Copying training dataset
2025-05-12 22:22:55,292:INFO:Defining folds
2025-05-12 22:22:55,292:INFO:Declaring metric variables
2025-05-12 22:22:55,296:INFO:Importing untrained model
2025-05-12 22:22:55,300:INFO:K Neighbors Regressor Imported successfully
2025-05-12 22:22:55,307:INFO:Starting cross validation
2025-05-12 22:22:55,311:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:55,590:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:55,590:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:55,597:INFO:Calculating mean and std
2025-05-12 22:22:55,599:INFO:Creating metrics dataframe
2025-05-12 22:22:55,601:INFO:Uploading results into container
2025-05-12 22:22:55,602:INFO:Uploading model into container now
2025-05-12 22:22:55,603:INFO:_master_model_container: 11
2025-05-12 22:22:55,603:INFO:_display_container: 2
2025-05-12 22:22:55,603:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-12 22:22:55,604:INFO:create_model() successfully completed......................................
2025-05-12 22:22:55,701:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:55,701:INFO:Creating metrics dataframe
2025-05-12 22:22:55,712:INFO:Initializing Decision Tree Regressor
2025-05-12 22:22:55,713:INFO:Total runtime is 0.06696569124857585 minutes
2025-05-12 22:22:55,717:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:55,718:INFO:Initializing create_model()
2025-05-12 22:22:55,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:55,718:INFO:Checking exceptions
2025-05-12 22:22:55,718:INFO:Importing libraries
2025-05-12 22:22:55,718:INFO:Copying training dataset
2025-05-12 22:22:55,723:INFO:Defining folds
2025-05-12 22:22:55,723:INFO:Declaring metric variables
2025-05-12 22:22:55,728:INFO:Importing untrained model
2025-05-12 22:22:55,734:INFO:Decision Tree Regressor Imported successfully
2025-05-12 22:22:55,742:INFO:Starting cross validation
2025-05-12 22:22:55,743:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:55,979:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:55,979:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:55,984:INFO:Calculating mean and std
2025-05-12 22:22:55,985:INFO:Creating metrics dataframe
2025-05-12 22:22:55,987:INFO:Uploading results into container
2025-05-12 22:22:55,989:INFO:Uploading model into container now
2025-05-12 22:22:55,989:INFO:_master_model_container: 12
2025-05-12 22:22:55,990:INFO:_display_container: 2
2025-05-12 22:22:55,990:INFO:DecisionTreeRegressor(random_state=123)
2025-05-12 22:22:55,990:INFO:create_model() successfully completed......................................
2025-05-12 22:22:56,077:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:56,079:INFO:Creating metrics dataframe
2025-05-12 22:22:56,088:INFO:Initializing Random Forest Regressor
2025-05-12 22:22:56,088:INFO:Total runtime is 0.0732298493385315 minutes
2025-05-12 22:22:56,091:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:56,091:INFO:Initializing create_model()
2025-05-12 22:22:56,091:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:56,091:INFO:Checking exceptions
2025-05-12 22:22:56,091:INFO:Importing libraries
2025-05-12 22:22:56,091:INFO:Copying training dataset
2025-05-12 22:22:56,097:INFO:Defining folds
2025-05-12 22:22:56,097:INFO:Declaring metric variables
2025-05-12 22:22:56,100:INFO:Importing untrained model
2025-05-12 22:22:56,105:INFO:Random Forest Regressor Imported successfully
2025-05-12 22:22:56,112:INFO:Starting cross validation
2025-05-12 22:22:56,114:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:56,950:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:56,950:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:56,960:INFO:Calculating mean and std
2025-05-12 22:22:56,961:INFO:Creating metrics dataframe
2025-05-12 22:22:56,963:INFO:Uploading results into container
2025-05-12 22:22:56,964:INFO:Uploading model into container now
2025-05-12 22:22:56,965:INFO:_master_model_container: 13
2025-05-12 22:22:56,965:INFO:_display_container: 2
2025-05-12 22:22:56,965:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:22:56,966:INFO:create_model() successfully completed......................................
2025-05-12 22:22:57,051:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:57,051:INFO:Creating metrics dataframe
2025-05-12 22:22:57,059:INFO:Initializing Extra Trees Regressor
2025-05-12 22:22:57,059:INFO:Total runtime is 0.08942150672276815 minutes
2025-05-12 22:22:57,063:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:57,063:INFO:Initializing create_model()
2025-05-12 22:22:57,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:57,064:INFO:Checking exceptions
2025-05-12 22:22:57,064:INFO:Importing libraries
2025-05-12 22:22:57,064:INFO:Copying training dataset
2025-05-12 22:22:57,068:INFO:Defining folds
2025-05-12 22:22:57,069:INFO:Declaring metric variables
2025-05-12 22:22:57,071:INFO:Importing untrained model
2025-05-12 22:22:57,076:INFO:Extra Trees Regressor Imported successfully
2025-05-12 22:22:57,082:INFO:Starting cross validation
2025-05-12 22:22:57,084:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:57,786:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:57,786:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:57,799:INFO:Calculating mean and std
2025-05-12 22:22:57,801:INFO:Creating metrics dataframe
2025-05-12 22:22:57,803:INFO:Uploading results into container
2025-05-12 22:22:57,804:INFO:Uploading model into container now
2025-05-12 22:22:57,804:INFO:_master_model_container: 14
2025-05-12 22:22:57,804:INFO:_display_container: 2
2025-05-12 22:22:57,806:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:22:57,806:INFO:create_model() successfully completed......................................
2025-05-12 22:22:57,893:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:57,893:INFO:Creating metrics dataframe
2025-05-12 22:22:57,903:INFO:Initializing AdaBoost Regressor
2025-05-12 22:22:57,903:INFO:Total runtime is 0.10348397095998128 minutes
2025-05-12 22:22:57,907:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:57,907:INFO:Initializing create_model()
2025-05-12 22:22:57,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:57,907:INFO:Checking exceptions
2025-05-12 22:22:57,907:INFO:Importing libraries
2025-05-12 22:22:57,907:INFO:Copying training dataset
2025-05-12 22:22:57,910:INFO:Defining folds
2025-05-12 22:22:57,910:INFO:Declaring metric variables
2025-05-12 22:22:57,916:INFO:Importing untrained model
2025-05-12 22:22:57,919:INFO:AdaBoost Regressor Imported successfully
2025-05-12 22:22:57,926:INFO:Starting cross validation
2025-05-12 22:22:57,928:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:58,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:58,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:58,629:INFO:Calculating mean and std
2025-05-12 22:22:58,631:INFO:Creating metrics dataframe
2025-05-12 22:22:58,633:INFO:Uploading results into container
2025-05-12 22:22:58,634:INFO:Uploading model into container now
2025-05-12 22:22:58,634:INFO:_master_model_container: 15
2025-05-12 22:22:58,636:INFO:_display_container: 2
2025-05-12 22:22:58,636:INFO:AdaBoostRegressor(random_state=123)
2025-05-12 22:22:58,636:INFO:create_model() successfully completed......................................
2025-05-12 22:22:58,731:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:58,731:INFO:Creating metrics dataframe
2025-05-12 22:22:58,742:INFO:Initializing Gradient Boosting Regressor
2025-05-12 22:22:58,742:INFO:Total runtime is 0.11746471722920736 minutes
2025-05-12 22:22:58,745:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:58,746:INFO:Initializing create_model()
2025-05-12 22:22:58,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:58,747:INFO:Checking exceptions
2025-05-12 22:22:58,747:INFO:Importing libraries
2025-05-12 22:22:58,747:INFO:Copying training dataset
2025-05-12 22:22:58,753:INFO:Defining folds
2025-05-12 22:22:58,753:INFO:Declaring metric variables
2025-05-12 22:22:58,757:INFO:Importing untrained model
2025-05-12 22:22:58,761:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 22:22:58,770:INFO:Starting cross validation
2025-05-12 22:22:58,771:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:59,227:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:59,227:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:59,231:INFO:Calculating mean and std
2025-05-12 22:22:59,233:INFO:Creating metrics dataframe
2025-05-12 22:22:59,236:INFO:Uploading results into container
2025-05-12 22:22:59,236:INFO:Uploading model into container now
2025-05-12 22:22:59,237:INFO:_master_model_container: 16
2025-05-12 22:22:59,237:INFO:_display_container: 2
2025-05-12 22:22:59,238:INFO:GradientBoostingRegressor(random_state=123)
2025-05-12 22:22:59,238:INFO:create_model() successfully completed......................................
2025-05-12 22:22:59,333:INFO:SubProcess create_model() end ==================================
2025-05-12 22:22:59,333:INFO:Creating metrics dataframe
2025-05-12 22:22:59,344:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:22:59,344:INFO:Total runtime is 0.12749578952789306 minutes
2025-05-12 22:22:59,347:INFO:SubProcess create_model() called ==================================
2025-05-12 22:22:59,347:INFO:Initializing create_model()
2025-05-12 22:22:59,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:22:59,349:INFO:Checking exceptions
2025-05-12 22:22:59,349:INFO:Importing libraries
2025-05-12 22:22:59,349:INFO:Copying training dataset
2025-05-12 22:22:59,354:INFO:Defining folds
2025-05-12 22:22:59,354:INFO:Declaring metric variables
2025-05-12 22:22:59,358:INFO:Importing untrained model
2025-05-12 22:22:59,363:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:22:59,372:INFO:Starting cross validation
2025-05-12 22:22:59,373:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:22:59,959:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:22:59,959:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:22:59,965:INFO:Calculating mean and std
2025-05-12 22:22:59,967:INFO:Creating metrics dataframe
2025-05-12 22:22:59,970:INFO:Uploading results into container
2025-05-12 22:22:59,971:INFO:Uploading model into container now
2025-05-12 22:22:59,971:INFO:_master_model_container: 17
2025-05-12 22:22:59,973:INFO:_display_container: 2
2025-05-12 22:22:59,974:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-12 22:22:59,974:INFO:create_model() successfully completed......................................
2025-05-12 22:23:00,089:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:00,089:INFO:Creating metrics dataframe
2025-05-12 22:23:00,101:INFO:Initializing Dummy Regressor
2025-05-12 22:23:00,101:INFO:Total runtime is 0.14011609156926472 minutes
2025-05-12 22:23:00,105:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:00,106:INFO:Initializing create_model()
2025-05-12 22:23:00,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B066610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:00,106:INFO:Checking exceptions
2025-05-12 22:23:00,106:INFO:Importing libraries
2025-05-12 22:23:00,106:INFO:Copying training dataset
2025-05-12 22:23:00,110:INFO:Defining folds
2025-05-12 22:23:00,111:INFO:Declaring metric variables
2025-05-12 22:23:00,115:INFO:Importing untrained model
2025-05-12 22:23:00,119:INFO:Dummy Regressor Imported successfully
2025-05-12 22:23:00,127:INFO:Starting cross validation
2025-05-12 22:23:00,130:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:00,348:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:23:00,348:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:23:00,349:INFO:Calculating mean and std
2025-05-12 22:23:00,350:INFO:Creating metrics dataframe
2025-05-12 22:23:00,354:INFO:Uploading results into container
2025-05-12 22:23:00,355:INFO:Uploading model into container now
2025-05-12 22:23:00,355:INFO:_master_model_container: 18
2025-05-12 22:23:00,355:INFO:_display_container: 2
2025-05-12 22:23:00,355:INFO:DummyRegressor()
2025-05-12 22:23:00,355:INFO:create_model() successfully completed......................................
2025-05-12 22:23:00,444:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:00,444:INFO:Creating metrics dataframe
2025-05-12 22:23:00,453:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:23:00,462:INFO:Initializing create_model()
2025-05-12 22:23:00,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:00,463:INFO:Checking exceptions
2025-05-12 22:23:00,464:INFO:Importing libraries
2025-05-12 22:23:00,464:INFO:Copying training dataset
2025-05-12 22:23:00,467:INFO:Defining folds
2025-05-12 22:23:00,468:INFO:Declaring metric variables
2025-05-12 22:23:00,468:INFO:Importing untrained model
2025-05-12 22:23:00,468:INFO:Declaring custom model
2025-05-12 22:23:00,468:INFO:Lasso Regression Imported successfully
2025-05-12 22:23:00,469:INFO:Cross validation set to False
2025-05-12 22:23:00,469:INFO:Fitting Model
2025-05-12 22:23:00,505:INFO:Lasso(random_state=123)
2025-05-12 22:23:00,505:INFO:create_model() successfully completed......................................
2025-05-12 22:23:00,608:INFO:_master_model_container: 18
2025-05-12 22:23:00,609:INFO:_display_container: 2
2025-05-12 22:23:00,609:INFO:Lasso(random_state=123)
2025-05-12 22:23:00,609:INFO:compare_models() successfully completed......................................
2025-05-12 22:23:00,631:INFO:Initializing create_model()
2025-05-12 22:23:00,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=dummy, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:00,631:INFO:Checking exceptions
2025-05-12 22:23:00,671:INFO:Importing libraries
2025-05-12 22:23:00,671:INFO:Copying training dataset
2025-05-12 22:23:00,679:INFO:Defining folds
2025-05-12 22:23:00,679:INFO:Declaring metric variables
2025-05-12 22:23:00,687:INFO:Importing untrained model
2025-05-12 22:23:00,694:INFO:Dummy Regressor Imported successfully
2025-05-12 22:23:00,706:INFO:Starting cross validation
2025-05-12 22:23:00,709:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:00,969:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:23:00,970:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:23:00,974:INFO:Calculating mean and std
2025-05-12 22:23:00,974:INFO:Creating metrics dataframe
2025-05-12 22:23:00,981:INFO:Finalizing model
2025-05-12 22:23:01,034:INFO:Uploading results into container
2025-05-12 22:23:01,036:INFO:Uploading model into container now
2025-05-12 22:23:01,047:INFO:_master_model_container: 19
2025-05-12 22:23:01,047:INFO:_display_container: 3
2025-05-12 22:23:01,048:INFO:DummyRegressor()
2025-05-12 22:23:01,048:INFO:create_model() successfully completed......................................
2025-05-12 22:23:01,146:INFO:Initializing tune_model()
2025-05-12 22:23:01,147:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA78EDB1D0>, estimator=DummyRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:23:01,147:INFO:Checking exceptions
2025-05-12 22:23:01,165:INFO:Copying training dataset
2025-05-12 22:23:01,168:INFO:Checking base model
2025-05-12 22:23:01,168:INFO:Base model : Dummy Regressor
2025-05-12 22:23:01,174:INFO:Declaring metric variables
2025-05-12 22:23:01,178:INFO:Defining Hyperparameters
2025-05-12 22:23:01,179:INFO:10 is bigger than total combinations 1, setting search algorithm to grid
2025-05-12 22:23:12,820:INFO:PyCaret ClassificationExperiment
2025-05-12 22:23:12,820:INFO:Logging name: clf-default-name
2025-05-12 22:23:12,820:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-12 22:23:12,820:INFO:version 3.3.2
2025-05-12 22:23:12,820:INFO:Initializing setup()
2025-05-12 22:23:12,820:INFO:self.USI: b78c
2025-05-12 22:23:12,820:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'is_multiclass', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', 'fix_imbalance', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:23:12,820:INFO:Checking environment
2025-05-12 22:23:12,820:INFO:python_version: 3.11.8
2025-05-12 22:23:12,820:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:23:12,820:INFO:machine: AMD64
2025-05-12 22:23:12,820:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:23:12,825:INFO:Memory: svmem(total=16907886592, available=2995605504, percent=82.3, used=13912281088, free=2995605504)
2025-05-12 22:23:12,826:INFO:Physical Core: 4
2025-05-12 22:23:12,826:INFO:Logical Core: 8
2025-05-12 22:23:12,826:INFO:Checking libraries
2025-05-12 22:23:12,826:INFO:System:
2025-05-12 22:23:12,826:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:23:12,826:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:23:12,826:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:23:12,826:INFO:PyCaret required dependencies:
2025-05-12 22:23:12,826:INFO:                 pip: 24.0
2025-05-12 22:23:12,826:INFO:          setuptools: 65.5.0
2025-05-12 22:23:12,826:INFO:             pycaret: 3.3.2
2025-05-12 22:23:12,826:INFO:             IPython: 9.2.0
2025-05-12 22:23:12,826:INFO:          ipywidgets: 8.1.7
2025-05-12 22:23:12,826:INFO:                tqdm: 4.67.1
2025-05-12 22:23:12,826:INFO:               numpy: 1.26.4
2025-05-12 22:23:12,826:INFO:              pandas: 2.1.4
2025-05-12 22:23:12,826:INFO:              jinja2: 3.1.6
2025-05-12 22:23:12,826:INFO:               scipy: 1.11.4
2025-05-12 22:23:12,826:INFO:              joblib: 1.3.2
2025-05-12 22:23:12,826:INFO:             sklearn: 1.4.2
2025-05-12 22:23:12,826:INFO:                pyod: 2.0.5
2025-05-12 22:23:12,826:INFO:            imblearn: 0.13.0
2025-05-12 22:23:12,826:INFO:   category_encoders: 2.7.0
2025-05-12 22:23:12,826:INFO:            lightgbm: 4.6.0
2025-05-12 22:23:12,826:INFO:               numba: 0.61.2
2025-05-12 22:23:12,826:INFO:            requests: 2.32.3
2025-05-12 22:23:12,826:INFO:          matplotlib: 3.7.5
2025-05-12 22:23:12,826:INFO:          scikitplot: 0.3.7
2025-05-12 22:23:12,826:INFO:         yellowbrick: 1.5
2025-05-12 22:23:12,827:INFO:              plotly: 5.24.1
2025-05-12 22:23:12,827:INFO:    plotly-resampler: Not installed
2025-05-12 22:23:12,827:INFO:             kaleido: 0.2.1
2025-05-12 22:23:12,827:INFO:           schemdraw: 0.15
2025-05-12 22:23:12,827:INFO:         statsmodels: 0.14.4
2025-05-12 22:23:12,827:INFO:              sktime: 0.26.0
2025-05-12 22:23:12,827:INFO:               tbats: 1.1.3
2025-05-12 22:23:12,827:INFO:            pmdarima: 2.0.4
2025-05-12 22:23:12,827:INFO:              psutil: 7.0.0
2025-05-12 22:23:12,827:INFO:          markupsafe: 3.0.2
2025-05-12 22:23:12,827:INFO:             pickle5: Not installed
2025-05-12 22:23:12,827:INFO:         cloudpickle: 3.1.1
2025-05-12 22:23:12,827:INFO:         deprecation: 2.1.0
2025-05-12 22:23:12,827:INFO:              xxhash: 3.5.0
2025-05-12 22:23:12,827:INFO:           wurlitzer: Not installed
2025-05-12 22:23:12,827:INFO:PyCaret optional dependencies:
2025-05-12 22:23:12,827:INFO:                shap: Not installed
2025-05-12 22:23:12,827:INFO:           interpret: Not installed
2025-05-12 22:23:12,827:INFO:                umap: Not installed
2025-05-12 22:23:12,827:INFO:     ydata_profiling: Not installed
2025-05-12 22:23:12,827:INFO:  explainerdashboard: Not installed
2025-05-12 22:23:12,827:INFO:             autoviz: Not installed
2025-05-12 22:23:12,827:INFO:           fairlearn: Not installed
2025-05-12 22:23:12,827:INFO:          deepchecks: Not installed
2025-05-12 22:23:12,827:INFO:             xgboost: Not installed
2025-05-12 22:23:12,827:INFO:            catboost: Not installed
2025-05-12 22:23:12,827:INFO:              kmodes: Not installed
2025-05-12 22:23:12,827:INFO:             mlxtend: Not installed
2025-05-12 22:23:12,827:INFO:       statsforecast: Not installed
2025-05-12 22:23:12,827:INFO:        tune_sklearn: Not installed
2025-05-12 22:23:12,827:INFO:                 ray: Not installed
2025-05-12 22:23:12,827:INFO:            hyperopt: Not installed
2025-05-12 22:23:12,827:INFO:              optuna: Not installed
2025-05-12 22:23:12,827:INFO:               skopt: Not installed
2025-05-12 22:23:12,827:INFO:              mlflow: Not installed
2025-05-12 22:23:12,827:INFO:              gradio: Not installed
2025-05-12 22:23:12,827:INFO:             fastapi: Not installed
2025-05-12 22:23:12,827:INFO:             uvicorn: Not installed
2025-05-12 22:23:12,827:INFO:              m2cgen: Not installed
2025-05-12 22:23:12,827:INFO:           evidently: Not installed
2025-05-12 22:23:12,828:INFO:               fugue: Not installed
2025-05-12 22:23:12,828:INFO:           streamlit: Not installed
2025-05-12 22:23:12,828:INFO:             prophet: Not installed
2025-05-12 22:23:12,828:INFO:None
2025-05-12 22:23:12,828:INFO:Set up data.
2025-05-12 22:23:12,832:INFO:Set up folding strategy.
2025-05-12 22:23:12,832:INFO:Set up train/test split.
2025-05-12 22:23:12,839:INFO:Set up index.
2025-05-12 22:23:12,839:INFO:Assigning column types.
2025-05-12 22:23:12,843:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:23:12,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:23:12,881:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:23:12,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:12,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:12,942:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:23:12,943:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:23:12,966:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:12,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:12,966:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:23:13,003:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:23:13,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,029:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,064:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:23:13,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,088:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-12 22:23:13,146:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,146:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,205:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,206:INFO:Preparing preprocessing pipeline...
2025-05-12 22:23:13,207:INFO:Set up simple imputation.
2025-05-12 22:23:13,208:INFO:Set up encoding of categorical features.
2025-05-12 22:23:13,208:INFO:Set up feature normalization.
2025-05-12 22:23:13,259:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:23:13,263:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:23:13,263:INFO:Creating final display dataframe.
2025-05-12 22:23:13,401:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              b78c
2025-05-12 22:23:13,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:23:13,581:INFO:setup() successfully completed in 0.76s...............
2025-05-12 22:23:13,596:INFO:Initializing compare_models()
2025-05-12 22:23:13,596:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-12 22:23:13,596:INFO:Checking exceptions
2025-05-12 22:23:13,601:INFO:Preparing display monitor
2025-05-12 22:23:13,620:INFO:Initializing Logistic Regression
2025-05-12 22:23:13,620:INFO:Total runtime is 0.0 minutes
2025-05-12 22:23:13,624:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:13,624:INFO:Initializing create_model()
2025-05-12 22:23:13,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:13,624:INFO:Checking exceptions
2025-05-12 22:23:13,624:INFO:Importing libraries
2025-05-12 22:23:13,624:INFO:Copying training dataset
2025-05-12 22:23:13,629:INFO:Defining folds
2025-05-12 22:23:13,629:INFO:Declaring metric variables
2025-05-12 22:23:13,632:INFO:Importing untrained model
2025-05-12 22:23:13,636:INFO:Logistic Regression Imported successfully
2025-05-12 22:23:13,642:INFO:Starting cross validation
2025-05-12 22:23:13,644:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:13,778:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:13,778:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:13,778:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:13,778:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:13,780:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:13,839:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:13,849:INFO:Calculating mean and std
2025-05-12 22:23:13,849:INFO:Creating metrics dataframe
2025-05-12 22:23:13,851:INFO:Uploading results into container
2025-05-12 22:23:13,851:INFO:Uploading model into container now
2025-05-12 22:23:13,851:INFO:_master_model_container: 1
2025-05-12 22:23:13,851:INFO:_display_container: 2
2025-05-12 22:23:13,852:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-12 22:23:13,852:INFO:create_model() successfully completed......................................
2025-05-12 22:23:13,949:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:13,949:INFO:Creating metrics dataframe
2025-05-12 22:23:13,954:INFO:Initializing K Neighbors Classifier
2025-05-12 22:23:13,954:INFO:Total runtime is 0.005555458863576253 minutes
2025-05-12 22:23:13,956:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:13,957:INFO:Initializing create_model()
2025-05-12 22:23:13,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:13,957:INFO:Checking exceptions
2025-05-12 22:23:13,957:INFO:Importing libraries
2025-05-12 22:23:13,957:INFO:Copying training dataset
2025-05-12 22:23:13,960:INFO:Defining folds
2025-05-12 22:23:13,960:INFO:Declaring metric variables
2025-05-12 22:23:13,963:INFO:Importing untrained model
2025-05-12 22:23:13,965:INFO:K Neighbors Classifier Imported successfully
2025-05-12 22:23:13,972:INFO:Starting cross validation
2025-05-12 22:23:13,974:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:14,118:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,120:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,124:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,137:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,139:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,221:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,232:INFO:Calculating mean and std
2025-05-12 22:23:14,232:INFO:Creating metrics dataframe
2025-05-12 22:23:14,235:INFO:Uploading results into container
2025-05-12 22:23:14,235:INFO:Uploading model into container now
2025-05-12 22:23:14,235:INFO:_master_model_container: 2
2025-05-12 22:23:14,235:INFO:_display_container: 2
2025-05-12 22:23:14,235:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-12 22:23:14,235:INFO:create_model() successfully completed......................................
2025-05-12 22:23:14,322:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:14,322:INFO:Creating metrics dataframe
2025-05-12 22:23:14,327:INFO:Initializing Naive Bayes
2025-05-12 22:23:14,327:INFO:Total runtime is 0.01177448829015096 minutes
2025-05-12 22:23:14,330:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:14,330:INFO:Initializing create_model()
2025-05-12 22:23:14,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:14,330:INFO:Checking exceptions
2025-05-12 22:23:14,330:INFO:Importing libraries
2025-05-12 22:23:14,330:INFO:Copying training dataset
2025-05-12 22:23:14,334:INFO:Defining folds
2025-05-12 22:23:14,335:INFO:Declaring metric variables
2025-05-12 22:23:14,338:INFO:Importing untrained model
2025-05-12 22:23:14,340:INFO:Naive Bayes Imported successfully
2025-05-12 22:23:14,345:INFO:Starting cross validation
2025-05-12 22:23:14,346:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:14,454:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,474:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,487:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,529:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,533:INFO:Calculating mean and std
2025-05-12 22:23:14,533:INFO:Creating metrics dataframe
2025-05-12 22:23:14,534:INFO:Uploading results into container
2025-05-12 22:23:14,534:INFO:Uploading model into container now
2025-05-12 22:23:14,534:INFO:_master_model_container: 3
2025-05-12 22:23:14,534:INFO:_display_container: 2
2025-05-12 22:23:14,534:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-12 22:23:14,536:INFO:create_model() successfully completed......................................
2025-05-12 22:23:14,620:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:14,620:INFO:Creating metrics dataframe
2025-05-12 22:23:14,625:INFO:Initializing Decision Tree Classifier
2025-05-12 22:23:14,625:INFO:Total runtime is 0.016750792662302654 minutes
2025-05-12 22:23:14,627:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:14,627:INFO:Initializing create_model()
2025-05-12 22:23:14,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:14,627:INFO:Checking exceptions
2025-05-12 22:23:14,627:INFO:Importing libraries
2025-05-12 22:23:14,627:INFO:Copying training dataset
2025-05-12 22:23:14,633:INFO:Defining folds
2025-05-12 22:23:14,633:INFO:Declaring metric variables
2025-05-12 22:23:14,635:INFO:Importing untrained model
2025-05-12 22:23:14,639:INFO:Decision Tree Classifier Imported successfully
2025-05-12 22:23:14,644:INFO:Starting cross validation
2025-05-12 22:23:14,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:14,753:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:14,821:INFO:Calculating mean and std
2025-05-12 22:23:14,822:INFO:Creating metrics dataframe
2025-05-12 22:23:14,823:INFO:Uploading results into container
2025-05-12 22:23:14,824:INFO:Uploading model into container now
2025-05-12 22:23:14,824:INFO:_master_model_container: 4
2025-05-12 22:23:14,824:INFO:_display_container: 2
2025-05-12 22:23:14,824:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-12 22:23:14,824:INFO:create_model() successfully completed......................................
2025-05-12 22:23:14,908:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:14,908:INFO:Creating metrics dataframe
2025-05-12 22:23:14,913:INFO:Initializing SVM - Linear Kernel
2025-05-12 22:23:14,913:INFO:Total runtime is 0.021540633837382 minutes
2025-05-12 22:23:14,917:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:14,917:INFO:Initializing create_model()
2025-05-12 22:23:14,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:14,917:INFO:Checking exceptions
2025-05-12 22:23:14,917:INFO:Importing libraries
2025-05-12 22:23:14,917:INFO:Copying training dataset
2025-05-12 22:23:14,920:INFO:Defining folds
2025-05-12 22:23:14,920:INFO:Declaring metric variables
2025-05-12 22:23:14,923:INFO:Importing untrained model
2025-05-12 22:23:14,925:INFO:SVM - Linear Kernel Imported successfully
2025-05-12 22:23:14,932:INFO:Starting cross validation
2025-05-12 22:23:14,934:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:15,043:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,051:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,110:INFO:Calculating mean and std
2025-05-12 22:23:15,110:INFO:Creating metrics dataframe
2025-05-12 22:23:15,112:INFO:Uploading results into container
2025-05-12 22:23:15,113:INFO:Uploading model into container now
2025-05-12 22:23:15,113:INFO:_master_model_container: 5
2025-05-12 22:23:15,113:INFO:_display_container: 2
2025-05-12 22:23:15,114:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-12 22:23:15,114:INFO:create_model() successfully completed......................................
2025-05-12 22:23:15,197:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:15,197:INFO:Creating metrics dataframe
2025-05-12 22:23:15,202:INFO:Initializing Ridge Classifier
2025-05-12 22:23:15,202:INFO:Total runtime is 0.026363412539164226 minutes
2025-05-12 22:23:15,205:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:15,205:INFO:Initializing create_model()
2025-05-12 22:23:15,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:15,205:INFO:Checking exceptions
2025-05-12 22:23:15,205:INFO:Importing libraries
2025-05-12 22:23:15,205:INFO:Copying training dataset
2025-05-12 22:23:15,207:INFO:Defining folds
2025-05-12 22:23:15,207:INFO:Declaring metric variables
2025-05-12 22:23:15,211:INFO:Importing untrained model
2025-05-12 22:23:15,214:INFO:Ridge Classifier Imported successfully
2025-05-12 22:23:15,221:INFO:Starting cross validation
2025-05-12 22:23:15,223:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:15,323:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,327:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,328:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,328:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,333:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,345:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,390:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,391:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:15,404:INFO:Calculating mean and std
2025-05-12 22:23:15,404:INFO:Creating metrics dataframe
2025-05-12 22:23:15,407:INFO:Uploading results into container
2025-05-12 22:23:15,407:INFO:Uploading model into container now
2025-05-12 22:23:15,407:INFO:_master_model_container: 6
2025-05-12 22:23:15,407:INFO:_display_container: 2
2025-05-12 22:23:15,408:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-12 22:23:15,408:INFO:create_model() successfully completed......................................
2025-05-12 22:23:15,493:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:15,493:INFO:Creating metrics dataframe
2025-05-12 22:23:15,501:INFO:Initializing Random Forest Classifier
2025-05-12 22:23:15,501:INFO:Total runtime is 0.03133915265401205 minutes
2025-05-12 22:23:15,503:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:15,504:INFO:Initializing create_model()
2025-05-12 22:23:15,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:15,504:INFO:Checking exceptions
2025-05-12 22:23:15,504:INFO:Importing libraries
2025-05-12 22:23:15,504:INFO:Copying training dataset
2025-05-12 22:23:15,507:INFO:Defining folds
2025-05-12 22:23:15,507:INFO:Declaring metric variables
2025-05-12 22:23:15,509:INFO:Importing untrained model
2025-05-12 22:23:15,512:INFO:Random Forest Classifier Imported successfully
2025-05-12 22:23:15,520:INFO:Starting cross validation
2025-05-12 22:23:15,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:15,999:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,027:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,034:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,034:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,058:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,087:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,144:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,385:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,408:INFO:Calculating mean and std
2025-05-12 22:23:16,408:INFO:Creating metrics dataframe
2025-05-12 22:23:16,410:INFO:Uploading results into container
2025-05-12 22:23:16,411:INFO:Uploading model into container now
2025-05-12 22:23:16,411:INFO:_master_model_container: 7
2025-05-12 22:23:16,411:INFO:_display_container: 2
2025-05-12 22:23:16,413:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-12 22:23:16,413:INFO:create_model() successfully completed......................................
2025-05-12 22:23:16,515:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:16,515:INFO:Creating metrics dataframe
2025-05-12 22:23:16,526:INFO:Initializing Quadratic Discriminant Analysis
2025-05-12 22:23:16,526:INFO:Total runtime is 0.048425912857055664 minutes
2025-05-12 22:23:16,531:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:16,531:INFO:Initializing create_model()
2025-05-12 22:23:16,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:16,532:INFO:Checking exceptions
2025-05-12 22:23:16,532:INFO:Importing libraries
2025-05-12 22:23:16,532:INFO:Copying training dataset
2025-05-12 22:23:16,536:INFO:Defining folds
2025-05-12 22:23:16,536:INFO:Declaring metric variables
2025-05-12 22:23:16,541:INFO:Importing untrained model
2025-05-12 22:23:16,547:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-12 22:23:16,559:INFO:Starting cross validation
2025-05-12 22:23:16,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:16,806:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:16,806:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:16,806:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:16,807:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:16,818:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:16,822:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:16,863:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:16,917:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:16,928:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:17,001:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:17,013:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:23:17,078:INFO:Calculating mean and std
2025-05-12 22:23:17,079:INFO:Creating metrics dataframe
2025-05-12 22:23:17,083:INFO:Uploading results into container
2025-05-12 22:23:17,085:INFO:Uploading model into container now
2025-05-12 22:23:17,085:INFO:_master_model_container: 8
2025-05-12 22:23:17,085:INFO:_display_container: 2
2025-05-12 22:23:17,086:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-12 22:23:17,086:INFO:create_model() successfully completed......................................
2025-05-12 22:23:17,203:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:17,203:INFO:Creating metrics dataframe
2025-05-12 22:23:17,212:INFO:Initializing Ada Boost Classifier
2025-05-12 22:23:17,212:INFO:Total runtime is 0.059854185581207274 minutes
2025-05-12 22:23:17,219:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:17,219:INFO:Initializing create_model()
2025-05-12 22:23:17,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:17,219:INFO:Checking exceptions
2025-05-12 22:23:17,220:INFO:Importing libraries
2025-05-12 22:23:17,220:INFO:Copying training dataset
2025-05-12 22:23:17,227:INFO:Defining folds
2025-05-12 22:23:17,227:INFO:Declaring metric variables
2025-05-12 22:23:17,234:INFO:Importing untrained model
2025-05-12 22:23:17,238:INFO:Ada Boost Classifier Imported successfully
2025-05-12 22:23:17,247:INFO:Starting cross validation
2025-05-12 22:23:17,249:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:17,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,397:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,397:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,399:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,410:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,436:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,715:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:17,859:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:17,875:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:17,889:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:23:18,057:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:18,081:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:18,095:INFO:Calculating mean and std
2025-05-12 22:23:18,098:INFO:Creating metrics dataframe
2025-05-12 22:23:18,100:INFO:Uploading results into container
2025-05-12 22:23:18,100:INFO:Uploading model into container now
2025-05-12 22:23:18,101:INFO:_master_model_container: 9
2025-05-12 22:23:18,101:INFO:_display_container: 2
2025-05-12 22:23:18,103:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-12 22:23:18,103:INFO:create_model() successfully completed......................................
2025-05-12 22:23:18,207:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:18,208:INFO:Creating metrics dataframe
2025-05-12 22:23:18,217:INFO:Initializing Gradient Boosting Classifier
2025-05-12 22:23:18,217:INFO:Total runtime is 0.07660452127456666 minutes
2025-05-12 22:23:18,220:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:18,221:INFO:Initializing create_model()
2025-05-12 22:23:18,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:18,221:INFO:Checking exceptions
2025-05-12 22:23:18,221:INFO:Importing libraries
2025-05-12 22:23:18,221:INFO:Copying training dataset
2025-05-12 22:23:18,226:INFO:Defining folds
2025-05-12 22:23:18,226:INFO:Declaring metric variables
2025-05-12 22:23:18,231:INFO:Importing untrained model
2025-05-12 22:23:18,237:INFO:Gradient Boosting Classifier Imported successfully
2025-05-12 22:23:18,247:INFO:Starting cross validation
2025-05-12 22:23:18,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:18,649:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:18,894:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:18,907:INFO:Calculating mean and std
2025-05-12 22:23:18,908:INFO:Creating metrics dataframe
2025-05-12 22:23:18,910:INFO:Uploading results into container
2025-05-12 22:23:18,911:INFO:Uploading model into container now
2025-05-12 22:23:18,911:INFO:_master_model_container: 10
2025-05-12 22:23:18,911:INFO:_display_container: 2
2025-05-12 22:23:18,913:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-12 22:23:18,913:INFO:create_model() successfully completed......................................
2025-05-12 22:23:19,009:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:19,010:INFO:Creating metrics dataframe
2025-05-12 22:23:19,022:INFO:Initializing Linear Discriminant Analysis
2025-05-12 22:23:19,022:INFO:Total runtime is 0.09002350568771363 minutes
2025-05-12 22:23:19,027:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:19,027:INFO:Initializing create_model()
2025-05-12 22:23:19,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:19,028:INFO:Checking exceptions
2025-05-12 22:23:19,028:INFO:Importing libraries
2025-05-12 22:23:19,028:INFO:Copying training dataset
2025-05-12 22:23:19,033:INFO:Defining folds
2025-05-12 22:23:19,033:INFO:Declaring metric variables
2025-05-12 22:23:19,037:INFO:Importing untrained model
2025-05-12 22:23:19,041:INFO:Linear Discriminant Analysis Imported successfully
2025-05-12 22:23:19,051:INFO:Starting cross validation
2025-05-12 22:23:19,053:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:19,211:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:19,211:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:19,216:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:19,218:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:19,219:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:19,323:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:19,337:INFO:Calculating mean and std
2025-05-12 22:23:19,338:INFO:Creating metrics dataframe
2025-05-12 22:23:19,341:INFO:Uploading results into container
2025-05-12 22:23:19,342:INFO:Uploading model into container now
2025-05-12 22:23:19,344:INFO:_master_model_container: 11
2025-05-12 22:23:19,344:INFO:_display_container: 2
2025-05-12 22:23:19,344:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-12 22:23:19,344:INFO:create_model() successfully completed......................................
2025-05-12 22:23:19,446:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:19,446:INFO:Creating metrics dataframe
2025-05-12 22:23:19,454:INFO:Initializing Extra Trees Classifier
2025-05-12 22:23:19,456:INFO:Total runtime is 0.09725764989852906 minutes
2025-05-12 22:23:19,459:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:19,459:INFO:Initializing create_model()
2025-05-12 22:23:19,460:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:19,460:INFO:Checking exceptions
2025-05-12 22:23:19,460:INFO:Importing libraries
2025-05-12 22:23:19,460:INFO:Copying training dataset
2025-05-12 22:23:19,464:INFO:Defining folds
2025-05-12 22:23:19,465:INFO:Declaring metric variables
2025-05-12 22:23:19,469:INFO:Importing untrained model
2025-05-12 22:23:19,474:INFO:Extra Trees Classifier Imported successfully
2025-05-12 22:23:19,483:INFO:Starting cross validation
2025-05-12 22:23:19,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:20,031:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:20,042:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:20,091:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:20,385:INFO:Calculating mean and std
2025-05-12 22:23:20,386:INFO:Creating metrics dataframe
2025-05-12 22:23:20,389:INFO:Uploading results into container
2025-05-12 22:23:20,389:INFO:Uploading model into container now
2025-05-12 22:23:20,390:INFO:_master_model_container: 12
2025-05-12 22:23:20,390:INFO:_display_container: 2
2025-05-12 22:23:20,390:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-12 22:23:20,390:INFO:create_model() successfully completed......................................
2025-05-12 22:23:20,488:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:20,488:INFO:Creating metrics dataframe
2025-05-12 22:23:20,501:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:23:20,501:INFO:Total runtime is 0.11467044750849406 minutes
2025-05-12 22:23:20,505:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:20,506:INFO:Initializing create_model()
2025-05-12 22:23:20,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:20,506:INFO:Checking exceptions
2025-05-12 22:23:20,506:INFO:Importing libraries
2025-05-12 22:23:20,506:INFO:Copying training dataset
2025-05-12 22:23:20,510:INFO:Defining folds
2025-05-12 22:23:20,511:INFO:Declaring metric variables
2025-05-12 22:23:20,518:INFO:Importing untrained model
2025-05-12 22:23:20,537:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:23:20,584:INFO:Starting cross validation
2025-05-12 22:23:20,587:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:20,997:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,052:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,059:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,224:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,243:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,366:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,387:INFO:Calculating mean and std
2025-05-12 22:23:21,390:INFO:Creating metrics dataframe
2025-05-12 22:23:21,396:INFO:Uploading results into container
2025-05-12 22:23:21,397:INFO:Uploading model into container now
2025-05-12 22:23:21,398:INFO:_master_model_container: 13
2025-05-12 22:23:21,398:INFO:_display_container: 2
2025-05-12 22:23:21,399:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:23:21,399:INFO:create_model() successfully completed......................................
2025-05-12 22:23:21,525:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:21,526:INFO:Creating metrics dataframe
2025-05-12 22:23:21,536:INFO:Initializing Dummy Classifier
2025-05-12 22:23:21,536:INFO:Total runtime is 0.1319331725438436 minutes
2025-05-12 22:23:21,541:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:21,541:INFO:Initializing create_model()
2025-05-12 22:23:21,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7B218C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:21,541:INFO:Checking exceptions
2025-05-12 22:23:21,542:INFO:Importing libraries
2025-05-12 22:23:21,542:INFO:Copying training dataset
2025-05-12 22:23:21,547:INFO:Defining folds
2025-05-12 22:23:21,547:INFO:Declaring metric variables
2025-05-12 22:23:21,551:INFO:Importing untrained model
2025-05-12 22:23:21,556:INFO:Dummy Classifier Imported successfully
2025-05-12 22:23:21,567:INFO:Starting cross validation
2025-05-12 22:23:21,569:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:21,722:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,727:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,737:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,753:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,754:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,769:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,784:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,881:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,889:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:21,909:INFO:Calculating mean and std
2025-05-12 22:23:21,911:INFO:Creating metrics dataframe
2025-05-12 22:23:21,914:INFO:Uploading results into container
2025-05-12 22:23:21,917:INFO:Uploading model into container now
2025-05-12 22:23:21,918:INFO:_master_model_container: 14
2025-05-12 22:23:21,918:INFO:_display_container: 2
2025-05-12 22:23:21,919:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:23:21,919:INFO:create_model() successfully completed......................................
2025-05-12 22:23:22,040:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:22,040:INFO:Creating metrics dataframe
2025-05-12 22:23:22,052:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:23:22,064:INFO:Initializing create_model()
2025-05-12 22:23:22,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:22,064:INFO:Checking exceptions
2025-05-12 22:23:22,066:INFO:Importing libraries
2025-05-12 22:23:22,066:INFO:Copying training dataset
2025-05-12 22:23:22,070:INFO:Defining folds
2025-05-12 22:23:22,070:INFO:Declaring metric variables
2025-05-12 22:23:22,070:INFO:Importing untrained model
2025-05-12 22:23:22,070:INFO:Declaring custom model
2025-05-12 22:23:22,071:INFO:Dummy Classifier Imported successfully
2025-05-12 22:23:22,072:INFO:Cross validation set to False
2025-05-12 22:23:22,072:INFO:Fitting Model
2025-05-12 22:23:22,119:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:23:22,119:INFO:create_model() successfully completed......................................
2025-05-12 22:23:22,243:INFO:_master_model_container: 14
2025-05-12 22:23:22,243:INFO:_display_container: 2
2025-05-12 22:23:22,243:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:23:22,243:INFO:compare_models() successfully completed......................................
2025-05-12 22:23:22,261:INFO:Initializing create_model()
2025-05-12 22:23:22,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=dummy, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:22,261:INFO:Checking exceptions
2025-05-12 22:23:22,278:INFO:Importing libraries
2025-05-12 22:23:22,279:INFO:Copying training dataset
2025-05-12 22:23:22,284:INFO:Defining folds
2025-05-12 22:23:22,284:INFO:Declaring metric variables
2025-05-12 22:23:22,290:INFO:Importing untrained model
2025-05-12 22:23:22,296:INFO:Dummy Classifier Imported successfully
2025-05-12 22:23:22,305:INFO:Starting cross validation
2025-05-12 22:23:22,308:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:22,463:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,463:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,466:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,470:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,510:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,513:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,527:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,532:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,585:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,588:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:22,603:INFO:Calculating mean and std
2025-05-12 22:23:22,603:INFO:Creating metrics dataframe
2025-05-12 22:23:22,609:INFO:Finalizing model
2025-05-12 22:23:22,661:INFO:Uploading results into container
2025-05-12 22:23:22,662:INFO:Uploading model into container now
2025-05-12 22:23:22,673:INFO:_master_model_container: 15
2025-05-12 22:23:22,673:INFO:_display_container: 3
2025-05-12 22:23:22,674:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:23:22,674:INFO:create_model() successfully completed......................................
2025-05-12 22:23:22,843:INFO:Initializing tune_model()
2025-05-12 22:23:22,843:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:23:22,844:INFO:Checking exceptions
2025-05-12 22:23:22,865:INFO:Copying training dataset
2025-05-12 22:23:22,869:INFO:Checking base model
2025-05-12 22:23:22,869:INFO:Base model : Dummy Classifier
2025-05-12 22:23:22,874:INFO:Declaring metric variables
2025-05-12 22:23:22,879:INFO:Defining Hyperparameters
2025-05-12 22:23:22,879:INFO:10 is bigger than total combinations 4, setting search algorithm to grid
2025-05-12 22:23:22,981:INFO:Tuning with n_jobs=-1
2025-05-12 22:23:22,981:INFO:Initializing GridSearchCV
2025-05-12 22:23:23,829:INFO:best_params: {'actual_estimator__strategy': 'most_frequent'}
2025-05-12 22:23:23,829:INFO:Hyperparameter search completed
2025-05-12 22:23:23,830:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:23,830:INFO:Initializing create_model()
2025-05-12 22:23:23,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA790971D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'strategy': 'most_frequent'})
2025-05-12 22:23:23,830:INFO:Checking exceptions
2025-05-12 22:23:23,830:INFO:Importing libraries
2025-05-12 22:23:23,830:INFO:Copying training dataset
2025-05-12 22:23:23,834:INFO:Defining folds
2025-05-12 22:23:23,834:INFO:Declaring metric variables
2025-05-12 22:23:23,840:INFO:Importing untrained model
2025-05-12 22:23:23,840:INFO:Declaring custom model
2025-05-12 22:23:23,846:INFO:Dummy Classifier Imported successfully
2025-05-12 22:23:23,856:INFO:Starting cross validation
2025-05-12 22:23:23,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:24,052:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,052:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,053:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,066:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,083:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,103:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,117:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,126:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,188:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,190:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,201:INFO:Calculating mean and std
2025-05-12 22:23:24,203:INFO:Creating metrics dataframe
2025-05-12 22:23:24,210:INFO:Finalizing model
2025-05-12 22:23:24,266:INFO:Uploading results into container
2025-05-12 22:23:24,266:INFO:Uploading model into container now
2025-05-12 22:23:24,267:INFO:_master_model_container: 16
2025-05-12 22:23:24,267:INFO:_display_container: 4
2025-05-12 22:23:24,268:INFO:DummyClassifier(constant=None, random_state=123, strategy='most_frequent')
2025-05-12 22:23:24,268:INFO:create_model() successfully completed......................................
2025-05-12 22:23:24,380:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:24,380:INFO:choose_better activated
2025-05-12 22:23:24,383:INFO:SubProcess create_model() called ==================================
2025-05-12 22:23:24,383:INFO:Initializing create_model()
2025-05-12 22:23:24,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:23:24,384:INFO:Checking exceptions
2025-05-12 22:23:24,386:INFO:Importing libraries
2025-05-12 22:23:24,386:INFO:Copying training dataset
2025-05-12 22:23:24,388:INFO:Defining folds
2025-05-12 22:23:24,389:INFO:Declaring metric variables
2025-05-12 22:23:24,389:INFO:Importing untrained model
2025-05-12 22:23:24,389:INFO:Declaring custom model
2025-05-12 22:23:24,390:INFO:Dummy Classifier Imported successfully
2025-05-12 22:23:24,390:INFO:Starting cross validation
2025-05-12 22:23:24,392:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:23:24,539:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,540:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,540:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,557:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,576:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,582:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,586:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,592:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,659:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,663:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:24,669:INFO:Calculating mean and std
2025-05-12 22:23:24,670:INFO:Creating metrics dataframe
2025-05-12 22:23:24,673:INFO:Finalizing model
2025-05-12 22:23:24,722:INFO:Uploading results into container
2025-05-12 22:23:24,723:INFO:Uploading model into container now
2025-05-12 22:23:24,724:INFO:_master_model_container: 17
2025-05-12 22:23:24,724:INFO:_display_container: 5
2025-05-12 22:23:24,724:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:23:24,724:INFO:create_model() successfully completed......................................
2025-05-12 22:23:24,837:INFO:SubProcess create_model() end ==================================
2025-05-12 22:23:24,838:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior') result for Accuracy is 0.8291
2025-05-12 22:23:24,838:INFO:DummyClassifier(constant=None, random_state=123, strategy='most_frequent') result for Accuracy is 0.8291
2025-05-12 22:23:24,838:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior') is best model
2025-05-12 22:23:24,838:INFO:choose_better completed
2025-05-12 22:23:24,839:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:23:24,852:INFO:_master_model_container: 17
2025-05-12 22:23:24,852:INFO:_display_container: 4
2025-05-12 22:23:24,853:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:23:24,853:INFO:tune_model() successfully completed......................................
2025-05-12 22:23:24,977:INFO:Initializing evaluate_model()
2025-05-12 22:23:24,977:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:23:24,988:INFO:Initializing plot_model()
2025-05-12 22:23:24,989:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:23:24,989:INFO:Checking exceptions
2025-05-12 22:23:24,991:INFO:Preloading libraries
2025-05-12 22:23:24,991:INFO:Copying training dataset
2025-05-12 22:23:24,991:INFO:Plot type: pipeline
2025-05-12 22:23:25,123:INFO:Visual Rendered Successfully
2025-05-12 22:23:25,224:INFO:plot_model() successfully completed......................................
2025-05-12 22:23:25,242:INFO:Initializing predict_model()
2025-05-12 22:23:25,242:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7B644A10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EA7AE1FC40>)
2025-05-12 22:23:25,242:INFO:Checking exceptions
2025-05-12 22:23:25,242:INFO:Preloading libraries
2025-05-12 22:23:25,440:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:23:25,577:INFO:Initializing save_model()
2025-05-12 22:23:25,577:INFO:save_model(model=DummyClassifier(constant=None, random_state=123, strategy='prior'), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-12 22:23:25,577:INFO:Adding model into prep_pipe
2025-05-12 22:23:25,584:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:23:25,591:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 DummyClassifier(constant=None, random_state=123,
                                 strategy='prior'))],
         verbose=False)
2025-05-12 22:23:25,592:INFO:save_model() successfully completed......................................
2025-05-12 22:24:02,824:INFO:PyCaret ClassificationExperiment
2025-05-12 22:24:02,824:INFO:Logging name: clf-default-name
2025-05-12 22:24:02,824:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-12 22:24:02,824:INFO:version 3.3.2
2025-05-12 22:24:02,826:INFO:Initializing setup()
2025-05-12 22:24:02,826:INFO:self.USI: 9efc
2025-05-12 22:24:02,826:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'is_multiclass', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', 'fix_imbalance', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:24:02,826:INFO:Checking environment
2025-05-12 22:24:02,826:INFO:python_version: 3.11.8
2025-05-12 22:24:02,826:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:24:02,826:INFO:machine: AMD64
2025-05-12 22:24:02,826:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:24:02,830:INFO:Memory: svmem(total=16907886592, available=3057942528, percent=81.9, used=13849944064, free=3057942528)
2025-05-12 22:24:02,831:INFO:Physical Core: 4
2025-05-12 22:24:02,831:INFO:Logical Core: 8
2025-05-12 22:24:02,831:INFO:Checking libraries
2025-05-12 22:24:02,831:INFO:System:
2025-05-12 22:24:02,831:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:24:02,831:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:24:02,831:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:24:02,831:INFO:PyCaret required dependencies:
2025-05-12 22:24:02,831:INFO:                 pip: 24.0
2025-05-12 22:24:02,831:INFO:          setuptools: 65.5.0
2025-05-12 22:24:02,831:INFO:             pycaret: 3.3.2
2025-05-12 22:24:02,831:INFO:             IPython: 9.2.0
2025-05-12 22:24:02,831:INFO:          ipywidgets: 8.1.7
2025-05-12 22:24:02,831:INFO:                tqdm: 4.67.1
2025-05-12 22:24:02,831:INFO:               numpy: 1.26.4
2025-05-12 22:24:02,831:INFO:              pandas: 2.1.4
2025-05-12 22:24:02,831:INFO:              jinja2: 3.1.6
2025-05-12 22:24:02,831:INFO:               scipy: 1.11.4
2025-05-12 22:24:02,831:INFO:              joblib: 1.3.2
2025-05-12 22:24:02,831:INFO:             sklearn: 1.4.2
2025-05-12 22:24:02,831:INFO:                pyod: 2.0.5
2025-05-12 22:24:02,831:INFO:            imblearn: 0.13.0
2025-05-12 22:24:02,831:INFO:   category_encoders: 2.7.0
2025-05-12 22:24:02,831:INFO:            lightgbm: 4.6.0
2025-05-12 22:24:02,831:INFO:               numba: 0.61.2
2025-05-12 22:24:02,831:INFO:            requests: 2.32.3
2025-05-12 22:24:02,831:INFO:          matplotlib: 3.7.5
2025-05-12 22:24:02,831:INFO:          scikitplot: 0.3.7
2025-05-12 22:24:02,831:INFO:         yellowbrick: 1.5
2025-05-12 22:24:02,831:INFO:              plotly: 5.24.1
2025-05-12 22:24:02,831:INFO:    plotly-resampler: Not installed
2025-05-12 22:24:02,831:INFO:             kaleido: 0.2.1
2025-05-12 22:24:02,831:INFO:           schemdraw: 0.15
2025-05-12 22:24:02,831:INFO:         statsmodels: 0.14.4
2025-05-12 22:24:02,831:INFO:              sktime: 0.26.0
2025-05-12 22:24:02,831:INFO:               tbats: 1.1.3
2025-05-12 22:24:02,831:INFO:            pmdarima: 2.0.4
2025-05-12 22:24:02,831:INFO:              psutil: 7.0.0
2025-05-12 22:24:02,831:INFO:          markupsafe: 3.0.2
2025-05-12 22:24:02,831:INFO:             pickle5: Not installed
2025-05-12 22:24:02,831:INFO:         cloudpickle: 3.1.1
2025-05-12 22:24:02,831:INFO:         deprecation: 2.1.0
2025-05-12 22:24:02,831:INFO:              xxhash: 3.5.0
2025-05-12 22:24:02,831:INFO:           wurlitzer: Not installed
2025-05-12 22:24:02,831:INFO:PyCaret optional dependencies:
2025-05-12 22:24:02,833:INFO:                shap: Not installed
2025-05-12 22:24:02,833:INFO:           interpret: Not installed
2025-05-12 22:24:02,833:INFO:                umap: Not installed
2025-05-12 22:24:02,833:INFO:     ydata_profiling: Not installed
2025-05-12 22:24:02,833:INFO:  explainerdashboard: Not installed
2025-05-12 22:24:02,833:INFO:             autoviz: Not installed
2025-05-12 22:24:02,833:INFO:           fairlearn: Not installed
2025-05-12 22:24:02,833:INFO:          deepchecks: Not installed
2025-05-12 22:24:02,833:INFO:             xgboost: Not installed
2025-05-12 22:24:02,833:INFO:            catboost: Not installed
2025-05-12 22:24:02,833:INFO:              kmodes: Not installed
2025-05-12 22:24:02,833:INFO:             mlxtend: Not installed
2025-05-12 22:24:02,833:INFO:       statsforecast: Not installed
2025-05-12 22:24:02,833:INFO:        tune_sklearn: Not installed
2025-05-12 22:24:02,833:INFO:                 ray: Not installed
2025-05-12 22:24:02,833:INFO:            hyperopt: Not installed
2025-05-12 22:24:02,833:INFO:              optuna: Not installed
2025-05-12 22:24:02,833:INFO:               skopt: Not installed
2025-05-12 22:24:02,833:INFO:              mlflow: Not installed
2025-05-12 22:24:02,833:INFO:              gradio: Not installed
2025-05-12 22:24:02,833:INFO:             fastapi: Not installed
2025-05-12 22:24:02,833:INFO:             uvicorn: Not installed
2025-05-12 22:24:02,833:INFO:              m2cgen: Not installed
2025-05-12 22:24:02,833:INFO:           evidently: Not installed
2025-05-12 22:24:02,833:INFO:               fugue: Not installed
2025-05-12 22:24:02,833:INFO:           streamlit: Not installed
2025-05-12 22:24:02,833:INFO:             prophet: Not installed
2025-05-12 22:24:02,833:INFO:None
2025-05-12 22:24:02,833:INFO:Set up data.
2025-05-12 22:24:02,836:INFO:Set up folding strategy.
2025-05-12 22:24:02,836:INFO:Set up train/test split.
2025-05-12 22:24:02,839:INFO:Set up index.
2025-05-12 22:24:02,839:INFO:Assigning column types.
2025-05-12 22:24:02,840:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:24:02,876:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:24:02,876:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:24:02,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:02,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:02,931:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:24:02,931:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:24:02,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:02,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:02,954:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:24:02,988:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:24:03,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,009:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,044:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:24:03,066:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,066:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,066:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-12 22:24:03,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,180:INFO:Preparing preprocessing pipeline...
2025-05-12 22:24:03,181:INFO:Set up simple imputation.
2025-05-12 22:24:03,183:INFO:Set up encoding of categorical features.
2025-05-12 22:24:03,183:INFO:Set up feature normalization.
2025-05-12 22:24:03,232:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:24:03,237:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:24:03,238:INFO:Creating final display dataframe.
2025-05-12 22:24:03,378:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              9efc
2025-05-12 22:24:03,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:24:03,496:INFO:setup() successfully completed in 0.67s...............
2025-05-12 22:24:03,508:INFO:Initializing compare_models()
2025-05-12 22:24:03,508:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-12 22:24:03,508:INFO:Checking exceptions
2025-05-12 22:24:03,510:INFO:Preparing display monitor
2025-05-12 22:24:03,530:INFO:Initializing Logistic Regression
2025-05-12 22:24:03,531:INFO:Total runtime is 1.6721089680989585e-05 minutes
2025-05-12 22:24:03,534:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:03,534:INFO:Initializing create_model()
2025-05-12 22:24:03,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:03,536:INFO:Checking exceptions
2025-05-12 22:24:03,536:INFO:Importing libraries
2025-05-12 22:24:03,536:INFO:Copying training dataset
2025-05-12 22:24:03,543:INFO:Defining folds
2025-05-12 22:24:03,544:INFO:Declaring metric variables
2025-05-12 22:24:03,568:INFO:Importing untrained model
2025-05-12 22:24:03,586:INFO:Logistic Regression Imported successfully
2025-05-12 22:24:03,601:INFO:Starting cross validation
2025-05-12 22:24:03,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:03,763:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,768:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,779:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,790:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,791:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,797:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,803:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,848:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:03,852:INFO:Calculating mean and std
2025-05-12 22:24:03,852:INFO:Creating metrics dataframe
2025-05-12 22:24:03,853:INFO:Uploading results into container
2025-05-12 22:24:03,854:INFO:Uploading model into container now
2025-05-12 22:24:03,854:INFO:_master_model_container: 1
2025-05-12 22:24:03,854:INFO:_display_container: 2
2025-05-12 22:24:03,855:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-12 22:24:03,855:INFO:create_model() successfully completed......................................
2025-05-12 22:24:03,943:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:03,944:INFO:Creating metrics dataframe
2025-05-12 22:24:03,948:INFO:Initializing K Neighbors Classifier
2025-05-12 22:24:03,948:INFO:Total runtime is 0.006966094175974528 minutes
2025-05-12 22:24:03,951:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:03,952:INFO:Initializing create_model()
2025-05-12 22:24:03,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:03,952:INFO:Checking exceptions
2025-05-12 22:24:03,952:INFO:Importing libraries
2025-05-12 22:24:03,952:INFO:Copying training dataset
2025-05-12 22:24:03,954:INFO:Defining folds
2025-05-12 22:24:03,954:INFO:Declaring metric variables
2025-05-12 22:24:03,957:INFO:Importing untrained model
2025-05-12 22:24:03,959:INFO:K Neighbors Classifier Imported successfully
2025-05-12 22:24:03,966:INFO:Starting cross validation
2025-05-12 22:24:03,968:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:04,111:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,111:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,115:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,131:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,144:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,206:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,218:INFO:Calculating mean and std
2025-05-12 22:24:04,218:INFO:Creating metrics dataframe
2025-05-12 22:24:04,219:INFO:Uploading results into container
2025-05-12 22:24:04,220:INFO:Uploading model into container now
2025-05-12 22:24:04,220:INFO:_master_model_container: 2
2025-05-12 22:24:04,220:INFO:_display_container: 2
2025-05-12 22:24:04,220:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-12 22:24:04,220:INFO:create_model() successfully completed......................................
2025-05-12 22:24:04,304:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:04,304:INFO:Creating metrics dataframe
2025-05-12 22:24:04,310:INFO:Initializing Naive Bayes
2025-05-12 22:24:04,310:INFO:Total runtime is 0.012993101278940836 minutes
2025-05-12 22:24:04,312:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:04,313:INFO:Initializing create_model()
2025-05-12 22:24:04,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:04,313:INFO:Checking exceptions
2025-05-12 22:24:04,313:INFO:Importing libraries
2025-05-12 22:24:04,313:INFO:Copying training dataset
2025-05-12 22:24:04,316:INFO:Defining folds
2025-05-12 22:24:04,316:INFO:Declaring metric variables
2025-05-12 22:24:04,317:INFO:Importing untrained model
2025-05-12 22:24:04,321:INFO:Naive Bayes Imported successfully
2025-05-12 22:24:04,328:INFO:Starting cross validation
2025-05-12 22:24:04,329:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:04,429:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,437:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,443:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,497:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,505:INFO:Calculating mean and std
2025-05-12 22:24:04,505:INFO:Creating metrics dataframe
2025-05-12 22:24:04,506:INFO:Uploading results into container
2025-05-12 22:24:04,507:INFO:Uploading model into container now
2025-05-12 22:24:04,507:INFO:_master_model_container: 3
2025-05-12 22:24:04,507:INFO:_display_container: 2
2025-05-12 22:24:04,507:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-12 22:24:04,507:INFO:create_model() successfully completed......................................
2025-05-12 22:24:04,591:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:04,591:INFO:Creating metrics dataframe
2025-05-12 22:24:04,597:INFO:Initializing Decision Tree Classifier
2025-05-12 22:24:04,597:INFO:Total runtime is 0.017779342333475747 minutes
2025-05-12 22:24:04,599:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:04,599:INFO:Initializing create_model()
2025-05-12 22:24:04,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:04,600:INFO:Checking exceptions
2025-05-12 22:24:04,600:INFO:Importing libraries
2025-05-12 22:24:04,600:INFO:Copying training dataset
2025-05-12 22:24:04,604:INFO:Defining folds
2025-05-12 22:24:04,604:INFO:Declaring metric variables
2025-05-12 22:24:04,606:INFO:Importing untrained model
2025-05-12 22:24:04,610:INFO:Decision Tree Classifier Imported successfully
2025-05-12 22:24:04,616:INFO:Starting cross validation
2025-05-12 22:24:04,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:04,728:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:04,805:INFO:Calculating mean and std
2025-05-12 22:24:04,805:INFO:Creating metrics dataframe
2025-05-12 22:24:04,807:INFO:Uploading results into container
2025-05-12 22:24:04,807:INFO:Uploading model into container now
2025-05-12 22:24:04,807:INFO:_master_model_container: 4
2025-05-12 22:24:04,809:INFO:_display_container: 2
2025-05-12 22:24:04,809:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-12 22:24:04,809:INFO:create_model() successfully completed......................................
2025-05-12 22:24:04,894:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:04,894:INFO:Creating metrics dataframe
2025-05-12 22:24:04,900:INFO:Initializing SVM - Linear Kernel
2025-05-12 22:24:04,900:INFO:Total runtime is 0.022830323378245032 minutes
2025-05-12 22:24:04,903:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:04,903:INFO:Initializing create_model()
2025-05-12 22:24:04,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:04,903:INFO:Checking exceptions
2025-05-12 22:24:04,903:INFO:Importing libraries
2025-05-12 22:24:04,903:INFO:Copying training dataset
2025-05-12 22:24:04,906:INFO:Defining folds
2025-05-12 22:24:04,906:INFO:Declaring metric variables
2025-05-12 22:24:04,909:INFO:Importing untrained model
2025-05-12 22:24:04,912:INFO:SVM - Linear Kernel Imported successfully
2025-05-12 22:24:04,919:INFO:Starting cross validation
2025-05-12 22:24:04,920:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:05,027:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,037:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,099:INFO:Calculating mean and std
2025-05-12 22:24:05,100:INFO:Creating metrics dataframe
2025-05-12 22:24:05,101:INFO:Uploading results into container
2025-05-12 22:24:05,102:INFO:Uploading model into container now
2025-05-12 22:24:05,102:INFO:_master_model_container: 5
2025-05-12 22:24:05,102:INFO:_display_container: 2
2025-05-12 22:24:05,103:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-12 22:24:05,103:INFO:create_model() successfully completed......................................
2025-05-12 22:24:05,188:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:05,189:INFO:Creating metrics dataframe
2025-05-12 22:24:05,194:INFO:Initializing Ridge Classifier
2025-05-12 22:24:05,194:INFO:Total runtime is 0.027726264794667558 minutes
2025-05-12 22:24:05,197:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:05,198:INFO:Initializing create_model()
2025-05-12 22:24:05,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:05,198:INFO:Checking exceptions
2025-05-12 22:24:05,198:INFO:Importing libraries
2025-05-12 22:24:05,198:INFO:Copying training dataset
2025-05-12 22:24:05,201:INFO:Defining folds
2025-05-12 22:24:05,202:INFO:Declaring metric variables
2025-05-12 22:24:05,205:INFO:Importing untrained model
2025-05-12 22:24:05,209:INFO:Ridge Classifier Imported successfully
2025-05-12 22:24:05,215:INFO:Starting cross validation
2025-05-12 22:24:05,216:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:05,322:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,323:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,325:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,328:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,337:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,338:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,340:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,387:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,389:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,397:INFO:Calculating mean and std
2025-05-12 22:24:05,398:INFO:Creating metrics dataframe
2025-05-12 22:24:05,399:INFO:Uploading results into container
2025-05-12 22:24:05,399:INFO:Uploading model into container now
2025-05-12 22:24:05,400:INFO:_master_model_container: 6
2025-05-12 22:24:05,400:INFO:_display_container: 2
2025-05-12 22:24:05,400:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-12 22:24:05,400:INFO:create_model() successfully completed......................................
2025-05-12 22:24:05,484:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:05,484:INFO:Creating metrics dataframe
2025-05-12 22:24:05,493:INFO:Initializing Random Forest Classifier
2025-05-12 22:24:05,493:INFO:Total runtime is 0.032708982626597084 minutes
2025-05-12 22:24:05,496:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:05,496:INFO:Initializing create_model()
2025-05-12 22:24:05,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:05,496:INFO:Checking exceptions
2025-05-12 22:24:05,496:INFO:Importing libraries
2025-05-12 22:24:05,496:INFO:Copying training dataset
2025-05-12 22:24:05,500:INFO:Defining folds
2025-05-12 22:24:05,500:INFO:Declaring metric variables
2025-05-12 22:24:05,503:INFO:Importing untrained model
2025-05-12 22:24:05,507:INFO:Random Forest Classifier Imported successfully
2025-05-12 22:24:05,513:INFO:Starting cross validation
2025-05-12 22:24:05,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:05,899:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,903:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,905:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,920:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,923:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,939:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:05,996:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:06,120:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:06,130:INFO:Calculating mean and std
2025-05-12 22:24:06,131:INFO:Creating metrics dataframe
2025-05-12 22:24:06,133:INFO:Uploading results into container
2025-05-12 22:24:06,134:INFO:Uploading model into container now
2025-05-12 22:24:06,134:INFO:_master_model_container: 7
2025-05-12 22:24:06,135:INFO:_display_container: 2
2025-05-12 22:24:06,135:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-12 22:24:06,135:INFO:create_model() successfully completed......................................
2025-05-12 22:24:06,221:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:06,221:INFO:Creating metrics dataframe
2025-05-12 22:24:06,227:INFO:Initializing Quadratic Discriminant Analysis
2025-05-12 22:24:06,227:INFO:Total runtime is 0.044942271709442136 minutes
2025-05-12 22:24:06,229:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:06,229:INFO:Initializing create_model()
2025-05-12 22:24:06,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:06,230:INFO:Checking exceptions
2025-05-12 22:24:06,230:INFO:Importing libraries
2025-05-12 22:24:06,230:INFO:Copying training dataset
2025-05-12 22:24:06,234:INFO:Defining folds
2025-05-12 22:24:06,234:INFO:Declaring metric variables
2025-05-12 22:24:06,237:INFO:Importing untrained model
2025-05-12 22:24:06,240:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-12 22:24:06,246:INFO:Starting cross validation
2025-05-12 22:24:06,247:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:06,313:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,316:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,317:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,317:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,320:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,321:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,322:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,351:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:06,356:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:24:06,422:INFO:Calculating mean and std
2025-05-12 22:24:06,423:INFO:Creating metrics dataframe
2025-05-12 22:24:06,424:INFO:Uploading results into container
2025-05-12 22:24:06,424:INFO:Uploading model into container now
2025-05-12 22:24:06,424:INFO:_master_model_container: 8
2025-05-12 22:24:06,425:INFO:_display_container: 2
2025-05-12 22:24:06,425:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-12 22:24:06,425:INFO:create_model() successfully completed......................................
2025-05-12 22:24:06,510:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:06,511:INFO:Creating metrics dataframe
2025-05-12 22:24:06,518:INFO:Initializing Ada Boost Classifier
2025-05-12 22:24:06,518:INFO:Total runtime is 0.04980565309524536 minutes
2025-05-12 22:24:06,521:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:06,521:INFO:Initializing create_model()
2025-05-12 22:24:06,521:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:06,521:INFO:Checking exceptions
2025-05-12 22:24:06,521:INFO:Importing libraries
2025-05-12 22:24:06,521:INFO:Copying training dataset
2025-05-12 22:24:06,525:INFO:Defining folds
2025-05-12 22:24:06,525:INFO:Declaring metric variables
2025-05-12 22:24:06,527:INFO:Importing untrained model
2025-05-12 22:24:06,531:INFO:Ada Boost Classifier Imported successfully
2025-05-12 22:24:06,539:INFO:Starting cross validation
2025-05-12 22:24:06,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:06,606:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,608:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,610:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,611:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,617:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,620:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,625:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,629:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,808:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:06,813:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:06,830:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,830:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:24:06,947:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:06,951:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:06,966:INFO:Calculating mean and std
2025-05-12 22:24:06,966:INFO:Creating metrics dataframe
2025-05-12 22:24:06,969:INFO:Uploading results into container
2025-05-12 22:24:06,969:INFO:Uploading model into container now
2025-05-12 22:24:06,969:INFO:_master_model_container: 9
2025-05-12 22:24:06,970:INFO:_display_container: 2
2025-05-12 22:24:06,970:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-12 22:24:06,970:INFO:create_model() successfully completed......................................
2025-05-12 22:24:07,064:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:07,064:INFO:Creating metrics dataframe
2025-05-12 22:24:07,071:INFO:Initializing Gradient Boosting Classifier
2025-05-12 22:24:07,071:INFO:Total runtime is 0.059021850426991776 minutes
2025-05-12 22:24:07,075:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:07,076:INFO:Initializing create_model()
2025-05-12 22:24:07,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:07,076:INFO:Checking exceptions
2025-05-12 22:24:07,076:INFO:Importing libraries
2025-05-12 22:24:07,076:INFO:Copying training dataset
2025-05-12 22:24:07,080:INFO:Defining folds
2025-05-12 22:24:07,080:INFO:Declaring metric variables
2025-05-12 22:24:07,084:INFO:Importing untrained model
2025-05-12 22:24:07,088:INFO:Gradient Boosting Classifier Imported successfully
2025-05-12 22:24:07,095:INFO:Starting cross validation
2025-05-12 22:24:07,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:07,477:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:07,713:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:07,723:INFO:Calculating mean and std
2025-05-12 22:24:07,724:INFO:Creating metrics dataframe
2025-05-12 22:24:07,726:INFO:Uploading results into container
2025-05-12 22:24:07,727:INFO:Uploading model into container now
2025-05-12 22:24:07,727:INFO:_master_model_container: 10
2025-05-12 22:24:07,727:INFO:_display_container: 2
2025-05-12 22:24:07,727:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-12 22:24:07,727:INFO:create_model() successfully completed......................................
2025-05-12 22:24:07,825:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:07,825:INFO:Creating metrics dataframe
2025-05-12 22:24:07,836:INFO:Initializing Linear Discriminant Analysis
2025-05-12 22:24:07,837:INFO:Total runtime is 0.07177834908167521 minutes
2025-05-12 22:24:07,842:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:07,842:INFO:Initializing create_model()
2025-05-12 22:24:07,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:07,843:INFO:Checking exceptions
2025-05-12 22:24:07,843:INFO:Importing libraries
2025-05-12 22:24:07,843:INFO:Copying training dataset
2025-05-12 22:24:07,847:INFO:Defining folds
2025-05-12 22:24:07,847:INFO:Declaring metric variables
2025-05-12 22:24:07,851:INFO:Importing untrained model
2025-05-12 22:24:07,856:INFO:Linear Discriminant Analysis Imported successfully
2025-05-12 22:24:07,864:INFO:Starting cross validation
2025-05-12 22:24:07,867:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:08,059:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:08,063:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:08,103:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:08,113:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:08,177:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:08,215:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:08,229:INFO:Calculating mean and std
2025-05-12 22:24:08,231:INFO:Creating metrics dataframe
2025-05-12 22:24:08,233:INFO:Uploading results into container
2025-05-12 22:24:08,234:INFO:Uploading model into container now
2025-05-12 22:24:08,235:INFO:_master_model_container: 11
2025-05-12 22:24:08,235:INFO:_display_container: 2
2025-05-12 22:24:08,236:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-12 22:24:08,236:INFO:create_model() successfully completed......................................
2025-05-12 22:24:08,357:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:08,357:INFO:Creating metrics dataframe
2025-05-12 22:24:08,367:INFO:Initializing Extra Trees Classifier
2025-05-12 22:24:08,367:INFO:Total runtime is 0.08061438004175822 minutes
2025-05-12 22:24:08,371:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:08,371:INFO:Initializing create_model()
2025-05-12 22:24:08,371:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:08,371:INFO:Checking exceptions
2025-05-12 22:24:08,371:INFO:Importing libraries
2025-05-12 22:24:08,371:INFO:Copying training dataset
2025-05-12 22:24:08,377:INFO:Defining folds
2025-05-12 22:24:08,377:INFO:Declaring metric variables
2025-05-12 22:24:08,381:INFO:Importing untrained model
2025-05-12 22:24:08,387:INFO:Extra Trees Classifier Imported successfully
2025-05-12 22:24:08,394:INFO:Starting cross validation
2025-05-12 22:24:08,397:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:08,904:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:08,986:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:09,049:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:09,271:INFO:Calculating mean and std
2025-05-12 22:24:09,273:INFO:Creating metrics dataframe
2025-05-12 22:24:09,276:INFO:Uploading results into container
2025-05-12 22:24:09,276:INFO:Uploading model into container now
2025-05-12 22:24:09,277:INFO:_master_model_container: 12
2025-05-12 22:24:09,277:INFO:_display_container: 2
2025-05-12 22:24:09,278:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-12 22:24:09,279:INFO:create_model() successfully completed......................................
2025-05-12 22:24:09,377:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:09,378:INFO:Creating metrics dataframe
2025-05-12 22:24:09,387:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:24:09,387:INFO:Total runtime is 0.09761213858922323 minutes
2025-05-12 22:24:09,389:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:09,390:INFO:Initializing create_model()
2025-05-12 22:24:09,390:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:09,390:INFO:Checking exceptions
2025-05-12 22:24:09,390:INFO:Importing libraries
2025-05-12 22:24:09,390:INFO:Copying training dataset
2025-05-12 22:24:09,395:INFO:Defining folds
2025-05-12 22:24:09,395:INFO:Declaring metric variables
2025-05-12 22:24:09,398:INFO:Importing untrained model
2025-05-12 22:24:09,402:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:24:09,409:INFO:Starting cross validation
2025-05-12 22:24:09,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:09,709:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:09,719:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:09,734:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:09,788:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:09,824:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:09,981:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,000:INFO:Calculating mean and std
2025-05-12 22:24:10,003:INFO:Creating metrics dataframe
2025-05-12 22:24:10,007:INFO:Uploading results into container
2025-05-12 22:24:10,008:INFO:Uploading model into container now
2025-05-12 22:24:10,009:INFO:_master_model_container: 13
2025-05-12 22:24:10,009:INFO:_display_container: 2
2025-05-12 22:24:10,010:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:24:10,010:INFO:create_model() successfully completed......................................
2025-05-12 22:24:10,130:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:10,130:INFO:Creating metrics dataframe
2025-05-12 22:24:10,140:INFO:Initializing Dummy Classifier
2025-05-12 22:24:10,141:INFO:Total runtime is 0.11017510096232097 minutes
2025-05-12 22:24:10,143:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:10,144:INFO:Initializing create_model()
2025-05-12 22:24:10,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA78E8FD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:10,144:INFO:Checking exceptions
2025-05-12 22:24:10,144:INFO:Importing libraries
2025-05-12 22:24:10,144:INFO:Copying training dataset
2025-05-12 22:24:10,149:INFO:Defining folds
2025-05-12 22:24:10,149:INFO:Declaring metric variables
2025-05-12 22:24:10,153:INFO:Importing untrained model
2025-05-12 22:24:10,157:INFO:Dummy Classifier Imported successfully
2025-05-12 22:24:10,167:INFO:Starting cross validation
2025-05-12 22:24:10,168:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:10,305:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,310:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,318:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,321:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,324:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,333:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,341:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,341:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,407:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,409:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:10,426:INFO:Calculating mean and std
2025-05-12 22:24:10,427:INFO:Creating metrics dataframe
2025-05-12 22:24:10,429:INFO:Uploading results into container
2025-05-12 22:24:10,429:INFO:Uploading model into container now
2025-05-12 22:24:10,430:INFO:_master_model_container: 14
2025-05-12 22:24:10,430:INFO:_display_container: 2
2025-05-12 22:24:10,430:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:24:10,430:INFO:create_model() successfully completed......................................
2025-05-12 22:24:10,533:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:10,533:INFO:Creating metrics dataframe
2025-05-12 22:24:10,545:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:24:10,554:INFO:Initializing create_model()
2025-05-12 22:24:10,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:10,554:INFO:Checking exceptions
2025-05-12 22:24:10,556:INFO:Importing libraries
2025-05-12 22:24:10,556:INFO:Copying training dataset
2025-05-12 22:24:10,559:INFO:Defining folds
2025-05-12 22:24:10,559:INFO:Declaring metric variables
2025-05-12 22:24:10,559:INFO:Importing untrained model
2025-05-12 22:24:10,559:INFO:Declaring custom model
2025-05-12 22:24:10,559:INFO:Dummy Classifier Imported successfully
2025-05-12 22:24:10,561:INFO:Cross validation set to False
2025-05-12 22:24:10,561:INFO:Fitting Model
2025-05-12 22:24:10,599:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:24:10,600:INFO:create_model() successfully completed......................................
2025-05-12 22:24:10,718:INFO:_master_model_container: 14
2025-05-12 22:24:10,718:INFO:_display_container: 2
2025-05-12 22:24:10,718:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:24:10,718:INFO:compare_models() successfully completed......................................
2025-05-12 22:24:10,743:INFO:Initializing create_model()
2025-05-12 22:24:10,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:10,743:INFO:Checking exceptions
2025-05-12 22:24:10,761:INFO:Importing libraries
2025-05-12 22:24:10,761:INFO:Copying training dataset
2025-05-12 22:24:10,767:INFO:Defining folds
2025-05-12 22:24:10,769:INFO:Declaring metric variables
2025-05-12 22:24:10,773:INFO:Importing untrained model
2025-05-12 22:24:10,779:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:24:10,788:INFO:Starting cross validation
2025-05-12 22:24:10,790:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:11,255:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:11,258:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:11,349:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:11,417:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:11,433:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:11,544:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:11,559:INFO:Calculating mean and std
2025-05-12 22:24:11,561:INFO:Creating metrics dataframe
2025-05-12 22:24:11,569:INFO:Finalizing model
2025-05-12 22:24:11,650:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:24:11,650:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.
2025-05-12 22:24:11,650:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-12 22:24:11,651:INFO:[LightGBM] [Info] Total Bins 117
2025-05-12 22:24:11,651:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:24:11,651:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:24:11,651:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:24:11,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:11,693:INFO:Uploading results into container
2025-05-12 22:24:11,696:INFO:Uploading model into container now
2025-05-12 22:24:11,715:INFO:_master_model_container: 15
2025-05-12 22:24:11,716:INFO:_display_container: 3
2025-05-12 22:24:11,716:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:24:11,717:INFO:create_model() successfully completed......................................
2025-05-12 22:24:11,879:INFO:Initializing tune_model()
2025-05-12 22:24:11,879:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:24:11,879:INFO:Checking exceptions
2025-05-12 22:24:11,902:INFO:Copying training dataset
2025-05-12 22:24:11,907:INFO:Checking base model
2025-05-12 22:24:11,909:INFO:Base model : Light Gradient Boosting Machine
2025-05-12 22:24:11,914:INFO:Declaring metric variables
2025-05-12 22:24:11,920:INFO:Defining Hyperparameters
2025-05-12 22:24:12,050:INFO:Tuning with n_jobs=-1
2025-05-12 22:24:12,050:INFO:Initializing RandomizedSearchCV
2025-05-12 22:24:19,325:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2025-05-12 22:24:19,327:INFO:Hyperparameter search completed
2025-05-12 22:24:19,327:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:19,329:INFO:Initializing create_model()
2025-05-12 22:24:19,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E027D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2025-05-12 22:24:19,330:INFO:Checking exceptions
2025-05-12 22:24:19,330:INFO:Importing libraries
2025-05-12 22:24:19,330:INFO:Copying training dataset
2025-05-12 22:24:19,338:INFO:Defining folds
2025-05-12 22:24:19,339:INFO:Declaring metric variables
2025-05-12 22:24:19,347:INFO:Importing untrained model
2025-05-12 22:24:19,347:INFO:Declaring custom model
2025-05-12 22:24:19,357:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:24:19,377:INFO:Starting cross validation
2025-05-12 22:24:19,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:19,804:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:19,813:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:19,816:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:19,839:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:19,863:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:19,888:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:19,947:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:20,026:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:20,071:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:20,072:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:20,093:INFO:Calculating mean and std
2025-05-12 22:24:20,096:INFO:Creating metrics dataframe
2025-05-12 22:24:20,109:INFO:Finalizing model
2025-05-12 22:24:20,183:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:24:20,183:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:24:20,183:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:24:20,183:INFO:[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.
2025-05-12 22:24:20,185:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:24:20,185:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:24:20,185:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:24:20,185:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:24:20,185:INFO:[LightGBM] [Info] Total Bins 0
2025-05-12 22:24:20,185:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 0
2025-05-12 22:24:20,185:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:24:20,186:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:24:20,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,201:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,201:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,201:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,201:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,201:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:24:20,216:INFO:Uploading results into container
2025-05-12 22:24:20,219:INFO:Uploading model into container now
2025-05-12 22:24:20,220:INFO:_master_model_container: 16
2025-05-12 22:24:20,220:INFO:_display_container: 4
2025-05-12 22:24:20,223:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:24:20,223:INFO:create_model() successfully completed......................................
2025-05-12 22:24:20,364:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:20,365:INFO:choose_better activated
2025-05-12 22:24:20,369:INFO:SubProcess create_model() called ==================================
2025-05-12 22:24:20,371:INFO:Initializing create_model()
2025-05-12 22:24:20,371:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:24:20,371:INFO:Checking exceptions
2025-05-12 22:24:20,373:INFO:Importing libraries
2025-05-12 22:24:20,373:INFO:Copying training dataset
2025-05-12 22:24:20,376:INFO:Defining folds
2025-05-12 22:24:20,377:INFO:Declaring metric variables
2025-05-12 22:24:20,377:INFO:Importing untrained model
2025-05-12 22:24:20,377:INFO:Declaring custom model
2025-05-12 22:24:20,378:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:24:20,378:INFO:Starting cross validation
2025-05-12 22:24:20,380:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:24:21,039:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:21,216:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:21,285:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:21,299:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:21,346:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:21,439:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:21,463:INFO:Calculating mean and std
2025-05-12 22:24:21,463:INFO:Creating metrics dataframe
2025-05-12 22:24:21,466:INFO:Finalizing model
2025-05-12 22:24:21,540:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:24:21,540:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.
2025-05-12 22:24:21,541:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-12 22:24:21,541:INFO:[LightGBM] [Info] Total Bins 117
2025-05-12 22:24:21,541:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:24:21,541:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:24:21,541:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:24:21,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:24:21,596:INFO:Uploading results into container
2025-05-12 22:24:21,597:INFO:Uploading model into container now
2025-05-12 22:24:21,598:INFO:_master_model_container: 17
2025-05-12 22:24:21,598:INFO:_display_container: 5
2025-05-12 22:24:21,599:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:24:21,599:INFO:create_model() successfully completed......................................
2025-05-12 22:24:21,751:INFO:SubProcess create_model() end ==================================
2025-05-12 22:24:21,753:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7891
2025-05-12 22:24:21,754:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8291
2025-05-12 22:24:21,754:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-12 22:24:21,756:INFO:choose_better completed
2025-05-12 22:24:21,769:INFO:_master_model_container: 17
2025-05-12 22:24:21,769:INFO:_display_container: 4
2025-05-12 22:24:21,770:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:24:21,771:INFO:tune_model() successfully completed......................................
2025-05-12 22:24:21,896:INFO:Initializing evaluate_model()
2025-05-12 22:24:21,896:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:24:21,907:INFO:Initializing plot_model()
2025-05-12 22:24:21,907:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:24:21,907:INFO:Checking exceptions
2025-05-12 22:24:21,910:INFO:Preloading libraries
2025-05-12 22:24:21,912:INFO:Copying training dataset
2025-05-12 22:24:21,912:INFO:Plot type: pipeline
2025-05-12 22:24:22,077:INFO:Visual Rendered Successfully
2025-05-12 22:24:22,183:INFO:plot_model() successfully completed......................................
2025-05-12 22:24:22,218:INFO:Initializing predict_model()
2025-05-12 22:24:22,219:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EA7E249FD0>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EA7E11FF60>)
2025-05-12 22:24:22,219:INFO:Checking exceptions
2025-05-12 22:24:22,219:INFO:Preloading libraries
2025-05-12 22:24:22,351:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:24:22,542:INFO:Initializing save_model()
2025-05-12 22:24:22,542:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-12 22:24:22,542:INFO:Adding model into prep_pipe
2025-05-12 22:24:22,557:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:24:22,577:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-12 22:24:22,577:INFO:save_model() successfully completed......................................
2025-05-12 22:25:09,778:INFO:PyCaret RegressionExperiment
2025-05-12 22:25:09,778:INFO:Logging name: reg-default-name
2025-05-12 22:25:09,778:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:25:09,778:INFO:version 3.3.2
2025-05-12 22:25:09,778:INFO:Initializing setup()
2025-05-12 22:25:09,778:INFO:self.USI: 36ac
2025-05-12 22:25:09,778:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'transform_target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:25:09,778:INFO:Checking environment
2025-05-12 22:25:09,778:INFO:python_version: 3.11.8
2025-05-12 22:25:09,778:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:25:09,778:INFO:machine: AMD64
2025-05-12 22:25:09,778:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:25:09,785:INFO:Memory: svmem(total=16907886592, available=2838208512, percent=83.2, used=14069678080, free=2838208512)
2025-05-12 22:25:09,785:INFO:Physical Core: 4
2025-05-12 22:25:09,785:INFO:Logical Core: 8
2025-05-12 22:25:09,785:INFO:Checking libraries
2025-05-12 22:25:09,785:INFO:System:
2025-05-12 22:25:09,785:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:25:09,785:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:25:09,785:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:25:09,785:INFO:PyCaret required dependencies:
2025-05-12 22:25:09,785:INFO:                 pip: 24.0
2025-05-12 22:25:09,785:INFO:          setuptools: 65.5.0
2025-05-12 22:25:09,785:INFO:             pycaret: 3.3.2
2025-05-12 22:25:09,785:INFO:             IPython: 9.2.0
2025-05-12 22:25:09,785:INFO:          ipywidgets: 8.1.7
2025-05-12 22:25:09,785:INFO:                tqdm: 4.67.1
2025-05-12 22:25:09,785:INFO:               numpy: 1.26.4
2025-05-12 22:25:09,785:INFO:              pandas: 2.1.4
2025-05-12 22:25:09,785:INFO:              jinja2: 3.1.6
2025-05-12 22:25:09,785:INFO:               scipy: 1.11.4
2025-05-12 22:25:09,785:INFO:              joblib: 1.3.2
2025-05-12 22:25:09,785:INFO:             sklearn: 1.4.2
2025-05-12 22:25:09,785:INFO:                pyod: 2.0.5
2025-05-12 22:25:09,785:INFO:            imblearn: 0.13.0
2025-05-12 22:25:09,786:INFO:   category_encoders: 2.7.0
2025-05-12 22:25:09,786:INFO:            lightgbm: 4.6.0
2025-05-12 22:25:09,786:INFO:               numba: 0.61.2
2025-05-12 22:25:09,786:INFO:            requests: 2.32.3
2025-05-12 22:25:09,786:INFO:          matplotlib: 3.7.5
2025-05-12 22:25:09,786:INFO:          scikitplot: 0.3.7
2025-05-12 22:25:09,786:INFO:         yellowbrick: 1.5
2025-05-12 22:25:09,786:INFO:              plotly: 5.24.1
2025-05-12 22:25:09,786:INFO:    plotly-resampler: Not installed
2025-05-12 22:25:09,786:INFO:             kaleido: 0.2.1
2025-05-12 22:25:09,786:INFO:           schemdraw: 0.15
2025-05-12 22:25:09,786:INFO:         statsmodels: 0.14.4
2025-05-12 22:25:09,786:INFO:              sktime: 0.26.0
2025-05-12 22:25:09,786:INFO:               tbats: 1.1.3
2025-05-12 22:25:09,786:INFO:            pmdarima: 2.0.4
2025-05-12 22:25:09,786:INFO:              psutil: 7.0.0
2025-05-12 22:25:09,787:INFO:          markupsafe: 3.0.2
2025-05-12 22:25:09,787:INFO:             pickle5: Not installed
2025-05-12 22:25:09,787:INFO:         cloudpickle: 3.1.1
2025-05-12 22:25:09,787:INFO:         deprecation: 2.1.0
2025-05-12 22:25:09,787:INFO:              xxhash: 3.5.0
2025-05-12 22:25:09,787:INFO:           wurlitzer: Not installed
2025-05-12 22:25:09,787:INFO:PyCaret optional dependencies:
2025-05-12 22:25:09,787:INFO:                shap: Not installed
2025-05-12 22:25:09,787:INFO:           interpret: Not installed
2025-05-12 22:25:09,787:INFO:                umap: Not installed
2025-05-12 22:25:09,787:INFO:     ydata_profiling: Not installed
2025-05-12 22:25:09,787:INFO:  explainerdashboard: Not installed
2025-05-12 22:25:09,788:INFO:             autoviz: Not installed
2025-05-12 22:25:09,788:INFO:           fairlearn: Not installed
2025-05-12 22:25:09,788:INFO:          deepchecks: Not installed
2025-05-12 22:25:09,788:INFO:             xgboost: Not installed
2025-05-12 22:25:09,788:INFO:            catboost: Not installed
2025-05-12 22:25:09,788:INFO:              kmodes: Not installed
2025-05-12 22:25:09,788:INFO:             mlxtend: Not installed
2025-05-12 22:25:09,788:INFO:       statsforecast: Not installed
2025-05-12 22:25:09,788:INFO:        tune_sklearn: Not installed
2025-05-12 22:25:09,788:INFO:                 ray: Not installed
2025-05-12 22:25:09,788:INFO:            hyperopt: Not installed
2025-05-12 22:25:09,788:INFO:              optuna: Not installed
2025-05-12 22:25:09,788:INFO:               skopt: Not installed
2025-05-12 22:25:09,788:INFO:              mlflow: Not installed
2025-05-12 22:25:09,789:INFO:              gradio: Not installed
2025-05-12 22:25:09,789:INFO:             fastapi: Not installed
2025-05-12 22:25:09,789:INFO:             uvicorn: Not installed
2025-05-12 22:25:09,789:INFO:              m2cgen: Not installed
2025-05-12 22:25:09,789:INFO:           evidently: Not installed
2025-05-12 22:25:09,789:INFO:               fugue: Not installed
2025-05-12 22:25:09,789:INFO:           streamlit: Not installed
2025-05-12 22:25:09,790:INFO:             prophet: Not installed
2025-05-12 22:25:09,790:INFO:None
2025-05-12 22:25:09,790:INFO:Set up data.
2025-05-12 22:25:09,795:INFO:Set up folding strategy.
2025-05-12 22:25:09,796:INFO:Set up train/test split.
2025-05-12 22:25:09,799:INFO:Set up index.
2025-05-12 22:25:09,799:INFO:Assigning column types.
2025-05-12 22:25:09,803:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:25:09,803:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,807:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,811:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,867:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:09,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:09,907:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,909:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,913:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,993:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:09,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:09,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:09,994:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:25:09,998:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,001:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,047:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,081:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,081:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,086:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,090:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,171:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:25:10,179:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,224:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,258:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,258:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,265:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,344:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,344:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,344:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,344:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:25:10,394:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,430:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,431:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,481:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,516:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:25:10,567:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,654:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:10,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,693:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,693:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:25:10,790:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:10,884:INFO:Preparing preprocessing pipeline...
2025-05-12 22:25:10,884:INFO:Set up simple imputation.
2025-05-12 22:25:10,887:INFO:Set up encoding of categorical features.
2025-05-12 22:25:10,887:INFO:Set up feature normalization.
2025-05-12 22:25:10,936:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:25:10,939:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:25:10,939:INFO:Creating final display dataframe.
2025-05-12 22:25:11,127:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type        Regression
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              36ac
2025-05-12 22:25:11,229:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:11,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:11,331:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:11,332:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:11,332:INFO:setup() successfully completed in 1.56s...............
2025-05-12 22:25:11,351:INFO:Initializing compare_models()
2025-05-12 22:25:11,351:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 22:25:11,352:INFO:Checking exceptions
2025-05-12 22:25:11,354:INFO:Preparing display monitor
2025-05-12 22:25:11,388:INFO:Initializing Linear Regression
2025-05-12 22:25:11,388:INFO:Total runtime is 1.6701221466064452e-05 minutes
2025-05-12 22:25:11,393:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:11,394:INFO:Initializing create_model()
2025-05-12 22:25:11,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:11,394:INFO:Checking exceptions
2025-05-12 22:25:11,394:INFO:Importing libraries
2025-05-12 22:25:11,394:INFO:Copying training dataset
2025-05-12 22:25:11,399:INFO:Defining folds
2025-05-12 22:25:11,399:INFO:Declaring metric variables
2025-05-12 22:25:11,402:INFO:Importing untrained model
2025-05-12 22:25:11,407:INFO:Linear Regression Imported successfully
2025-05-12 22:25:11,413:INFO:Starting cross validation
2025-05-12 22:25:11,415:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:11,608:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:11,608:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:11,617:INFO:Calculating mean and std
2025-05-12 22:25:11,617:INFO:Creating metrics dataframe
2025-05-12 22:25:11,620:INFO:Uploading results into container
2025-05-12 22:25:11,620:INFO:Uploading model into container now
2025-05-12 22:25:11,621:INFO:_master_model_container: 1
2025-05-12 22:25:11,621:INFO:_display_container: 2
2025-05-12 22:25:11,621:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-05-12 22:25:11,621:INFO:create_model() successfully completed......................................
2025-05-12 22:25:11,721:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:11,721:INFO:Creating metrics dataframe
2025-05-12 22:25:11,726:INFO:Initializing Lasso Regression
2025-05-12 22:25:11,726:INFO:Total runtime is 0.005647528171539307 minutes
2025-05-12 22:25:11,729:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:11,729:INFO:Initializing create_model()
2025-05-12 22:25:11,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:11,729:INFO:Checking exceptions
2025-05-12 22:25:11,729:INFO:Importing libraries
2025-05-12 22:25:11,729:INFO:Copying training dataset
2025-05-12 22:25:11,732:INFO:Defining folds
2025-05-12 22:25:11,732:INFO:Declaring metric variables
2025-05-12 22:25:11,736:INFO:Importing untrained model
2025-05-12 22:25:11,741:INFO:Lasso Regression Imported successfully
2025-05-12 22:25:11,747:INFO:Starting cross validation
2025-05-12 22:25:11,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:11,934:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:11,934:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:11,937:INFO:Calculating mean and std
2025-05-12 22:25:11,937:INFO:Creating metrics dataframe
2025-05-12 22:25:11,937:INFO:Uploading results into container
2025-05-12 22:25:11,939:INFO:Uploading model into container now
2025-05-12 22:25:11,940:INFO:_master_model_container: 2
2025-05-12 22:25:11,940:INFO:_display_container: 2
2025-05-12 22:25:11,940:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-05-12 22:25:11,941:INFO:create_model() successfully completed......................................
2025-05-12 22:25:12,047:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:12,047:INFO:Creating metrics dataframe
2025-05-12 22:25:12,052:INFO:Initializing Ridge Regression
2025-05-12 22:25:12,053:INFO:Total runtime is 0.011103037993113199 minutes
2025-05-12 22:25:12,056:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:12,056:INFO:Initializing create_model()
2025-05-12 22:25:12,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:12,056:INFO:Checking exceptions
2025-05-12 22:25:12,056:INFO:Importing libraries
2025-05-12 22:25:12,056:INFO:Copying training dataset
2025-05-12 22:25:12,060:INFO:Defining folds
2025-05-12 22:25:12,060:INFO:Declaring metric variables
2025-05-12 22:25:12,063:INFO:Importing untrained model
2025-05-12 22:25:12,067:INFO:Ridge Regression Imported successfully
2025-05-12 22:25:12,073:INFO:Starting cross validation
2025-05-12 22:25:12,074:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:12,284:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:12,284:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:12,293:INFO:Calculating mean and std
2025-05-12 22:25:12,293:INFO:Creating metrics dataframe
2025-05-12 22:25:12,294:INFO:Uploading results into container
2025-05-12 22:25:12,294:INFO:Uploading model into container now
2025-05-12 22:25:12,296:INFO:_master_model_container: 3
2025-05-12 22:25:12,296:INFO:_display_container: 2
2025-05-12 22:25:12,296:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-05-12 22:25:12,296:INFO:create_model() successfully completed......................................
2025-05-12 22:25:12,401:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:12,403:INFO:Creating metrics dataframe
2025-05-12 22:25:12,409:INFO:Initializing Elastic Net
2025-05-12 22:25:12,409:INFO:Total runtime is 0.017030918598175047 minutes
2025-05-12 22:25:12,413:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:12,414:INFO:Initializing create_model()
2025-05-12 22:25:12,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:12,414:INFO:Checking exceptions
2025-05-12 22:25:12,414:INFO:Importing libraries
2025-05-12 22:25:12,414:INFO:Copying training dataset
2025-05-12 22:25:12,419:INFO:Defining folds
2025-05-12 22:25:12,419:INFO:Declaring metric variables
2025-05-12 22:25:12,423:INFO:Importing untrained model
2025-05-12 22:25:12,428:INFO:Elastic Net Imported successfully
2025-05-12 22:25:12,438:INFO:Starting cross validation
2025-05-12 22:25:12,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:12,739:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:12,739:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:12,749:INFO:Calculating mean and std
2025-05-12 22:25:12,752:INFO:Creating metrics dataframe
2025-05-12 22:25:12,754:INFO:Uploading results into container
2025-05-12 22:25:12,754:INFO:Uploading model into container now
2025-05-12 22:25:12,756:INFO:_master_model_container: 4
2025-05-12 22:25:12,756:INFO:_display_container: 2
2025-05-12 22:25:12,757:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-05-12 22:25:12,757:INFO:create_model() successfully completed......................................
2025-05-12 22:25:12,873:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:12,873:INFO:Creating metrics dataframe
2025-05-12 22:25:12,881:INFO:Initializing Least Angle Regression
2025-05-12 22:25:12,881:INFO:Total runtime is 0.0248988668123881 minutes
2025-05-12 22:25:12,888:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:12,888:INFO:Initializing create_model()
2025-05-12 22:25:12,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:12,888:INFO:Checking exceptions
2025-05-12 22:25:12,888:INFO:Importing libraries
2025-05-12 22:25:12,888:INFO:Copying training dataset
2025-05-12 22:25:12,893:INFO:Defining folds
2025-05-12 22:25:12,893:INFO:Declaring metric variables
2025-05-12 22:25:12,897:INFO:Importing untrained model
2025-05-12 22:25:12,903:INFO:Least Angle Regression Imported successfully
2025-05-12 22:25:12,911:INFO:Starting cross validation
2025-05-12 22:25:12,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:13,235:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:13,235:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:13,244:INFO:Calculating mean and std
2025-05-12 22:25:13,245:INFO:Creating metrics dataframe
2025-05-12 22:25:13,248:INFO:Uploading results into container
2025-05-12 22:25:13,248:INFO:Uploading model into container now
2025-05-12 22:25:13,251:INFO:_master_model_container: 5
2025-05-12 22:25:13,251:INFO:_display_container: 2
2025-05-12 22:25:13,252:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-05-12 22:25:13,252:INFO:create_model() successfully completed......................................
2025-05-12 22:25:13,375:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:13,375:INFO:Creating metrics dataframe
2025-05-12 22:25:13,383:INFO:Initializing Lasso Least Angle Regression
2025-05-12 22:25:13,383:INFO:Total runtime is 0.033265928427378334 minutes
2025-05-12 22:25:13,387:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:13,387:INFO:Initializing create_model()
2025-05-12 22:25:13,387:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:13,389:INFO:Checking exceptions
2025-05-12 22:25:13,389:INFO:Importing libraries
2025-05-12 22:25:13,389:INFO:Copying training dataset
2025-05-12 22:25:13,393:INFO:Defining folds
2025-05-12 22:25:13,394:INFO:Declaring metric variables
2025-05-12 22:25:13,398:INFO:Importing untrained model
2025-05-12 22:25:13,403:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:25:13,412:INFO:Starting cross validation
2025-05-12 22:25:13,413:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:13,698:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:13,699:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:13,700:INFO:Calculating mean and std
2025-05-12 22:25:13,701:INFO:Creating metrics dataframe
2025-05-12 22:25:13,704:INFO:Uploading results into container
2025-05-12 22:25:13,705:INFO:Uploading model into container now
2025-05-12 22:25:13,706:INFO:_master_model_container: 6
2025-05-12 22:25:13,706:INFO:_display_container: 2
2025-05-12 22:25:13,706:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-05-12 22:25:13,707:INFO:create_model() successfully completed......................................
2025-05-12 22:25:13,824:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:13,824:INFO:Creating metrics dataframe
2025-05-12 22:25:13,833:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 22:25:13,834:INFO:Total runtime is 0.040789866447448725 minutes
2025-05-12 22:25:13,839:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:13,839:INFO:Initializing create_model()
2025-05-12 22:25:13,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:13,839:INFO:Checking exceptions
2025-05-12 22:25:13,839:INFO:Importing libraries
2025-05-12 22:25:13,839:INFO:Copying training dataset
2025-05-12 22:25:13,845:INFO:Defining folds
2025-05-12 22:25:13,845:INFO:Declaring metric variables
2025-05-12 22:25:13,851:INFO:Importing untrained model
2025-05-12 22:25:13,856:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 22:25:13,865:INFO:Starting cross validation
2025-05-12 22:25:13,867:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:14,199:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:14,199:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:14,208:INFO:Calculating mean and std
2025-05-12 22:25:14,210:INFO:Creating metrics dataframe
2025-05-12 22:25:14,213:INFO:Uploading results into container
2025-05-12 22:25:14,214:INFO:Uploading model into container now
2025-05-12 22:25:14,214:INFO:_master_model_container: 7
2025-05-12 22:25:14,214:INFO:_display_container: 2
2025-05-12 22:25:14,216:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-05-12 22:25:14,216:INFO:create_model() successfully completed......................................
2025-05-12 22:25:14,327:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:14,327:INFO:Creating metrics dataframe
2025-05-12 22:25:14,335:INFO:Initializing Bayesian Ridge
2025-05-12 22:25:14,336:INFO:Total runtime is 0.04914723634719848 minutes
2025-05-12 22:25:14,339:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:14,339:INFO:Initializing create_model()
2025-05-12 22:25:14,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:14,339:INFO:Checking exceptions
2025-05-12 22:25:14,339:INFO:Importing libraries
2025-05-12 22:25:14,339:INFO:Copying training dataset
2025-05-12 22:25:14,343:INFO:Defining folds
2025-05-12 22:25:14,343:INFO:Declaring metric variables
2025-05-12 22:25:14,347:INFO:Importing untrained model
2025-05-12 22:25:14,354:INFO:Bayesian Ridge Imported successfully
2025-05-12 22:25:14,362:INFO:Starting cross validation
2025-05-12 22:25:14,366:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:14,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:14,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:14,626:INFO:Calculating mean and std
2025-05-12 22:25:14,627:INFO:Creating metrics dataframe
2025-05-12 22:25:14,630:INFO:Uploading results into container
2025-05-12 22:25:14,631:INFO:Uploading model into container now
2025-05-12 22:25:14,633:INFO:_master_model_container: 8
2025-05-12 22:25:14,633:INFO:_display_container: 2
2025-05-12 22:25:14,633:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-05-12 22:25:14,633:INFO:create_model() successfully completed......................................
2025-05-12 22:25:14,737:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:14,738:INFO:Creating metrics dataframe
2025-05-12 22:25:14,746:INFO:Initializing Passive Aggressive Regressor
2025-05-12 22:25:14,746:INFO:Total runtime is 0.055983444054921463 minutes
2025-05-12 22:25:14,750:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:14,750:INFO:Initializing create_model()
2025-05-12 22:25:14,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:14,750:INFO:Checking exceptions
2025-05-12 22:25:14,750:INFO:Importing libraries
2025-05-12 22:25:14,750:INFO:Copying training dataset
2025-05-12 22:25:14,755:INFO:Defining folds
2025-05-12 22:25:14,756:INFO:Declaring metric variables
2025-05-12 22:25:14,759:INFO:Importing untrained model
2025-05-12 22:25:14,764:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 22:25:14,773:INFO:Starting cross validation
2025-05-12 22:25:14,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:15,011:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:15,011:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:15,017:INFO:Calculating mean and std
2025-05-12 22:25:15,019:INFO:Creating metrics dataframe
2025-05-12 22:25:15,021:INFO:Uploading results into container
2025-05-12 22:25:15,021:INFO:Uploading model into container now
2025-05-12 22:25:15,022:INFO:_master_model_container: 9
2025-05-12 22:25:15,022:INFO:_display_container: 2
2025-05-12 22:25:15,022:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-12 22:25:15,022:INFO:create_model() successfully completed......................................
2025-05-12 22:25:15,125:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:15,125:INFO:Creating metrics dataframe
2025-05-12 22:25:15,134:INFO:Initializing Huber Regressor
2025-05-12 22:25:15,134:INFO:Total runtime is 0.062446180979410806 minutes
2025-05-12 22:25:15,136:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:15,137:INFO:Initializing create_model()
2025-05-12 22:25:15,137:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:15,137:INFO:Checking exceptions
2025-05-12 22:25:15,137:INFO:Importing libraries
2025-05-12 22:25:15,137:INFO:Copying training dataset
2025-05-12 22:25:15,143:INFO:Defining folds
2025-05-12 22:25:15,143:INFO:Declaring metric variables
2025-05-12 22:25:15,148:INFO:Importing untrained model
2025-05-12 22:25:15,153:INFO:Huber Regressor Imported successfully
2025-05-12 22:25:15,160:INFO:Starting cross validation
2025-05-12 22:25:15,161:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:15,474:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:15,474:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:15,481:INFO:Calculating mean and std
2025-05-12 22:25:15,483:INFO:Creating metrics dataframe
2025-05-12 22:25:15,487:INFO:Uploading results into container
2025-05-12 22:25:15,489:INFO:Uploading model into container now
2025-05-12 22:25:15,489:INFO:_master_model_container: 10
2025-05-12 22:25:15,490:INFO:_display_container: 2
2025-05-12 22:25:15,490:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-05-12 22:25:15,491:INFO:create_model() successfully completed......................................
2025-05-12 22:25:15,595:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:15,595:INFO:Creating metrics dataframe
2025-05-12 22:25:15,605:INFO:Initializing K Neighbors Regressor
2025-05-12 22:25:15,606:INFO:Total runtime is 0.07032041947046916 minutes
2025-05-12 22:25:15,610:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:15,610:INFO:Initializing create_model()
2025-05-12 22:25:15,610:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:15,611:INFO:Checking exceptions
2025-05-12 22:25:15,611:INFO:Importing libraries
2025-05-12 22:25:15,611:INFO:Copying training dataset
2025-05-12 22:25:15,617:INFO:Defining folds
2025-05-12 22:25:15,617:INFO:Declaring metric variables
2025-05-12 22:25:15,621:INFO:Importing untrained model
2025-05-12 22:25:15,626:INFO:K Neighbors Regressor Imported successfully
2025-05-12 22:25:15,657:INFO:Starting cross validation
2025-05-12 22:25:15,659:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:15,982:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:15,983:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:15,994:INFO:Calculating mean and std
2025-05-12 22:25:15,995:INFO:Creating metrics dataframe
2025-05-12 22:25:15,998:INFO:Uploading results into container
2025-05-12 22:25:15,998:INFO:Uploading model into container now
2025-05-12 22:25:15,999:INFO:_master_model_container: 11
2025-05-12 22:25:16,000:INFO:_display_container: 2
2025-05-12 22:25:16,000:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-05-12 22:25:16,000:INFO:create_model() successfully completed......................................
2025-05-12 22:25:16,104:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:16,104:INFO:Creating metrics dataframe
2025-05-12 22:25:16,124:INFO:Initializing Decision Tree Regressor
2025-05-12 22:25:16,124:INFO:Total runtime is 0.07895351648330688 minutes
2025-05-12 22:25:16,149:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:16,149:INFO:Initializing create_model()
2025-05-12 22:25:16,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:16,149:INFO:Checking exceptions
2025-05-12 22:25:16,149:INFO:Importing libraries
2025-05-12 22:25:16,150:INFO:Copying training dataset
2025-05-12 22:25:16,157:INFO:Defining folds
2025-05-12 22:25:16,157:INFO:Declaring metric variables
2025-05-12 22:25:16,179:INFO:Importing untrained model
2025-05-12 22:25:16,198:INFO:Decision Tree Regressor Imported successfully
2025-05-12 22:25:16,215:INFO:Starting cross validation
2025-05-12 22:25:16,219:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:16,526:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:16,527:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:16,533:INFO:Calculating mean and std
2025-05-12 22:25:16,535:INFO:Creating metrics dataframe
2025-05-12 22:25:16,538:INFO:Uploading results into container
2025-05-12 22:25:16,539:INFO:Uploading model into container now
2025-05-12 22:25:16,540:INFO:_master_model_container: 12
2025-05-12 22:25:16,540:INFO:_display_container: 2
2025-05-12 22:25:16,541:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-05-12 22:25:16,541:INFO:create_model() successfully completed......................................
2025-05-12 22:25:16,657:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:16,658:INFO:Creating metrics dataframe
2025-05-12 22:25:16,669:INFO:Initializing Random Forest Regressor
2025-05-12 22:25:16,669:INFO:Total runtime is 0.08803116083145142 minutes
2025-05-12 22:25:16,673:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:16,674:INFO:Initializing create_model()
2025-05-12 22:25:16,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:16,674:INFO:Checking exceptions
2025-05-12 22:25:16,674:INFO:Importing libraries
2025-05-12 22:25:16,674:INFO:Copying training dataset
2025-05-12 22:25:16,679:INFO:Defining folds
2025-05-12 22:25:16,680:INFO:Declaring metric variables
2025-05-12 22:25:16,685:INFO:Importing untrained model
2025-05-12 22:25:16,691:INFO:Random Forest Regressor Imported successfully
2025-05-12 22:25:16,700:INFO:Starting cross validation
2025-05-12 22:25:16,704:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:17,638:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:17,638:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:17,649:INFO:Calculating mean and std
2025-05-12 22:25:17,650:INFO:Creating metrics dataframe
2025-05-12 22:25:17,653:INFO:Uploading results into container
2025-05-12 22:25:17,654:INFO:Uploading model into container now
2025-05-12 22:25:17,655:INFO:_master_model_container: 13
2025-05-12 22:25:17,655:INFO:_display_container: 2
2025-05-12 22:25:17,656:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-05-12 22:25:17,656:INFO:create_model() successfully completed......................................
2025-05-12 22:25:17,771:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:17,771:INFO:Creating metrics dataframe
2025-05-12 22:25:17,783:INFO:Initializing Extra Trees Regressor
2025-05-12 22:25:17,783:INFO:Total runtime is 0.10659570296605428 minutes
2025-05-12 22:25:17,787:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:17,787:INFO:Initializing create_model()
2025-05-12 22:25:17,787:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:17,787:INFO:Checking exceptions
2025-05-12 22:25:17,787:INFO:Importing libraries
2025-05-12 22:25:17,788:INFO:Copying training dataset
2025-05-12 22:25:17,791:INFO:Defining folds
2025-05-12 22:25:17,793:INFO:Declaring metric variables
2025-05-12 22:25:17,797:INFO:Importing untrained model
2025-05-12 22:25:17,801:INFO:Extra Trees Regressor Imported successfully
2025-05-12 22:25:17,809:INFO:Starting cross validation
2025-05-12 22:25:17,813:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:18,488:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:18,488:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:18,499:INFO:Calculating mean and std
2025-05-12 22:25:18,500:INFO:Creating metrics dataframe
2025-05-12 22:25:18,503:INFO:Uploading results into container
2025-05-12 22:25:18,504:INFO:Uploading model into container now
2025-05-12 22:25:18,505:INFO:_master_model_container: 14
2025-05-12 22:25:18,505:INFO:_display_container: 2
2025-05-12 22:25:18,505:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-05-12 22:25:18,506:INFO:create_model() successfully completed......................................
2025-05-12 22:25:18,607:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:18,607:INFO:Creating metrics dataframe
2025-05-12 22:25:18,618:INFO:Initializing AdaBoost Regressor
2025-05-12 22:25:18,618:INFO:Total runtime is 0.12051774263381958 minutes
2025-05-12 22:25:18,621:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:18,621:INFO:Initializing create_model()
2025-05-12 22:25:18,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:18,621:INFO:Checking exceptions
2025-05-12 22:25:18,622:INFO:Importing libraries
2025-05-12 22:25:18,622:INFO:Copying training dataset
2025-05-12 22:25:18,626:INFO:Defining folds
2025-05-12 22:25:18,626:INFO:Declaring metric variables
2025-05-12 22:25:18,629:INFO:Importing untrained model
2025-05-12 22:25:18,634:INFO:AdaBoost Regressor Imported successfully
2025-05-12 22:25:18,641:INFO:Starting cross validation
2025-05-12 22:25:18,643:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:19,247:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:19,247:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:19,250:INFO:Calculating mean and std
2025-05-12 22:25:19,251:INFO:Creating metrics dataframe
2025-05-12 22:25:19,253:INFO:Uploading results into container
2025-05-12 22:25:19,254:INFO:Uploading model into container now
2025-05-12 22:25:19,254:INFO:_master_model_container: 15
2025-05-12 22:25:19,254:INFO:_display_container: 2
2025-05-12 22:25:19,255:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-05-12 22:25:19,255:INFO:create_model() successfully completed......................................
2025-05-12 22:25:19,365:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:19,365:INFO:Creating metrics dataframe
2025-05-12 22:25:19,376:INFO:Initializing Gradient Boosting Regressor
2025-05-12 22:25:19,376:INFO:Total runtime is 0.1331573208173116 minutes
2025-05-12 22:25:19,381:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:19,381:INFO:Initializing create_model()
2025-05-12 22:25:19,381:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:19,381:INFO:Checking exceptions
2025-05-12 22:25:19,381:INFO:Importing libraries
2025-05-12 22:25:19,381:INFO:Copying training dataset
2025-05-12 22:25:19,387:INFO:Defining folds
2025-05-12 22:25:19,387:INFO:Declaring metric variables
2025-05-12 22:25:19,390:INFO:Importing untrained model
2025-05-12 22:25:19,397:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 22:25:19,404:INFO:Starting cross validation
2025-05-12 22:25:19,407:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:19,923:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:19,924:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:19,933:INFO:Calculating mean and std
2025-05-12 22:25:19,934:INFO:Creating metrics dataframe
2025-05-12 22:25:19,936:INFO:Uploading results into container
2025-05-12 22:25:19,937:INFO:Uploading model into container now
2025-05-12 22:25:19,938:INFO:_master_model_container: 16
2025-05-12 22:25:19,938:INFO:_display_container: 2
2025-05-12 22:25:19,938:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-12 22:25:19,939:INFO:create_model() successfully completed......................................
2025-05-12 22:25:20,059:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:20,060:INFO:Creating metrics dataframe
2025-05-12 22:25:20,073:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:25:20,073:INFO:Total runtime is 0.1447648564974467 minutes
2025-05-12 22:25:20,079:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:20,080:INFO:Initializing create_model()
2025-05-12 22:25:20,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:20,080:INFO:Checking exceptions
2025-05-12 22:25:20,080:INFO:Importing libraries
2025-05-12 22:25:20,080:INFO:Copying training dataset
2025-05-12 22:25:20,084:INFO:Defining folds
2025-05-12 22:25:20,086:INFO:Declaring metric variables
2025-05-12 22:25:20,089:INFO:Importing untrained model
2025-05-12 22:25:20,096:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:25:20,106:INFO:Starting cross validation
2025-05-12 22:25:20,108:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:20,649:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:20,649:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:20,657:INFO:Calculating mean and std
2025-05-12 22:25:20,660:INFO:Creating metrics dataframe
2025-05-12 22:25:20,664:INFO:Uploading results into container
2025-05-12 22:25:20,664:INFO:Uploading model into container now
2025-05-12 22:25:20,666:INFO:_master_model_container: 17
2025-05-12 22:25:20,666:INFO:_display_container: 2
2025-05-12 22:25:20,668:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:25:20,668:INFO:create_model() successfully completed......................................
2025-05-12 22:25:20,803:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:20,804:INFO:Creating metrics dataframe
2025-05-12 22:25:20,816:INFO:Initializing Dummy Regressor
2025-05-12 22:25:20,816:INFO:Total runtime is 0.15715911785761516 minutes
2025-05-12 22:25:20,820:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:20,821:INFO:Initializing create_model()
2025-05-12 22:25:20,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E07F110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:20,821:INFO:Checking exceptions
2025-05-12 22:25:20,821:INFO:Importing libraries
2025-05-12 22:25:20,821:INFO:Copying training dataset
2025-05-12 22:25:20,826:INFO:Defining folds
2025-05-12 22:25:20,826:INFO:Declaring metric variables
2025-05-12 22:25:20,831:INFO:Importing untrained model
2025-05-12 22:25:20,844:INFO:Dummy Regressor Imported successfully
2025-05-12 22:25:20,867:INFO:Starting cross validation
2025-05-12 22:25:20,872:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:21,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:21,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:21,181:INFO:Calculating mean and std
2025-05-12 22:25:21,183:INFO:Creating metrics dataframe
2025-05-12 22:25:21,186:INFO:Uploading results into container
2025-05-12 22:25:21,187:INFO:Uploading model into container now
2025-05-12 22:25:21,187:INFO:_master_model_container: 18
2025-05-12 22:25:21,188:INFO:_display_container: 2
2025-05-12 22:25:21,188:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-05-12 22:25:21,188:INFO:create_model() successfully completed......................................
2025-05-12 22:25:21,298:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:21,298:INFO:Creating metrics dataframe
2025-05-12 22:25:21,311:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:25:21,321:INFO:Initializing create_model()
2025-05-12 22:25:21,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:21,321:INFO:Checking exceptions
2025-05-12 22:25:21,324:INFO:Importing libraries
2025-05-12 22:25:21,324:INFO:Copying training dataset
2025-05-12 22:25:21,328:INFO:Defining folds
2025-05-12 22:25:21,329:INFO:Declaring metric variables
2025-05-12 22:25:21,329:INFO:Importing untrained model
2025-05-12 22:25:21,329:INFO:Declaring custom model
2025-05-12 22:25:21,329:INFO:Lasso Regression Imported successfully
2025-05-12 22:25:21,331:INFO:Cross validation set to False
2025-05-12 22:25:21,331:INFO:Fitting Model
2025-05-12 22:25:21,378:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-05-12 22:25:21,378:INFO:create_model() successfully completed......................................
2025-05-12 22:25:21,511:INFO:_master_model_container: 18
2025-05-12 22:25:21,511:INFO:_display_container: 2
2025-05-12 22:25:21,512:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-05-12 22:25:21,512:INFO:compare_models() successfully completed......................................
2025-05-12 22:25:21,579:INFO:Initializing create_model()
2025-05-12 22:25:21,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:21,579:INFO:Checking exceptions
2025-05-12 22:25:21,603:INFO:Importing libraries
2025-05-12 22:25:21,603:INFO:Copying training dataset
2025-05-12 22:25:21,611:INFO:Defining folds
2025-05-12 22:25:21,612:INFO:Declaring metric variables
2025-05-12 22:25:21,621:INFO:Importing untrained model
2025-05-12 22:25:21,636:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:25:21,650:INFO:Starting cross validation
2025-05-12 22:25:21,653:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:22,287:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:22,288:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:22,303:INFO:Calculating mean and std
2025-05-12 22:25:22,303:INFO:Creating metrics dataframe
2025-05-12 22:25:22,311:INFO:Finalizing model
2025-05-12 22:25:22,381:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.
2025-05-12 22:25:22,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-12 22:25:22,383:INFO:[LightGBM] [Info] Total Bins 116
2025-05-12 22:25:22,383:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:25:22,383:INFO:[LightGBM] [Info] Start training from score 0.161905
2025-05-12 22:25:22,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:22,420:INFO:Uploading results into container
2025-05-12 22:25:22,423:INFO:Uploading model into container now
2025-05-12 22:25:22,443:INFO:_master_model_container: 19
2025-05-12 22:25:22,443:INFO:_display_container: 3
2025-05-12 22:25:22,444:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:25:22,444:INFO:create_model() successfully completed......................................
2025-05-12 22:25:22,599:INFO:Initializing tune_model()
2025-05-12 22:25:22,600:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:25:22,600:INFO:Checking exceptions
2025-05-12 22:25:22,623:INFO:Copying training dataset
2025-05-12 22:25:22,627:INFO:Checking base model
2025-05-12 22:25:22,627:INFO:Base model : Light Gradient Boosting Machine
2025-05-12 22:25:22,632:INFO:Declaring metric variables
2025-05-12 22:25:22,638:INFO:Defining Hyperparameters
2025-05-12 22:25:22,749:INFO:Tuning with n_jobs=-1
2025-05-12 22:25:22,749:INFO:Initializing RandomizedSearchCV
2025-05-12 22:25:29,564:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2025-05-12 22:25:29,567:INFO:Hyperparameter search completed
2025-05-12 22:25:29,567:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:29,569:INFO:Initializing create_model()
2025-05-12 22:25:29,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E0A7010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2025-05-12 22:25:29,570:INFO:Checking exceptions
2025-05-12 22:25:29,570:INFO:Importing libraries
2025-05-12 22:25:29,570:INFO:Copying training dataset
2025-05-12 22:25:29,576:INFO:Defining folds
2025-05-12 22:25:29,576:INFO:Declaring metric variables
2025-05-12 22:25:29,581:INFO:Importing untrained model
2025-05-12 22:25:29,581:INFO:Declaring custom model
2025-05-12 22:25:29,590:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:25:29,603:INFO:Starting cross validation
2025-05-12 22:25:29,606:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:30,115:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:30,116:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:30,135:INFO:Calculating mean and std
2025-05-12 22:25:30,137:INFO:Creating metrics dataframe
2025-05-12 22:25:30,150:INFO:Finalizing model
2025-05-12 22:25:30,215:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:25:30,215:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:25:30,215:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:25:30,215:INFO:[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.
2025-05-12 22:25:30,217:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:25:30,217:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:25:30,217:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:25:30,217:INFO:[LightGBM] [Info] Total Bins 0
2025-05-12 22:25:30,217:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 0
2025-05-12 22:25:30,217:INFO:[LightGBM] [Info] Start training from score 0.161905
2025-05-12 22:25:30,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,229:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,232:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,232:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,232:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,236:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,236:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,236:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,236:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,236:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:25:30,249:INFO:Uploading results into container
2025-05-12 22:25:30,250:INFO:Uploading model into container now
2025-05-12 22:25:30,251:INFO:_master_model_container: 20
2025-05-12 22:25:30,251:INFO:_display_container: 4
2025-05-12 22:25:30,254:INFO:LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:25:30,254:INFO:create_model() successfully completed......................................
2025-05-12 22:25:30,435:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:30,435:INFO:choose_better activated
2025-05-12 22:25:30,446:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:30,448:INFO:Initializing create_model()
2025-05-12 22:25:30,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:30,449:INFO:Checking exceptions
2025-05-12 22:25:30,451:INFO:Importing libraries
2025-05-12 22:25:30,453:INFO:Copying training dataset
2025-05-12 22:25:30,457:INFO:Defining folds
2025-05-12 22:25:30,457:INFO:Declaring metric variables
2025-05-12 22:25:30,459:INFO:Importing untrained model
2025-05-12 22:25:30,459:INFO:Declaring custom model
2025-05-12 22:25:30,460:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:25:30,460:INFO:Starting cross validation
2025-05-12 22:25:30,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:31,067:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:31,067:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:31,097:INFO:Calculating mean and std
2025-05-12 22:25:31,098:INFO:Creating metrics dataframe
2025-05-12 22:25:31,101:INFO:Finalizing model
2025-05-12 22:25:31,238:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.
2025-05-12 22:25:31,238:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-12 22:25:31,238:INFO:[LightGBM] [Info] Total Bins 116
2025-05-12 22:25:31,238:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:25:31,239:INFO:[LightGBM] [Info] Start training from score 0.161905
2025-05-12 22:25:31,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:25:31,337:INFO:Uploading results into container
2025-05-12 22:25:31,338:INFO:Uploading model into container now
2025-05-12 22:25:31,339:INFO:_master_model_container: 21
2025-05-12 22:25:31,339:INFO:_display_container: 5
2025-05-12 22:25:31,340:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:25:31,340:INFO:create_model() successfully completed......................................
2025-05-12 22:25:31,483:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:31,483:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for R2 is -0.2315
2025-05-12 22:25:31,484:INFO:LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) result for R2 is -0.0421
2025-05-12 22:25:31,486:INFO:LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-12 22:25:31,486:INFO:choose_better completed
2025-05-12 22:25:31,498:INFO:_master_model_container: 21
2025-05-12 22:25:31,498:INFO:_display_container: 4
2025-05-12 22:25:31,500:INFO:LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:25:31,500:INFO:tune_model() successfully completed......................................
2025-05-12 22:25:31,671:INFO:Initializing evaluate_model()
2025-05-12 22:25:31,671:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:25:31,687:INFO:Initializing plot_model()
2025-05-12 22:25:31,687:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:25:31,688:INFO:Checking exceptions
2025-05-12 22:25:31,692:INFO:Preloading libraries
2025-05-12 22:25:31,693:INFO:Copying training dataset
2025-05-12 22:25:31,693:INFO:Plot type: pipeline
2025-05-12 22:25:31,900:INFO:Visual Rendered Successfully
2025-05-12 22:25:32,019:INFO:plot_model() successfully completed......................................
2025-05-12 22:25:32,044:INFO:Initializing predict_model()
2025-05-12 22:25:32,044:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DEF3ED0>, estimator=LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EA7B591C60>)
2025-05-12 22:25:32,046:INFO:Checking exceptions
2025-05-12 22:25:32,046:INFO:Preloading libraries
2025-05-12 22:25:32,169:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:25:32,358:INFO:Initializing save_model()
2025-05-12 22:25:32,358:INFO:save_model(model=LGBMRegressor(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
              class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
              importance_type='split', learning_rate=1e-07, max_depth=-1,
              min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
              n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
              random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-12 22:25:32,358:INFO:Adding model into prep_pipe
2025-05-12 22:25:32,372:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:25:32,389:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                               boosting_type='gbdt', class_weight=None,
                               colsample_bytree=1.0, feature_fraction=0.9,
                               importance_type='split', learning_rate=1e-07,
                               max_depth=-1, min_child_samples=91,
                               min_child_weight=0.001, min_split_gain=0.5,
                               n_estimators=130, n_jobs=-1, num_leaves=80,
                               objective=None, random_state=123, reg_alpha=4,
                               reg_lambda=1e-06, subsample=1.0,
                               subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-12 22:25:32,389:INFO:save_model() successfully completed......................................
2025-05-12 22:25:36,929:INFO:PyCaret RegressionExperiment
2025-05-12 22:25:36,930:INFO:Logging name: reg-default-name
2025-05-12 22:25:36,930:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:25:36,930:INFO:version 3.3.2
2025-05-12 22:25:36,930:INFO:Initializing setup()
2025-05-12 22:25:36,930:INFO:self.USI: 53fa
2025-05-12 22:25:36,930:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'transform_target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:25:36,930:INFO:Checking environment
2025-05-12 22:25:36,930:INFO:python_version: 3.11.8
2025-05-12 22:25:36,930:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:25:36,930:INFO:machine: AMD64
2025-05-12 22:25:36,930:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:25:36,935:INFO:Memory: svmem(total=16907886592, available=2867486720, percent=83.0, used=14040399872, free=2867486720)
2025-05-12 22:25:36,935:INFO:Physical Core: 4
2025-05-12 22:25:36,935:INFO:Logical Core: 8
2025-05-12 22:25:36,935:INFO:Checking libraries
2025-05-12 22:25:36,936:INFO:System:
2025-05-12 22:25:36,936:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:25:36,936:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:25:36,936:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:25:36,936:INFO:PyCaret required dependencies:
2025-05-12 22:25:36,936:INFO:                 pip: 24.0
2025-05-12 22:25:36,936:INFO:          setuptools: 65.5.0
2025-05-12 22:25:36,936:INFO:             pycaret: 3.3.2
2025-05-12 22:25:36,936:INFO:             IPython: 9.2.0
2025-05-12 22:25:36,936:INFO:          ipywidgets: 8.1.7
2025-05-12 22:25:36,936:INFO:                tqdm: 4.67.1
2025-05-12 22:25:36,936:INFO:               numpy: 1.26.4
2025-05-12 22:25:36,936:INFO:              pandas: 2.1.4
2025-05-12 22:25:36,936:INFO:              jinja2: 3.1.6
2025-05-12 22:25:36,936:INFO:               scipy: 1.11.4
2025-05-12 22:25:36,936:INFO:              joblib: 1.3.2
2025-05-12 22:25:36,936:INFO:             sklearn: 1.4.2
2025-05-12 22:25:36,936:INFO:                pyod: 2.0.5
2025-05-12 22:25:36,936:INFO:            imblearn: 0.13.0
2025-05-12 22:25:36,936:INFO:   category_encoders: 2.7.0
2025-05-12 22:25:36,936:INFO:            lightgbm: 4.6.0
2025-05-12 22:25:36,936:INFO:               numba: 0.61.2
2025-05-12 22:25:36,936:INFO:            requests: 2.32.3
2025-05-12 22:25:36,936:INFO:          matplotlib: 3.7.5
2025-05-12 22:25:36,936:INFO:          scikitplot: 0.3.7
2025-05-12 22:25:36,936:INFO:         yellowbrick: 1.5
2025-05-12 22:25:36,936:INFO:              plotly: 5.24.1
2025-05-12 22:25:36,936:INFO:    plotly-resampler: Not installed
2025-05-12 22:25:36,936:INFO:             kaleido: 0.2.1
2025-05-12 22:25:36,936:INFO:           schemdraw: 0.15
2025-05-12 22:25:36,936:INFO:         statsmodels: 0.14.4
2025-05-12 22:25:36,936:INFO:              sktime: 0.26.0
2025-05-12 22:25:36,936:INFO:               tbats: 1.1.3
2025-05-12 22:25:36,936:INFO:            pmdarima: 2.0.4
2025-05-12 22:25:36,936:INFO:              psutil: 7.0.0
2025-05-12 22:25:36,936:INFO:          markupsafe: 3.0.2
2025-05-12 22:25:36,936:INFO:             pickle5: Not installed
2025-05-12 22:25:36,937:INFO:         cloudpickle: 3.1.1
2025-05-12 22:25:36,937:INFO:         deprecation: 2.1.0
2025-05-12 22:25:36,937:INFO:              xxhash: 3.5.0
2025-05-12 22:25:36,937:INFO:           wurlitzer: Not installed
2025-05-12 22:25:36,937:INFO:PyCaret optional dependencies:
2025-05-12 22:25:36,937:INFO:                shap: Not installed
2025-05-12 22:25:36,937:INFO:           interpret: Not installed
2025-05-12 22:25:36,937:INFO:                umap: Not installed
2025-05-12 22:25:36,937:INFO:     ydata_profiling: Not installed
2025-05-12 22:25:36,937:INFO:  explainerdashboard: Not installed
2025-05-12 22:25:36,937:INFO:             autoviz: Not installed
2025-05-12 22:25:36,937:INFO:           fairlearn: Not installed
2025-05-12 22:25:36,937:INFO:          deepchecks: Not installed
2025-05-12 22:25:36,937:INFO:             xgboost: Not installed
2025-05-12 22:25:36,937:INFO:            catboost: Not installed
2025-05-12 22:25:36,937:INFO:              kmodes: Not installed
2025-05-12 22:25:36,937:INFO:             mlxtend: Not installed
2025-05-12 22:25:36,937:INFO:       statsforecast: Not installed
2025-05-12 22:25:36,937:INFO:        tune_sklearn: Not installed
2025-05-12 22:25:36,937:INFO:                 ray: Not installed
2025-05-12 22:25:36,937:INFO:            hyperopt: Not installed
2025-05-12 22:25:36,937:INFO:              optuna: Not installed
2025-05-12 22:25:36,937:INFO:               skopt: Not installed
2025-05-12 22:25:36,937:INFO:              mlflow: Not installed
2025-05-12 22:25:36,937:INFO:              gradio: Not installed
2025-05-12 22:25:36,937:INFO:             fastapi: Not installed
2025-05-12 22:25:36,937:INFO:             uvicorn: Not installed
2025-05-12 22:25:36,937:INFO:              m2cgen: Not installed
2025-05-12 22:25:36,937:INFO:           evidently: Not installed
2025-05-12 22:25:36,937:INFO:               fugue: Not installed
2025-05-12 22:25:36,937:INFO:           streamlit: Not installed
2025-05-12 22:25:36,937:INFO:             prophet: Not installed
2025-05-12 22:25:36,937:INFO:None
2025-05-12 22:25:36,937:INFO:Set up data.
2025-05-12 22:25:36,941:INFO:Set up folding strategy.
2025-05-12 22:25:36,941:INFO:Set up train/test split.
2025-05-12 22:25:36,943:INFO:Set up index.
2025-05-12 22:25:36,943:INFO:Assigning column types.
2025-05-12 22:25:36,944:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:25:36,946:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:25:36,949:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:36,952:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:36,997:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,033:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,036:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,040:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,084:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,119:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,120:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:25:37,123:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,128:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,173:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,206:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,211:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,214:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,259:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,293:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,294:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:25:37,302:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,346:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,379:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,379:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,379:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,386:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,429:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,466:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,467:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:25:37,519:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,553:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,605:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,648:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,648:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,648:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,648:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:25:37,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,786:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:25:37,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,821:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,823:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:25:37,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:37,914:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:38,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:38,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:38,009:INFO:Preparing preprocessing pipeline...
2025-05-12 22:25:38,009:INFO:Set up simple imputation.
2025-05-12 22:25:38,010:INFO:Set up encoding of categorical features.
2025-05-12 22:25:38,010:INFO:Set up feature normalization.
2025-05-12 22:25:38,056:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:25:38,061:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:25:38,061:INFO:Creating final display dataframe.
2025-05-12 22:25:38,188:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type        Regression
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              53fa
2025-05-12 22:25:38,286:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:38,286:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:38,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:38,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:25:38,381:INFO:setup() successfully completed in 1.45s...............
2025-05-12 22:25:38,394:INFO:Initializing compare_models()
2025-05-12 22:25:38,394:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 22:25:38,394:INFO:Checking exceptions
2025-05-12 22:25:38,397:INFO:Preparing display monitor
2025-05-12 22:25:38,420:INFO:Initializing Linear Regression
2025-05-12 22:25:38,420:INFO:Total runtime is 0.0 minutes
2025-05-12 22:25:38,424:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:38,425:INFO:Initializing create_model()
2025-05-12 22:25:38,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:38,425:INFO:Checking exceptions
2025-05-12 22:25:38,425:INFO:Importing libraries
2025-05-12 22:25:38,425:INFO:Copying training dataset
2025-05-12 22:25:38,429:INFO:Defining folds
2025-05-12 22:25:38,429:INFO:Declaring metric variables
2025-05-12 22:25:38,434:INFO:Importing untrained model
2025-05-12 22:25:38,438:INFO:Linear Regression Imported successfully
2025-05-12 22:25:38,446:INFO:Starting cross validation
2025-05-12 22:25:38,449:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:38,741:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:38,741:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:38,749:INFO:Calculating mean and std
2025-05-12 22:25:38,750:INFO:Creating metrics dataframe
2025-05-12 22:25:38,751:INFO:Uploading results into container
2025-05-12 22:25:38,753:INFO:Uploading model into container now
2025-05-12 22:25:38,754:INFO:_master_model_container: 1
2025-05-12 22:25:38,754:INFO:_display_container: 2
2025-05-12 22:25:38,754:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-05-12 22:25:38,754:INFO:create_model() successfully completed......................................
2025-05-12 22:25:38,897:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:38,897:INFO:Creating metrics dataframe
2025-05-12 22:25:38,927:INFO:Initializing Lasso Regression
2025-05-12 22:25:38,927:INFO:Total runtime is 0.008444428443908691 minutes
2025-05-12 22:25:38,933:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:38,933:INFO:Initializing create_model()
2025-05-12 22:25:38,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:38,935:INFO:Checking exceptions
2025-05-12 22:25:38,935:INFO:Importing libraries
2025-05-12 22:25:38,935:INFO:Copying training dataset
2025-05-12 22:25:38,941:INFO:Defining folds
2025-05-12 22:25:38,941:INFO:Declaring metric variables
2025-05-12 22:25:38,947:INFO:Importing untrained model
2025-05-12 22:25:38,953:INFO:Lasso Regression Imported successfully
2025-05-12 22:25:38,968:INFO:Starting cross validation
2025-05-12 22:25:38,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:39,263:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:39,263:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:39,268:INFO:Calculating mean and std
2025-05-12 22:25:39,269:INFO:Creating metrics dataframe
2025-05-12 22:25:39,271:INFO:Uploading results into container
2025-05-12 22:25:39,271:INFO:Uploading model into container now
2025-05-12 22:25:39,272:INFO:_master_model_container: 2
2025-05-12 22:25:39,272:INFO:_display_container: 2
2025-05-12 22:25:39,272:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-05-12 22:25:39,272:INFO:create_model() successfully completed......................................
2025-05-12 22:25:39,380:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:39,380:INFO:Creating metrics dataframe
2025-05-12 22:25:39,387:INFO:Initializing Ridge Regression
2025-05-12 22:25:39,387:INFO:Total runtime is 0.016120497385660806 minutes
2025-05-12 22:25:39,391:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:39,391:INFO:Initializing create_model()
2025-05-12 22:25:39,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:39,391:INFO:Checking exceptions
2025-05-12 22:25:39,392:INFO:Importing libraries
2025-05-12 22:25:39,392:INFO:Copying training dataset
2025-05-12 22:25:39,395:INFO:Defining folds
2025-05-12 22:25:39,395:INFO:Declaring metric variables
2025-05-12 22:25:39,398:INFO:Importing untrained model
2025-05-12 22:25:39,401:INFO:Ridge Regression Imported successfully
2025-05-12 22:25:39,410:INFO:Starting cross validation
2025-05-12 22:25:39,412:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:39,644:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:39,644:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:39,647:INFO:Calculating mean and std
2025-05-12 22:25:39,649:INFO:Creating metrics dataframe
2025-05-12 22:25:39,654:INFO:Uploading results into container
2025-05-12 22:25:39,655:INFO:Uploading model into container now
2025-05-12 22:25:39,656:INFO:_master_model_container: 3
2025-05-12 22:25:39,656:INFO:_display_container: 2
2025-05-12 22:25:39,657:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-05-12 22:25:39,658:INFO:create_model() successfully completed......................................
2025-05-12 22:25:39,793:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:39,793:INFO:Creating metrics dataframe
2025-05-12 22:25:39,801:INFO:Initializing Elastic Net
2025-05-12 22:25:39,801:INFO:Total runtime is 0.023012268543243408 minutes
2025-05-12 22:25:39,804:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:39,804:INFO:Initializing create_model()
2025-05-12 22:25:39,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:39,806:INFO:Checking exceptions
2025-05-12 22:25:39,806:INFO:Importing libraries
2025-05-12 22:25:39,806:INFO:Copying training dataset
2025-05-12 22:25:39,812:INFO:Defining folds
2025-05-12 22:25:39,813:INFO:Declaring metric variables
2025-05-12 22:25:39,817:INFO:Importing untrained model
2025-05-12 22:25:39,824:INFO:Elastic Net Imported successfully
2025-05-12 22:25:39,836:INFO:Starting cross validation
2025-05-12 22:25:39,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:40,115:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:40,115:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:40,122:INFO:Calculating mean and std
2025-05-12 22:25:40,124:INFO:Creating metrics dataframe
2025-05-12 22:25:40,127:INFO:Uploading results into container
2025-05-12 22:25:40,129:INFO:Uploading model into container now
2025-05-12 22:25:40,130:INFO:_master_model_container: 4
2025-05-12 22:25:40,130:INFO:_display_container: 2
2025-05-12 22:25:40,131:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-05-12 22:25:40,131:INFO:create_model() successfully completed......................................
2025-05-12 22:25:40,256:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:40,256:INFO:Creating metrics dataframe
2025-05-12 22:25:40,267:INFO:Initializing Least Angle Regression
2025-05-12 22:25:40,267:INFO:Total runtime is 0.030776119232177733 minutes
2025-05-12 22:25:40,272:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:40,273:INFO:Initializing create_model()
2025-05-12 22:25:40,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:40,273:INFO:Checking exceptions
2025-05-12 22:25:40,273:INFO:Importing libraries
2025-05-12 22:25:40,273:INFO:Copying training dataset
2025-05-12 22:25:40,279:INFO:Defining folds
2025-05-12 22:25:40,280:INFO:Declaring metric variables
2025-05-12 22:25:40,284:INFO:Importing untrained model
2025-05-12 22:25:40,291:INFO:Least Angle Regression Imported successfully
2025-05-12 22:25:40,303:INFO:Starting cross validation
2025-05-12 22:25:40,306:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:40,638:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:40,638:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:40,649:INFO:Calculating mean and std
2025-05-12 22:25:40,650:INFO:Creating metrics dataframe
2025-05-12 22:25:40,653:INFO:Uploading results into container
2025-05-12 22:25:40,654:INFO:Uploading model into container now
2025-05-12 22:25:40,654:INFO:_master_model_container: 5
2025-05-12 22:25:40,654:INFO:_display_container: 2
2025-05-12 22:25:40,656:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-05-12 22:25:40,656:INFO:create_model() successfully completed......................................
2025-05-12 22:25:40,770:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:40,770:INFO:Creating metrics dataframe
2025-05-12 22:25:40,780:INFO:Initializing Lasso Least Angle Regression
2025-05-12 22:25:40,780:INFO:Total runtime is 0.03933552503585815 minutes
2025-05-12 22:25:40,784:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:40,784:INFO:Initializing create_model()
2025-05-12 22:25:40,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:40,785:INFO:Checking exceptions
2025-05-12 22:25:40,785:INFO:Importing libraries
2025-05-12 22:25:40,785:INFO:Copying training dataset
2025-05-12 22:25:40,790:INFO:Defining folds
2025-05-12 22:25:40,791:INFO:Declaring metric variables
2025-05-12 22:25:40,795:INFO:Importing untrained model
2025-05-12 22:25:40,800:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:25:40,809:INFO:Starting cross validation
2025-05-12 22:25:40,811:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:41,045:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:41,045:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:41,056:INFO:Calculating mean and std
2025-05-12 22:25:41,058:INFO:Creating metrics dataframe
2025-05-12 22:25:41,060:INFO:Uploading results into container
2025-05-12 22:25:41,060:INFO:Uploading model into container now
2025-05-12 22:25:41,061:INFO:_master_model_container: 6
2025-05-12 22:25:41,061:INFO:_display_container: 2
2025-05-12 22:25:41,062:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-05-12 22:25:41,062:INFO:create_model() successfully completed......................................
2025-05-12 22:25:41,166:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:41,166:INFO:Creating metrics dataframe
2025-05-12 22:25:41,173:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 22:25:41,174:INFO:Total runtime is 0.04587920904159546 minutes
2025-05-12 22:25:41,178:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:41,178:INFO:Initializing create_model()
2025-05-12 22:25:41,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:41,178:INFO:Checking exceptions
2025-05-12 22:25:41,179:INFO:Importing libraries
2025-05-12 22:25:41,179:INFO:Copying training dataset
2025-05-12 22:25:41,183:INFO:Defining folds
2025-05-12 22:25:41,183:INFO:Declaring metric variables
2025-05-12 22:25:41,186:INFO:Importing untrained model
2025-05-12 22:25:41,191:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 22:25:41,199:INFO:Starting cross validation
2025-05-12 22:25:41,200:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:41,416:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:41,416:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:41,418:INFO:Calculating mean and std
2025-05-12 22:25:41,420:INFO:Creating metrics dataframe
2025-05-12 22:25:41,421:INFO:Uploading results into container
2025-05-12 22:25:41,422:INFO:Uploading model into container now
2025-05-12 22:25:41,423:INFO:_master_model_container: 7
2025-05-12 22:25:41,423:INFO:_display_container: 2
2025-05-12 22:25:41,423:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-05-12 22:25:41,423:INFO:create_model() successfully completed......................................
2025-05-12 22:25:41,526:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:41,527:INFO:Creating metrics dataframe
2025-05-12 22:25:41,535:INFO:Initializing Bayesian Ridge
2025-05-12 22:25:41,536:INFO:Total runtime is 0.05192452669143677 minutes
2025-05-12 22:25:41,540:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:41,541:INFO:Initializing create_model()
2025-05-12 22:25:41,541:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:41,541:INFO:Checking exceptions
2025-05-12 22:25:41,541:INFO:Importing libraries
2025-05-12 22:25:41,541:INFO:Copying training dataset
2025-05-12 22:25:41,546:INFO:Defining folds
2025-05-12 22:25:41,546:INFO:Declaring metric variables
2025-05-12 22:25:41,550:INFO:Importing untrained model
2025-05-12 22:25:41,555:INFO:Bayesian Ridge Imported successfully
2025-05-12 22:25:41,563:INFO:Starting cross validation
2025-05-12 22:25:41,565:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:41,817:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:41,817:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:41,826:INFO:Calculating mean and std
2025-05-12 22:25:41,827:INFO:Creating metrics dataframe
2025-05-12 22:25:41,829:INFO:Uploading results into container
2025-05-12 22:25:41,830:INFO:Uploading model into container now
2025-05-12 22:25:41,830:INFO:_master_model_container: 8
2025-05-12 22:25:41,830:INFO:_display_container: 2
2025-05-12 22:25:41,831:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-05-12 22:25:41,831:INFO:create_model() successfully completed......................................
2025-05-12 22:25:41,934:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:41,934:INFO:Creating metrics dataframe
2025-05-12 22:25:41,943:INFO:Initializing Passive Aggressive Regressor
2025-05-12 22:25:41,943:INFO:Total runtime is 0.05871344407399495 minutes
2025-05-12 22:25:41,947:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:41,948:INFO:Initializing create_model()
2025-05-12 22:25:41,948:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:41,948:INFO:Checking exceptions
2025-05-12 22:25:41,948:INFO:Importing libraries
2025-05-12 22:25:41,948:INFO:Copying training dataset
2025-05-12 22:25:41,953:INFO:Defining folds
2025-05-12 22:25:41,953:INFO:Declaring metric variables
2025-05-12 22:25:41,958:INFO:Importing untrained model
2025-05-12 22:25:41,963:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 22:25:41,970:INFO:Starting cross validation
2025-05-12 22:25:41,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:42,196:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:42,196:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:42,203:INFO:Calculating mean and std
2025-05-12 22:25:42,204:INFO:Creating metrics dataframe
2025-05-12 22:25:42,206:INFO:Uploading results into container
2025-05-12 22:25:42,207:INFO:Uploading model into container now
2025-05-12 22:25:42,207:INFO:_master_model_container: 9
2025-05-12 22:25:42,207:INFO:_display_container: 2
2025-05-12 22:25:42,207:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-12 22:25:42,208:INFO:create_model() successfully completed......................................
2025-05-12 22:25:42,323:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:42,323:INFO:Creating metrics dataframe
2025-05-12 22:25:42,331:INFO:Initializing Huber Regressor
2025-05-12 22:25:42,331:INFO:Total runtime is 0.0651872436205546 minutes
2025-05-12 22:25:42,336:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:42,336:INFO:Initializing create_model()
2025-05-12 22:25:42,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:42,336:INFO:Checking exceptions
2025-05-12 22:25:42,337:INFO:Importing libraries
2025-05-12 22:25:42,337:INFO:Copying training dataset
2025-05-12 22:25:42,343:INFO:Defining folds
2025-05-12 22:25:42,343:INFO:Declaring metric variables
2025-05-12 22:25:42,346:INFO:Importing untrained model
2025-05-12 22:25:42,349:INFO:Huber Regressor Imported successfully
2025-05-12 22:25:42,358:INFO:Starting cross validation
2025-05-12 22:25:42,361:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:42,890:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:42,890:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:42,897:INFO:Calculating mean and std
2025-05-12 22:25:42,899:INFO:Creating metrics dataframe
2025-05-12 22:25:42,901:INFO:Uploading results into container
2025-05-12 22:25:42,902:INFO:Uploading model into container now
2025-05-12 22:25:42,903:INFO:_master_model_container: 10
2025-05-12 22:25:42,903:INFO:_display_container: 2
2025-05-12 22:25:42,904:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-05-12 22:25:42,904:INFO:create_model() successfully completed......................................
2025-05-12 22:25:43,032:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:43,032:INFO:Creating metrics dataframe
2025-05-12 22:25:43,043:INFO:Initializing K Neighbors Regressor
2025-05-12 22:25:43,043:INFO:Total runtime is 0.07705143292744954 minutes
2025-05-12 22:25:43,047:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:43,048:INFO:Initializing create_model()
2025-05-12 22:25:43,048:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:43,049:INFO:Checking exceptions
2025-05-12 22:25:43,049:INFO:Importing libraries
2025-05-12 22:25:43,049:INFO:Copying training dataset
2025-05-12 22:25:43,057:INFO:Defining folds
2025-05-12 22:25:43,058:INFO:Declaring metric variables
2025-05-12 22:25:43,065:INFO:Importing untrained model
2025-05-12 22:25:43,071:INFO:K Neighbors Regressor Imported successfully
2025-05-12 22:25:43,083:INFO:Starting cross validation
2025-05-12 22:25:43,084:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:43,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:43,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:43,407:INFO:Calculating mean and std
2025-05-12 22:25:43,409:INFO:Creating metrics dataframe
2025-05-12 22:25:43,410:INFO:Uploading results into container
2025-05-12 22:25:43,411:INFO:Uploading model into container now
2025-05-12 22:25:43,411:INFO:_master_model_container: 11
2025-05-12 22:25:43,411:INFO:_display_container: 2
2025-05-12 22:25:43,412:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-05-12 22:25:43,412:INFO:create_model() successfully completed......................................
2025-05-12 22:25:43,515:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:43,515:INFO:Creating metrics dataframe
2025-05-12 22:25:43,526:INFO:Initializing Decision Tree Regressor
2025-05-12 22:25:43,527:INFO:Total runtime is 0.08510981003443399 minutes
2025-05-12 22:25:43,530:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:43,531:INFO:Initializing create_model()
2025-05-12 22:25:43,531:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:43,531:INFO:Checking exceptions
2025-05-12 22:25:43,531:INFO:Importing libraries
2025-05-12 22:25:43,531:INFO:Copying training dataset
2025-05-12 22:25:43,537:INFO:Defining folds
2025-05-12 22:25:43,537:INFO:Declaring metric variables
2025-05-12 22:25:43,541:INFO:Importing untrained model
2025-05-12 22:25:43,546:INFO:Decision Tree Regressor Imported successfully
2025-05-12 22:25:43,557:INFO:Starting cross validation
2025-05-12 22:25:43,559:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:43,859:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:43,859:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:43,870:INFO:Calculating mean and std
2025-05-12 22:25:43,871:INFO:Creating metrics dataframe
2025-05-12 22:25:43,874:INFO:Uploading results into container
2025-05-12 22:25:43,875:INFO:Uploading model into container now
2025-05-12 22:25:43,875:INFO:_master_model_container: 12
2025-05-12 22:25:43,876:INFO:_display_container: 2
2025-05-12 22:25:43,876:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-05-12 22:25:43,877:INFO:create_model() successfully completed......................................
2025-05-12 22:25:43,993:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:43,993:INFO:Creating metrics dataframe
2025-05-12 22:25:44,003:INFO:Initializing Random Forest Regressor
2025-05-12 22:25:44,003:INFO:Total runtime is 0.09304766257603962 minutes
2025-05-12 22:25:44,007:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:44,008:INFO:Initializing create_model()
2025-05-12 22:25:44,008:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:44,008:INFO:Checking exceptions
2025-05-12 22:25:44,008:INFO:Importing libraries
2025-05-12 22:25:44,008:INFO:Copying training dataset
2025-05-12 22:25:44,014:INFO:Defining folds
2025-05-12 22:25:44,014:INFO:Declaring metric variables
2025-05-12 22:25:44,020:INFO:Importing untrained model
2025-05-12 22:25:44,026:INFO:Random Forest Regressor Imported successfully
2025-05-12 22:25:44,036:INFO:Starting cross validation
2025-05-12 22:25:44,038:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:44,989:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:44,989:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:44,997:INFO:Calculating mean and std
2025-05-12 22:25:44,998:INFO:Creating metrics dataframe
2025-05-12 22:25:44,999:INFO:Uploading results into container
2025-05-12 22:25:45,000:INFO:Uploading model into container now
2025-05-12 22:25:45,001:INFO:_master_model_container: 13
2025-05-12 22:25:45,001:INFO:_display_container: 2
2025-05-12 22:25:45,001:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-05-12 22:25:45,003:INFO:create_model() successfully completed......................................
2025-05-12 22:25:45,106:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:45,107:INFO:Creating metrics dataframe
2025-05-12 22:25:45,117:INFO:Initializing Extra Trees Regressor
2025-05-12 22:25:45,117:INFO:Total runtime is 0.11161555846532184 minutes
2025-05-12 22:25:45,123:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:45,123:INFO:Initializing create_model()
2025-05-12 22:25:45,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:45,124:INFO:Checking exceptions
2025-05-12 22:25:45,124:INFO:Importing libraries
2025-05-12 22:25:45,124:INFO:Copying training dataset
2025-05-12 22:25:45,128:INFO:Defining folds
2025-05-12 22:25:45,128:INFO:Declaring metric variables
2025-05-12 22:25:45,131:INFO:Importing untrained model
2025-05-12 22:25:45,137:INFO:Extra Trees Regressor Imported successfully
2025-05-12 22:25:45,147:INFO:Starting cross validation
2025-05-12 22:25:45,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:46,013:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:46,014:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:46,015:INFO:Calculating mean and std
2025-05-12 22:25:46,016:INFO:Creating metrics dataframe
2025-05-12 22:25:46,017:INFO:Uploading results into container
2025-05-12 22:25:46,019:INFO:Uploading model into container now
2025-05-12 22:25:46,020:INFO:_master_model_container: 14
2025-05-12 22:25:46,020:INFO:_display_container: 2
2025-05-12 22:25:46,021:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-05-12 22:25:46,021:INFO:create_model() successfully completed......................................
2025-05-12 22:25:46,129:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:46,130:INFO:Creating metrics dataframe
2025-05-12 22:25:46,141:INFO:Initializing AdaBoost Regressor
2025-05-12 22:25:46,143:INFO:Total runtime is 0.1287141720453898 minutes
2025-05-12 22:25:46,148:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:46,149:INFO:Initializing create_model()
2025-05-12 22:25:46,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:46,149:INFO:Checking exceptions
2025-05-12 22:25:46,149:INFO:Importing libraries
2025-05-12 22:25:46,149:INFO:Copying training dataset
2025-05-12 22:25:46,155:INFO:Defining folds
2025-05-12 22:25:46,155:INFO:Declaring metric variables
2025-05-12 22:25:46,159:INFO:Importing untrained model
2025-05-12 22:25:46,164:INFO:AdaBoost Regressor Imported successfully
2025-05-12 22:25:46,172:INFO:Starting cross validation
2025-05-12 22:25:46,175:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:46,818:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:46,818:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:46,825:INFO:Calculating mean and std
2025-05-12 22:25:46,827:INFO:Creating metrics dataframe
2025-05-12 22:25:46,829:INFO:Uploading results into container
2025-05-12 22:25:46,829:INFO:Uploading model into container now
2025-05-12 22:25:46,830:INFO:_master_model_container: 15
2025-05-12 22:25:46,830:INFO:_display_container: 2
2025-05-12 22:25:46,830:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-05-12 22:25:46,830:INFO:create_model() successfully completed......................................
2025-05-12 22:25:46,941:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:46,941:INFO:Creating metrics dataframe
2025-05-12 22:25:46,953:INFO:Initializing Gradient Boosting Regressor
2025-05-12 22:25:46,953:INFO:Total runtime is 0.1422084371248881 minutes
2025-05-12 22:25:46,957:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:46,957:INFO:Initializing create_model()
2025-05-12 22:25:46,957:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:46,957:INFO:Checking exceptions
2025-05-12 22:25:46,957:INFO:Importing libraries
2025-05-12 22:25:46,958:INFO:Copying training dataset
2025-05-12 22:25:46,962:INFO:Defining folds
2025-05-12 22:25:46,962:INFO:Declaring metric variables
2025-05-12 22:25:46,965:INFO:Importing untrained model
2025-05-12 22:25:46,971:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 22:25:46,979:INFO:Starting cross validation
2025-05-12 22:25:46,981:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:47,441:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:47,441:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:47,445:INFO:Calculating mean and std
2025-05-12 22:25:47,446:INFO:Creating metrics dataframe
2025-05-12 22:25:47,447:INFO:Uploading results into container
2025-05-12 22:25:47,449:INFO:Uploading model into container now
2025-05-12 22:25:47,450:INFO:_master_model_container: 16
2025-05-12 22:25:47,450:INFO:_display_container: 2
2025-05-12 22:25:47,451:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-12 22:25:47,451:INFO:create_model() successfully completed......................................
2025-05-12 22:25:47,551:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:47,551:INFO:Creating metrics dataframe
2025-05-12 22:25:47,563:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:25:47,563:INFO:Total runtime is 0.15237617095311481 minutes
2025-05-12 22:25:47,567:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:47,568:INFO:Initializing create_model()
2025-05-12 22:25:47,568:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:47,568:INFO:Checking exceptions
2025-05-12 22:25:47,568:INFO:Importing libraries
2025-05-12 22:25:47,568:INFO:Copying training dataset
2025-05-12 22:25:47,573:INFO:Defining folds
2025-05-12 22:25:47,573:INFO:Declaring metric variables
2025-05-12 22:25:47,577:INFO:Importing untrained model
2025-05-12 22:25:47,583:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:25:47,608:INFO:Starting cross validation
2025-05-12 22:25:47,610:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:48,302:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:48,303:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:48,313:INFO:Calculating mean and std
2025-05-12 22:25:48,317:INFO:Creating metrics dataframe
2025-05-12 22:25:48,321:INFO:Uploading results into container
2025-05-12 22:25:48,323:INFO:Uploading model into container now
2025-05-12 22:25:48,324:INFO:_master_model_container: 17
2025-05-12 22:25:48,324:INFO:_display_container: 2
2025-05-12 22:25:48,325:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:25:48,326:INFO:create_model() successfully completed......................................
2025-05-12 22:25:48,467:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:48,467:INFO:Creating metrics dataframe
2025-05-12 22:25:48,481:INFO:Initializing Dummy Regressor
2025-05-12 22:25:48,481:INFO:Total runtime is 0.16768298546473184 minutes
2025-05-12 22:25:48,486:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:48,487:INFO:Initializing create_model()
2025-05-12 22:25:48,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E734610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:48,487:INFO:Checking exceptions
2025-05-12 22:25:48,487:INFO:Importing libraries
2025-05-12 22:25:48,487:INFO:Copying training dataset
2025-05-12 22:25:48,492:INFO:Defining folds
2025-05-12 22:25:48,492:INFO:Declaring metric variables
2025-05-12 22:25:48,496:INFO:Importing untrained model
2025-05-12 22:25:48,501:INFO:Dummy Regressor Imported successfully
2025-05-12 22:25:48,513:INFO:Starting cross validation
2025-05-12 22:25:48,517:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:48,749:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:48,750:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:48,764:INFO:Calculating mean and std
2025-05-12 22:25:48,766:INFO:Creating metrics dataframe
2025-05-12 22:25:48,768:INFO:Uploading results into container
2025-05-12 22:25:48,769:INFO:Uploading model into container now
2025-05-12 22:25:48,770:INFO:_master_model_container: 18
2025-05-12 22:25:48,770:INFO:_display_container: 2
2025-05-12 22:25:48,770:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-05-12 22:25:48,771:INFO:create_model() successfully completed......................................
2025-05-12 22:25:48,874:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:48,874:INFO:Creating metrics dataframe
2025-05-12 22:25:48,884:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:25:48,894:INFO:Initializing create_model()
2025-05-12 22:25:48,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:48,894:INFO:Checking exceptions
2025-05-12 22:25:48,896:INFO:Importing libraries
2025-05-12 22:25:48,896:INFO:Copying training dataset
2025-05-12 22:25:48,899:INFO:Defining folds
2025-05-12 22:25:48,899:INFO:Declaring metric variables
2025-05-12 22:25:48,899:INFO:Importing untrained model
2025-05-12 22:25:48,900:INFO:Declaring custom model
2025-05-12 22:25:48,900:INFO:Lasso Regression Imported successfully
2025-05-12 22:25:48,901:INFO:Cross validation set to False
2025-05-12 22:25:48,901:INFO:Fitting Model
2025-05-12 22:25:48,948:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-05-12 22:25:48,948:INFO:create_model() successfully completed......................................
2025-05-12 22:25:49,129:INFO:_master_model_container: 18
2025-05-12 22:25:49,129:INFO:_display_container: 2
2025-05-12 22:25:49,129:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-05-12 22:25:49,129:INFO:compare_models() successfully completed......................................
2025-05-12 22:25:49,149:INFO:Initializing create_model()
2025-05-12 22:25:49,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=lar, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:49,149:INFO:Checking exceptions
2025-05-12 22:25:49,169:INFO:Importing libraries
2025-05-12 22:25:49,169:INFO:Copying training dataset
2025-05-12 22:25:49,175:INFO:Defining folds
2025-05-12 22:25:49,177:INFO:Declaring metric variables
2025-05-12 22:25:49,182:INFO:Importing untrained model
2025-05-12 22:25:49,187:INFO:Least Angle Regression Imported successfully
2025-05-12 22:25:49,196:INFO:Starting cross validation
2025-05-12 22:25:49,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:49,581:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:49,581:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:49,589:INFO:Calculating mean and std
2025-05-12 22:25:49,589:INFO:Creating metrics dataframe
2025-05-12 22:25:49,595:INFO:Finalizing model
2025-05-12 22:25:49,653:INFO:Uploading results into container
2025-05-12 22:25:49,654:INFO:Uploading model into container now
2025-05-12 22:25:49,666:INFO:_master_model_container: 19
2025-05-12 22:25:49,666:INFO:_display_container: 3
2025-05-12 22:25:49,666:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-05-12 22:25:49,666:INFO:create_model() successfully completed......................................
2025-05-12 22:25:49,800:INFO:Initializing tune_model()
2025-05-12 22:25:49,801:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:25:49,801:INFO:Checking exceptions
2025-05-12 22:25:49,823:INFO:Copying training dataset
2025-05-12 22:25:49,828:INFO:Checking base model
2025-05-12 22:25:49,829:INFO:Base model : Least Angle Regression
2025-05-12 22:25:49,836:INFO:Declaring metric variables
2025-05-12 22:25:49,841:INFO:Defining Hyperparameters
2025-05-12 22:25:49,980:INFO:Tuning with n_jobs=-1
2025-05-12 22:25:49,980:INFO:Initializing RandomizedSearchCV
2025-05-12 22:25:52,355:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__eps': 1e-05}
2025-05-12 22:25:52,356:INFO:Hyperparameter search completed
2025-05-12 22:25:52,356:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:52,357:INFO:Initializing create_model()
2025-05-12 22:25:52,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7EB1F290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'eps': 1e-05})
2025-05-12 22:25:52,357:INFO:Checking exceptions
2025-05-12 22:25:52,357:INFO:Importing libraries
2025-05-12 22:25:52,358:INFO:Copying training dataset
2025-05-12 22:25:52,363:INFO:Defining folds
2025-05-12 22:25:52,363:INFO:Declaring metric variables
2025-05-12 22:25:52,370:INFO:Importing untrained model
2025-05-12 22:25:52,370:INFO:Declaring custom model
2025-05-12 22:25:52,376:INFO:Least Angle Regression Imported successfully
2025-05-12 22:25:52,389:INFO:Starting cross validation
2025-05-12 22:25:52,393:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:52,800:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:52,800:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:52,809:INFO:Calculating mean and std
2025-05-12 22:25:52,813:INFO:Creating metrics dataframe
2025-05-12 22:25:52,823:INFO:Finalizing model
2025-05-12 22:25:52,890:INFO:Uploading results into container
2025-05-12 22:25:52,891:INFO:Uploading model into container now
2025-05-12 22:25:52,892:INFO:_master_model_container: 20
2025-05-12 22:25:52,892:INFO:_display_container: 4
2025-05-12 22:25:52,892:INFO:Lars(copy_X=True, eps=1e-05, fit_intercept=True, fit_path=True, jitter=None,
     n_nonzero_coefs=500, precompute='auto', random_state=123, verbose=False)
2025-05-12 22:25:52,892:INFO:create_model() successfully completed......................................
2025-05-12 22:25:53,008:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:53,008:INFO:choose_better activated
2025-05-12 22:25:53,013:INFO:SubProcess create_model() called ==================================
2025-05-12 22:25:53,014:INFO:Initializing create_model()
2025-05-12 22:25:53,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:25:53,015:INFO:Checking exceptions
2025-05-12 22:25:53,017:INFO:Importing libraries
2025-05-12 22:25:53,017:INFO:Copying training dataset
2025-05-12 22:25:53,021:INFO:Defining folds
2025-05-12 22:25:53,021:INFO:Declaring metric variables
2025-05-12 22:25:53,021:INFO:Importing untrained model
2025-05-12 22:25:53,021:INFO:Declaring custom model
2025-05-12 22:25:53,021:INFO:Least Angle Regression Imported successfully
2025-05-12 22:25:53,022:INFO:Starting cross validation
2025-05-12 22:25:53,023:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:25:53,320:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:25:53,320:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:25:53,326:INFO:Calculating mean and std
2025-05-12 22:25:53,327:INFO:Creating metrics dataframe
2025-05-12 22:25:53,330:INFO:Finalizing model
2025-05-12 22:25:53,389:INFO:Uploading results into container
2025-05-12 22:25:53,389:INFO:Uploading model into container now
2025-05-12 22:25:53,390:INFO:_master_model_container: 21
2025-05-12 22:25:53,390:INFO:_display_container: 5
2025-05-12 22:25:53,390:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-05-12 22:25:53,390:INFO:create_model() successfully completed......................................
2025-05-12 22:25:53,503:INFO:SubProcess create_model() end ==================================
2025-05-12 22:25:53,504:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False) result for R2 is -0.1521
2025-05-12 22:25:53,504:INFO:Lars(copy_X=True, eps=1e-05, fit_intercept=True, fit_path=True, jitter=None,
     n_nonzero_coefs=500, precompute='auto', random_state=123, verbose=False) result for R2 is -0.1521
2025-05-12 22:25:53,504:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False) is best model
2025-05-12 22:25:53,504:INFO:choose_better completed
2025-05-12 22:25:53,505:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:25:53,517:INFO:_master_model_container: 21
2025-05-12 22:25:53,517:INFO:_display_container: 4
2025-05-12 22:25:53,519:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-05-12 22:25:53,519:INFO:tune_model() successfully completed......................................
2025-05-12 22:25:53,641:INFO:Initializing evaluate_model()
2025-05-12 22:25:53,642:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:25:53,654:INFO:Initializing plot_model()
2025-05-12 22:25:53,654:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:25:53,654:INFO:Checking exceptions
2025-05-12 22:25:53,658:INFO:Preloading libraries
2025-05-12 22:25:53,658:INFO:Copying training dataset
2025-05-12 22:25:53,658:INFO:Plot type: pipeline
2025-05-12 22:25:53,771:INFO:Visual Rendered Successfully
2025-05-12 22:25:53,872:INFO:plot_model() successfully completed......................................
2025-05-12 22:25:53,889:INFO:Initializing predict_model()
2025-05-12 22:25:53,889:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7E06BF50>, estimator=Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EA7AE1FC40>)
2025-05-12 22:25:53,890:INFO:Checking exceptions
2025-05-12 22:25:53,890:INFO:Preloading libraries
2025-05-12 22:25:53,986:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:25:54,106:INFO:Initializing save_model()
2025-05-12 22:25:54,106:INFO:save_model(model=Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-12 22:25:54,106:INFO:Adding model into prep_pipe
2025-05-12 22:25:54,117:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:25:54,123:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 Lars(copy_X=True, eps=2.220446049250313e-16,
                      fit_intercept=True, fit_path=True, jitter=None,
                      n_nonzero_coefs=500, precompute='auto', random_state=123,
                      verbose=False))],
         verbose=False)
2025-05-12 22:25:54,123:INFO:save_model() successfully completed......................................
2025-05-12 22:27:07,904:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:27:07,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:27:07,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:27:07,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-12 22:27:08,623:INFO:PyCaret ClassificationExperiment
2025-05-12 22:27:08,623:INFO:Logging name: clf-default-name
2025-05-12 22:27:08,623:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-12 22:27:08,623:INFO:version 3.3.2
2025-05-12 22:27:08,624:INFO:Initializing setup()
2025-05-12 22:27:08,624:INFO:self.USI: 7ca3
2025-05-12 22:27:08,624:INFO:self._variable_keys: {'fold_groups_param', 'memory', 'n_jobs_param', 'fold_generator', 'X', 'seed', '_available_plots', '_ml_usecase', 'y_train', 'html_param', 'logging_param', 'target_param', 'idx', 'log_plots_param', 'pipeline', 'fix_imbalance', 'gpu_n_jobs_param', 'y_test', 'exp_id', 'y', 'is_multiclass', 'data', 'gpu_param', 'X_train', 'USI', 'exp_name_log', 'fold_shuffle_param', 'X_test'}
2025-05-12 22:27:08,624:INFO:Checking environment
2025-05-12 22:27:08,624:INFO:python_version: 3.11.8
2025-05-12 22:27:08,624:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:27:08,624:INFO:machine: AMD64
2025-05-12 22:27:08,624:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:27:08,630:INFO:Memory: svmem(total=16907886592, available=2697539584, percent=84.0, used=14210347008, free=2697539584)
2025-05-12 22:27:08,630:INFO:Physical Core: 4
2025-05-12 22:27:08,631:INFO:Logical Core: 8
2025-05-12 22:27:08,631:INFO:Checking libraries
2025-05-12 22:27:08,631:INFO:System:
2025-05-12 22:27:08,631:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:27:08,631:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:27:08,631:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:27:08,631:INFO:PyCaret required dependencies:
2025-05-12 22:27:08,667:INFO:                 pip: 24.0
2025-05-12 22:27:08,667:INFO:          setuptools: 65.5.0
2025-05-12 22:27:08,667:INFO:             pycaret: 3.3.2
2025-05-12 22:27:08,668:INFO:             IPython: 9.2.0
2025-05-12 22:27:08,668:INFO:          ipywidgets: 8.1.7
2025-05-12 22:27:08,668:INFO:                tqdm: 4.67.1
2025-05-12 22:27:08,668:INFO:               numpy: 1.26.4
2025-05-12 22:27:08,668:INFO:              pandas: 2.1.4
2025-05-12 22:27:08,668:INFO:              jinja2: 3.1.6
2025-05-12 22:27:08,668:INFO:               scipy: 1.11.4
2025-05-12 22:27:08,668:INFO:              joblib: 1.3.2
2025-05-12 22:27:08,668:INFO:             sklearn: 1.4.2
2025-05-12 22:27:08,668:INFO:                pyod: 2.0.5
2025-05-12 22:27:08,668:INFO:            imblearn: 0.13.0
2025-05-12 22:27:08,668:INFO:   category_encoders: 2.7.0
2025-05-12 22:27:08,668:INFO:            lightgbm: 4.6.0
2025-05-12 22:27:08,668:INFO:               numba: 0.61.2
2025-05-12 22:27:08,668:INFO:            requests: 2.32.3
2025-05-12 22:27:08,668:INFO:          matplotlib: 3.7.5
2025-05-12 22:27:08,668:INFO:          scikitplot: 0.3.7
2025-05-12 22:27:08,668:INFO:         yellowbrick: 1.5
2025-05-12 22:27:08,668:INFO:              plotly: 5.24.1
2025-05-12 22:27:08,668:INFO:    plotly-resampler: Not installed
2025-05-12 22:27:08,668:INFO:             kaleido: 0.2.1
2025-05-12 22:27:08,668:INFO:           schemdraw: 0.15
2025-05-12 22:27:08,668:INFO:         statsmodels: 0.14.4
2025-05-12 22:27:08,669:INFO:              sktime: 0.26.0
2025-05-12 22:27:08,669:INFO:               tbats: 1.1.3
2025-05-12 22:27:08,669:INFO:            pmdarima: 2.0.4
2025-05-12 22:27:08,669:INFO:              psutil: 7.0.0
2025-05-12 22:27:08,669:INFO:          markupsafe: 3.0.2
2025-05-12 22:27:08,669:INFO:             pickle5: Not installed
2025-05-12 22:27:08,669:INFO:         cloudpickle: 3.1.1
2025-05-12 22:27:08,669:INFO:         deprecation: 2.1.0
2025-05-12 22:27:08,669:INFO:              xxhash: 3.5.0
2025-05-12 22:27:08,669:INFO:           wurlitzer: Not installed
2025-05-12 22:27:08,669:INFO:PyCaret optional dependencies:
2025-05-12 22:27:08,683:INFO:                shap: Not installed
2025-05-12 22:27:08,683:INFO:           interpret: Not installed
2025-05-12 22:27:08,683:INFO:                umap: Not installed
2025-05-12 22:27:08,683:INFO:     ydata_profiling: Not installed
2025-05-12 22:27:08,683:INFO:  explainerdashboard: Not installed
2025-05-12 22:27:08,683:INFO:             autoviz: Not installed
2025-05-12 22:27:08,683:INFO:           fairlearn: Not installed
2025-05-12 22:27:08,683:INFO:          deepchecks: Not installed
2025-05-12 22:27:08,683:INFO:             xgboost: Not installed
2025-05-12 22:27:08,683:INFO:            catboost: Not installed
2025-05-12 22:27:08,683:INFO:              kmodes: Not installed
2025-05-12 22:27:08,684:INFO:             mlxtend: Not installed
2025-05-12 22:27:08,684:INFO:       statsforecast: Not installed
2025-05-12 22:27:08,684:INFO:        tune_sklearn: Not installed
2025-05-12 22:27:08,684:INFO:                 ray: Not installed
2025-05-12 22:27:08,684:INFO:            hyperopt: Not installed
2025-05-12 22:27:08,684:INFO:              optuna: Not installed
2025-05-12 22:27:08,684:INFO:               skopt: Not installed
2025-05-12 22:27:08,684:INFO:              mlflow: Not installed
2025-05-12 22:27:08,684:INFO:              gradio: Not installed
2025-05-12 22:27:08,684:INFO:             fastapi: Not installed
2025-05-12 22:27:08,684:INFO:             uvicorn: Not installed
2025-05-12 22:27:08,684:INFO:              m2cgen: Not installed
2025-05-12 22:27:08,684:INFO:           evidently: Not installed
2025-05-12 22:27:08,684:INFO:               fugue: Not installed
2025-05-12 22:27:08,684:INFO:           streamlit: Not installed
2025-05-12 22:27:08,684:INFO:             prophet: Not installed
2025-05-12 22:27:08,684:INFO:None
2025-05-12 22:27:08,684:INFO:Set up data.
2025-05-12 22:27:08,691:INFO:Set up folding strategy.
2025-05-12 22:27:08,691:INFO:Set up train/test split.
2025-05-12 22:27:08,699:INFO:Set up index.
2025-05-12 22:27:08,699:INFO:Assigning column types.
2025-05-12 22:27:08,703:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:27:08,762:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:27:08,766:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:08,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:08,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:08,874:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:27:08,876:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:08,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:08,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:08,913:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:27:08,968:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:09,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,056:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:09,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,090:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-12 22:27:09,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,260:INFO:Preparing preprocessing pipeline...
2025-05-12 22:27:09,261:INFO:Set up simple imputation.
2025-05-12 22:27:09,263:INFO:Set up encoding of categorical features.
2025-05-12 22:27:09,263:INFO:Set up feature normalization.
2025-05-12 22:27:09,334:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:27:09,342:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:27:09,342:INFO:Creating final display dataframe.
2025-05-12 22:27:09,511:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              7ca3
2025-05-12 22:27:09,600:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:09,714:INFO:setup() successfully completed in 1.09s...............
2025-05-12 22:27:09,727:INFO:Initializing compare_models()
2025-05-12 22:27:09,728:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-12 22:27:09,728:INFO:Checking exceptions
2025-05-12 22:27:09,733:INFO:Preparing display monitor
2025-05-12 22:27:09,768:INFO:Initializing Logistic Regression
2025-05-12 22:27:09,768:INFO:Total runtime is 0.0 minutes
2025-05-12 22:27:09,775:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:09,776:INFO:Initializing create_model()
2025-05-12 22:27:09,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:09,776:INFO:Checking exceptions
2025-05-12 22:27:09,776:INFO:Importing libraries
2025-05-12 22:27:09,777:INFO:Copying training dataset
2025-05-12 22:27:09,783:INFO:Defining folds
2025-05-12 22:27:09,783:INFO:Declaring metric variables
2025-05-12 22:27:09,789:INFO:Importing untrained model
2025-05-12 22:27:09,796:INFO:Logistic Regression Imported successfully
2025-05-12 22:27:09,808:INFO:Starting cross validation
2025-05-12 22:27:09,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:19,048:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,069:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,219:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,267:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,362:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,447:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,558:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,588:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:19,714:INFO:Calculating mean and std
2025-05-12 22:27:19,716:INFO:Creating metrics dataframe
2025-05-12 22:27:19,719:INFO:Uploading results into container
2025-05-12 22:27:19,720:INFO:Uploading model into container now
2025-05-12 22:27:19,721:INFO:_master_model_container: 1
2025-05-12 22:27:19,721:INFO:_display_container: 2
2025-05-12 22:27:19,723:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-12 22:27:19,723:INFO:create_model() successfully completed......................................
2025-05-12 22:27:19,817:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:19,817:INFO:Creating metrics dataframe
2025-05-12 22:27:19,825:INFO:Initializing K Neighbors Classifier
2025-05-12 22:27:19,826:INFO:Total runtime is 0.1676392396291097 minutes
2025-05-12 22:27:19,831:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:19,831:INFO:Initializing create_model()
2025-05-12 22:27:19,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:19,832:INFO:Checking exceptions
2025-05-12 22:27:19,832:INFO:Importing libraries
2025-05-12 22:27:19,832:INFO:Copying training dataset
2025-05-12 22:27:19,839:INFO:Defining folds
2025-05-12 22:27:19,839:INFO:Declaring metric variables
2025-05-12 22:27:19,846:INFO:Importing untrained model
2025-05-12 22:27:19,852:INFO:K Neighbors Classifier Imported successfully
2025-05-12 22:27:19,863:INFO:Starting cross validation
2025-05-12 22:27:19,866:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:20,116:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,154:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,183:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,187:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,211:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,319:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,330:INFO:Calculating mean and std
2025-05-12 22:27:20,333:INFO:Creating metrics dataframe
2025-05-12 22:27:20,336:INFO:Uploading results into container
2025-05-12 22:27:20,337:INFO:Uploading model into container now
2025-05-12 22:27:20,337:INFO:_master_model_container: 2
2025-05-12 22:27:20,337:INFO:_display_container: 2
2025-05-12 22:27:20,339:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-12 22:27:20,339:INFO:create_model() successfully completed......................................
2025-05-12 22:27:20,423:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:20,423:INFO:Creating metrics dataframe
2025-05-12 22:27:20,436:INFO:Initializing Naive Bayes
2025-05-12 22:27:20,436:INFO:Total runtime is 0.17779157956441244 minutes
2025-05-12 22:27:20,443:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:20,443:INFO:Initializing create_model()
2025-05-12 22:27:20,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:20,443:INFO:Checking exceptions
2025-05-12 22:27:20,443:INFO:Importing libraries
2025-05-12 22:27:20,443:INFO:Copying training dataset
2025-05-12 22:27:20,448:INFO:Defining folds
2025-05-12 22:27:20,449:INFO:Declaring metric variables
2025-05-12 22:27:20,453:INFO:Importing untrained model
2025-05-12 22:27:20,460:INFO:Naive Bayes Imported successfully
2025-05-12 22:27:20,469:INFO:Starting cross validation
2025-05-12 22:27:20,472:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:20,673:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,676:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,684:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,819:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:20,830:INFO:Calculating mean and std
2025-05-12 22:27:20,831:INFO:Creating metrics dataframe
2025-05-12 22:27:20,835:INFO:Uploading results into container
2025-05-12 22:27:20,835:INFO:Uploading model into container now
2025-05-12 22:27:20,836:INFO:_master_model_container: 3
2025-05-12 22:27:20,836:INFO:_display_container: 2
2025-05-12 22:27:20,836:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-12 22:27:20,836:INFO:create_model() successfully completed......................................
2025-05-12 22:27:20,929:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:20,929:INFO:Creating metrics dataframe
2025-05-12 22:27:20,938:INFO:Initializing Decision Tree Classifier
2025-05-12 22:27:20,938:INFO:Total runtime is 0.18616087039311727 minutes
2025-05-12 22:27:20,944:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:20,945:INFO:Initializing create_model()
2025-05-12 22:27:20,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:20,946:INFO:Checking exceptions
2025-05-12 22:27:20,946:INFO:Importing libraries
2025-05-12 22:27:20,946:INFO:Copying training dataset
2025-05-12 22:27:20,953:INFO:Defining folds
2025-05-12 22:27:20,953:INFO:Declaring metric variables
2025-05-12 22:27:20,959:INFO:Importing untrained model
2025-05-12 22:27:20,967:INFO:Decision Tree Classifier Imported successfully
2025-05-12 22:27:20,979:INFO:Starting cross validation
2025-05-12 22:27:20,982:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:21,208:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:21,306:INFO:Calculating mean and std
2025-05-12 22:27:21,309:INFO:Creating metrics dataframe
2025-05-12 22:27:21,313:INFO:Uploading results into container
2025-05-12 22:27:21,314:INFO:Uploading model into container now
2025-05-12 22:27:21,314:INFO:_master_model_container: 4
2025-05-12 22:27:21,314:INFO:_display_container: 2
2025-05-12 22:27:21,315:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-12 22:27:21,315:INFO:create_model() successfully completed......................................
2025-05-12 22:27:21,406:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:21,407:INFO:Creating metrics dataframe
2025-05-12 22:27:21,416:INFO:Initializing SVM - Linear Kernel
2025-05-12 22:27:21,417:INFO:Total runtime is 0.19414552847544353 minutes
2025-05-12 22:27:21,421:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:21,421:INFO:Initializing create_model()
2025-05-12 22:27:21,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:21,421:INFO:Checking exceptions
2025-05-12 22:27:21,421:INFO:Importing libraries
2025-05-12 22:27:21,421:INFO:Copying training dataset
2025-05-12 22:27:21,430:INFO:Defining folds
2025-05-12 22:27:21,430:INFO:Declaring metric variables
2025-05-12 22:27:21,438:INFO:Importing untrained model
2025-05-12 22:27:21,447:INFO:SVM - Linear Kernel Imported successfully
2025-05-12 22:27:21,461:INFO:Starting cross validation
2025-05-12 22:27:21,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:21,715:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:21,804:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:21,973:INFO:Calculating mean and std
2025-05-12 22:27:21,975:INFO:Creating metrics dataframe
2025-05-12 22:27:21,978:INFO:Uploading results into container
2025-05-12 22:27:21,979:INFO:Uploading model into container now
2025-05-12 22:27:21,980:INFO:_master_model_container: 5
2025-05-12 22:27:21,980:INFO:_display_container: 2
2025-05-12 22:27:21,981:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-12 22:27:21,981:INFO:create_model() successfully completed......................................
2025-05-12 22:27:22,079:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:22,079:INFO:Creating metrics dataframe
2025-05-12 22:27:22,091:INFO:Initializing Ridge Classifier
2025-05-12 22:27:22,091:INFO:Total runtime is 0.2053900440533956 minutes
2025-05-12 22:27:22,098:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:22,099:INFO:Initializing create_model()
2025-05-12 22:27:22,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:22,099:INFO:Checking exceptions
2025-05-12 22:27:22,099:INFO:Importing libraries
2025-05-12 22:27:22,099:INFO:Copying training dataset
2025-05-12 22:27:22,105:INFO:Defining folds
2025-05-12 22:27:22,106:INFO:Declaring metric variables
2025-05-12 22:27:22,112:INFO:Importing untrained model
2025-05-12 22:27:22,119:INFO:Ridge Classifier Imported successfully
2025-05-12 22:27:22,129:INFO:Starting cross validation
2025-05-12 22:27:22,131:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:22,359:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,455:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,469:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,477:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,499:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,527:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,536:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,536:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,613:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:22,628:INFO:Calculating mean and std
2025-05-12 22:27:22,629:INFO:Creating metrics dataframe
2025-05-12 22:27:22,632:INFO:Uploading results into container
2025-05-12 22:27:22,633:INFO:Uploading model into container now
2025-05-12 22:27:22,633:INFO:_master_model_container: 6
2025-05-12 22:27:22,633:INFO:_display_container: 2
2025-05-12 22:27:22,634:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-12 22:27:22,634:INFO:create_model() successfully completed......................................
2025-05-12 22:27:22,723:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:22,723:INFO:Creating metrics dataframe
2025-05-12 22:27:22,733:INFO:Initializing Random Forest Classifier
2025-05-12 22:27:22,733:INFO:Total runtime is 0.21607719262441 minutes
2025-05-12 22:27:22,737:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:22,737:INFO:Initializing create_model()
2025-05-12 22:27:22,737:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:22,737:INFO:Checking exceptions
2025-05-12 22:27:22,737:INFO:Importing libraries
2025-05-12 22:27:22,739:INFO:Copying training dataset
2025-05-12 22:27:22,744:INFO:Defining folds
2025-05-12 22:27:22,744:INFO:Declaring metric variables
2025-05-12 22:27:22,749:INFO:Importing untrained model
2025-05-12 22:27:22,757:INFO:Random Forest Classifier Imported successfully
2025-05-12 22:27:22,767:INFO:Starting cross validation
2025-05-12 22:27:22,769:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:23,510:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:23,526:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:23,571:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:23,579:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:23,580:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:23,657:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:23,741:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:24,034:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:24,052:INFO:Calculating mean and std
2025-05-12 22:27:24,053:INFO:Creating metrics dataframe
2025-05-12 22:27:24,056:INFO:Uploading results into container
2025-05-12 22:27:24,057:INFO:Uploading model into container now
2025-05-12 22:27:24,057:INFO:_master_model_container: 7
2025-05-12 22:27:24,058:INFO:_display_container: 2
2025-05-12 22:27:24,058:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-12 22:27:24,058:INFO:create_model() successfully completed......................................
2025-05-12 22:27:24,141:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:24,142:INFO:Creating metrics dataframe
2025-05-12 22:27:24,151:INFO:Initializing Quadratic Discriminant Analysis
2025-05-12 22:27:24,151:INFO:Total runtime is 0.23971670071283976 minutes
2025-05-12 22:27:24,156:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:24,157:INFO:Initializing create_model()
2025-05-12 22:27:24,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:24,157:INFO:Checking exceptions
2025-05-12 22:27:24,157:INFO:Importing libraries
2025-05-12 22:27:24,157:INFO:Copying training dataset
2025-05-12 22:27:24,160:INFO:Defining folds
2025-05-12 22:27:24,160:INFO:Declaring metric variables
2025-05-12 22:27:24,164:INFO:Importing untrained model
2025-05-12 22:27:24,168:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-12 22:27:24,177:INFO:Starting cross validation
2025-05-12 22:27:24,180:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:24,275:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,276:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,279:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,284:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,300:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,300:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,306:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,309:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,336:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:24,413:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,419:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:24,476:INFO:Calculating mean and std
2025-05-12 22:27:24,477:INFO:Creating metrics dataframe
2025-05-12 22:27:24,480:INFO:Uploading results into container
2025-05-12 22:27:24,481:INFO:Uploading model into container now
2025-05-12 22:27:24,481:INFO:_master_model_container: 8
2025-05-12 22:27:24,481:INFO:_display_container: 2
2025-05-12 22:27:24,482:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-12 22:27:24,482:INFO:create_model() successfully completed......................................
2025-05-12 22:27:24,559:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:24,559:INFO:Creating metrics dataframe
2025-05-12 22:27:24,569:INFO:Initializing Ada Boost Classifier
2025-05-12 22:27:24,569:INFO:Total runtime is 0.2466849446296692 minutes
2025-05-12 22:27:24,576:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:24,576:INFO:Initializing create_model()
2025-05-12 22:27:24,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:24,576:INFO:Checking exceptions
2025-05-12 22:27:24,576:INFO:Importing libraries
2025-05-12 22:27:24,576:INFO:Copying training dataset
2025-05-12 22:27:24,583:INFO:Defining folds
2025-05-12 22:27:24,583:INFO:Declaring metric variables
2025-05-12 22:27:24,587:INFO:Importing untrained model
2025-05-12 22:27:24,593:INFO:Ada Boost Classifier Imported successfully
2025-05-12 22:27:24,601:INFO:Starting cross validation
2025-05-12 22:27:24,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:24,706:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:24,709:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:24,714:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:24,723:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:24,734:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:24,740:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:24,744:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:24,802:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:25,157:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:25,193:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:25,257:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:25,273:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:25,549:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:25,550:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:25,565:INFO:Calculating mean and std
2025-05-12 22:27:25,566:INFO:Creating metrics dataframe
2025-05-12 22:27:25,570:INFO:Uploading results into container
2025-05-12 22:27:25,571:INFO:Uploading model into container now
2025-05-12 22:27:25,572:INFO:_master_model_container: 9
2025-05-12 22:27:25,572:INFO:_display_container: 2
2025-05-12 22:27:25,573:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-12 22:27:25,573:INFO:create_model() successfully completed......................................
2025-05-12 22:27:25,673:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:25,673:INFO:Creating metrics dataframe
2025-05-12 22:27:25,690:INFO:Initializing Gradient Boosting Classifier
2025-05-12 22:27:25,691:INFO:Total runtime is 0.265375276406606 minutes
2025-05-12 22:27:25,696:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:25,697:INFO:Initializing create_model()
2025-05-12 22:27:25,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:25,697:INFO:Checking exceptions
2025-05-12 22:27:25,698:INFO:Importing libraries
2025-05-12 22:27:25,698:INFO:Copying training dataset
2025-05-12 22:27:25,706:INFO:Defining folds
2025-05-12 22:27:25,706:INFO:Declaring metric variables
2025-05-12 22:27:25,713:INFO:Importing untrained model
2025-05-12 22:27:25,720:INFO:Gradient Boosting Classifier Imported successfully
2025-05-12 22:27:25,732:INFO:Starting cross validation
2025-05-12 22:27:25,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:26,464:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:26,608:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:26,623:INFO:Calculating mean and std
2025-05-12 22:27:26,625:INFO:Creating metrics dataframe
2025-05-12 22:27:26,628:INFO:Uploading results into container
2025-05-12 22:27:26,629:INFO:Uploading model into container now
2025-05-12 22:27:26,630:INFO:_master_model_container: 10
2025-05-12 22:27:26,630:INFO:_display_container: 2
2025-05-12 22:27:26,631:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-12 22:27:26,631:INFO:create_model() successfully completed......................................
2025-05-12 22:27:26,707:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:26,707:INFO:Creating metrics dataframe
2025-05-12 22:27:26,721:INFO:Initializing Linear Discriminant Analysis
2025-05-12 22:27:26,723:INFO:Total runtime is 0.28257929881413774 minutes
2025-05-12 22:27:26,727:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:26,728:INFO:Initializing create_model()
2025-05-12 22:27:26,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:26,728:INFO:Checking exceptions
2025-05-12 22:27:26,728:INFO:Importing libraries
2025-05-12 22:27:26,728:INFO:Copying training dataset
2025-05-12 22:27:26,733:INFO:Defining folds
2025-05-12 22:27:26,733:INFO:Declaring metric variables
2025-05-12 22:27:26,740:INFO:Importing untrained model
2025-05-12 22:27:26,749:INFO:Linear Discriminant Analysis Imported successfully
2025-05-12 22:27:26,757:INFO:Starting cross validation
2025-05-12 22:27:26,761:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:26,931:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:26,939:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:26,966:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:26,979:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:26,980:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:27,068:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:27,081:INFO:Calculating mean and std
2025-05-12 22:27:27,081:INFO:Creating metrics dataframe
2025-05-12 22:27:27,086:INFO:Uploading results into container
2025-05-12 22:27:27,087:INFO:Uploading model into container now
2025-05-12 22:27:27,088:INFO:_master_model_container: 11
2025-05-12 22:27:27,088:INFO:_display_container: 2
2025-05-12 22:27:27,089:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-12 22:27:27,089:INFO:create_model() successfully completed......................................
2025-05-12 22:27:27,171:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:27,172:INFO:Creating metrics dataframe
2025-05-12 22:27:27,185:INFO:Initializing Extra Trees Classifier
2025-05-12 22:27:27,185:INFO:Total runtime is 0.2902848164240519 minutes
2025-05-12 22:27:27,190:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:27,191:INFO:Initializing create_model()
2025-05-12 22:27:27,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:27,191:INFO:Checking exceptions
2025-05-12 22:27:27,191:INFO:Importing libraries
2025-05-12 22:27:27,191:INFO:Copying training dataset
2025-05-12 22:27:27,196:INFO:Defining folds
2025-05-12 22:27:27,197:INFO:Declaring metric variables
2025-05-12 22:27:27,201:INFO:Importing untrained model
2025-05-12 22:27:27,208:INFO:Extra Trees Classifier Imported successfully
2025-05-12 22:27:27,217:INFO:Starting cross validation
2025-05-12 22:27:27,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:27,849:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:27,881:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:27,896:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:28,219:INFO:Calculating mean and std
2025-05-12 22:27:28,220:INFO:Creating metrics dataframe
2025-05-12 22:27:28,224:INFO:Uploading results into container
2025-05-12 22:27:28,224:INFO:Uploading model into container now
2025-05-12 22:27:28,225:INFO:_master_model_container: 12
2025-05-12 22:27:28,225:INFO:_display_container: 2
2025-05-12 22:27:28,226:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-12 22:27:28,226:INFO:create_model() successfully completed......................................
2025-05-12 22:27:28,306:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:28,306:INFO:Creating metrics dataframe
2025-05-12 22:27:28,317:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:27:28,318:INFO:Total runtime is 0.30916332403818764 minutes
2025-05-12 22:27:28,323:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:28,323:INFO:Initializing create_model()
2025-05-12 22:27:28,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:28,323:INFO:Checking exceptions
2025-05-12 22:27:28,323:INFO:Importing libraries
2025-05-12 22:27:28,323:INFO:Copying training dataset
2025-05-12 22:27:28,328:INFO:Defining folds
2025-05-12 22:27:28,329:INFO:Declaring metric variables
2025-05-12 22:27:28,333:INFO:Importing untrained model
2025-05-12 22:27:28,344:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:27:28,364:INFO:Starting cross validation
2025-05-12 22:27:28,376:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:28,792:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:28,803:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:28,961:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,005:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,104:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,263:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,289:INFO:Calculating mean and std
2025-05-12 22:27:29,291:INFO:Creating metrics dataframe
2025-05-12 22:27:29,298:INFO:Uploading results into container
2025-05-12 22:27:29,300:INFO:Uploading model into container now
2025-05-12 22:27:29,301:INFO:_master_model_container: 13
2025-05-12 22:27:29,302:INFO:_display_container: 2
2025-05-12 22:27:29,303:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:27:29,303:INFO:create_model() successfully completed......................................
2025-05-12 22:27:29,421:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:29,423:INFO:Creating metrics dataframe
2025-05-12 22:27:29,438:INFO:Initializing Dummy Classifier
2025-05-12 22:27:29,439:INFO:Total runtime is 0.3278443336486816 minutes
2025-05-12 22:27:29,444:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:29,444:INFO:Initializing create_model()
2025-05-12 22:27:29,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D50FEEAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:29,444:INFO:Checking exceptions
2025-05-12 22:27:29,445:INFO:Importing libraries
2025-05-12 22:27:29,445:INFO:Copying training dataset
2025-05-12 22:27:29,450:INFO:Defining folds
2025-05-12 22:27:29,451:INFO:Declaring metric variables
2025-05-12 22:27:29,455:INFO:Importing untrained model
2025-05-12 22:27:29,461:INFO:Dummy Classifier Imported successfully
2025-05-12 22:27:29,473:INFO:Starting cross validation
2025-05-12 22:27:29,475:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:29,658:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,660:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,668:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,731:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,737:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,759:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,769:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,841:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,841:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:29,860:INFO:Calculating mean and std
2025-05-12 22:27:29,861:INFO:Creating metrics dataframe
2025-05-12 22:27:29,866:INFO:Uploading results into container
2025-05-12 22:27:29,867:INFO:Uploading model into container now
2025-05-12 22:27:29,869:INFO:_master_model_container: 14
2025-05-12 22:27:29,869:INFO:_display_container: 2
2025-05-12 22:27:29,869:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:27:29,870:INFO:create_model() successfully completed......................................
2025-05-12 22:27:29,970:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:29,970:INFO:Creating metrics dataframe
2025-05-12 22:27:29,993:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:27:30,007:INFO:Initializing create_model()
2025-05-12 22:27:30,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:30,009:INFO:Checking exceptions
2025-05-12 22:27:30,012:INFO:Importing libraries
2025-05-12 22:27:30,012:INFO:Copying training dataset
2025-05-12 22:27:30,017:INFO:Defining folds
2025-05-12 22:27:30,017:INFO:Declaring metric variables
2025-05-12 22:27:30,017:INFO:Importing untrained model
2025-05-12 22:27:30,017:INFO:Declaring custom model
2025-05-12 22:27:30,017:INFO:Dummy Classifier Imported successfully
2025-05-12 22:27:30,020:INFO:Cross validation set to False
2025-05-12 22:27:30,020:INFO:Fitting Model
2025-05-12 22:27:30,078:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:27:30,078:INFO:create_model() successfully completed......................................
2025-05-12 22:27:30,225:INFO:_master_model_container: 14
2025-05-12 22:27:30,225:INFO:_display_container: 2
2025-05-12 22:27:30,226:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:27:30,226:INFO:compare_models() successfully completed......................................
2025-05-12 22:27:30,254:INFO:Initializing create_model()
2025-05-12 22:27:30,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:30,254:INFO:Checking exceptions
2025-05-12 22:27:30,277:INFO:Importing libraries
2025-05-12 22:27:30,277:INFO:Copying training dataset
2025-05-12 22:27:30,284:INFO:Defining folds
2025-05-12 22:27:30,284:INFO:Declaring metric variables
2025-05-12 22:27:30,290:INFO:Importing untrained model
2025-05-12 22:27:30,297:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:27:30,308:INFO:Starting cross validation
2025-05-12 22:27:30,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:31,304:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:31,341:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:31,376:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:31,589:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:31,695:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:31,877:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:31,899:INFO:Calculating mean and std
2025-05-12 22:27:31,903:INFO:Creating metrics dataframe
2025-05-12 22:27:31,916:INFO:Finalizing model
2025-05-12 22:27:32,000:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:27:32,000:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.
2025-05-12 22:27:32,000:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-12 22:27:32,000:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-12 22:27:32,001:INFO:[LightGBM] [Info] Total Bins 117
2025-05-12 22:27:32,001:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:27:32,001:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:27:32,001:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:27:32,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:32,049:INFO:Uploading results into container
2025-05-12 22:27:32,051:INFO:Uploading model into container now
2025-05-12 22:27:32,073:INFO:_master_model_container: 15
2025-05-12 22:27:32,073:INFO:_display_container: 3
2025-05-12 22:27:32,074:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:27:32,074:INFO:create_model() successfully completed......................................
2025-05-12 22:27:32,208:INFO:Initializing tune_model()
2025-05-12 22:27:32,208:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:27:32,208:INFO:Checking exceptions
2025-05-12 22:27:32,231:INFO:Copying training dataset
2025-05-12 22:27:32,234:INFO:Checking base model
2025-05-12 22:27:32,234:INFO:Base model : Light Gradient Boosting Machine
2025-05-12 22:27:32,242:INFO:Declaring metric variables
2025-05-12 22:27:32,247:INFO:Defining Hyperparameters
2025-05-12 22:27:32,334:INFO:Tuning with n_jobs=-1
2025-05-12 22:27:32,334:INFO:Initializing RandomizedSearchCV
2025-05-12 22:27:41,274:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2025-05-12 22:27:41,277:INFO:Hyperparameter search completed
2025-05-12 22:27:41,277:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:41,279:INFO:Initializing create_model()
2025-05-12 22:27:41,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51214C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2025-05-12 22:27:41,279:INFO:Checking exceptions
2025-05-12 22:27:41,279:INFO:Importing libraries
2025-05-12 22:27:41,280:INFO:Copying training dataset
2025-05-12 22:27:41,287:INFO:Defining folds
2025-05-12 22:27:41,287:INFO:Declaring metric variables
2025-05-12 22:27:41,294:INFO:Importing untrained model
2025-05-12 22:27:41,294:INFO:Declaring custom model
2025-05-12 22:27:41,302:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:27:41,316:INFO:Starting cross validation
2025-05-12 22:27:41,319:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:41,611:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,612:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,630:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,647:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,713:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,729:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,821:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,845:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,889:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,899:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:41,917:INFO:Calculating mean and std
2025-05-12 22:27:41,923:INFO:Creating metrics dataframe
2025-05-12 22:27:41,933:INFO:Finalizing model
2025-05-12 22:27:42,007:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:27:42,007:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:27:42,008:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:27:42,008:INFO:[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.
2025-05-12 22:27:42,009:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:27:42,009:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:27:42,009:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:27:42,009:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:27:42,009:INFO:[LightGBM] [Info] Total Bins 0
2025-05-12 22:27:42,009:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 0
2025-05-12 22:27:42,009:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:27:42,009:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:27:42,009:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,009:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,009:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,020:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,020:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:27:42,039:INFO:Uploading results into container
2025-05-12 22:27:42,041:INFO:Uploading model into container now
2025-05-12 22:27:42,041:INFO:_master_model_container: 16
2025-05-12 22:27:42,043:INFO:_display_container: 4
2025-05-12 22:27:42,044:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:27:42,044:INFO:create_model() successfully completed......................................
2025-05-12 22:27:42,152:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:42,152:INFO:choose_better activated
2025-05-12 22:27:42,156:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:42,157:INFO:Initializing create_model()
2025-05-12 22:27:42,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:42,157:INFO:Checking exceptions
2025-05-12 22:27:42,159:INFO:Importing libraries
2025-05-12 22:27:42,160:INFO:Copying training dataset
2025-05-12 22:27:42,163:INFO:Defining folds
2025-05-12 22:27:42,163:INFO:Declaring metric variables
2025-05-12 22:27:42,164:INFO:Importing untrained model
2025-05-12 22:27:42,164:INFO:Declaring custom model
2025-05-12 22:27:42,166:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:27:42,166:INFO:Starting cross validation
2025-05-12 22:27:42,167:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:42,479:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:42,493:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:42,523:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:42,632:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:42,639:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:42,759:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:42,782:INFO:Calculating mean and std
2025-05-12 22:27:42,783:INFO:Creating metrics dataframe
2025-05-12 22:27:42,785:INFO:Finalizing model
2025-05-12 22:27:42,851:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:27:42,851:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.
2025-05-12 22:27:42,851:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-12 22:27:42,853:INFO:[LightGBM] [Info] Total Bins 117
2025-05-12 22:27:42,853:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:27:42,853:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:27:42,854:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:27:42,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:27:42,884:INFO:Uploading results into container
2025-05-12 22:27:42,885:INFO:Uploading model into container now
2025-05-12 22:27:42,885:INFO:_master_model_container: 17
2025-05-12 22:27:42,886:INFO:_display_container: 5
2025-05-12 22:27:42,887:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:27:42,887:INFO:create_model() successfully completed......................................
2025-05-12 22:27:42,988:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:42,989:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7891
2025-05-12 22:27:42,989:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8291
2025-05-12 22:27:42,990:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-12 22:27:42,990:INFO:choose_better completed
2025-05-12 22:27:43,003:INFO:_master_model_container: 17
2025-05-12 22:27:43,003:INFO:_display_container: 4
2025-05-12 22:27:43,004:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:27:43,004:INFO:tune_model() successfully completed......................................
2025-05-12 22:27:43,107:INFO:Initializing evaluate_model()
2025-05-12 22:27:43,108:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:27:43,119:INFO:Initializing plot_model()
2025-05-12 22:27:43,120:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:27:43,120:INFO:Checking exceptions
2025-05-12 22:27:43,124:INFO:Preloading libraries
2025-05-12 22:27:43,125:INFO:Copying training dataset
2025-05-12 22:27:43,125:INFO:Plot type: pipeline
2025-05-12 22:27:43,367:INFO:Visual Rendered Successfully
2025-05-12 22:27:43,448:INFO:plot_model() successfully completed......................................
2025-05-12 22:27:43,473:INFO:Initializing predict_model()
2025-05-12 22:27:43,473:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D2DAA4B10>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027D2DA511C0>)
2025-05-12 22:27:43,473:INFO:Checking exceptions
2025-05-12 22:27:43,473:INFO:Preloading libraries
2025-05-12 22:27:43,617:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:43,788:INFO:Initializing save_model()
2025-05-12 22:27:43,788:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-12 22:27:43,788:INFO:Adding model into prep_pipe
2025-05-12 22:27:43,803:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:27:43,823:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-12 22:27:43,823:INFO:save_model() successfully completed......................................
2025-05-12 22:27:50,877:INFO:PyCaret ClassificationExperiment
2025-05-12 22:27:50,877:INFO:Logging name: clf-default-name
2025-05-12 22:27:50,878:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-12 22:27:50,878:INFO:version 3.3.2
2025-05-12 22:27:50,878:INFO:Initializing setup()
2025-05-12 22:27:50,878:INFO:self.USI: 3347
2025-05-12 22:27:50,878:INFO:self._variable_keys: {'fold_groups_param', 'memory', 'n_jobs_param', 'fold_generator', 'X', 'seed', '_available_plots', '_ml_usecase', 'y_train', 'html_param', 'logging_param', 'target_param', 'idx', 'log_plots_param', 'pipeline', 'fix_imbalance', 'gpu_n_jobs_param', 'y_test', 'exp_id', 'y', 'is_multiclass', 'data', 'gpu_param', 'X_train', 'USI', 'exp_name_log', 'fold_shuffle_param', 'X_test'}
2025-05-12 22:27:50,878:INFO:Checking environment
2025-05-12 22:27:50,878:INFO:python_version: 3.11.8
2025-05-12 22:27:50,878:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:27:50,878:INFO:machine: AMD64
2025-05-12 22:27:50,878:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:27:50,882:INFO:Memory: svmem(total=16907886592, available=2438205440, percent=85.6, used=14469681152, free=2438205440)
2025-05-12 22:27:50,883:INFO:Physical Core: 4
2025-05-12 22:27:50,883:INFO:Logical Core: 8
2025-05-12 22:27:50,883:INFO:Checking libraries
2025-05-12 22:27:50,883:INFO:System:
2025-05-12 22:27:50,883:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:27:50,883:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:27:50,883:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:27:50,883:INFO:PyCaret required dependencies:
2025-05-12 22:27:50,883:INFO:                 pip: 24.0
2025-05-12 22:27:50,883:INFO:          setuptools: 65.5.0
2025-05-12 22:27:50,883:INFO:             pycaret: 3.3.2
2025-05-12 22:27:50,883:INFO:             IPython: 9.2.0
2025-05-12 22:27:50,883:INFO:          ipywidgets: 8.1.7
2025-05-12 22:27:50,883:INFO:                tqdm: 4.67.1
2025-05-12 22:27:50,883:INFO:               numpy: 1.26.4
2025-05-12 22:27:50,883:INFO:              pandas: 2.1.4
2025-05-12 22:27:50,883:INFO:              jinja2: 3.1.6
2025-05-12 22:27:50,883:INFO:               scipy: 1.11.4
2025-05-12 22:27:50,883:INFO:              joblib: 1.3.2
2025-05-12 22:27:50,883:INFO:             sklearn: 1.4.2
2025-05-12 22:27:50,883:INFO:                pyod: 2.0.5
2025-05-12 22:27:50,883:INFO:            imblearn: 0.13.0
2025-05-12 22:27:50,883:INFO:   category_encoders: 2.7.0
2025-05-12 22:27:50,883:INFO:            lightgbm: 4.6.0
2025-05-12 22:27:50,883:INFO:               numba: 0.61.2
2025-05-12 22:27:50,884:INFO:            requests: 2.32.3
2025-05-12 22:27:50,884:INFO:          matplotlib: 3.7.5
2025-05-12 22:27:50,884:INFO:          scikitplot: 0.3.7
2025-05-12 22:27:50,884:INFO:         yellowbrick: 1.5
2025-05-12 22:27:50,884:INFO:              plotly: 5.24.1
2025-05-12 22:27:50,884:INFO:    plotly-resampler: Not installed
2025-05-12 22:27:50,884:INFO:             kaleido: 0.2.1
2025-05-12 22:27:50,884:INFO:           schemdraw: 0.15
2025-05-12 22:27:50,884:INFO:         statsmodels: 0.14.4
2025-05-12 22:27:50,884:INFO:              sktime: 0.26.0
2025-05-12 22:27:50,884:INFO:               tbats: 1.1.3
2025-05-12 22:27:50,884:INFO:            pmdarima: 2.0.4
2025-05-12 22:27:50,884:INFO:              psutil: 7.0.0
2025-05-12 22:27:50,884:INFO:          markupsafe: 3.0.2
2025-05-12 22:27:50,884:INFO:             pickle5: Not installed
2025-05-12 22:27:50,884:INFO:         cloudpickle: 3.1.1
2025-05-12 22:27:50,884:INFO:         deprecation: 2.1.0
2025-05-12 22:27:50,884:INFO:              xxhash: 3.5.0
2025-05-12 22:27:50,884:INFO:           wurlitzer: Not installed
2025-05-12 22:27:50,884:INFO:PyCaret optional dependencies:
2025-05-12 22:27:50,884:INFO:                shap: Not installed
2025-05-12 22:27:50,884:INFO:           interpret: Not installed
2025-05-12 22:27:50,884:INFO:                umap: Not installed
2025-05-12 22:27:50,884:INFO:     ydata_profiling: Not installed
2025-05-12 22:27:50,884:INFO:  explainerdashboard: Not installed
2025-05-12 22:27:50,884:INFO:             autoviz: Not installed
2025-05-12 22:27:50,884:INFO:           fairlearn: Not installed
2025-05-12 22:27:50,884:INFO:          deepchecks: Not installed
2025-05-12 22:27:50,884:INFO:             xgboost: Not installed
2025-05-12 22:27:50,884:INFO:            catboost: Not installed
2025-05-12 22:27:50,884:INFO:              kmodes: Not installed
2025-05-12 22:27:50,884:INFO:             mlxtend: Not installed
2025-05-12 22:27:50,884:INFO:       statsforecast: Not installed
2025-05-12 22:27:50,884:INFO:        tune_sklearn: Not installed
2025-05-12 22:27:50,884:INFO:                 ray: Not installed
2025-05-12 22:27:50,885:INFO:            hyperopt: Not installed
2025-05-12 22:27:50,885:INFO:              optuna: Not installed
2025-05-12 22:27:50,885:INFO:               skopt: Not installed
2025-05-12 22:27:50,885:INFO:              mlflow: Not installed
2025-05-12 22:27:50,885:INFO:              gradio: Not installed
2025-05-12 22:27:50,885:INFO:             fastapi: Not installed
2025-05-12 22:27:50,885:INFO:             uvicorn: Not installed
2025-05-12 22:27:50,885:INFO:              m2cgen: Not installed
2025-05-12 22:27:50,885:INFO:           evidently: Not installed
2025-05-12 22:27:50,885:INFO:               fugue: Not installed
2025-05-12 22:27:50,885:INFO:           streamlit: Not installed
2025-05-12 22:27:50,885:INFO:             prophet: Not installed
2025-05-12 22:27:50,885:INFO:None
2025-05-12 22:27:50,885:INFO:Set up data.
2025-05-12 22:27:50,888:INFO:Set up folding strategy.
2025-05-12 22:27:50,888:INFO:Set up train/test split.
2025-05-12 22:27:50,892:INFO:Set up index.
2025-05-12 22:27:50,892:INFO:Assigning column types.
2025-05-12 22:27:50,894:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:27:50,980:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:27:50,981:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:51,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,013:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,049:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:27:51,050:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:51,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,071:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:27:51,107:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:51,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,162:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:27:51,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,183:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,184:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-12 22:27:51,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,293:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,294:INFO:Preparing preprocessing pipeline...
2025-05-12 22:27:51,294:INFO:Set up simple imputation.
2025-05-12 22:27:51,296:INFO:Set up encoding of categorical features.
2025-05-12 22:27:51,296:INFO:Set up feature normalization.
2025-05-12 22:27:51,343:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:27:51,347:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:27:51,347:INFO:Creating final display dataframe.
2025-05-12 22:27:51,471:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              3347
2025-05-12 22:27:51,536:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,536:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:27:51,593:INFO:setup() successfully completed in 0.72s...............
2025-05-12 22:27:51,609:INFO:Initializing compare_models()
2025-05-12 22:27:51,609:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-12 22:27:51,609:INFO:Checking exceptions
2025-05-12 22:27:51,611:INFO:Preparing display monitor
2025-05-12 22:27:51,633:INFO:Initializing Logistic Regression
2025-05-12 22:27:51,633:INFO:Total runtime is 0.0 minutes
2025-05-12 22:27:51,637:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:51,637:INFO:Initializing create_model()
2025-05-12 22:27:51,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:51,638:INFO:Checking exceptions
2025-05-12 22:27:51,638:INFO:Importing libraries
2025-05-12 22:27:51,638:INFO:Copying training dataset
2025-05-12 22:27:51,641:INFO:Defining folds
2025-05-12 22:27:51,641:INFO:Declaring metric variables
2025-05-12 22:27:51,646:INFO:Importing untrained model
2025-05-12 22:27:51,651:INFO:Logistic Regression Imported successfully
2025-05-12 22:27:51,660:INFO:Starting cross validation
2025-05-12 22:27:51,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:51,806:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,807:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,817:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,829:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,850:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,852:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,857:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,900:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:51,909:INFO:Calculating mean and std
2025-05-12 22:27:51,910:INFO:Creating metrics dataframe
2025-05-12 22:27:51,911:INFO:Uploading results into container
2025-05-12 22:27:51,911:INFO:Uploading model into container now
2025-05-12 22:27:51,913:INFO:_master_model_container: 1
2025-05-12 22:27:51,913:INFO:_display_container: 2
2025-05-12 22:27:51,913:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-12 22:27:51,913:INFO:create_model() successfully completed......................................
2025-05-12 22:27:51,983:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:51,983:INFO:Creating metrics dataframe
2025-05-12 22:27:51,991:INFO:Initializing K Neighbors Classifier
2025-05-12 22:27:51,991:INFO:Total runtime is 0.005974737803141276 minutes
2025-05-12 22:27:51,996:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:51,996:INFO:Initializing create_model()
2025-05-12 22:27:51,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:51,996:INFO:Checking exceptions
2025-05-12 22:27:51,996:INFO:Importing libraries
2025-05-12 22:27:51,996:INFO:Copying training dataset
2025-05-12 22:27:51,999:INFO:Defining folds
2025-05-12 22:27:51,999:INFO:Declaring metric variables
2025-05-12 22:27:52,002:INFO:Importing untrained model
2025-05-12 22:27:52,007:INFO:K Neighbors Classifier Imported successfully
2025-05-12 22:27:52,014:INFO:Starting cross validation
2025-05-12 22:27:52,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:52,157:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,157:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,171:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,175:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,187:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,257:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,265:INFO:Calculating mean and std
2025-05-12 22:27:52,265:INFO:Creating metrics dataframe
2025-05-12 22:27:52,266:INFO:Uploading results into container
2025-05-12 22:27:52,267:INFO:Uploading model into container now
2025-05-12 22:27:52,267:INFO:_master_model_container: 2
2025-05-12 22:27:52,267:INFO:_display_container: 2
2025-05-12 22:27:52,267:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-12 22:27:52,267:INFO:create_model() successfully completed......................................
2025-05-12 22:27:52,334:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:52,334:INFO:Creating metrics dataframe
2025-05-12 22:27:52,339:INFO:Initializing Naive Bayes
2025-05-12 22:27:52,339:INFO:Total runtime is 0.011779212951660156 minutes
2025-05-12 22:27:52,342:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:52,343:INFO:Initializing create_model()
2025-05-12 22:27:52,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:52,343:INFO:Checking exceptions
2025-05-12 22:27:52,343:INFO:Importing libraries
2025-05-12 22:27:52,343:INFO:Copying training dataset
2025-05-12 22:27:52,347:INFO:Defining folds
2025-05-12 22:27:52,347:INFO:Declaring metric variables
2025-05-12 22:27:52,350:INFO:Importing untrained model
2025-05-12 22:27:52,352:INFO:Naive Bayes Imported successfully
2025-05-12 22:27:52,359:INFO:Starting cross validation
2025-05-12 22:27:52,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:52,469:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,470:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,499:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,533:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,543:INFO:Calculating mean and std
2025-05-12 22:27:52,543:INFO:Creating metrics dataframe
2025-05-12 22:27:52,544:INFO:Uploading results into container
2025-05-12 22:27:52,544:INFO:Uploading model into container now
2025-05-12 22:27:52,546:INFO:_master_model_container: 3
2025-05-12 22:27:52,546:INFO:_display_container: 2
2025-05-12 22:27:52,546:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-12 22:27:52,546:INFO:create_model() successfully completed......................................
2025-05-12 22:27:52,609:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:52,609:INFO:Creating metrics dataframe
2025-05-12 22:27:52,615:INFO:Initializing Decision Tree Classifier
2025-05-12 22:27:52,615:INFO:Total runtime is 0.016368858019510903 minutes
2025-05-12 22:27:52,618:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:52,619:INFO:Initializing create_model()
2025-05-12 22:27:52,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:52,619:INFO:Checking exceptions
2025-05-12 22:27:52,619:INFO:Importing libraries
2025-05-12 22:27:52,619:INFO:Copying training dataset
2025-05-12 22:27:52,622:INFO:Defining folds
2025-05-12 22:27:52,622:INFO:Declaring metric variables
2025-05-12 22:27:52,625:INFO:Importing untrained model
2025-05-12 22:27:52,629:INFO:Decision Tree Classifier Imported successfully
2025-05-12 22:27:52,635:INFO:Starting cross validation
2025-05-12 22:27:52,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:52,767:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:52,827:INFO:Calculating mean and std
2025-05-12 22:27:52,827:INFO:Creating metrics dataframe
2025-05-12 22:27:52,830:INFO:Uploading results into container
2025-05-12 22:27:52,830:INFO:Uploading model into container now
2025-05-12 22:27:52,831:INFO:_master_model_container: 4
2025-05-12 22:27:52,831:INFO:_display_container: 2
2025-05-12 22:27:52,831:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-12 22:27:52,831:INFO:create_model() successfully completed......................................
2025-05-12 22:27:52,897:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:52,897:INFO:Creating metrics dataframe
2025-05-12 22:27:52,903:INFO:Initializing SVM - Linear Kernel
2025-05-12 22:27:52,903:INFO:Total runtime is 0.02116921345392863 minutes
2025-05-12 22:27:52,904:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:52,906:INFO:Initializing create_model()
2025-05-12 22:27:52,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:52,906:INFO:Checking exceptions
2025-05-12 22:27:52,906:INFO:Importing libraries
2025-05-12 22:27:52,906:INFO:Copying training dataset
2025-05-12 22:27:52,909:INFO:Defining folds
2025-05-12 22:27:52,909:INFO:Declaring metric variables
2025-05-12 22:27:52,912:INFO:Importing untrained model
2025-05-12 22:27:52,916:INFO:SVM - Linear Kernel Imported successfully
2025-05-12 22:27:52,922:INFO:Starting cross validation
2025-05-12 22:27:52,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:53,032:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,061:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,131:INFO:Calculating mean and std
2025-05-12 22:27:53,133:INFO:Creating metrics dataframe
2025-05-12 22:27:53,135:INFO:Uploading results into container
2025-05-12 22:27:53,135:INFO:Uploading model into container now
2025-05-12 22:27:53,136:INFO:_master_model_container: 5
2025-05-12 22:27:53,136:INFO:_display_container: 2
2025-05-12 22:27:53,136:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-12 22:27:53,136:INFO:create_model() successfully completed......................................
2025-05-12 22:27:53,206:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:53,207:INFO:Creating metrics dataframe
2025-05-12 22:27:53,215:INFO:Initializing Ridge Classifier
2025-05-12 22:27:53,215:INFO:Total runtime is 0.026364723841349285 minutes
2025-05-12 22:27:53,217:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:53,219:INFO:Initializing create_model()
2025-05-12 22:27:53,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:53,219:INFO:Checking exceptions
2025-05-12 22:27:53,219:INFO:Importing libraries
2025-05-12 22:27:53,219:INFO:Copying training dataset
2025-05-12 22:27:53,223:INFO:Defining folds
2025-05-12 22:27:53,223:INFO:Declaring metric variables
2025-05-12 22:27:53,226:INFO:Importing untrained model
2025-05-12 22:27:53,230:INFO:Ridge Classifier Imported successfully
2025-05-12 22:27:53,237:INFO:Starting cross validation
2025-05-12 22:27:53,239:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:53,374:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,381:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,381:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,389:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,394:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,397:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,399:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,476:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,480:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:53,494:INFO:Calculating mean and std
2025-05-12 22:27:53,494:INFO:Creating metrics dataframe
2025-05-12 22:27:53,497:INFO:Uploading results into container
2025-05-12 22:27:53,497:INFO:Uploading model into container now
2025-05-12 22:27:53,498:INFO:_master_model_container: 6
2025-05-12 22:27:53,498:INFO:_display_container: 2
2025-05-12 22:27:53,498:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-12 22:27:53,498:INFO:create_model() successfully completed......................................
2025-05-12 22:27:53,579:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:53,579:INFO:Creating metrics dataframe
2025-05-12 22:27:53,587:INFO:Initializing Random Forest Classifier
2025-05-12 22:27:53,587:INFO:Total runtime is 0.03256822427113851 minutes
2025-05-12 22:27:53,590:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:53,591:INFO:Initializing create_model()
2025-05-12 22:27:53,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:53,591:INFO:Checking exceptions
2025-05-12 22:27:53,591:INFO:Importing libraries
2025-05-12 22:27:53,591:INFO:Copying training dataset
2025-05-12 22:27:53,596:INFO:Defining folds
2025-05-12 22:27:53,596:INFO:Declaring metric variables
2025-05-12 22:27:53,600:INFO:Importing untrained model
2025-05-12 22:27:53,606:INFO:Random Forest Classifier Imported successfully
2025-05-12 22:27:53,615:INFO:Starting cross validation
2025-05-12 22:27:53,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:54,258:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,283:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,284:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,291:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,303:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,303:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,434:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,661:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,671:INFO:Calculating mean and std
2025-05-12 22:27:54,673:INFO:Creating metrics dataframe
2025-05-12 22:27:54,676:INFO:Uploading results into container
2025-05-12 22:27:54,677:INFO:Uploading model into container now
2025-05-12 22:27:54,678:INFO:_master_model_container: 7
2025-05-12 22:27:54,678:INFO:_display_container: 2
2025-05-12 22:27:54,679:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-12 22:27:54,679:INFO:create_model() successfully completed......................................
2025-05-12 22:27:54,756:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:54,756:INFO:Creating metrics dataframe
2025-05-12 22:27:54,764:INFO:Initializing Quadratic Discriminant Analysis
2025-05-12 22:27:54,764:INFO:Total runtime is 0.052192703882853186 minutes
2025-05-12 22:27:54,768:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:54,768:INFO:Initializing create_model()
2025-05-12 22:27:54,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:54,769:INFO:Checking exceptions
2025-05-12 22:27:54,769:INFO:Importing libraries
2025-05-12 22:27:54,769:INFO:Copying training dataset
2025-05-12 22:27:54,774:INFO:Defining folds
2025-05-12 22:27:54,774:INFO:Declaring metric variables
2025-05-12 22:27:54,779:INFO:Importing untrained model
2025-05-12 22:27:54,783:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-12 22:27:54,794:INFO:Starting cross validation
2025-05-12 22:27:54,796:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:54,892:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:54,893:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:54,893:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:54,893:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:54,907:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:54,908:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:54,911:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:54,949:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:54,951:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:55,020:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:55,026:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:27:55,070:INFO:Calculating mean and std
2025-05-12 22:27:55,071:INFO:Creating metrics dataframe
2025-05-12 22:27:55,073:INFO:Uploading results into container
2025-05-12 22:27:55,074:INFO:Uploading model into container now
2025-05-12 22:27:55,075:INFO:_master_model_container: 8
2025-05-12 22:27:55,075:INFO:_display_container: 2
2025-05-12 22:27:55,076:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-12 22:27:55,076:INFO:create_model() successfully completed......................................
2025-05-12 22:27:55,153:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:55,153:INFO:Creating metrics dataframe
2025-05-12 22:27:55,162:INFO:Initializing Ada Boost Classifier
2025-05-12 22:27:55,163:INFO:Total runtime is 0.05881415208180745 minutes
2025-05-12 22:27:55,166:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:55,167:INFO:Initializing create_model()
2025-05-12 22:27:55,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:55,167:INFO:Checking exceptions
2025-05-12 22:27:55,167:INFO:Importing libraries
2025-05-12 22:27:55,167:INFO:Copying training dataset
2025-05-12 22:27:55,171:INFO:Defining folds
2025-05-12 22:27:55,171:INFO:Declaring metric variables
2025-05-12 22:27:55,176:INFO:Importing untrained model
2025-05-12 22:27:55,180:INFO:Ada Boost Classifier Imported successfully
2025-05-12 22:27:55,187:INFO:Starting cross validation
2025-05-12 22:27:55,191:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:55,280:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,285:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,287:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,296:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,299:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,299:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,307:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,310:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,547:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:55,576:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:55,632:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,636:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:27:55,828:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:55,840:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:55,851:INFO:Calculating mean and std
2025-05-12 22:27:55,853:INFO:Creating metrics dataframe
2025-05-12 22:27:55,856:INFO:Uploading results into container
2025-05-12 22:27:55,858:INFO:Uploading model into container now
2025-05-12 22:27:55,859:INFO:_master_model_container: 9
2025-05-12 22:27:55,859:INFO:_display_container: 2
2025-05-12 22:27:55,860:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-12 22:27:55,860:INFO:create_model() successfully completed......................................
2025-05-12 22:27:55,962:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:55,962:INFO:Creating metrics dataframe
2025-05-12 22:27:55,973:INFO:Initializing Gradient Boosting Classifier
2025-05-12 22:27:55,973:INFO:Total runtime is 0.07234033346176147 minutes
2025-05-12 22:27:55,978:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:55,978:INFO:Initializing create_model()
2025-05-12 22:27:55,979:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:55,979:INFO:Checking exceptions
2025-05-12 22:27:55,979:INFO:Importing libraries
2025-05-12 22:27:55,979:INFO:Copying training dataset
2025-05-12 22:27:55,983:INFO:Defining folds
2025-05-12 22:27:55,983:INFO:Declaring metric variables
2025-05-12 22:27:55,989:INFO:Importing untrained model
2025-05-12 22:27:55,994:INFO:Gradient Boosting Classifier Imported successfully
2025-05-12 22:27:56,005:INFO:Starting cross validation
2025-05-12 22:27:56,007:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:56,432:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:56,699:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:56,711:INFO:Calculating mean and std
2025-05-12 22:27:56,713:INFO:Creating metrics dataframe
2025-05-12 22:27:56,714:INFO:Uploading results into container
2025-05-12 22:27:56,716:INFO:Uploading model into container now
2025-05-12 22:27:56,716:INFO:_master_model_container: 10
2025-05-12 22:27:56,716:INFO:_display_container: 2
2025-05-12 22:27:56,717:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-12 22:27:56,717:INFO:create_model() successfully completed......................................
2025-05-12 22:27:56,799:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:56,799:INFO:Creating metrics dataframe
2025-05-12 22:27:56,809:INFO:Initializing Linear Discriminant Analysis
2025-05-12 22:27:56,809:INFO:Total runtime is 0.08626944224039713 minutes
2025-05-12 22:27:56,814:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:56,814:INFO:Initializing create_model()
2025-05-12 22:27:56,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:56,814:INFO:Checking exceptions
2025-05-12 22:27:56,814:INFO:Importing libraries
2025-05-12 22:27:56,815:INFO:Copying training dataset
2025-05-12 22:27:56,820:INFO:Defining folds
2025-05-12 22:27:56,820:INFO:Declaring metric variables
2025-05-12 22:27:56,824:INFO:Importing untrained model
2025-05-12 22:27:56,830:INFO:Linear Discriminant Analysis Imported successfully
2025-05-12 22:27:56,841:INFO:Starting cross validation
2025-05-12 22:27:56,843:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:57,000:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,006:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,015:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,031:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,057:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,139:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,153:INFO:Calculating mean and std
2025-05-12 22:27:57,156:INFO:Creating metrics dataframe
2025-05-12 22:27:57,160:INFO:Uploading results into container
2025-05-12 22:27:57,160:INFO:Uploading model into container now
2025-05-12 22:27:57,162:INFO:_master_model_container: 11
2025-05-12 22:27:57,162:INFO:_display_container: 2
2025-05-12 22:27:57,163:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-12 22:27:57,163:INFO:create_model() successfully completed......................................
2025-05-12 22:27:57,246:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:57,246:INFO:Creating metrics dataframe
2025-05-12 22:27:57,257:INFO:Initializing Extra Trees Classifier
2025-05-12 22:27:57,257:INFO:Total runtime is 0.09373947779337564 minutes
2025-05-12 22:27:57,261:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:57,262:INFO:Initializing create_model()
2025-05-12 22:27:57,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:57,262:INFO:Checking exceptions
2025-05-12 22:27:57,262:INFO:Importing libraries
2025-05-12 22:27:57,262:INFO:Copying training dataset
2025-05-12 22:27:57,267:INFO:Defining folds
2025-05-12 22:27:57,267:INFO:Declaring metric variables
2025-05-12 22:27:57,272:INFO:Importing untrained model
2025-05-12 22:27:57,277:INFO:Extra Trees Classifier Imported successfully
2025-05-12 22:27:57,288:INFO:Starting cross validation
2025-05-12 22:27:57,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:57,872:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,890:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:57,955:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:58,242:INFO:Calculating mean and std
2025-05-12 22:27:58,243:INFO:Creating metrics dataframe
2025-05-12 22:27:58,244:INFO:Uploading results into container
2025-05-12 22:27:58,246:INFO:Uploading model into container now
2025-05-12 22:27:58,246:INFO:_master_model_container: 12
2025-05-12 22:27:58,246:INFO:_display_container: 2
2025-05-12 22:27:58,247:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-12 22:27:58,247:INFO:create_model() successfully completed......................................
2025-05-12 22:27:58,330:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:58,331:INFO:Creating metrics dataframe
2025-05-12 22:27:58,344:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:27:58,344:INFO:Total runtime is 0.11185899178187052 minutes
2025-05-12 22:27:58,348:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:58,348:INFO:Initializing create_model()
2025-05-12 22:27:58,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:58,349:INFO:Checking exceptions
2025-05-12 22:27:58,349:INFO:Importing libraries
2025-05-12 22:27:58,349:INFO:Copying training dataset
2025-05-12 22:27:58,357:INFO:Defining folds
2025-05-12 22:27:58,357:INFO:Declaring metric variables
2025-05-12 22:27:58,360:INFO:Importing untrained model
2025-05-12 22:27:58,364:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:27:58,373:INFO:Starting cross validation
2025-05-12 22:27:58,376:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:58,832:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:58,853:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:58,863:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,020:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,033:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,118:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,133:INFO:Calculating mean and std
2025-05-12 22:27:59,136:INFO:Creating metrics dataframe
2025-05-12 22:27:59,139:INFO:Uploading results into container
2025-05-12 22:27:59,139:INFO:Uploading model into container now
2025-05-12 22:27:59,140:INFO:_master_model_container: 13
2025-05-12 22:27:59,140:INFO:_display_container: 2
2025-05-12 22:27:59,141:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:27:59,143:INFO:create_model() successfully completed......................................
2025-05-12 22:27:59,240:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:59,240:INFO:Creating metrics dataframe
2025-05-12 22:27:59,251:INFO:Initializing Dummy Classifier
2025-05-12 22:27:59,251:INFO:Total runtime is 0.12696446975072223 minutes
2025-05-12 22:27:59,255:INFO:SubProcess create_model() called ==================================
2025-05-12 22:27:59,256:INFO:Initializing create_model()
2025-05-12 22:27:59,256:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51C0AF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:59,256:INFO:Checking exceptions
2025-05-12 22:27:59,256:INFO:Importing libraries
2025-05-12 22:27:59,256:INFO:Copying training dataset
2025-05-12 22:27:59,261:INFO:Defining folds
2025-05-12 22:27:59,261:INFO:Declaring metric variables
2025-05-12 22:27:59,265:INFO:Importing untrained model
2025-05-12 22:27:59,270:INFO:Dummy Classifier Imported successfully
2025-05-12 22:27:59,279:INFO:Starting cross validation
2025-05-12 22:27:59,281:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:27:59,443:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,445:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,459:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,467:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,470:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,472:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,477:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,497:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,565:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,566:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:27:59,582:INFO:Calculating mean and std
2025-05-12 22:27:59,584:INFO:Creating metrics dataframe
2025-05-12 22:27:59,586:INFO:Uploading results into container
2025-05-12 22:27:59,587:INFO:Uploading model into container now
2025-05-12 22:27:59,587:INFO:_master_model_container: 14
2025-05-12 22:27:59,588:INFO:_display_container: 2
2025-05-12 22:27:59,588:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:27:59,588:INFO:create_model() successfully completed......................................
2025-05-12 22:27:59,669:INFO:SubProcess create_model() end ==================================
2025-05-12 22:27:59,669:INFO:Creating metrics dataframe
2025-05-12 22:27:59,680:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:27:59,695:INFO:Initializing create_model()
2025-05-12 22:27:59,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:59,696:INFO:Checking exceptions
2025-05-12 22:27:59,698:INFO:Importing libraries
2025-05-12 22:27:59,698:INFO:Copying training dataset
2025-05-12 22:27:59,703:INFO:Defining folds
2025-05-12 22:27:59,704:INFO:Declaring metric variables
2025-05-12 22:27:59,704:INFO:Importing untrained model
2025-05-12 22:27:59,704:INFO:Declaring custom model
2025-05-12 22:27:59,704:INFO:Dummy Classifier Imported successfully
2025-05-12 22:27:59,706:INFO:Cross validation set to False
2025-05-12 22:27:59,706:INFO:Fitting Model
2025-05-12 22:27:59,749:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:27:59,749:INFO:create_model() successfully completed......................................
2025-05-12 22:27:59,849:INFO:_master_model_container: 14
2025-05-12 22:27:59,849:INFO:_display_container: 2
2025-05-12 22:27:59,849:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:27:59,849:INFO:compare_models() successfully completed......................................
2025-05-12 22:27:59,870:INFO:Initializing create_model()
2025-05-12 22:27:59,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:27:59,871:INFO:Checking exceptions
2025-05-12 22:27:59,895:INFO:Importing libraries
2025-05-12 22:27:59,895:INFO:Copying training dataset
2025-05-12 22:27:59,900:INFO:Defining folds
2025-05-12 22:27:59,900:INFO:Declaring metric variables
2025-05-12 22:27:59,906:INFO:Importing untrained model
2025-05-12 22:27:59,911:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:27:59,921:INFO:Starting cross validation
2025-05-12 22:27:59,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:00,327:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:00,332:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:00,363:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:00,533:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:00,566:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:00,676:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:00,694:INFO:Calculating mean and std
2025-05-12 22:28:00,694:INFO:Creating metrics dataframe
2025-05-12 22:28:00,704:INFO:Finalizing model
2025-05-12 22:28:00,779:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:28:00,779:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000074 seconds.
2025-05-12 22:28:00,779:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-12 22:28:00,779:INFO:[LightGBM] [Info] Total Bins 117
2025-05-12 22:28:00,779:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:28:00,779:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:28:00,779:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:28:00,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:00,815:INFO:Uploading results into container
2025-05-12 22:28:00,816:INFO:Uploading model into container now
2025-05-12 22:28:00,841:INFO:_master_model_container: 15
2025-05-12 22:28:00,841:INFO:_display_container: 3
2025-05-12 22:28:00,843:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:28:00,843:INFO:create_model() successfully completed......................................
2025-05-12 22:28:00,972:INFO:Initializing tune_model()
2025-05-12 22:28:00,972:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:28:00,972:INFO:Checking exceptions
2025-05-12 22:28:01,001:INFO:Copying training dataset
2025-05-12 22:28:01,010:INFO:Checking base model
2025-05-12 22:28:01,010:INFO:Base model : Light Gradient Boosting Machine
2025-05-12 22:28:01,022:INFO:Declaring metric variables
2025-05-12 22:28:01,029:INFO:Defining Hyperparameters
2025-05-12 22:28:01,147:INFO:Tuning with n_jobs=-1
2025-05-12 22:28:01,147:INFO:Initializing RandomizedSearchCV
2025-05-12 22:28:08,121:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2025-05-12 22:28:08,123:INFO:Hyperparameter search completed
2025-05-12 22:28:08,124:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:08,126:INFO:Initializing create_model()
2025-05-12 22:28:08,126:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D519ADD50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2025-05-12 22:28:08,126:INFO:Checking exceptions
2025-05-12 22:28:08,126:INFO:Importing libraries
2025-05-12 22:28:08,127:INFO:Copying training dataset
2025-05-12 22:28:08,135:INFO:Defining folds
2025-05-12 22:28:08,135:INFO:Declaring metric variables
2025-05-12 22:28:08,140:INFO:Importing untrained model
2025-05-12 22:28:08,141:INFO:Declaring custom model
2025-05-12 22:28:08,150:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:28:08,164:INFO:Starting cross validation
2025-05-12 22:28:08,166:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:08,487:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,488:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,491:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,519:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,547:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,550:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,647:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,689:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,731:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,733:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:08,749:INFO:Calculating mean and std
2025-05-12 22:28:08,751:INFO:Creating metrics dataframe
2025-05-12 22:28:08,761:INFO:Finalizing model
2025-05-12 22:28:08,831:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:28:08,831:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:28:08,831:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:28:08,833:INFO:[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.
2025-05-12 22:28:08,834:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-05-12 22:28:08,834:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-05-12 22:28:08,834:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-05-12 22:28:08,834:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:28:08,834:INFO:[LightGBM] [Info] Total Bins 0
2025-05-12 22:28:08,834:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 0
2025-05-12 22:28:08,835:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:28:08,835:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:28:08,835:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,835:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,835:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,835:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,853:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,853:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-05-12 22:28:08,866:INFO:Uploading results into container
2025-05-12 22:28:08,867:INFO:Uploading model into container now
2025-05-12 22:28:08,868:INFO:_master_model_container: 16
2025-05-12 22:28:08,868:INFO:_display_container: 4
2025-05-12 22:28:08,869:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:28:08,869:INFO:create_model() successfully completed......................................
2025-05-12 22:28:08,977:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:08,979:INFO:choose_better activated
2025-05-12 22:28:08,983:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:08,984:INFO:Initializing create_model()
2025-05-12 22:28:08,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:08,984:INFO:Checking exceptions
2025-05-12 22:28:08,986:INFO:Importing libraries
2025-05-12 22:28:08,986:INFO:Copying training dataset
2025-05-12 22:28:08,990:INFO:Defining folds
2025-05-12 22:28:08,990:INFO:Declaring metric variables
2025-05-12 22:28:08,990:INFO:Importing untrained model
2025-05-12 22:28:08,990:INFO:Declaring custom model
2025-05-12 22:28:08,991:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:28:08,993:INFO:Starting cross validation
2025-05-12 22:28:08,995:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:09,391:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:09,401:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:09,451:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:09,464:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:09,587:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:09,773:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:09,788:INFO:Calculating mean and std
2025-05-12 22:28:09,789:INFO:Creating metrics dataframe
2025-05-12 22:28:09,793:INFO:Finalizing model
2025-05-12 22:28:09,868:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-05-12 22:28:09,868:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000068 seconds.
2025-05-12 22:28:09,868:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-12 22:28:09,868:INFO:[LightGBM] [Info] Total Bins 117
2025-05-12 22:28:09,869:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-05-12 22:28:09,869:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-05-12 22:28:09,869:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-05-12 22:28:09,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-12 22:28:09,897:INFO:Uploading results into container
2025-05-12 22:28:09,898:INFO:Uploading model into container now
2025-05-12 22:28:09,899:INFO:_master_model_container: 17
2025-05-12 22:28:09,899:INFO:_display_container: 5
2025-05-12 22:28:09,899:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:28:09,899:INFO:create_model() successfully completed......................................
2025-05-12 22:28:10,008:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:10,009:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7891
2025-05-12 22:28:10,011:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8291
2025-05-12 22:28:10,012:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-05-12 22:28:10,013:INFO:choose_better completed
2025-05-12 22:28:10,028:INFO:_master_model_container: 17
2025-05-12 22:28:10,029:INFO:_display_container: 4
2025-05-12 22:28:10,029:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:28:10,030:INFO:tune_model() successfully completed......................................
2025-05-12 22:28:10,164:INFO:Initializing evaluate_model()
2025-05-12 22:28:10,164:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:28:10,178:INFO:Initializing plot_model()
2025-05-12 22:28:10,178:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:28:10,179:INFO:Checking exceptions
2025-05-12 22:28:10,181:INFO:Preloading libraries
2025-05-12 22:28:10,183:INFO:Copying training dataset
2025-05-12 22:28:10,183:INFO:Plot type: pipeline
2025-05-12 22:28:10,412:INFO:Visual Rendered Successfully
2025-05-12 22:28:10,488:INFO:plot_model() successfully completed......................................
2025-05-12 22:28:10,513:INFO:Initializing predict_model()
2025-05-12 22:28:10,513:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51C0FA50>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027D517ECD60>)
2025-05-12 22:28:10,513:INFO:Checking exceptions
2025-05-12 22:28:10,513:INFO:Preloading libraries
2025-05-12 22:28:10,631:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:10,785:INFO:Initializing save_model()
2025-05-12 22:28:10,785:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-12 22:28:10,785:INFO:Adding model into prep_pipe
2025-05-12 22:28:10,799:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:28:10,817:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-12 22:28:10,817:INFO:save_model() successfully completed......................................
2025-05-12 22:28:14,026:INFO:PyCaret ClassificationExperiment
2025-05-12 22:28:14,027:INFO:Logging name: clf-default-name
2025-05-12 22:28:14,027:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-12 22:28:14,027:INFO:version 3.3.2
2025-05-12 22:28:14,027:INFO:Initializing setup()
2025-05-12 22:28:14,027:INFO:self.USI: a35d
2025-05-12 22:28:14,027:INFO:self._variable_keys: {'fold_groups_param', 'memory', 'n_jobs_param', 'fold_generator', 'X', 'seed', '_available_plots', '_ml_usecase', 'y_train', 'html_param', 'logging_param', 'target_param', 'idx', 'log_plots_param', 'pipeline', 'fix_imbalance', 'gpu_n_jobs_param', 'y_test', 'exp_id', 'y', 'is_multiclass', 'data', 'gpu_param', 'X_train', 'USI', 'exp_name_log', 'fold_shuffle_param', 'X_test'}
2025-05-12 22:28:14,027:INFO:Checking environment
2025-05-12 22:28:14,027:INFO:python_version: 3.11.8
2025-05-12 22:28:14,027:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:28:14,027:INFO:machine: AMD64
2025-05-12 22:28:14,027:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:28:14,034:INFO:Memory: svmem(total=16907886592, available=2407600128, percent=85.8, used=14500286464, free=2407600128)
2025-05-12 22:28:14,034:INFO:Physical Core: 4
2025-05-12 22:28:14,034:INFO:Logical Core: 8
2025-05-12 22:28:14,034:INFO:Checking libraries
2025-05-12 22:28:14,034:INFO:System:
2025-05-12 22:28:14,035:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:28:14,035:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:28:14,035:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:28:14,035:INFO:PyCaret required dependencies:
2025-05-12 22:28:14,035:INFO:                 pip: 24.0
2025-05-12 22:28:14,035:INFO:          setuptools: 65.5.0
2025-05-12 22:28:14,035:INFO:             pycaret: 3.3.2
2025-05-12 22:28:14,035:INFO:             IPython: 9.2.0
2025-05-12 22:28:14,035:INFO:          ipywidgets: 8.1.7
2025-05-12 22:28:14,035:INFO:                tqdm: 4.67.1
2025-05-12 22:28:14,035:INFO:               numpy: 1.26.4
2025-05-12 22:28:14,035:INFO:              pandas: 2.1.4
2025-05-12 22:28:14,035:INFO:              jinja2: 3.1.6
2025-05-12 22:28:14,035:INFO:               scipy: 1.11.4
2025-05-12 22:28:14,035:INFO:              joblib: 1.3.2
2025-05-12 22:28:14,035:INFO:             sklearn: 1.4.2
2025-05-12 22:28:14,035:INFO:                pyod: 2.0.5
2025-05-12 22:28:14,035:INFO:            imblearn: 0.13.0
2025-05-12 22:28:14,036:INFO:   category_encoders: 2.7.0
2025-05-12 22:28:14,036:INFO:            lightgbm: 4.6.0
2025-05-12 22:28:14,036:INFO:               numba: 0.61.2
2025-05-12 22:28:14,036:INFO:            requests: 2.32.3
2025-05-12 22:28:14,036:INFO:          matplotlib: 3.7.5
2025-05-12 22:28:14,036:INFO:          scikitplot: 0.3.7
2025-05-12 22:28:14,036:INFO:         yellowbrick: 1.5
2025-05-12 22:28:14,036:INFO:              plotly: 5.24.1
2025-05-12 22:28:14,036:INFO:    plotly-resampler: Not installed
2025-05-12 22:28:14,036:INFO:             kaleido: 0.2.1
2025-05-12 22:28:14,036:INFO:           schemdraw: 0.15
2025-05-12 22:28:14,036:INFO:         statsmodels: 0.14.4
2025-05-12 22:28:14,036:INFO:              sktime: 0.26.0
2025-05-12 22:28:14,036:INFO:               tbats: 1.1.3
2025-05-12 22:28:14,036:INFO:            pmdarima: 2.0.4
2025-05-12 22:28:14,036:INFO:              psutil: 7.0.0
2025-05-12 22:28:14,036:INFO:          markupsafe: 3.0.2
2025-05-12 22:28:14,036:INFO:             pickle5: Not installed
2025-05-12 22:28:14,036:INFO:         cloudpickle: 3.1.1
2025-05-12 22:28:14,037:INFO:         deprecation: 2.1.0
2025-05-12 22:28:14,037:INFO:              xxhash: 3.5.0
2025-05-12 22:28:14,037:INFO:           wurlitzer: Not installed
2025-05-12 22:28:14,037:INFO:PyCaret optional dependencies:
2025-05-12 22:28:14,037:INFO:                shap: Not installed
2025-05-12 22:28:14,037:INFO:           interpret: Not installed
2025-05-12 22:28:14,037:INFO:                umap: Not installed
2025-05-12 22:28:14,037:INFO:     ydata_profiling: Not installed
2025-05-12 22:28:14,037:INFO:  explainerdashboard: Not installed
2025-05-12 22:28:14,037:INFO:             autoviz: Not installed
2025-05-12 22:28:14,037:INFO:           fairlearn: Not installed
2025-05-12 22:28:14,037:INFO:          deepchecks: Not installed
2025-05-12 22:28:14,037:INFO:             xgboost: Not installed
2025-05-12 22:28:14,037:INFO:            catboost: Not installed
2025-05-12 22:28:14,038:INFO:              kmodes: Not installed
2025-05-12 22:28:14,038:INFO:             mlxtend: Not installed
2025-05-12 22:28:14,038:INFO:       statsforecast: Not installed
2025-05-12 22:28:14,038:INFO:        tune_sklearn: Not installed
2025-05-12 22:28:14,038:INFO:                 ray: Not installed
2025-05-12 22:28:14,038:INFO:            hyperopt: Not installed
2025-05-12 22:28:14,038:INFO:              optuna: Not installed
2025-05-12 22:28:14,038:INFO:               skopt: Not installed
2025-05-12 22:28:14,038:INFO:              mlflow: Not installed
2025-05-12 22:28:14,038:INFO:              gradio: Not installed
2025-05-12 22:28:14,038:INFO:             fastapi: Not installed
2025-05-12 22:28:14,038:INFO:             uvicorn: Not installed
2025-05-12 22:28:14,038:INFO:              m2cgen: Not installed
2025-05-12 22:28:14,038:INFO:           evidently: Not installed
2025-05-12 22:28:14,038:INFO:               fugue: Not installed
2025-05-12 22:28:14,039:INFO:           streamlit: Not installed
2025-05-12 22:28:14,039:INFO:             prophet: Not installed
2025-05-12 22:28:14,039:INFO:None
2025-05-12 22:28:14,039:INFO:Set up data.
2025-05-12 22:28:14,043:INFO:Set up folding strategy.
2025-05-12 22:28:14,043:INFO:Set up train/test split.
2025-05-12 22:28:14,046:INFO:Set up index.
2025-05-12 22:28:14,047:INFO:Assigning column types.
2025-05-12 22:28:14,049:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:28:14,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:28:14,099:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:28:14,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,166:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:28:14,167:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:28:14,194:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,194:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,195:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:28:14,237:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:28:14,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,266:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,310:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-12 22:28:14,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,340:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-12 22:28:14,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,487:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,487:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,489:INFO:Preparing preprocessing pipeline...
2025-05-12 22:28:14,490:INFO:Set up simple imputation.
2025-05-12 22:28:14,491:INFO:Set up encoding of categorical features.
2025-05-12 22:28:14,491:INFO:Set up feature normalization.
2025-05-12 22:28:14,550:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:28:14,555:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:28:14,555:INFO:Creating final display dataframe.
2025-05-12 22:28:14,716:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              a35d
2025-05-12 22:28:14,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,864:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:28:14,865:INFO:setup() successfully completed in 0.84s...............
2025-05-12 22:28:14,881:INFO:Initializing compare_models()
2025-05-12 22:28:14,881:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-12 22:28:14,881:INFO:Checking exceptions
2025-05-12 22:28:14,884:INFO:Preparing display monitor
2025-05-12 22:28:14,913:INFO:Initializing Logistic Regression
2025-05-12 22:28:14,913:INFO:Total runtime is 0.0 minutes
2025-05-12 22:28:14,917:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:14,917:INFO:Initializing create_model()
2025-05-12 22:28:14,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:14,918:INFO:Checking exceptions
2025-05-12 22:28:14,918:INFO:Importing libraries
2025-05-12 22:28:14,918:INFO:Copying training dataset
2025-05-12 22:28:14,924:INFO:Defining folds
2025-05-12 22:28:14,924:INFO:Declaring metric variables
2025-05-12 22:28:14,930:INFO:Importing untrained model
2025-05-12 22:28:14,935:INFO:Logistic Regression Imported successfully
2025-05-12 22:28:14,945:INFO:Starting cross validation
2025-05-12 22:28:14,947:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:15,150:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,177:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,178:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,186:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,193:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,205:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,286:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,299:INFO:Calculating mean and std
2025-05-12 22:28:15,300:INFO:Creating metrics dataframe
2025-05-12 22:28:15,301:INFO:Uploading results into container
2025-05-12 22:28:15,303:INFO:Uploading model into container now
2025-05-12 22:28:15,303:INFO:_master_model_container: 1
2025-05-12 22:28:15,303:INFO:_display_container: 2
2025-05-12 22:28:15,304:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-12 22:28:15,304:INFO:create_model() successfully completed......................................
2025-05-12 22:28:15,387:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:15,387:INFO:Creating metrics dataframe
2025-05-12 22:28:15,395:INFO:Initializing K Neighbors Classifier
2025-05-12 22:28:15,395:INFO:Total runtime is 0.00803908109664917 minutes
2025-05-12 22:28:15,399:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:15,399:INFO:Initializing create_model()
2025-05-12 22:28:15,400:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:15,400:INFO:Checking exceptions
2025-05-12 22:28:15,400:INFO:Importing libraries
2025-05-12 22:28:15,400:INFO:Copying training dataset
2025-05-12 22:28:15,403:INFO:Defining folds
2025-05-12 22:28:15,403:INFO:Declaring metric variables
2025-05-12 22:28:15,408:INFO:Importing untrained model
2025-05-12 22:28:15,411:INFO:K Neighbors Classifier Imported successfully
2025-05-12 22:28:15,420:INFO:Starting cross validation
2025-05-12 22:28:15,423:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:15,642:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,647:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,681:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,687:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,689:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,807:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:15,823:INFO:Calculating mean and std
2025-05-12 22:28:15,823:INFO:Creating metrics dataframe
2025-05-12 22:28:15,825:INFO:Uploading results into container
2025-05-12 22:28:15,826:INFO:Uploading model into container now
2025-05-12 22:28:15,826:INFO:_master_model_container: 2
2025-05-12 22:28:15,826:INFO:_display_container: 2
2025-05-12 22:28:15,827:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-12 22:28:15,827:INFO:create_model() successfully completed......................................
2025-05-12 22:28:15,909:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:15,909:INFO:Creating metrics dataframe
2025-05-12 22:28:15,916:INFO:Initializing Naive Bayes
2025-05-12 22:28:15,916:INFO:Total runtime is 0.016720116138458252 minutes
2025-05-12 22:28:15,921:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:15,922:INFO:Initializing create_model()
2025-05-12 22:28:15,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:15,922:INFO:Checking exceptions
2025-05-12 22:28:15,922:INFO:Importing libraries
2025-05-12 22:28:15,922:INFO:Copying training dataset
2025-05-12 22:28:15,927:INFO:Defining folds
2025-05-12 22:28:15,927:INFO:Declaring metric variables
2025-05-12 22:28:15,930:INFO:Importing untrained model
2025-05-12 22:28:15,936:INFO:Naive Bayes Imported successfully
2025-05-12 22:28:15,947:INFO:Starting cross validation
2025-05-12 22:28:15,949:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:16,100:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:16,104:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:16,113:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:16,216:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:16,227:INFO:Calculating mean and std
2025-05-12 22:28:16,228:INFO:Creating metrics dataframe
2025-05-12 22:28:16,230:INFO:Uploading results into container
2025-05-12 22:28:16,231:INFO:Uploading model into container now
2025-05-12 22:28:16,231:INFO:_master_model_container: 3
2025-05-12 22:28:16,232:INFO:_display_container: 2
2025-05-12 22:28:16,232:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-12 22:28:16,232:INFO:create_model() successfully completed......................................
2025-05-12 22:28:16,313:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:16,313:INFO:Creating metrics dataframe
2025-05-12 22:28:16,321:INFO:Initializing Decision Tree Classifier
2025-05-12 22:28:16,321:INFO:Total runtime is 0.023478575547536212 minutes
2025-05-12 22:28:16,324:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:16,326:INFO:Initializing create_model()
2025-05-12 22:28:16,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:16,326:INFO:Checking exceptions
2025-05-12 22:28:16,326:INFO:Importing libraries
2025-05-12 22:28:16,326:INFO:Copying training dataset
2025-05-12 22:28:16,330:INFO:Defining folds
2025-05-12 22:28:16,330:INFO:Declaring metric variables
2025-05-12 22:28:16,334:INFO:Importing untrained model
2025-05-12 22:28:16,341:INFO:Decision Tree Classifier Imported successfully
2025-05-12 22:28:16,349:INFO:Starting cross validation
2025-05-12 22:28:16,351:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:16,507:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:16,617:INFO:Calculating mean and std
2025-05-12 22:28:16,618:INFO:Creating metrics dataframe
2025-05-12 22:28:16,621:INFO:Uploading results into container
2025-05-12 22:28:16,622:INFO:Uploading model into container now
2025-05-12 22:28:16,622:INFO:_master_model_container: 4
2025-05-12 22:28:16,622:INFO:_display_container: 2
2025-05-12 22:28:16,623:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-12 22:28:16,623:INFO:create_model() successfully completed......................................
2025-05-12 22:28:16,699:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:16,700:INFO:Creating metrics dataframe
2025-05-12 22:28:16,710:INFO:Initializing SVM - Linear Kernel
2025-05-12 22:28:16,710:INFO:Total runtime is 0.029951679706573486 minutes
2025-05-12 22:28:16,714:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:16,714:INFO:Initializing create_model()
2025-05-12 22:28:16,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:16,716:INFO:Checking exceptions
2025-05-12 22:28:16,716:INFO:Importing libraries
2025-05-12 22:28:16,716:INFO:Copying training dataset
2025-05-12 22:28:16,720:INFO:Defining folds
2025-05-12 22:28:16,720:INFO:Declaring metric variables
2025-05-12 22:28:16,724:INFO:Importing untrained model
2025-05-12 22:28:16,730:INFO:SVM - Linear Kernel Imported successfully
2025-05-12 22:28:16,741:INFO:Starting cross validation
2025-05-12 22:28:16,743:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:16,900:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:16,937:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,028:INFO:Calculating mean and std
2025-05-12 22:28:17,030:INFO:Creating metrics dataframe
2025-05-12 22:28:17,032:INFO:Uploading results into container
2025-05-12 22:28:17,033:INFO:Uploading model into container now
2025-05-12 22:28:17,033:INFO:_master_model_container: 5
2025-05-12 22:28:17,034:INFO:_display_container: 2
2025-05-12 22:28:17,034:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-12 22:28:17,034:INFO:create_model() successfully completed......................................
2025-05-12 22:28:17,143:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:17,144:INFO:Creating metrics dataframe
2025-05-12 22:28:17,157:INFO:Initializing Ridge Classifier
2025-05-12 22:28:17,159:INFO:Total runtime is 0.03743065992991129 minutes
2025-05-12 22:28:17,166:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:17,167:INFO:Initializing create_model()
2025-05-12 22:28:17,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:17,167:INFO:Checking exceptions
2025-05-12 22:28:17,167:INFO:Importing libraries
2025-05-12 22:28:17,167:INFO:Copying training dataset
2025-05-12 22:28:17,178:INFO:Defining folds
2025-05-12 22:28:17,178:INFO:Declaring metric variables
2025-05-12 22:28:17,185:INFO:Importing untrained model
2025-05-12 22:28:17,193:INFO:Ridge Classifier Imported successfully
2025-05-12 22:28:17,209:INFO:Starting cross validation
2025-05-12 22:28:17,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:17,395:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,396:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,398:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,436:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,440:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,463:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,471:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,546:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,547:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:17,565:INFO:Calculating mean and std
2025-05-12 22:28:17,566:INFO:Creating metrics dataframe
2025-05-12 22:28:17,569:INFO:Uploading results into container
2025-05-12 22:28:17,570:INFO:Uploading model into container now
2025-05-12 22:28:17,571:INFO:_master_model_container: 6
2025-05-12 22:28:17,571:INFO:_display_container: 2
2025-05-12 22:28:17,571:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-12 22:28:17,573:INFO:create_model() successfully completed......................................
2025-05-12 22:28:17,679:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:17,679:INFO:Creating metrics dataframe
2025-05-12 22:28:17,689:INFO:Initializing Random Forest Classifier
2025-05-12 22:28:17,689:INFO:Total runtime is 0.046272607644399 minutes
2025-05-12 22:28:17,694:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:17,694:INFO:Initializing create_model()
2025-05-12 22:28:17,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:17,694:INFO:Checking exceptions
2025-05-12 22:28:17,694:INFO:Importing libraries
2025-05-12 22:28:17,694:INFO:Copying training dataset
2025-05-12 22:28:17,701:INFO:Defining folds
2025-05-12 22:28:17,701:INFO:Declaring metric variables
2025-05-12 22:28:17,709:INFO:Importing untrained model
2025-05-12 22:28:17,714:INFO:Random Forest Classifier Imported successfully
2025-05-12 22:28:17,724:INFO:Starting cross validation
2025-05-12 22:28:17,727:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:18,455:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,455:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,461:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,479:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,484:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,515:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,636:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,865:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:18,873:INFO:Calculating mean and std
2025-05-12 22:28:18,875:INFO:Creating metrics dataframe
2025-05-12 22:28:18,877:INFO:Uploading results into container
2025-05-12 22:28:18,877:INFO:Uploading model into container now
2025-05-12 22:28:18,878:INFO:_master_model_container: 7
2025-05-12 22:28:18,878:INFO:_display_container: 2
2025-05-12 22:28:18,878:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-12 22:28:18,878:INFO:create_model() successfully completed......................................
2025-05-12 22:28:18,953:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:18,953:INFO:Creating metrics dataframe
2025-05-12 22:28:18,961:INFO:Initializing Quadratic Discriminant Analysis
2025-05-12 22:28:18,961:INFO:Total runtime is 0.06747546990712483 minutes
2025-05-12 22:28:18,970:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:18,970:INFO:Initializing create_model()
2025-05-12 22:28:18,971:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:18,971:INFO:Checking exceptions
2025-05-12 22:28:18,971:INFO:Importing libraries
2025-05-12 22:28:18,971:INFO:Copying training dataset
2025-05-12 22:28:18,991:INFO:Defining folds
2025-05-12 22:28:18,991:INFO:Declaring metric variables
2025-05-12 22:28:18,998:INFO:Importing untrained model
2025-05-12 22:28:19,007:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-12 22:28:19,016:INFO:Starting cross validation
2025-05-12 22:28:19,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:19,116:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,119:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,120:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,125:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,131:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,140:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,163:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:19,259:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,265:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-12 22:28:19,311:INFO:Calculating mean and std
2025-05-12 22:28:19,312:INFO:Creating metrics dataframe
2025-05-12 22:28:19,313:INFO:Uploading results into container
2025-05-12 22:28:19,315:INFO:Uploading model into container now
2025-05-12 22:28:19,316:INFO:_master_model_container: 8
2025-05-12 22:28:19,316:INFO:_display_container: 2
2025-05-12 22:28:19,316:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-12 22:28:19,316:INFO:create_model() successfully completed......................................
2025-05-12 22:28:19,398:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:19,398:INFO:Creating metrics dataframe
2025-05-12 22:28:19,409:INFO:Initializing Ada Boost Classifier
2025-05-12 22:28:19,409:INFO:Total runtime is 0.07493642965952554 minutes
2025-05-12 22:28:19,414:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:19,414:INFO:Initializing create_model()
2025-05-12 22:28:19,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:19,414:INFO:Checking exceptions
2025-05-12 22:28:19,414:INFO:Importing libraries
2025-05-12 22:28:19,414:INFO:Copying training dataset
2025-05-12 22:28:19,419:INFO:Defining folds
2025-05-12 22:28:19,419:INFO:Declaring metric variables
2025-05-12 22:28:19,424:INFO:Importing untrained model
2025-05-12 22:28:19,427:INFO:Ada Boost Classifier Imported successfully
2025-05-12 22:28:19,437:INFO:Starting cross validation
2025-05-12 22:28:19,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:19,536:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,539:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,542:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,544:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,545:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,547:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,564:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,626:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,837:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:19,956:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,960:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-12 22:28:19,981:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:20,134:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:20,136:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:20,146:INFO:Calculating mean and std
2025-05-12 22:28:20,147:INFO:Creating metrics dataframe
2025-05-12 22:28:20,149:INFO:Uploading results into container
2025-05-12 22:28:20,151:INFO:Uploading model into container now
2025-05-12 22:28:20,151:INFO:_master_model_container: 9
2025-05-12 22:28:20,151:INFO:_display_container: 2
2025-05-12 22:28:20,153:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-12 22:28:20,153:INFO:create_model() successfully completed......................................
2025-05-12 22:28:20,231:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:20,231:INFO:Creating metrics dataframe
2025-05-12 22:28:20,241:INFO:Initializing Gradient Boosting Classifier
2025-05-12 22:28:20,242:INFO:Total runtime is 0.08881661097208658 minutes
2025-05-12 22:28:20,245:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:20,245:INFO:Initializing create_model()
2025-05-12 22:28:20,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:20,245:INFO:Checking exceptions
2025-05-12 22:28:20,245:INFO:Importing libraries
2025-05-12 22:28:20,245:INFO:Copying training dataset
2025-05-12 22:28:20,251:INFO:Defining folds
2025-05-12 22:28:20,251:INFO:Declaring metric variables
2025-05-12 22:28:20,255:INFO:Importing untrained model
2025-05-12 22:28:20,260:INFO:Gradient Boosting Classifier Imported successfully
2025-05-12 22:28:20,269:INFO:Starting cross validation
2025-05-12 22:28:20,270:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:20,717:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:20,916:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:20,934:INFO:Calculating mean and std
2025-05-12 22:28:20,935:INFO:Creating metrics dataframe
2025-05-12 22:28:20,937:INFO:Uploading results into container
2025-05-12 22:28:20,937:INFO:Uploading model into container now
2025-05-12 22:28:20,937:INFO:_master_model_container: 10
2025-05-12 22:28:20,937:INFO:_display_container: 2
2025-05-12 22:28:20,939:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-12 22:28:20,939:INFO:create_model() successfully completed......................................
2025-05-12 22:28:21,015:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:21,015:INFO:Creating metrics dataframe
2025-05-12 22:28:21,026:INFO:Initializing Linear Discriminant Analysis
2025-05-12 22:28:21,026:INFO:Total runtime is 0.10188523133595784 minutes
2025-05-12 22:28:21,029:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:21,029:INFO:Initializing create_model()
2025-05-12 22:28:21,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:21,030:INFO:Checking exceptions
2025-05-12 22:28:21,030:INFO:Importing libraries
2025-05-12 22:28:21,030:INFO:Copying training dataset
2025-05-12 22:28:21,036:INFO:Defining folds
2025-05-12 22:28:21,036:INFO:Declaring metric variables
2025-05-12 22:28:21,041:INFO:Importing untrained model
2025-05-12 22:28:21,044:INFO:Linear Discriminant Analysis Imported successfully
2025-05-12 22:28:21,053:INFO:Starting cross validation
2025-05-12 22:28:21,055:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:21,206:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:21,207:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:21,229:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:21,230:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:21,245:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:21,323:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:21,330:INFO:Calculating mean and std
2025-05-12 22:28:21,331:INFO:Creating metrics dataframe
2025-05-12 22:28:21,333:INFO:Uploading results into container
2025-05-12 22:28:21,334:INFO:Uploading model into container now
2025-05-12 22:28:21,334:INFO:_master_model_container: 11
2025-05-12 22:28:21,334:INFO:_display_container: 2
2025-05-12 22:28:21,336:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-12 22:28:21,336:INFO:create_model() successfully completed......................................
2025-05-12 22:28:21,417:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:21,417:INFO:Creating metrics dataframe
2025-05-12 22:28:21,427:INFO:Initializing Extra Trees Classifier
2025-05-12 22:28:21,427:INFO:Total runtime is 0.10856681664784748 minutes
2025-05-12 22:28:21,430:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:21,431:INFO:Initializing create_model()
2025-05-12 22:28:21,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:21,431:INFO:Checking exceptions
2025-05-12 22:28:21,431:INFO:Importing libraries
2025-05-12 22:28:21,431:INFO:Copying training dataset
2025-05-12 22:28:21,437:INFO:Defining folds
2025-05-12 22:28:21,437:INFO:Declaring metric variables
2025-05-12 22:28:21,440:INFO:Importing untrained model
2025-05-12 22:28:21,444:INFO:Extra Trees Classifier Imported successfully
2025-05-12 22:28:21,454:INFO:Starting cross validation
2025-05-12 22:28:21,455:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:22,098:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:22,147:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:22,198:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:22,459:INFO:Calculating mean and std
2025-05-12 22:28:22,461:INFO:Creating metrics dataframe
2025-05-12 22:28:22,463:INFO:Uploading results into container
2025-05-12 22:28:22,464:INFO:Uploading model into container now
2025-05-12 22:28:22,466:INFO:_master_model_container: 12
2025-05-12 22:28:22,466:INFO:_display_container: 2
2025-05-12 22:28:22,466:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-12 22:28:22,466:INFO:create_model() successfully completed......................................
2025-05-12 22:28:22,544:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:22,544:INFO:Creating metrics dataframe
2025-05-12 22:28:22,554:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:28:22,554:INFO:Total runtime is 0.1273613731066386 minutes
2025-05-12 22:28:22,558:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:22,559:INFO:Initializing create_model()
2025-05-12 22:28:22,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:22,559:INFO:Checking exceptions
2025-05-12 22:28:22,559:INFO:Importing libraries
2025-05-12 22:28:22,559:INFO:Copying training dataset
2025-05-12 22:28:22,565:INFO:Defining folds
2025-05-12 22:28:22,565:INFO:Declaring metric variables
2025-05-12 22:28:22,569:INFO:Importing untrained model
2025-05-12 22:28:22,575:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:28:22,584:INFO:Starting cross validation
2025-05-12 22:28:22,587:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:22,917:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:22,944:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:22,948:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,046:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,068:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,228:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,253:INFO:Calculating mean and std
2025-05-12 22:28:23,255:INFO:Creating metrics dataframe
2025-05-12 22:28:23,259:INFO:Uploading results into container
2025-05-12 22:28:23,260:INFO:Uploading model into container now
2025-05-12 22:28:23,261:INFO:_master_model_container: 13
2025-05-12 22:28:23,261:INFO:_display_container: 2
2025-05-12 22:28:23,265:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:28:23,265:INFO:create_model() successfully completed......................................
2025-05-12 22:28:23,372:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:23,372:INFO:Creating metrics dataframe
2025-05-12 22:28:23,386:INFO:Initializing Dummy Classifier
2025-05-12 22:28:23,386:INFO:Total runtime is 0.14121649265289307 minutes
2025-05-12 22:28:23,390:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:23,391:INFO:Initializing create_model()
2025-05-12 22:28:23,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51AF73D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:23,391:INFO:Checking exceptions
2025-05-12 22:28:23,391:INFO:Importing libraries
2025-05-12 22:28:23,391:INFO:Copying training dataset
2025-05-12 22:28:23,397:INFO:Defining folds
2025-05-12 22:28:23,397:INFO:Declaring metric variables
2025-05-12 22:28:23,401:INFO:Importing untrained model
2025-05-12 22:28:23,408:INFO:Dummy Classifier Imported successfully
2025-05-12 22:28:23,419:INFO:Starting cross validation
2025-05-12 22:28:23,421:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:23,594:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,600:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,607:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,624:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,637:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,657:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,659:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,660:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,776:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,786:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:23,799:INFO:Calculating mean and std
2025-05-12 22:28:23,802:INFO:Creating metrics dataframe
2025-05-12 22:28:23,806:INFO:Uploading results into container
2025-05-12 22:28:23,808:INFO:Uploading model into container now
2025-05-12 22:28:23,808:INFO:_master_model_container: 14
2025-05-12 22:28:23,809:INFO:_display_container: 2
2025-05-12 22:28:23,809:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:28:23,809:INFO:create_model() successfully completed......................................
2025-05-12 22:28:23,920:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:23,921:INFO:Creating metrics dataframe
2025-05-12 22:28:23,936:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:28:23,949:INFO:Initializing create_model()
2025-05-12 22:28:23,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:23,949:INFO:Checking exceptions
2025-05-12 22:28:23,951:INFO:Importing libraries
2025-05-12 22:28:23,951:INFO:Copying training dataset
2025-05-12 22:28:23,956:INFO:Defining folds
2025-05-12 22:28:23,956:INFO:Declaring metric variables
2025-05-12 22:28:23,956:INFO:Importing untrained model
2025-05-12 22:28:23,957:INFO:Declaring custom model
2025-05-12 22:28:23,957:INFO:Dummy Classifier Imported successfully
2025-05-12 22:28:23,958:INFO:Cross validation set to False
2025-05-12 22:28:23,958:INFO:Fitting Model
2025-05-12 22:28:24,039:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:28:24,040:INFO:create_model() successfully completed......................................
2025-05-12 22:28:24,156:INFO:_master_model_container: 14
2025-05-12 22:28:24,156:INFO:_display_container: 2
2025-05-12 22:28:24,156:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:28:24,156:INFO:compare_models() successfully completed......................................
2025-05-12 22:28:24,184:INFO:Initializing create_model()
2025-05-12 22:28:24,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=dummy, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:24,186:INFO:Checking exceptions
2025-05-12 22:28:24,206:INFO:Importing libraries
2025-05-12 22:28:24,207:INFO:Copying training dataset
2025-05-12 22:28:24,214:INFO:Defining folds
2025-05-12 22:28:24,214:INFO:Declaring metric variables
2025-05-12 22:28:24,219:INFO:Importing untrained model
2025-05-12 22:28:24,224:INFO:Dummy Classifier Imported successfully
2025-05-12 22:28:24,237:INFO:Starting cross validation
2025-05-12 22:28:24,239:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:24,407:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,416:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,435:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,449:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,461:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,476:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,481:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,483:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,532:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,539:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:24,552:INFO:Calculating mean and std
2025-05-12 22:28:24,552:INFO:Creating metrics dataframe
2025-05-12 22:28:24,559:INFO:Finalizing model
2025-05-12 22:28:24,613:INFO:Uploading results into container
2025-05-12 22:28:24,615:INFO:Uploading model into container now
2025-05-12 22:28:24,627:INFO:_master_model_container: 15
2025-05-12 22:28:24,627:INFO:_display_container: 3
2025-05-12 22:28:24,627:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:28:24,627:INFO:create_model() successfully completed......................................
2025-05-12 22:28:24,839:INFO:Initializing tune_model()
2025-05-12 22:28:24,839:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:28:24,839:INFO:Checking exceptions
2025-05-12 22:28:24,864:INFO:Copying training dataset
2025-05-12 22:28:24,869:INFO:Checking base model
2025-05-12 22:28:24,869:INFO:Base model : Dummy Classifier
2025-05-12 22:28:24,874:INFO:Declaring metric variables
2025-05-12 22:28:24,881:INFO:Defining Hyperparameters
2025-05-12 22:28:24,881:INFO:10 is bigger than total combinations 4, setting search algorithm to grid
2025-05-12 22:28:24,968:INFO:Tuning with n_jobs=-1
2025-05-12 22:28:24,968:INFO:Initializing GridSearchCV
2025-05-12 22:28:25,921:INFO:best_params: {'actual_estimator__strategy': 'most_frequent'}
2025-05-12 22:28:25,923:INFO:Hyperparameter search completed
2025-05-12 22:28:25,923:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:25,924:INFO:Initializing create_model()
2025-05-12 22:28:25,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D51BFCB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'strategy': 'most_frequent'})
2025-05-12 22:28:25,924:INFO:Checking exceptions
2025-05-12 22:28:25,924:INFO:Importing libraries
2025-05-12 22:28:25,924:INFO:Copying training dataset
2025-05-12 22:28:25,931:INFO:Defining folds
2025-05-12 22:28:25,933:INFO:Declaring metric variables
2025-05-12 22:28:25,937:INFO:Importing untrained model
2025-05-12 22:28:25,937:INFO:Declaring custom model
2025-05-12 22:28:25,943:INFO:Dummy Classifier Imported successfully
2025-05-12 22:28:25,955:INFO:Starting cross validation
2025-05-12 22:28:25,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:26,124:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,129:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,133:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,136:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,136:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,154:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,162:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,169:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,235:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,240:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,253:INFO:Calculating mean and std
2025-05-12 22:28:26,254:INFO:Creating metrics dataframe
2025-05-12 22:28:26,261:INFO:Finalizing model
2025-05-12 22:28:26,311:INFO:Uploading results into container
2025-05-12 22:28:26,313:INFO:Uploading model into container now
2025-05-12 22:28:26,313:INFO:_master_model_container: 16
2025-05-12 22:28:26,313:INFO:_display_container: 4
2025-05-12 22:28:26,313:INFO:DummyClassifier(constant=None, random_state=123, strategy='most_frequent')
2025-05-12 22:28:26,313:INFO:create_model() successfully completed......................................
2025-05-12 22:28:26,389:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:26,390:INFO:choose_better activated
2025-05-12 22:28:26,393:INFO:SubProcess create_model() called ==================================
2025-05-12 22:28:26,394:INFO:Initializing create_model()
2025-05-12 22:28:26,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:28:26,394:INFO:Checking exceptions
2025-05-12 22:28:26,396:INFO:Importing libraries
2025-05-12 22:28:26,396:INFO:Copying training dataset
2025-05-12 22:28:26,400:INFO:Defining folds
2025-05-12 22:28:26,400:INFO:Declaring metric variables
2025-05-12 22:28:26,401:INFO:Importing untrained model
2025-05-12 22:28:26,401:INFO:Declaring custom model
2025-05-12 22:28:26,401:INFO:Dummy Classifier Imported successfully
2025-05-12 22:28:26,401:INFO:Starting cross validation
2025-05-12 22:28:26,403:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:28:26,546:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,551:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,551:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,553:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,565:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,568:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,581:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,661:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,663:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:26,679:INFO:Calculating mean and std
2025-05-12 22:28:26,679:INFO:Creating metrics dataframe
2025-05-12 22:28:26,682:INFO:Finalizing model
2025-05-12 22:28:26,724:INFO:Uploading results into container
2025-05-12 22:28:26,724:INFO:Uploading model into container now
2025-05-12 22:28:26,726:INFO:_master_model_container: 17
2025-05-12 22:28:26,726:INFO:_display_container: 5
2025-05-12 22:28:26,726:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:28:26,726:INFO:create_model() successfully completed......................................
2025-05-12 22:28:26,810:INFO:SubProcess create_model() end ==================================
2025-05-12 22:28:26,810:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior') result for Accuracy is 0.8291
2025-05-12 22:28:26,811:INFO:DummyClassifier(constant=None, random_state=123, strategy='most_frequent') result for Accuracy is 0.8291
2025-05-12 22:28:26,811:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior') is best model
2025-05-12 22:28:26,811:INFO:choose_better completed
2025-05-12 22:28:26,811:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:28:26,822:INFO:_master_model_container: 17
2025-05-12 22:28:26,822:INFO:_display_container: 4
2025-05-12 22:28:26,822:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-12 22:28:26,822:INFO:tune_model() successfully completed......................................
2025-05-12 22:28:26,914:INFO:Initializing evaluate_model()
2025-05-12 22:28:26,914:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:28:26,927:INFO:Initializing plot_model()
2025-05-12 22:28:26,928:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:28:26,928:INFO:Checking exceptions
2025-05-12 22:28:26,930:INFO:Preloading libraries
2025-05-12 22:28:26,930:INFO:Copying training dataset
2025-05-12 22:28:26,930:INFO:Plot type: pipeline
2025-05-12 22:28:27,056:INFO:Visual Rendered Successfully
2025-05-12 22:28:27,141:INFO:plot_model() successfully completed......................................
2025-05-12 22:28:27,163:INFO:Initializing predict_model()
2025-05-12 22:28:27,164:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027D51A91B20>)
2025-05-12 22:28:27,164:INFO:Checking exceptions
2025-05-12 22:28:27,164:INFO:Preloading libraries
2025-05-12 22:28:27,276:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:28:27,391:INFO:Initializing save_model()
2025-05-12 22:28:27,391:INFO:save_model(model=DummyClassifier(constant=None, random_state=123, strategy='prior'), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-12 22:28:27,391:INFO:Adding model into prep_pipe
2025-05-12 22:28:27,399:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:28:27,405:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 DummyClassifier(constant=None, random_state=123,
                                 strategy='prior'))],
         verbose=False)
2025-05-12 22:28:27,405:INFO:save_model() successfully completed......................................
2025-05-12 22:29:48,072:INFO:Initializing predict_model()
2025-05-12 22:29:48,072:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D51F22E90>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027D51A90220>)
2025-05-12 22:29:48,072:INFO:Checking exceptions
2025-05-12 22:29:48,072:INFO:Preloading libraries
2025-05-12 22:29:48,154:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-12 22:29:48,307:INFO:Initializing save_model()
2025-05-12 22:29:48,307:INFO:save_model(model=DummyClassifier(constant=None, random_state=123, strategy='prior'), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-12 22:29:48,307:INFO:Adding model into prep_pipe
2025-05-12 22:29:48,319:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:29:48,327:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 DummyClassifier(constant=None, random_state=123,
                                 strategy='prior'))],
         verbose=False)
2025-05-12 22:29:48,327:INFO:save_model() successfully completed......................................
2025-05-12 22:30:54,335:INFO:PyCaret RegressionExperiment
2025-05-12 22:30:54,335:INFO:Logging name: reg-default-name
2025-05-12 22:30:54,335:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-12 22:30:54,335:INFO:version 3.3.2
2025-05-12 22:30:54,335:INFO:Initializing setup()
2025-05-12 22:30:54,335:INFO:self.USI: 19b1
2025-05-12 22:30:54,335:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'X_test', 'fold_shuffle_param', 'idx', 'pipeline', 'y_train', 'X_train', 'n_jobs_param', 'html_param', 'fold_generator', 'target_param', 'transform_target_param', 'X', 'memory', 'exp_name_log', 'USI', 'y', '_available_plots', '_ml_usecase', 'data', 'gpu_param', 'exp_id', 'fold_groups_param', 'y_test'}
2025-05-12 22:30:54,335:INFO:Checking environment
2025-05-12 22:30:54,335:INFO:python_version: 3.11.8
2025-05-12 22:30:54,335:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-12 22:30:54,335:INFO:machine: AMD64
2025-05-12 22:30:54,335:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-12 22:30:54,340:INFO:Memory: svmem(total=16907886592, available=2868690944, percent=83.0, used=14039195648, free=2868690944)
2025-05-12 22:30:54,340:INFO:Physical Core: 4
2025-05-12 22:30:54,340:INFO:Logical Core: 8
2025-05-12 22:30:54,340:INFO:Checking libraries
2025-05-12 22:30:54,340:INFO:System:
2025-05-12 22:30:54,340:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-12 22:30:54,340:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-12 22:30:54,340:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-12 22:30:54,340:INFO:PyCaret required dependencies:
2025-05-12 22:30:54,341:INFO:                 pip: 24.0
2025-05-12 22:30:54,341:INFO:          setuptools: 65.5.0
2025-05-12 22:30:54,341:INFO:             pycaret: 3.3.2
2025-05-12 22:30:54,341:INFO:             IPython: 9.2.0
2025-05-12 22:30:54,341:INFO:          ipywidgets: 8.1.7
2025-05-12 22:30:54,341:INFO:                tqdm: 4.67.1
2025-05-12 22:30:54,341:INFO:               numpy: 1.26.4
2025-05-12 22:30:54,341:INFO:              pandas: 2.1.4
2025-05-12 22:30:54,341:INFO:              jinja2: 3.1.6
2025-05-12 22:30:54,341:INFO:               scipy: 1.11.4
2025-05-12 22:30:54,341:INFO:              joblib: 1.3.2
2025-05-12 22:30:54,341:INFO:             sklearn: 1.4.2
2025-05-12 22:30:54,341:INFO:                pyod: 2.0.5
2025-05-12 22:30:54,341:INFO:            imblearn: 0.13.0
2025-05-12 22:30:54,341:INFO:   category_encoders: 2.7.0
2025-05-12 22:30:54,341:INFO:            lightgbm: 4.6.0
2025-05-12 22:30:54,341:INFO:               numba: 0.61.2
2025-05-12 22:30:54,341:INFO:            requests: 2.32.3
2025-05-12 22:30:54,341:INFO:          matplotlib: 3.7.5
2025-05-12 22:30:54,341:INFO:          scikitplot: 0.3.7
2025-05-12 22:30:54,341:INFO:         yellowbrick: 1.5
2025-05-12 22:30:54,341:INFO:              plotly: 5.24.1
2025-05-12 22:30:54,341:INFO:    plotly-resampler: Not installed
2025-05-12 22:30:54,341:INFO:             kaleido: 0.2.1
2025-05-12 22:30:54,341:INFO:           schemdraw: 0.15
2025-05-12 22:30:54,341:INFO:         statsmodels: 0.14.4
2025-05-12 22:30:54,341:INFO:              sktime: 0.26.0
2025-05-12 22:30:54,341:INFO:               tbats: 1.1.3
2025-05-12 22:30:54,341:INFO:            pmdarima: 2.0.4
2025-05-12 22:30:54,341:INFO:              psutil: 7.0.0
2025-05-12 22:30:54,341:INFO:          markupsafe: 3.0.2
2025-05-12 22:30:54,341:INFO:             pickle5: Not installed
2025-05-12 22:30:54,341:INFO:         cloudpickle: 3.1.1
2025-05-12 22:30:54,341:INFO:         deprecation: 2.1.0
2025-05-12 22:30:54,341:INFO:              xxhash: 3.5.0
2025-05-12 22:30:54,341:INFO:           wurlitzer: Not installed
2025-05-12 22:30:54,341:INFO:PyCaret optional dependencies:
2025-05-12 22:30:54,341:INFO:                shap: Not installed
2025-05-12 22:30:54,341:INFO:           interpret: Not installed
2025-05-12 22:30:54,341:INFO:                umap: Not installed
2025-05-12 22:30:54,341:INFO:     ydata_profiling: Not installed
2025-05-12 22:30:54,341:INFO:  explainerdashboard: Not installed
2025-05-12 22:30:54,341:INFO:             autoviz: Not installed
2025-05-12 22:30:54,341:INFO:           fairlearn: Not installed
2025-05-12 22:30:54,341:INFO:          deepchecks: Not installed
2025-05-12 22:30:54,341:INFO:             xgboost: Not installed
2025-05-12 22:30:54,341:INFO:            catboost: Not installed
2025-05-12 22:30:54,341:INFO:              kmodes: Not installed
2025-05-12 22:30:54,341:INFO:             mlxtend: Not installed
2025-05-12 22:30:54,341:INFO:       statsforecast: Not installed
2025-05-12 22:30:54,341:INFO:        tune_sklearn: Not installed
2025-05-12 22:30:54,341:INFO:                 ray: Not installed
2025-05-12 22:30:54,343:INFO:            hyperopt: Not installed
2025-05-12 22:30:54,343:INFO:              optuna: Not installed
2025-05-12 22:30:54,343:INFO:               skopt: Not installed
2025-05-12 22:30:54,343:INFO:              mlflow: Not installed
2025-05-12 22:30:54,343:INFO:              gradio: Not installed
2025-05-12 22:30:54,343:INFO:             fastapi: Not installed
2025-05-12 22:30:54,343:INFO:             uvicorn: Not installed
2025-05-12 22:30:54,343:INFO:              m2cgen: Not installed
2025-05-12 22:30:54,343:INFO:           evidently: Not installed
2025-05-12 22:30:54,343:INFO:               fugue: Not installed
2025-05-12 22:30:54,343:INFO:           streamlit: Not installed
2025-05-12 22:30:54,343:INFO:             prophet: Not installed
2025-05-12 22:30:54,343:INFO:None
2025-05-12 22:30:54,343:INFO:Set up data.
2025-05-12 22:30:54,347:INFO:Set up folding strategy.
2025-05-12 22:30:54,347:INFO:Set up train/test split.
2025-05-12 22:30:54,351:INFO:Set up index.
2025-05-12 22:30:54,351:INFO:Assigning column types.
2025-05-12 22:30:54,355:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-12 22:30:54,356:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,360:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,363:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,415:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,453:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,454:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,454:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,459:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,461:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,510:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,546:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,547:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-12 22:30:54,553:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,559:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,615:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,652:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,657:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,660:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,716:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,754:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,755:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,756:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-12 22:30:54,766:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,813:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,850:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,851:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,851:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,860:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,907:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,953:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:54,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:54,954:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-12 22:30:55,017:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:55,056:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:55,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,131:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:55,169:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-12 22:30:55,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,170:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,170:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-12 22:30:55,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:55,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,331:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-12 22:30:55,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,385:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-12 22:30:55,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,571:INFO:Preparing preprocessing pipeline...
2025-05-12 22:30:55,571:INFO:Set up simple imputation.
2025-05-12 22:30:55,573:INFO:Set up encoding of categorical features.
2025-05-12 22:30:55,573:INFO:Set up feature normalization.
2025-05-12 22:30:55,629:INFO:Finished creating preprocessing pipeline.
2025-05-12 22:30:55,637:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-12 22:30:55,637:INFO:Creating final display dataframe.
2025-05-12 22:30:55,775:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type        Regression
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              19b1
2025-05-12 22:30:55,870:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,961:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-12 22:30:55,961:INFO:setup() successfully completed in 1.63s...............
2025-05-12 22:30:55,974:INFO:Initializing compare_models()
2025-05-12 22:30:55,974:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-12 22:30:55,974:INFO:Checking exceptions
2025-05-12 22:30:55,976:INFO:Preparing display monitor
2025-05-12 22:30:55,997:INFO:Initializing Linear Regression
2025-05-12 22:30:55,998:INFO:Total runtime is 1.6709168752034504e-05 minutes
2025-05-12 22:30:56,000:INFO:SubProcess create_model() called ==================================
2025-05-12 22:30:56,000:INFO:Initializing create_model()
2025-05-12 22:30:56,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:30:56,000:INFO:Checking exceptions
2025-05-12 22:30:56,000:INFO:Importing libraries
2025-05-12 22:30:56,000:INFO:Copying training dataset
2025-05-12 22:30:56,004:INFO:Defining folds
2025-05-12 22:30:56,005:INFO:Declaring metric variables
2025-05-12 22:30:56,008:INFO:Importing untrained model
2025-05-12 22:30:56,010:INFO:Linear Regression Imported successfully
2025-05-12 22:30:56,018:INFO:Starting cross validation
2025-05-12 22:30:56,020:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:01,933:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:01,934:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:01,946:INFO:Calculating mean and std
2025-05-12 22:31:01,947:INFO:Creating metrics dataframe
2025-05-12 22:31:01,949:INFO:Uploading results into container
2025-05-12 22:31:01,950:INFO:Uploading model into container now
2025-05-12 22:31:01,950:INFO:_master_model_container: 1
2025-05-12 22:31:01,950:INFO:_display_container: 2
2025-05-12 22:31:01,951:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2025-05-12 22:31:01,951:INFO:create_model() successfully completed......................................
2025-05-12 22:31:02,081:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:02,081:INFO:Creating metrics dataframe
2025-05-12 22:31:02,088:INFO:Initializing Lasso Regression
2025-05-12 22:31:02,088:INFO:Total runtime is 0.10153021415074666 minutes
2025-05-12 22:31:02,092:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:02,092:INFO:Initializing create_model()
2025-05-12 22:31:02,093:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:02,093:INFO:Checking exceptions
2025-05-12 22:31:02,093:INFO:Importing libraries
2025-05-12 22:31:02,093:INFO:Copying training dataset
2025-05-12 22:31:02,097:INFO:Defining folds
2025-05-12 22:31:02,097:INFO:Declaring metric variables
2025-05-12 22:31:02,103:INFO:Importing untrained model
2025-05-12 22:31:02,108:INFO:Lasso Regression Imported successfully
2025-05-12 22:31:02,116:INFO:Starting cross validation
2025-05-12 22:31:02,118:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:02,431:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:02,431:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:06,199:INFO:Calculating mean and std
2025-05-12 22:31:06,201:INFO:Creating metrics dataframe
2025-05-12 22:31:06,206:INFO:Uploading results into container
2025-05-12 22:31:06,207:INFO:Uploading model into container now
2025-05-12 22:31:06,207:INFO:_master_model_container: 2
2025-05-12 22:31:06,208:INFO:_display_container: 2
2025-05-12 22:31:06,208:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-05-12 22:31:06,209:INFO:create_model() successfully completed......................................
2025-05-12 22:31:06,326:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:06,327:INFO:Creating metrics dataframe
2025-05-12 22:31:06,333:INFO:Initializing Ridge Regression
2025-05-12 22:31:06,334:INFO:Total runtime is 0.17228774229685465 minutes
2025-05-12 22:31:06,337:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:06,337:INFO:Initializing create_model()
2025-05-12 22:31:06,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:06,337:INFO:Checking exceptions
2025-05-12 22:31:06,337:INFO:Importing libraries
2025-05-12 22:31:06,337:INFO:Copying training dataset
2025-05-12 22:31:06,343:INFO:Defining folds
2025-05-12 22:31:06,343:INFO:Declaring metric variables
2025-05-12 22:31:06,347:INFO:Importing untrained model
2025-05-12 22:31:06,351:INFO:Ridge Regression Imported successfully
2025-05-12 22:31:06,376:INFO:Starting cross validation
2025-05-12 22:31:06,379:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:06,691:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:06,691:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:06,703:INFO:Calculating mean and std
2025-05-12 22:31:06,705:INFO:Creating metrics dataframe
2025-05-12 22:31:06,707:INFO:Uploading results into container
2025-05-12 22:31:06,708:INFO:Uploading model into container now
2025-05-12 22:31:06,709:INFO:_master_model_container: 3
2025-05-12 22:31:06,709:INFO:_display_container: 2
2025-05-12 22:31:06,709:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2025-05-12 22:31:06,709:INFO:create_model() successfully completed......................................
2025-05-12 22:31:06,816:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:06,816:INFO:Creating metrics dataframe
2025-05-12 22:31:06,823:INFO:Initializing Elastic Net
2025-05-12 22:31:06,823:INFO:Total runtime is 0.18043437798817952 minutes
2025-05-12 22:31:06,827:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:06,827:INFO:Initializing create_model()
2025-05-12 22:31:06,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:06,828:INFO:Checking exceptions
2025-05-12 22:31:06,828:INFO:Importing libraries
2025-05-12 22:31:06,828:INFO:Copying training dataset
2025-05-12 22:31:06,831:INFO:Defining folds
2025-05-12 22:31:06,833:INFO:Declaring metric variables
2025-05-12 22:31:06,837:INFO:Importing untrained model
2025-05-12 22:31:06,842:INFO:Elastic Net Imported successfully
2025-05-12 22:31:06,848:INFO:Starting cross validation
2025-05-12 22:31:06,849:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:07,074:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:07,074:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:07,077:INFO:Calculating mean and std
2025-05-12 22:31:07,079:INFO:Creating metrics dataframe
2025-05-12 22:31:07,081:INFO:Uploading results into container
2025-05-12 22:31:07,081:INFO:Uploading model into container now
2025-05-12 22:31:07,082:INFO:_master_model_container: 4
2025-05-12 22:31:07,082:INFO:_display_container: 2
2025-05-12 22:31:07,083:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2025-05-12 22:31:07,083:INFO:create_model() successfully completed......................................
2025-05-12 22:31:07,190:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:07,190:INFO:Creating metrics dataframe
2025-05-12 22:31:07,197:INFO:Initializing Least Angle Regression
2025-05-12 22:31:07,197:INFO:Total runtime is 0.18666961987813313 minutes
2025-05-12 22:31:07,199:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:07,200:INFO:Initializing create_model()
2025-05-12 22:31:07,200:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:07,200:INFO:Checking exceptions
2025-05-12 22:31:07,200:INFO:Importing libraries
2025-05-12 22:31:07,200:INFO:Copying training dataset
2025-05-12 22:31:07,206:INFO:Defining folds
2025-05-12 22:31:07,206:INFO:Declaring metric variables
2025-05-12 22:31:07,209:INFO:Importing untrained model
2025-05-12 22:31:07,215:INFO:Least Angle Regression Imported successfully
2025-05-12 22:31:07,224:INFO:Starting cross validation
2025-05-12 22:31:07,226:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:07,457:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:07,457:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:07,472:INFO:Calculating mean and std
2025-05-12 22:31:07,474:INFO:Creating metrics dataframe
2025-05-12 22:31:07,477:INFO:Uploading results into container
2025-05-12 22:31:07,478:INFO:Uploading model into container now
2025-05-12 22:31:07,478:INFO:_master_model_container: 5
2025-05-12 22:31:07,478:INFO:_display_container: 2
2025-05-12 22:31:07,479:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2025-05-12 22:31:07,479:INFO:create_model() successfully completed......................................
2025-05-12 22:31:07,589:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:07,590:INFO:Creating metrics dataframe
2025-05-12 22:31:07,596:INFO:Initializing Lasso Least Angle Regression
2025-05-12 22:31:07,597:INFO:Total runtime is 0.19333307345708212 minutes
2025-05-12 22:31:07,600:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:07,601:INFO:Initializing create_model()
2025-05-12 22:31:07,601:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:07,601:INFO:Checking exceptions
2025-05-12 22:31:07,601:INFO:Importing libraries
2025-05-12 22:31:07,601:INFO:Copying training dataset
2025-05-12 22:31:07,607:INFO:Defining folds
2025-05-12 22:31:07,607:INFO:Declaring metric variables
2025-05-12 22:31:07,612:INFO:Importing untrained model
2025-05-12 22:31:07,615:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:31:07,624:INFO:Starting cross validation
2025-05-12 22:31:07,627:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:07,888:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:07,888:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:07,895:INFO:Calculating mean and std
2025-05-12 22:31:07,896:INFO:Creating metrics dataframe
2025-05-12 22:31:07,897:INFO:Uploading results into container
2025-05-12 22:31:07,899:INFO:Uploading model into container now
2025-05-12 22:31:07,899:INFO:_master_model_container: 6
2025-05-12 22:31:07,899:INFO:_display_container: 2
2025-05-12 22:31:07,900:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-05-12 22:31:07,901:INFO:create_model() successfully completed......................................
2025-05-12 22:31:08,011:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:08,011:INFO:Creating metrics dataframe
2025-05-12 22:31:08,017:INFO:Initializing Orthogonal Matching Pursuit
2025-05-12 22:31:08,017:INFO:Total runtime is 0.20034611622492474 minutes
2025-05-12 22:31:08,023:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:08,023:INFO:Initializing create_model()
2025-05-12 22:31:08,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:08,023:INFO:Checking exceptions
2025-05-12 22:31:08,023:INFO:Importing libraries
2025-05-12 22:31:08,024:INFO:Copying training dataset
2025-05-12 22:31:08,027:INFO:Defining folds
2025-05-12 22:31:08,027:INFO:Declaring metric variables
2025-05-12 22:31:08,031:INFO:Importing untrained model
2025-05-12 22:31:08,037:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-12 22:31:08,045:INFO:Starting cross validation
2025-05-12 22:31:08,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:08,279:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:08,279:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:08,286:INFO:Calculating mean and std
2025-05-12 22:31:08,287:INFO:Creating metrics dataframe
2025-05-12 22:31:08,289:INFO:Uploading results into container
2025-05-12 22:31:08,290:INFO:Uploading model into container now
2025-05-12 22:31:08,291:INFO:_master_model_container: 7
2025-05-12 22:31:08,291:INFO:_display_container: 2
2025-05-12 22:31:08,291:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2025-05-12 22:31:08,291:INFO:create_model() successfully completed......................................
2025-05-12 22:31:08,401:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:08,401:INFO:Creating metrics dataframe
2025-05-12 22:31:08,409:INFO:Initializing Bayesian Ridge
2025-05-12 22:31:08,409:INFO:Total runtime is 0.20687454541524253 minutes
2025-05-12 22:31:08,413:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:08,414:INFO:Initializing create_model()
2025-05-12 22:31:08,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:08,414:INFO:Checking exceptions
2025-05-12 22:31:08,414:INFO:Importing libraries
2025-05-12 22:31:08,414:INFO:Copying training dataset
2025-05-12 22:31:08,417:INFO:Defining folds
2025-05-12 22:31:08,417:INFO:Declaring metric variables
2025-05-12 22:31:08,422:INFO:Importing untrained model
2025-05-12 22:31:08,427:INFO:Bayesian Ridge Imported successfully
2025-05-12 22:31:08,433:INFO:Starting cross validation
2025-05-12 22:31:08,436:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:08,672:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:08,672:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:08,680:INFO:Calculating mean and std
2025-05-12 22:31:08,682:INFO:Creating metrics dataframe
2025-05-12 22:31:08,683:INFO:Uploading results into container
2025-05-12 22:31:08,684:INFO:Uploading model into container now
2025-05-12 22:31:08,684:INFO:_master_model_container: 8
2025-05-12 22:31:08,684:INFO:_display_container: 2
2025-05-12 22:31:08,684:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2025-05-12 22:31:08,686:INFO:create_model() successfully completed......................................
2025-05-12 22:31:08,797:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:08,797:INFO:Creating metrics dataframe
2025-05-12 22:31:08,806:INFO:Initializing Passive Aggressive Regressor
2025-05-12 22:31:08,806:INFO:Total runtime is 0.213483468691508 minutes
2025-05-12 22:31:08,810:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:08,810:INFO:Initializing create_model()
2025-05-12 22:31:08,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:08,811:INFO:Checking exceptions
2025-05-12 22:31:08,811:INFO:Importing libraries
2025-05-12 22:31:08,811:INFO:Copying training dataset
2025-05-12 22:31:08,817:INFO:Defining folds
2025-05-12 22:31:08,818:INFO:Declaring metric variables
2025-05-12 22:31:08,821:INFO:Importing untrained model
2025-05-12 22:31:08,826:INFO:Passive Aggressive Regressor Imported successfully
2025-05-12 22:31:08,833:INFO:Starting cross validation
2025-05-12 22:31:08,835:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:09,057:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:09,057:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:09,059:INFO:Calculating mean and std
2025-05-12 22:31:09,060:INFO:Creating metrics dataframe
2025-05-12 22:31:09,063:INFO:Uploading results into container
2025-05-12 22:31:09,065:INFO:Uploading model into container now
2025-05-12 22:31:09,065:INFO:_master_model_container: 9
2025-05-12 22:31:09,065:INFO:_display_container: 2
2025-05-12 22:31:09,066:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-12 22:31:09,066:INFO:create_model() successfully completed......................................
2025-05-12 22:31:09,173:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:09,174:INFO:Creating metrics dataframe
2025-05-12 22:31:09,182:INFO:Initializing Huber Regressor
2025-05-12 22:31:09,182:INFO:Total runtime is 0.21974949042002362 minutes
2025-05-12 22:31:09,186:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:09,186:INFO:Initializing create_model()
2025-05-12 22:31:09,186:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:09,186:INFO:Checking exceptions
2025-05-12 22:31:09,186:INFO:Importing libraries
2025-05-12 22:31:09,187:INFO:Copying training dataset
2025-05-12 22:31:09,191:INFO:Defining folds
2025-05-12 22:31:09,191:INFO:Declaring metric variables
2025-05-12 22:31:09,194:INFO:Importing untrained model
2025-05-12 22:31:09,200:INFO:Huber Regressor Imported successfully
2025-05-12 22:31:09,207:INFO:Starting cross validation
2025-05-12 22:31:09,209:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:09,511:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:09,511:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:09,521:INFO:Calculating mean and std
2025-05-12 22:31:09,522:INFO:Creating metrics dataframe
2025-05-12 22:31:09,523:INFO:Uploading results into container
2025-05-12 22:31:09,524:INFO:Uploading model into container now
2025-05-12 22:31:09,524:INFO:_master_model_container: 10
2025-05-12 22:31:09,524:INFO:_display_container: 2
2025-05-12 22:31:09,524:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2025-05-12 22:31:09,524:INFO:create_model() successfully completed......................................
2025-05-12 22:31:09,627:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:09,627:INFO:Creating metrics dataframe
2025-05-12 22:31:09,640:INFO:Initializing K Neighbors Regressor
2025-05-12 22:31:09,641:INFO:Total runtime is 0.22740835746129356 minutes
2025-05-12 22:31:09,646:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:09,646:INFO:Initializing create_model()
2025-05-12 22:31:09,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:09,646:INFO:Checking exceptions
2025-05-12 22:31:09,647:INFO:Importing libraries
2025-05-12 22:31:09,647:INFO:Copying training dataset
2025-05-12 22:31:09,653:INFO:Defining folds
2025-05-12 22:31:09,653:INFO:Declaring metric variables
2025-05-12 22:31:09,658:INFO:Importing untrained model
2025-05-12 22:31:09,661:INFO:K Neighbors Regressor Imported successfully
2025-05-12 22:31:09,670:INFO:Starting cross validation
2025-05-12 22:31:09,672:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:09,945:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:09,945:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:09,950:INFO:Calculating mean and std
2025-05-12 22:31:09,951:INFO:Creating metrics dataframe
2025-05-12 22:31:09,954:INFO:Uploading results into container
2025-05-12 22:31:09,955:INFO:Uploading model into container now
2025-05-12 22:31:09,956:INFO:_master_model_container: 11
2025-05-12 22:31:09,956:INFO:_display_container: 2
2025-05-12 22:31:09,956:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2025-05-12 22:31:09,957:INFO:create_model() successfully completed......................................
2025-05-12 22:31:10,061:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:10,061:INFO:Creating metrics dataframe
2025-05-12 22:31:10,070:INFO:Initializing Decision Tree Regressor
2025-05-12 22:31:10,070:INFO:Total runtime is 0.23454980055491131 minutes
2025-05-12 22:31:10,073:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:10,074:INFO:Initializing create_model()
2025-05-12 22:31:10,074:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:10,074:INFO:Checking exceptions
2025-05-12 22:31:10,074:INFO:Importing libraries
2025-05-12 22:31:10,074:INFO:Copying training dataset
2025-05-12 22:31:10,078:INFO:Defining folds
2025-05-12 22:31:10,079:INFO:Declaring metric variables
2025-05-12 22:31:10,083:INFO:Importing untrained model
2025-05-12 22:31:10,088:INFO:Decision Tree Regressor Imported successfully
2025-05-12 22:31:10,095:INFO:Starting cross validation
2025-05-12 22:31:10,097:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:10,341:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:10,342:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:10,349:INFO:Calculating mean and std
2025-05-12 22:31:10,351:INFO:Creating metrics dataframe
2025-05-12 22:31:10,353:INFO:Uploading results into container
2025-05-12 22:31:10,353:INFO:Uploading model into container now
2025-05-12 22:31:10,353:INFO:_master_model_container: 12
2025-05-12 22:31:10,354:INFO:_display_container: 2
2025-05-12 22:31:10,354:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2025-05-12 22:31:10,354:INFO:create_model() successfully completed......................................
2025-05-12 22:31:10,465:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:10,465:INFO:Creating metrics dataframe
2025-05-12 22:31:10,474:INFO:Initializing Random Forest Regressor
2025-05-12 22:31:10,474:INFO:Total runtime is 0.24129261970520022 minutes
2025-05-12 22:31:10,478:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:10,478:INFO:Initializing create_model()
2025-05-12 22:31:10,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:10,479:INFO:Checking exceptions
2025-05-12 22:31:10,479:INFO:Importing libraries
2025-05-12 22:31:10,479:INFO:Copying training dataset
2025-05-12 22:31:10,484:INFO:Defining folds
2025-05-12 22:31:10,485:INFO:Declaring metric variables
2025-05-12 22:31:10,489:INFO:Importing untrained model
2025-05-12 22:31:10,493:INFO:Random Forest Regressor Imported successfully
2025-05-12 22:31:10,519:INFO:Starting cross validation
2025-05-12 22:31:10,526:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:11,424:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:11,425:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:11,435:INFO:Calculating mean and std
2025-05-12 22:31:11,436:INFO:Creating metrics dataframe
2025-05-12 22:31:11,439:INFO:Uploading results into container
2025-05-12 22:31:11,439:INFO:Uploading model into container now
2025-05-12 22:31:11,440:INFO:_master_model_container: 13
2025-05-12 22:31:11,440:INFO:_display_container: 2
2025-05-12 22:31:11,441:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2025-05-12 22:31:11,441:INFO:create_model() successfully completed......................................
2025-05-12 22:31:11,539:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:11,539:INFO:Creating metrics dataframe
2025-05-12 22:31:11,549:INFO:Initializing Extra Trees Regressor
2025-05-12 22:31:11,549:INFO:Total runtime is 0.2592085361480713 minutes
2025-05-12 22:31:11,553:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:11,554:INFO:Initializing create_model()
2025-05-12 22:31:11,554:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:11,554:INFO:Checking exceptions
2025-05-12 22:31:11,554:INFO:Importing libraries
2025-05-12 22:31:11,554:INFO:Copying training dataset
2025-05-12 22:31:11,558:INFO:Defining folds
2025-05-12 22:31:11,558:INFO:Declaring metric variables
2025-05-12 22:31:11,563:INFO:Importing untrained model
2025-05-12 22:31:11,569:INFO:Extra Trees Regressor Imported successfully
2025-05-12 22:31:11,576:INFO:Starting cross validation
2025-05-12 22:31:11,577:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:12,256:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:12,256:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:12,260:INFO:Calculating mean and std
2025-05-12 22:31:12,261:INFO:Creating metrics dataframe
2025-05-12 22:31:12,263:INFO:Uploading results into container
2025-05-12 22:31:12,264:INFO:Uploading model into container now
2025-05-12 22:31:12,265:INFO:_master_model_container: 14
2025-05-12 22:31:12,266:INFO:_display_container: 2
2025-05-12 22:31:12,267:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2025-05-12 22:31:12,268:INFO:create_model() successfully completed......................................
2025-05-12 22:31:12,374:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:12,374:INFO:Creating metrics dataframe
2025-05-12 22:31:12,384:INFO:Initializing AdaBoost Regressor
2025-05-12 22:31:12,384:INFO:Total runtime is 0.2731213728586833 minutes
2025-05-12 22:31:12,387:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:12,388:INFO:Initializing create_model()
2025-05-12 22:31:12,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:12,388:INFO:Checking exceptions
2025-05-12 22:31:12,388:INFO:Importing libraries
2025-05-12 22:31:12,388:INFO:Copying training dataset
2025-05-12 22:31:12,391:INFO:Defining folds
2025-05-12 22:31:12,391:INFO:Declaring metric variables
2025-05-12 22:31:12,396:INFO:Importing untrained model
2025-05-12 22:31:12,401:INFO:AdaBoost Regressor Imported successfully
2025-05-12 22:31:12,408:INFO:Starting cross validation
2025-05-12 22:31:12,410:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:13,057:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:13,057:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:13,067:INFO:Calculating mean and std
2025-05-12 22:31:13,069:INFO:Creating metrics dataframe
2025-05-12 22:31:13,071:INFO:Uploading results into container
2025-05-12 22:31:13,072:INFO:Uploading model into container now
2025-05-12 22:31:13,072:INFO:_master_model_container: 15
2025-05-12 22:31:13,073:INFO:_display_container: 2
2025-05-12 22:31:13,073:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2025-05-12 22:31:13,073:INFO:create_model() successfully completed......................................
2025-05-12 22:31:13,187:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:13,187:INFO:Creating metrics dataframe
2025-05-12 22:31:13,199:INFO:Initializing Gradient Boosting Regressor
2025-05-12 22:31:13,199:INFO:Total runtime is 0.2866994698842367 minutes
2025-05-12 22:31:13,202:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:13,203:INFO:Initializing create_model()
2025-05-12 22:31:13,203:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:13,203:INFO:Checking exceptions
2025-05-12 22:31:13,203:INFO:Importing libraries
2025-05-12 22:31:13,203:INFO:Copying training dataset
2025-05-12 22:31:13,209:INFO:Defining folds
2025-05-12 22:31:13,209:INFO:Declaring metric variables
2025-05-12 22:31:13,213:INFO:Importing untrained model
2025-05-12 22:31:13,219:INFO:Gradient Boosting Regressor Imported successfully
2025-05-12 22:31:13,224:INFO:Starting cross validation
2025-05-12 22:31:13,227:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:13,655:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:13,655:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:13,660:INFO:Calculating mean and std
2025-05-12 22:31:13,663:INFO:Creating metrics dataframe
2025-05-12 22:31:13,667:INFO:Uploading results into container
2025-05-12 22:31:13,669:INFO:Uploading model into container now
2025-05-12 22:31:13,669:INFO:_master_model_container: 16
2025-05-12 22:31:13,669:INFO:_display_container: 2
2025-05-12 22:31:13,670:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-12 22:31:13,670:INFO:create_model() successfully completed......................................
2025-05-12 22:31:13,780:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:13,780:INFO:Creating metrics dataframe
2025-05-12 22:31:13,790:INFO:Initializing Light Gradient Boosting Machine
2025-05-12 22:31:13,790:INFO:Total runtime is 0.29656286636988327 minutes
2025-05-12 22:31:13,796:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:13,796:INFO:Initializing create_model()
2025-05-12 22:31:13,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:13,797:INFO:Checking exceptions
2025-05-12 22:31:13,797:INFO:Importing libraries
2025-05-12 22:31:13,797:INFO:Copying training dataset
2025-05-12 22:31:13,801:INFO:Defining folds
2025-05-12 22:31:13,801:INFO:Declaring metric variables
2025-05-12 22:31:13,806:INFO:Importing untrained model
2025-05-12 22:31:13,811:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-12 22:31:13,819:INFO:Starting cross validation
2025-05-12 22:31:13,821:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:14,415:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:14,415:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:14,430:INFO:Calculating mean and std
2025-05-12 22:31:14,433:INFO:Creating metrics dataframe
2025-05-12 22:31:14,437:INFO:Uploading results into container
2025-05-12 22:31:14,438:INFO:Uploading model into container now
2025-05-12 22:31:14,439:INFO:_master_model_container: 17
2025-05-12 22:31:14,439:INFO:_display_container: 2
2025-05-12 22:31:14,440:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2025-05-12 22:31:14,440:INFO:create_model() successfully completed......................................
2025-05-12 22:31:14,571:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:14,571:INFO:Creating metrics dataframe
2025-05-12 22:31:14,582:INFO:Initializing Dummy Regressor
2025-05-12 22:31:14,582:INFO:Total runtime is 0.3097551544507345 minutes
2025-05-12 22:31:14,585:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:14,585:INFO:Initializing create_model()
2025-05-12 22:31:14,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7F011990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:14,587:INFO:Checking exceptions
2025-05-12 22:31:14,587:INFO:Importing libraries
2025-05-12 22:31:14,587:INFO:Copying training dataset
2025-05-12 22:31:14,591:INFO:Defining folds
2025-05-12 22:31:14,591:INFO:Declaring metric variables
2025-05-12 22:31:14,595:INFO:Importing untrained model
2025-05-12 22:31:14,600:INFO:Dummy Regressor Imported successfully
2025-05-12 22:31:14,607:INFO:Starting cross validation
2025-05-12 22:31:14,609:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:14,821:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:14,821:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:14,830:INFO:Calculating mean and std
2025-05-12 22:31:14,831:INFO:Creating metrics dataframe
2025-05-12 22:31:14,833:INFO:Uploading results into container
2025-05-12 22:31:14,834:INFO:Uploading model into container now
2025-05-12 22:31:14,834:INFO:_master_model_container: 18
2025-05-12 22:31:14,834:INFO:_display_container: 2
2025-05-12 22:31:14,834:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2025-05-12 22:31:14,835:INFO:create_model() successfully completed......................................
2025-05-12 22:31:14,939:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:14,939:INFO:Creating metrics dataframe
2025-05-12 22:31:14,951:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-12 22:31:14,960:INFO:Initializing create_model()
2025-05-12 22:31:14,960:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:14,960:INFO:Checking exceptions
2025-05-12 22:31:14,963:INFO:Importing libraries
2025-05-12 22:31:14,963:INFO:Copying training dataset
2025-05-12 22:31:14,967:INFO:Defining folds
2025-05-12 22:31:14,967:INFO:Declaring metric variables
2025-05-12 22:31:14,967:INFO:Importing untrained model
2025-05-12 22:31:14,968:INFO:Declaring custom model
2025-05-12 22:31:14,968:INFO:Lasso Regression Imported successfully
2025-05-12 22:31:14,969:INFO:Cross validation set to False
2025-05-12 22:31:14,969:INFO:Fitting Model
2025-05-12 22:31:15,004:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-05-12 22:31:15,004:INFO:create_model() successfully completed......................................
2025-05-12 22:31:15,125:INFO:_master_model_container: 18
2025-05-12 22:31:15,125:INFO:_display_container: 2
2025-05-12 22:31:15,126:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2025-05-12 22:31:15,126:INFO:compare_models() successfully completed......................................
2025-05-12 22:31:15,144:INFO:Initializing create_model()
2025-05-12 22:31:15,144:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=llar, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:15,144:INFO:Checking exceptions
2025-05-12 22:31:15,164:INFO:Importing libraries
2025-05-12 22:31:15,164:INFO:Copying training dataset
2025-05-12 22:31:15,170:INFO:Defining folds
2025-05-12 22:31:15,171:INFO:Declaring metric variables
2025-05-12 22:31:15,175:INFO:Importing untrained model
2025-05-12 22:31:15,183:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:31:15,192:INFO:Starting cross validation
2025-05-12 22:31:15,195:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:15,604:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:15,605:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:15,616:INFO:Calculating mean and std
2025-05-12 22:31:15,617:INFO:Creating metrics dataframe
2025-05-12 22:31:15,626:INFO:Finalizing model
2025-05-12 22:31:15,699:INFO:Uploading results into container
2025-05-12 22:31:15,701:INFO:Uploading model into container now
2025-05-12 22:31:15,714:INFO:_master_model_container: 19
2025-05-12 22:31:15,714:INFO:_display_container: 3
2025-05-12 22:31:15,714:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-05-12 22:31:15,716:INFO:create_model() successfully completed......................................
2025-05-12 22:31:15,857:INFO:Initializing tune_model()
2025-05-12 22:31:15,857:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-12 22:31:15,857:INFO:Checking exceptions
2025-05-12 22:31:15,881:INFO:Copying training dataset
2025-05-12 22:31:15,886:INFO:Checking base model
2025-05-12 22:31:15,886:INFO:Base model : Lasso Least Angle Regression
2025-05-12 22:31:15,890:INFO:Declaring metric variables
2025-05-12 22:31:15,896:INFO:Defining Hyperparameters
2025-05-12 22:31:16,013:INFO:Tuning with n_jobs=-1
2025-05-12 22:31:16,013:INFO:Initializing RandomizedSearchCV
2025-05-12 22:31:18,279:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__eps': 5e-05, 'actual_estimator__alpha': 0.7}
2025-05-12 22:31:18,281:INFO:Hyperparameter search completed
2025-05-12 22:31:18,281:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:18,282:INFO:Initializing create_model()
2025-05-12 22:31:18,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EA7E917C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'eps': 5e-05, 'alpha': 0.7})
2025-05-12 22:31:18,283:INFO:Checking exceptions
2025-05-12 22:31:18,283:INFO:Importing libraries
2025-05-12 22:31:18,283:INFO:Copying training dataset
2025-05-12 22:31:18,291:INFO:Defining folds
2025-05-12 22:31:18,291:INFO:Declaring metric variables
2025-05-12 22:31:18,297:INFO:Importing untrained model
2025-05-12 22:31:18,297:INFO:Declaring custom model
2025-05-12 22:31:18,304:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:31:18,317:INFO:Starting cross validation
2025-05-12 22:31:18,321:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:18,727:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:18,727:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:18,732:INFO:Calculating mean and std
2025-05-12 22:31:18,735:INFO:Creating metrics dataframe
2025-05-12 22:31:18,747:INFO:Finalizing model
2025-05-12 22:31:18,831:INFO:Uploading results into container
2025-05-12 22:31:18,832:INFO:Uploading model into container now
2025-05-12 22:31:18,833:INFO:_master_model_container: 20
2025-05-12 22:31:18,833:INFO:_display_container: 4
2025-05-12 22:31:18,833:INFO:LassoLars(alpha=0.7, copy_X=True, eps=5e-05, fit_intercept=True, fit_path=True,
          jitter=None, max_iter=500, positive=False, precompute='auto',
          random_state=123, verbose=False)
2025-05-12 22:31:18,833:INFO:create_model() successfully completed......................................
2025-05-12 22:31:18,959:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:18,959:INFO:choose_better activated
2025-05-12 22:31:18,965:INFO:SubProcess create_model() called ==================================
2025-05-12 22:31:18,965:INFO:Initializing create_model()
2025-05-12 22:31:18,965:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-12 22:31:18,966:INFO:Checking exceptions
2025-05-12 22:31:18,969:INFO:Importing libraries
2025-05-12 22:31:18,969:INFO:Copying training dataset
2025-05-12 22:31:18,973:INFO:Defining folds
2025-05-12 22:31:18,974:INFO:Declaring metric variables
2025-05-12 22:31:18,975:INFO:Importing untrained model
2025-05-12 22:31:18,975:INFO:Declaring custom model
2025-05-12 22:31:18,976:INFO:Lasso Least Angle Regression Imported successfully
2025-05-12 22:31:18,976:INFO:Starting cross validation
2025-05-12 22:31:18,977:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-12 22:31:19,262:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-05-12 22:31:19,262:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-05-12 22:31:19,266:INFO:Calculating mean and std
2025-05-12 22:31:19,267:INFO:Creating metrics dataframe
2025-05-12 22:31:19,271:INFO:Finalizing model
2025-05-12 22:31:19,353:INFO:Uploading results into container
2025-05-12 22:31:19,354:INFO:Uploading model into container now
2025-05-12 22:31:19,354:INFO:_master_model_container: 21
2025-05-12 22:31:19,354:INFO:_display_container: 5
2025-05-12 22:31:19,356:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-05-12 22:31:19,356:INFO:create_model() successfully completed......................................
2025-05-12 22:31:19,471:INFO:SubProcess create_model() end ==================================
2025-05-12 22:31:19,471:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False) result for R2 is -0.0421
2025-05-12 22:31:19,473:INFO:LassoLars(alpha=0.7, copy_X=True, eps=5e-05, fit_intercept=True, fit_path=True,
          jitter=None, max_iter=500, positive=False, precompute='auto',
          random_state=123, verbose=False) result for R2 is -0.0421
2025-05-12 22:31:19,473:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False) is best model
2025-05-12 22:31:19,473:INFO:choose_better completed
2025-05-12 22:31:19,474:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-12 22:31:19,483:INFO:_master_model_container: 21
2025-05-12 22:31:19,484:INFO:_display_container: 4
2025-05-12 22:31:19,484:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2025-05-12 22:31:19,484:INFO:tune_model() successfully completed......................................
2025-05-12 22:31:19,640:INFO:Initializing evaluate_model()
2025-05-12 22:31:19,640:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-12 22:31:19,654:INFO:Initializing plot_model()
2025-05-12 22:31:19,654:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-12 22:31:19,654:INFO:Checking exceptions
2025-05-12 22:31:19,657:INFO:Preloading libraries
2025-05-12 22:31:19,658:INFO:Copying training dataset
2025-05-12 22:31:19,658:INFO:Plot type: pipeline
2025-05-12 22:31:19,795:INFO:Visual Rendered Successfully
2025-05-12 22:31:19,905:INFO:plot_model() successfully completed......................................
2025-05-12 22:31:19,929:INFO:Initializing predict_model()
2025-05-12 22:31:19,929:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EA7DED8690>, estimator=LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EA7E11FCE0>)
2025-05-12 22:31:19,929:INFO:Checking exceptions
2025-05-12 22:31:19,929:INFO:Preloading libraries
2025-05-12 22:31:20,109:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-12 22:31:20,241:INFO:Initializing save_model()
2025-05-12 22:31:20,241:INFO:save_model(model=LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False), model_name=modelo_final_lasso, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=na...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-12 22:31:20,241:INFO:Adding model into prep_pipe
2025-05-12 22:31:20,251:INFO:modelo_final_lasso.pkl saved in current working directory
2025-05-12 22:31:20,256:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_impu...
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16,
                           fit_intercept=True, fit_path=True, jitter=None,
                           max_iter=500, positive=False, precompute='auto',
                           random_state=123, verbose=False))],
         verbose=False)
2025-05-12 22:31:20,257:INFO:save_model() successfully completed......................................
2025-05-14 19:58:32,722:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 19:58:32,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 19:58:32,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 19:58:32,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 19:58:35,558:INFO:PyCaret ClassificationExperiment
2025-05-14 19:58:35,558:INFO:Logging name: clf-default-name
2025-05-14 19:58:35,559:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 19:58:35,559:INFO:version 3.3.2
2025-05-14 19:58:35,559:INFO:Initializing setup()
2025-05-14 19:58:35,559:INFO:self.USI: 3b6c
2025-05-14 19:58:35,559:INFO:self._variable_keys: {'_ml_usecase', 'gpu_param', 'fold_groups_param', 'html_param', '_available_plots', 'fold_shuffle_param', 'fix_imbalance', 'idx', 'y_test', 'X_train', 'pipeline', 'fold_generator', 'data', 'exp_id', 'memory', 'logging_param', 'X', 'y_train', 'is_multiclass', 'seed', 'n_jobs_param', 'X_test', 'y', 'USI', 'target_param', 'log_plots_param', 'gpu_n_jobs_param', 'exp_name_log'}
2025-05-14 19:58:35,559:INFO:Checking environment
2025-05-14 19:58:35,559:INFO:python_version: 3.11.8
2025-05-14 19:58:35,559:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-14 19:58:35,559:INFO:machine: AMD64
2025-05-14 19:58:35,559:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-14 19:58:35,562:INFO:Memory: svmem(total=16907886592, available=4339724288, percent=74.3, used=12568162304, free=4339724288)
2025-05-14 19:58:35,564:INFO:Physical Core: 4
2025-05-14 19:58:35,564:INFO:Logical Core: 8
2025-05-14 19:58:35,564:INFO:Checking libraries
2025-05-14 19:58:35,564:INFO:System:
2025-05-14 19:58:35,564:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-14 19:58:35,564:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-14 19:58:35,564:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-14 19:58:35,564:INFO:PyCaret required dependencies:
2025-05-14 19:58:35,647:INFO:                 pip: 24.0
2025-05-14 19:58:35,647:INFO:          setuptools: 65.5.0
2025-05-14 19:58:35,647:INFO:             pycaret: 3.3.2
2025-05-14 19:58:35,647:INFO:             IPython: 9.2.0
2025-05-14 19:58:35,647:INFO:          ipywidgets: 8.1.7
2025-05-14 19:58:35,648:INFO:                tqdm: 4.67.1
2025-05-14 19:58:35,648:INFO:               numpy: 1.26.4
2025-05-14 19:58:35,648:INFO:              pandas: 2.1.4
2025-05-14 19:58:35,648:INFO:              jinja2: 3.1.6
2025-05-14 19:58:35,648:INFO:               scipy: 1.11.4
2025-05-14 19:58:35,648:INFO:              joblib: 1.3.2
2025-05-14 19:58:35,648:INFO:             sklearn: 1.4.2
2025-05-14 19:58:35,648:INFO:                pyod: 2.0.5
2025-05-14 19:58:35,648:INFO:            imblearn: 0.13.0
2025-05-14 19:58:35,648:INFO:   category_encoders: 2.7.0
2025-05-14 19:58:35,648:INFO:            lightgbm: 4.6.0
2025-05-14 19:58:35,648:INFO:               numba: 0.61.2
2025-05-14 19:58:35,648:INFO:            requests: 2.32.3
2025-05-14 19:58:35,649:INFO:          matplotlib: 3.7.5
2025-05-14 19:58:35,649:INFO:          scikitplot: 0.3.7
2025-05-14 19:58:35,649:INFO:         yellowbrick: 1.5
2025-05-14 19:58:35,649:INFO:              plotly: 5.24.1
2025-05-14 19:58:35,649:INFO:    plotly-resampler: Not installed
2025-05-14 19:58:35,649:INFO:             kaleido: 0.2.1
2025-05-14 19:58:35,649:INFO:           schemdraw: 0.15
2025-05-14 19:58:35,649:INFO:         statsmodels: 0.14.4
2025-05-14 19:58:35,649:INFO:              sktime: 0.26.0
2025-05-14 19:58:35,649:INFO:               tbats: 1.1.3
2025-05-14 19:58:35,649:INFO:            pmdarima: 2.0.4
2025-05-14 19:58:35,649:INFO:              psutil: 7.0.0
2025-05-14 19:58:35,649:INFO:          markupsafe: 3.0.2
2025-05-14 19:58:35,649:INFO:             pickle5: Not installed
2025-05-14 19:58:35,649:INFO:         cloudpickle: 3.1.1
2025-05-14 19:58:35,649:INFO:         deprecation: 2.1.0
2025-05-14 19:58:35,649:INFO:              xxhash: 3.5.0
2025-05-14 19:58:35,649:INFO:           wurlitzer: Not installed
2025-05-14 19:58:35,649:INFO:PyCaret optional dependencies:
2025-05-14 19:58:35,661:INFO:                shap: Not installed
2025-05-14 19:58:35,661:INFO:           interpret: Not installed
2025-05-14 19:58:35,662:INFO:                umap: Not installed
2025-05-14 19:58:35,662:INFO:     ydata_profiling: Not installed
2025-05-14 19:58:35,662:INFO:  explainerdashboard: Not installed
2025-05-14 19:58:35,662:INFO:             autoviz: Not installed
2025-05-14 19:58:35,662:INFO:           fairlearn: Not installed
2025-05-14 19:58:35,662:INFO:          deepchecks: Not installed
2025-05-14 19:58:35,662:INFO:             xgboost: Not installed
2025-05-14 19:58:35,662:INFO:            catboost: Not installed
2025-05-14 19:58:35,662:INFO:              kmodes: Not installed
2025-05-14 19:58:35,662:INFO:             mlxtend: Not installed
2025-05-14 19:58:35,662:INFO:       statsforecast: Not installed
2025-05-14 19:58:35,662:INFO:        tune_sklearn: Not installed
2025-05-14 19:58:35,662:INFO:                 ray: Not installed
2025-05-14 19:58:35,662:INFO:            hyperopt: Not installed
2025-05-14 19:58:35,662:INFO:              optuna: Not installed
2025-05-14 19:58:35,662:INFO:               skopt: Not installed
2025-05-14 19:58:35,662:INFO:              mlflow: Not installed
2025-05-14 19:58:35,662:INFO:              gradio: Not installed
2025-05-14 19:58:35,662:INFO:             fastapi: Not installed
2025-05-14 19:58:35,662:INFO:             uvicorn: Not installed
2025-05-14 19:58:35,662:INFO:              m2cgen: Not installed
2025-05-14 19:58:35,662:INFO:           evidently: Not installed
2025-05-14 19:58:35,662:INFO:               fugue: Not installed
2025-05-14 19:58:35,662:INFO:           streamlit: Not installed
2025-05-14 19:58:35,662:INFO:             prophet: Not installed
2025-05-14 19:58:35,662:INFO:None
2025-05-14 19:58:35,662:INFO:Set up data.
2025-05-14 19:58:35,675:INFO:Set up folding strategy.
2025-05-14 19:58:35,675:INFO:Set up train/test split.
2025-05-14 19:58:35,711:INFO:Set up index.
2025-05-14 19:58:35,712:INFO:Assigning column types.
2025-05-14 19:58:35,714:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 19:58:35,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 19:58:35,770:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 19:58:35,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:35,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:35,860:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 19:58:35,861:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 19:58:35,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:35,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:35,913:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 19:58:35,997:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 19:58:36,041:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:36,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:36,123:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 19:58:36,185:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:36,185:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:36,186:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 19:58:36,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:36,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:36,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:36,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:36,456:INFO:Preparing preprocessing pipeline...
2025-05-14 19:58:36,458:INFO:Set up simple imputation.
2025-05-14 19:58:36,464:INFO:Set up encoding of categorical features.
2025-05-14 19:58:36,464:INFO:Set up feature normalization.
2025-05-14 19:58:36,585:INFO:Finished creating preprocessing pipeline.
2025-05-14 19:58:36,594:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strate...
                 TransformerWrapper(exclude=None, include=['tipo_plan'],
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-14 19:58:36,594:INFO:Creating final display dataframe.
2025-05-14 19:58:36,779:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             churn
2                   Target type            Binary
3           Original data shape          (300, 7)
4        Transformed data shape          (300, 9)
5   Transformed train set shape          (210, 9)
6    Transformed test set shape           (90, 9)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              3b6c
2025-05-14 19:58:36,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:36,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:36,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:36,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 19:58:36,992:INFO:setup() successfully completed in 1.44s...............
2025-05-14 19:58:36,992:INFO:Initializing compare_models()
2025-05-14 19:58:36,992:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 19:58:36,993:INFO:Checking exceptions
2025-05-14 19:58:36,998:INFO:Preparing display monitor
2025-05-14 19:58:37,034:INFO:Initializing Logistic Regression
2025-05-14 19:58:37,034:INFO:Total runtime is 0.0 minutes
2025-05-14 19:58:37,041:INFO:SubProcess create_model() called ==================================
2025-05-14 19:58:37,042:INFO:Initializing create_model()
2025-05-14 19:58:37,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA048F27D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:37,042:INFO:Checking exceptions
2025-05-14 19:58:37,042:INFO:Importing libraries
2025-05-14 19:58:37,042:INFO:Copying training dataset
2025-05-14 19:58:37,050:INFO:Defining folds
2025-05-14 19:58:37,050:INFO:Declaring metric variables
2025-05-14 19:58:37,056:INFO:Importing untrained model
2025-05-14 19:58:37,064:INFO:Logistic Regression Imported successfully
2025-05-14 19:58:37,079:INFO:Starting cross validation
2025-05-14 19:58:37,081:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:58:47,913:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:48,446:INFO:Calculating mean and std
2025-05-14 19:58:48,451:INFO:Creating metrics dataframe
2025-05-14 19:58:48,458:INFO:Uploading results into container
2025-05-14 19:58:48,458:INFO:Uploading model into container now
2025-05-14 19:58:48,460:INFO:_master_model_container: 1
2025-05-14 19:58:48,461:INFO:_display_container: 2
2025-05-14 19:58:48,462:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 19:58:48,463:INFO:create_model() successfully completed......................................
2025-05-14 19:58:48,592:INFO:SubProcess create_model() end ==================================
2025-05-14 19:58:48,592:INFO:Creating metrics dataframe
2025-05-14 19:58:48,604:INFO:Initializing K Neighbors Classifier
2025-05-14 19:58:48,604:INFO:Total runtime is 0.19283087253570558 minutes
2025-05-14 19:58:48,611:INFO:SubProcess create_model() called ==================================
2025-05-14 19:58:48,612:INFO:Initializing create_model()
2025-05-14 19:58:48,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA048F27D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:48,613:INFO:Checking exceptions
2025-05-14 19:58:48,613:INFO:Importing libraries
2025-05-14 19:58:48,613:INFO:Copying training dataset
2025-05-14 19:58:48,622:INFO:Defining folds
2025-05-14 19:58:48,622:INFO:Declaring metric variables
2025-05-14 19:58:48,632:INFO:Importing untrained model
2025-05-14 19:58:48,639:INFO:K Neighbors Classifier Imported successfully
2025-05-14 19:58:48,655:INFO:Starting cross validation
2025-05-14 19:58:48,658:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:58:49,185:INFO:Calculating mean and std
2025-05-14 19:58:49,189:INFO:Creating metrics dataframe
2025-05-14 19:58:49,195:INFO:Uploading results into container
2025-05-14 19:58:49,196:INFO:Uploading model into container now
2025-05-14 19:58:49,197:INFO:_master_model_container: 2
2025-05-14 19:58:49,197:INFO:_display_container: 2
2025-05-14 19:58:49,199:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 19:58:49,199:INFO:create_model() successfully completed......................................
2025-05-14 19:58:49,307:INFO:SubProcess create_model() end ==================================
2025-05-14 19:58:49,307:INFO:Creating metrics dataframe
2025-05-14 19:58:49,320:INFO:Initializing Naive Bayes
2025-05-14 19:58:49,321:INFO:Total runtime is 0.20476601123809815 minutes
2025-05-14 19:58:49,329:INFO:SubProcess create_model() called ==================================
2025-05-14 19:58:49,329:INFO:Initializing create_model()
2025-05-14 19:58:49,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA048F27D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:49,330:INFO:Checking exceptions
2025-05-14 19:58:49,330:INFO:Importing libraries
2025-05-14 19:58:49,330:INFO:Copying training dataset
2025-05-14 19:58:49,337:INFO:Defining folds
2025-05-14 19:58:49,337:INFO:Declaring metric variables
2025-05-14 19:58:49,344:INFO:Importing untrained model
2025-05-14 19:58:49,350:INFO:Naive Bayes Imported successfully
2025-05-14 19:58:49,364:INFO:Starting cross validation
2025-05-14 19:58:49,366:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:58:49,691:INFO:Calculating mean and std
2025-05-14 19:58:49,694:INFO:Creating metrics dataframe
2025-05-14 19:58:49,697:INFO:Uploading results into container
2025-05-14 19:58:49,698:INFO:Uploading model into container now
2025-05-14 19:58:49,699:INFO:_master_model_container: 3
2025-05-14 19:58:49,699:INFO:_display_container: 2
2025-05-14 19:58:49,699:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 19:58:49,699:INFO:create_model() successfully completed......................................
2025-05-14 19:58:49,800:INFO:SubProcess create_model() end ==================================
2025-05-14 19:58:49,800:INFO:Creating metrics dataframe
2025-05-14 19:58:49,812:INFO:Initializing Decision Tree Classifier
2025-05-14 19:58:49,812:INFO:Total runtime is 0.2129623850186666 minutes
2025-05-14 19:58:49,820:INFO:SubProcess create_model() called ==================================
2025-05-14 19:58:49,820:INFO:Initializing create_model()
2025-05-14 19:58:49,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA048F27D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:49,821:INFO:Checking exceptions
2025-05-14 19:58:49,821:INFO:Importing libraries
2025-05-14 19:58:49,822:INFO:Copying training dataset
2025-05-14 19:58:49,829:INFO:Defining folds
2025-05-14 19:58:49,830:INFO:Declaring metric variables
2025-05-14 19:58:49,837:INFO:Importing untrained model
2025-05-14 19:58:49,850:INFO:Decision Tree Classifier Imported successfully
2025-05-14 19:58:49,866:INFO:Starting cross validation
2025-05-14 19:58:49,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:58:50,195:INFO:Calculating mean and std
2025-05-14 19:58:50,197:INFO:Creating metrics dataframe
2025-05-14 19:58:50,200:INFO:Uploading results into container
2025-05-14 19:58:50,201:INFO:Uploading model into container now
2025-05-14 19:58:50,202:INFO:_master_model_container: 4
2025-05-14 19:58:50,202:INFO:_display_container: 2
2025-05-14 19:58:50,204:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-14 19:58:50,204:INFO:create_model() successfully completed......................................
2025-05-14 19:58:50,317:INFO:SubProcess create_model() end ==================================
2025-05-14 19:58:50,317:INFO:Creating metrics dataframe
2025-05-14 19:58:50,337:INFO:Initializing SVM - Linear Kernel
2025-05-14 19:58:50,337:INFO:Total runtime is 0.22171100775400798 minutes
2025-05-14 19:58:50,344:INFO:SubProcess create_model() called ==================================
2025-05-14 19:58:50,344:INFO:Initializing create_model()
2025-05-14 19:58:50,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA048F27D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:50,344:INFO:Checking exceptions
2025-05-14 19:58:50,345:INFO:Importing libraries
2025-05-14 19:58:50,345:INFO:Copying training dataset
2025-05-14 19:58:50,351:INFO:Defining folds
2025-05-14 19:58:50,352:INFO:Declaring metric variables
2025-05-14 19:58:50,356:INFO:Importing untrained model
2025-05-14 19:58:50,363:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 19:58:50,379:INFO:Starting cross validation
2025-05-14 19:58:50,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:58:50,712:INFO:Calculating mean and std
2025-05-14 19:58:50,715:INFO:Creating metrics dataframe
2025-05-14 19:58:50,722:INFO:Uploading results into container
2025-05-14 19:58:50,725:INFO:Uploading model into container now
2025-05-14 19:58:50,726:INFO:_master_model_container: 5
2025-05-14 19:58:50,727:INFO:_display_container: 2
2025-05-14 19:58:50,728:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 19:58:50,728:INFO:create_model() successfully completed......................................
2025-05-14 19:58:50,837:INFO:SubProcess create_model() end ==================================
2025-05-14 19:58:50,837:INFO:Creating metrics dataframe
2025-05-14 19:58:50,853:INFO:Initializing Ridge Classifier
2025-05-14 19:58:50,854:INFO:Total runtime is 0.23032711346944174 minutes
2025-05-14 19:58:50,860:INFO:SubProcess create_model() called ==================================
2025-05-14 19:58:50,860:INFO:Initializing create_model()
2025-05-14 19:58:50,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA048F27D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:50,861:INFO:Checking exceptions
2025-05-14 19:58:50,861:INFO:Importing libraries
2025-05-14 19:58:50,861:INFO:Copying training dataset
2025-05-14 19:58:50,868:INFO:Defining folds
2025-05-14 19:58:50,870:INFO:Declaring metric variables
2025-05-14 19:58:50,875:INFO:Importing untrained model
2025-05-14 19:58:50,882:INFO:Ridge Classifier Imported successfully
2025-05-14 19:58:50,898:INFO:Starting cross validation
2025-05-14 19:58:50,902:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:58:51,069:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:51,084:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:51,088:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:51,231:INFO:Calculating mean and std
2025-05-14 19:58:51,233:INFO:Creating metrics dataframe
2025-05-14 19:58:51,237:INFO:Uploading results into container
2025-05-14 19:58:51,239:INFO:Uploading model into container now
2025-05-14 19:58:51,240:INFO:_master_model_container: 6
2025-05-14 19:58:51,240:INFO:_display_container: 2
2025-05-14 19:58:51,241:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-14 19:58:51,241:INFO:create_model() successfully completed......................................
2025-05-14 19:58:51,357:INFO:SubProcess create_model() end ==================================
2025-05-14 19:58:51,358:INFO:Creating metrics dataframe
2025-05-14 19:58:51,378:INFO:Initializing Random Forest Classifier
2025-05-14 19:58:51,378:INFO:Total runtime is 0.23906991481781006 minutes
2025-05-14 19:58:51,387:INFO:SubProcess create_model() called ==================================
2025-05-14 19:58:51,388:INFO:Initializing create_model()
2025-05-14 19:58:51,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA048F27D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:51,388:INFO:Checking exceptions
2025-05-14 19:58:51,388:INFO:Importing libraries
2025-05-14 19:58:51,388:INFO:Copying training dataset
2025-05-14 19:58:51,398:INFO:Defining folds
2025-05-14 19:58:51,399:INFO:Declaring metric variables
2025-05-14 19:58:51,409:INFO:Importing untrained model
2025-05-14 19:58:51,421:INFO:Random Forest Classifier Imported successfully
2025-05-14 19:58:51,437:INFO:Starting cross validation
2025-05-14 19:58:51,440:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:58:52,277:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:53,001:INFO:Calculating mean and std
2025-05-14 19:58:53,005:INFO:Creating metrics dataframe
2025-05-14 19:58:53,009:INFO:Uploading results into container
2025-05-14 19:58:53,011:INFO:Uploading model into container now
2025-05-14 19:58:53,012:INFO:_master_model_container: 7
2025-05-14 19:58:53,012:INFO:_display_container: 2
2025-05-14 19:58:53,014:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-14 19:58:53,014:INFO:create_model() successfully completed......................................
2025-05-14 19:58:53,130:INFO:SubProcess create_model() end ==================================
2025-05-14 19:58:53,130:INFO:Creating metrics dataframe
2025-05-14 19:58:53,149:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 19:58:53,150:INFO:Total runtime is 0.2686023434003194 minutes
2025-05-14 19:58:53,159:INFO:SubProcess create_model() called ==================================
2025-05-14 19:58:53,160:INFO:Initializing create_model()
2025-05-14 19:58:53,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA048F27D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:53,161:INFO:Checking exceptions
2025-05-14 19:58:53,161:INFO:Importing libraries
2025-05-14 19:58:53,161:INFO:Copying training dataset
2025-05-14 19:58:53,171:INFO:Defining folds
2025-05-14 19:58:53,171:INFO:Declaring metric variables
2025-05-14 19:58:53,179:INFO:Importing untrained model
2025-05-14 19:58:53,190:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 19:58:53,204:INFO:Starting cross validation
2025-05-14 19:58:53,208:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:58:53,345:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 19:58:53,345:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 19:58:53,347:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 19:58:53,347:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 19:58:53,347:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 19:58:53,347:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 19:58:53,347:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 19:58:53,348:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 19:58:53,505:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 19:58:53,507:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 19:58:53,600:INFO:Calculating mean and std
2025-05-14 19:58:53,602:INFO:Creating metrics dataframe
2025-05-14 19:58:53,607:INFO:Uploading results into container
2025-05-14 19:58:53,608:INFO:Uploading model into container now
2025-05-14 19:58:53,609:INFO:_master_model_container: 8
2025-05-14 19:58:53,610:INFO:_display_container: 2
2025-05-14 19:58:53,611:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 19:58:53,611:INFO:create_model() successfully completed......................................
2025-05-14 19:58:53,718:INFO:SubProcess create_model() end ==================================
2025-05-14 19:58:53,718:INFO:Creating metrics dataframe
2025-05-14 19:58:53,731:INFO:Initializing Ada Boost Classifier
2025-05-14 19:58:53,731:INFO:Total runtime is 0.2782853484153747 minutes
2025-05-14 19:58:53,740:INFO:SubProcess create_model() called ==================================
2025-05-14 19:58:53,741:INFO:Initializing create_model()
2025-05-14 19:58:53,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA048F27D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:53,742:INFO:Checking exceptions
2025-05-14 19:58:53,742:INFO:Importing libraries
2025-05-14 19:58:53,742:INFO:Copying training dataset
2025-05-14 19:58:53,751:INFO:Defining folds
2025-05-14 19:58:53,751:INFO:Declaring metric variables
2025-05-14 19:58:53,759:INFO:Importing untrained model
2025-05-14 19:58:53,769:INFO:Ada Boost Classifier Imported successfully
2025-05-14 19:58:53,781:INFO:Starting cross validation
2025-05-14 19:58:53,782:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:58:53,897:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 19:58:53,897:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 19:58:53,897:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 19:58:53,897:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 19:58:53,897:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 19:58:54,205:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:54,288:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 19:58:54,288:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 19:58:54,623:INFO:Calculating mean and std
2025-05-14 19:58:54,625:INFO:Creating metrics dataframe
2025-05-14 19:58:54,631:INFO:Uploading results into container
2025-05-14 19:58:54,632:INFO:Uploading model into container now
2025-05-14 19:58:54,634:INFO:_master_model_container: 9
2025-05-14 19:58:54,634:INFO:_display_container: 2
2025-05-14 19:58:54,634:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-14 19:58:54,634:INFO:create_model() successfully completed......................................
2025-05-14 19:58:54,729:INFO:SubProcess create_model() end ==================================
2025-05-14 19:58:54,729:INFO:Creating metrics dataframe
2025-05-14 19:58:54,744:INFO:Initializing Gradient Boosting Classifier
2025-05-14 19:58:54,745:INFO:Total runtime is 0.2951772888501485 minutes
2025-05-14 19:58:54,750:INFO:SubProcess create_model() called ==================================
2025-05-14 19:58:54,750:INFO:Initializing create_model()
2025-05-14 19:58:54,751:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA048F27D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:54,751:INFO:Checking exceptions
2025-05-14 19:58:54,751:INFO:Importing libraries
2025-05-14 19:58:54,751:INFO:Copying training dataset
2025-05-14 19:58:54,758:INFO:Defining folds
2025-05-14 19:58:54,759:INFO:Declaring metric variables
2025-05-14 19:58:54,768:INFO:Importing untrained model
2025-05-14 19:58:54,775:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 19:58:54,785:INFO:Starting cross validation
2025-05-14 19:58:54,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:58:55,679:INFO:Calculating mean and std
2025-05-14 19:58:55,680:INFO:Creating metrics dataframe
2025-05-14 19:58:55,685:INFO:Uploading results into container
2025-05-14 19:58:55,687:INFO:Uploading model into container now
2025-05-14 19:58:55,687:INFO:_master_model_container: 10
2025-05-14 19:58:55,687:INFO:_display_container: 2
2025-05-14 19:58:55,688:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 19:58:55,688:INFO:create_model() successfully completed......................................
2025-05-14 19:58:55,782:INFO:SubProcess create_model() end ==================================
2025-05-14 19:58:55,782:INFO:Creating metrics dataframe
2025-05-14 19:58:55,793:INFO:Initializing Linear Discriminant Analysis
2025-05-14 19:58:55,793:INFO:Total runtime is 0.3126457095146179 minutes
2025-05-14 19:58:55,800:INFO:SubProcess create_model() called ==================================
2025-05-14 19:58:55,800:INFO:Initializing create_model()
2025-05-14 19:58:55,801:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA048F27D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:55,801:INFO:Checking exceptions
2025-05-14 19:58:55,801:INFO:Importing libraries
2025-05-14 19:58:55,801:INFO:Copying training dataset
2025-05-14 19:58:55,809:INFO:Defining folds
2025-05-14 19:58:55,809:INFO:Declaring metric variables
2025-05-14 19:58:55,816:INFO:Importing untrained model
2025-05-14 19:58:55,825:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 19:58:55,841:INFO:Starting cross validation
2025-05-14 19:58:55,843:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:58:55,980:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:56,145:INFO:Calculating mean and std
2025-05-14 19:58:56,146:INFO:Creating metrics dataframe
2025-05-14 19:58:56,150:INFO:Uploading results into container
2025-05-14 19:58:56,151:INFO:Uploading model into container now
2025-05-14 19:58:56,151:INFO:_master_model_container: 11
2025-05-14 19:58:56,151:INFO:_display_container: 2
2025-05-14 19:58:56,152:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 19:58:56,152:INFO:create_model() successfully completed......................................
2025-05-14 19:58:56,252:INFO:SubProcess create_model() end ==================================
2025-05-14 19:58:56,252:INFO:Creating metrics dataframe
2025-05-14 19:58:56,271:INFO:Initializing Extra Trees Classifier
2025-05-14 19:58:56,271:INFO:Total runtime is 0.32061282396316526 minutes
2025-05-14 19:58:56,280:INFO:SubProcess create_model() called ==================================
2025-05-14 19:58:56,281:INFO:Initializing create_model()
2025-05-14 19:58:56,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA048F27D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:56,282:INFO:Checking exceptions
2025-05-14 19:58:56,282:INFO:Importing libraries
2025-05-14 19:58:56,282:INFO:Copying training dataset
2025-05-14 19:58:56,290:INFO:Defining folds
2025-05-14 19:58:56,291:INFO:Declaring metric variables
2025-05-14 19:58:56,296:INFO:Importing untrained model
2025-05-14 19:58:56,302:INFO:Extra Trees Classifier Imported successfully
2025-05-14 19:58:56,320:INFO:Starting cross validation
2025-05-14 19:58:56,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:58:56,871:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:57,200:INFO:Calculating mean and std
2025-05-14 19:58:57,201:INFO:Creating metrics dataframe
2025-05-14 19:58:57,203:INFO:Uploading results into container
2025-05-14 19:58:57,203:INFO:Uploading model into container now
2025-05-14 19:58:57,204:INFO:_master_model_container: 12
2025-05-14 19:58:57,204:INFO:_display_container: 2
2025-05-14 19:58:57,204:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-14 19:58:57,204:INFO:create_model() successfully completed......................................
2025-05-14 19:58:57,277:INFO:SubProcess create_model() end ==================================
2025-05-14 19:58:57,277:INFO:Creating metrics dataframe
2025-05-14 19:58:57,287:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 19:58:57,287:INFO:Total runtime is 0.3375413656234741 minutes
2025-05-14 19:58:57,290:INFO:SubProcess create_model() called ==================================
2025-05-14 19:58:57,291:INFO:Initializing create_model()
2025-05-14 19:58:57,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA048F27D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:57,291:INFO:Checking exceptions
2025-05-14 19:58:57,291:INFO:Importing libraries
2025-05-14 19:58:57,291:INFO:Copying training dataset
2025-05-14 19:58:57,294:INFO:Defining folds
2025-05-14 19:58:57,295:INFO:Declaring metric variables
2025-05-14 19:58:57,298:INFO:Importing untrained model
2025-05-14 19:58:57,302:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 19:58:57,313:INFO:Starting cross validation
2025-05-14 19:58:57,314:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:58:57,866:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:58,038:INFO:Calculating mean and std
2025-05-14 19:58:58,039:INFO:Creating metrics dataframe
2025-05-14 19:58:58,042:INFO:Uploading results into container
2025-05-14 19:58:58,044:INFO:Uploading model into container now
2025-05-14 19:58:58,045:INFO:_master_model_container: 13
2025-05-14 19:58:58,045:INFO:_display_container: 2
2025-05-14 19:58:58,047:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 19:58:58,047:INFO:create_model() successfully completed......................................
2025-05-14 19:58:58,146:INFO:SubProcess create_model() end ==================================
2025-05-14 19:58:58,146:INFO:Creating metrics dataframe
2025-05-14 19:58:58,161:INFO:Initializing Dummy Classifier
2025-05-14 19:58:58,161:INFO:Total runtime is 0.3521206259727478 minutes
2025-05-14 19:58:58,167:INFO:SubProcess create_model() called ==================================
2025-05-14 19:58:58,167:INFO:Initializing create_model()
2025-05-14 19:58:58,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA048F27D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:58,168:INFO:Checking exceptions
2025-05-14 19:58:58,168:INFO:Importing libraries
2025-05-14 19:58:58,168:INFO:Copying training dataset
2025-05-14 19:58:58,174:INFO:Defining folds
2025-05-14 19:58:58,174:INFO:Declaring metric variables
2025-05-14 19:58:58,178:INFO:Importing untrained model
2025-05-14 19:58:58,183:INFO:Dummy Classifier Imported successfully
2025-05-14 19:58:58,195:INFO:Starting cross validation
2025-05-14 19:58:58,196:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:58:58,327:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:58,332:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:58,338:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:58,342:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:58,346:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:58,346:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:58,347:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:58,364:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:58,412:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:58,415:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:58,427:INFO:Calculating mean and std
2025-05-14 19:58:58,428:INFO:Creating metrics dataframe
2025-05-14 19:58:58,431:INFO:Uploading results into container
2025-05-14 19:58:58,431:INFO:Uploading model into container now
2025-05-14 19:58:58,432:INFO:_master_model_container: 14
2025-05-14 19:58:58,432:INFO:_display_container: 2
2025-05-14 19:58:58,433:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-14 19:58:58,433:INFO:create_model() successfully completed......................................
2025-05-14 19:58:58,508:INFO:SubProcess create_model() end ==================================
2025-05-14 19:58:58,508:INFO:Creating metrics dataframe
2025-05-14 19:58:58,520:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-14 19:58:58,528:INFO:Initializing create_model()
2025-05-14 19:58:58,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:58,529:INFO:Checking exceptions
2025-05-14 19:58:58,530:INFO:Importing libraries
2025-05-14 19:58:58,532:INFO:Copying training dataset
2025-05-14 19:58:58,534:INFO:Defining folds
2025-05-14 19:58:58,534:INFO:Declaring metric variables
2025-05-14 19:58:58,534:INFO:Importing untrained model
2025-05-14 19:58:58,535:INFO:Declaring custom model
2025-05-14 19:58:58,535:INFO:Ridge Classifier Imported successfully
2025-05-14 19:58:58,536:INFO:Cross validation set to False
2025-05-14 19:58:58,536:INFO:Fitting Model
2025-05-14 19:58:58,568:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-14 19:58:58,568:INFO:create_model() successfully completed......................................
2025-05-14 19:58:58,661:INFO:_master_model_container: 14
2025-05-14 19:58:58,661:INFO:_display_container: 2
2025-05-14 19:58:58,662:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-14 19:58:58,662:INFO:compare_models() successfully completed......................................
2025-05-14 19:58:58,662:INFO:Initializing create_model()
2025-05-14 19:58:58,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:58:58,662:INFO:Checking exceptions
2025-05-14 19:58:58,677:INFO:Importing libraries
2025-05-14 19:58:58,677:INFO:Copying training dataset
2025-05-14 19:58:58,682:INFO:Defining folds
2025-05-14 19:58:58,682:INFO:Declaring metric variables
2025-05-14 19:58:58,686:INFO:Importing untrained model
2025-05-14 19:58:58,689:INFO:Random Forest Classifier Imported successfully
2025-05-14 19:58:58,697:INFO:Starting cross validation
2025-05-14 19:58:58,699:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:58:59,274:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:58:59,724:INFO:Calculating mean and std
2025-05-14 19:58:59,725:INFO:Creating metrics dataframe
2025-05-14 19:58:59,731:INFO:Finalizing model
2025-05-14 19:58:59,928:INFO:Uploading results into container
2025-05-14 19:58:59,929:INFO:Uploading model into container now
2025-05-14 19:58:59,940:INFO:_master_model_container: 15
2025-05-14 19:58:59,940:INFO:_display_container: 3
2025-05-14 19:58:59,940:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-14 19:58:59,940:INFO:create_model() successfully completed......................................
2025-05-14 19:59:00,007:INFO:Initializing tune_model()
2025-05-14 19:59:00,007:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 19:59:00,007:INFO:Checking exceptions
2025-05-14 19:59:00,022:INFO:Copying training dataset
2025-05-14 19:59:00,025:INFO:Checking base model
2025-05-14 19:59:00,025:INFO:Base model : Random Forest Classifier
2025-05-14 19:59:00,029:INFO:Declaring metric variables
2025-05-14 19:59:00,034:INFO:Defining Hyperparameters
2025-05-14 19:59:00,117:INFO:Tuning with n_jobs=-1
2025-05-14 19:59:00,117:INFO:Initializing RandomizedSearchCV
2025-05-14 19:59:11,142:INFO:best_params: {'actual_estimator__n_estimators': 70, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': False}
2025-05-14 19:59:11,143:INFO:Hyperparameter search completed
2025-05-14 19:59:11,143:INFO:SubProcess create_model() called ==================================
2025-05-14 19:59:11,144:INFO:Initializing create_model()
2025-05-14 19:59:11,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA03DCCA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 70, 'min_samples_split': 9, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 'sqrt', 'max_depth': 3, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': False})
2025-05-14 19:59:11,144:INFO:Checking exceptions
2025-05-14 19:59:11,145:INFO:Importing libraries
2025-05-14 19:59:11,145:INFO:Copying training dataset
2025-05-14 19:59:11,150:INFO:Defining folds
2025-05-14 19:59:11,151:INFO:Declaring metric variables
2025-05-14 19:59:11,155:INFO:Importing untrained model
2025-05-14 19:59:11,155:INFO:Declaring custom model
2025-05-14 19:59:11,160:INFO:Random Forest Classifier Imported successfully
2025-05-14 19:59:11,170:INFO:Starting cross validation
2025-05-14 19:59:11,172:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:59:11,620:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:59:11,683:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:59:11,686:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:59:11,699:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:59:11,713:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:59:11,760:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:59:11,775:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:59:11,935:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:59:11,955:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:59:11,968:INFO:Calculating mean and std
2025-05-14 19:59:11,969:INFO:Creating metrics dataframe
2025-05-14 19:59:11,975:INFO:Finalizing model
2025-05-14 19:59:12,108:INFO:Uploading results into container
2025-05-14 19:59:12,109:INFO:Uploading model into container now
2025-05-14 19:59:12,109:INFO:_master_model_container: 16
2025-05-14 19:59:12,110:INFO:_display_container: 4
2025-05-14 19:59:12,110:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-14 19:59:12,110:INFO:create_model() successfully completed......................................
2025-05-14 19:59:12,178:INFO:SubProcess create_model() end ==================================
2025-05-14 19:59:12,179:INFO:choose_better activated
2025-05-14 19:59:12,182:INFO:SubProcess create_model() called ==================================
2025-05-14 19:59:12,182:INFO:Initializing create_model()
2025-05-14 19:59:12,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 19:59:12,182:INFO:Checking exceptions
2025-05-14 19:59:12,185:INFO:Importing libraries
2025-05-14 19:59:12,185:INFO:Copying training dataset
2025-05-14 19:59:12,188:INFO:Defining folds
2025-05-14 19:59:12,188:INFO:Declaring metric variables
2025-05-14 19:59:12,188:INFO:Importing untrained model
2025-05-14 19:59:12,189:INFO:Declaring custom model
2025-05-14 19:59:12,189:INFO:Random Forest Classifier Imported successfully
2025-05-14 19:59:12,189:INFO:Starting cross validation
2025-05-14 19:59:12,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 19:59:12,876:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:59:13,296:INFO:Calculating mean and std
2025-05-14 19:59:13,296:INFO:Creating metrics dataframe
2025-05-14 19:59:13,298:INFO:Finalizing model
2025-05-14 19:59:13,490:INFO:Uploading results into container
2025-05-14 19:59:13,490:INFO:Uploading model into container now
2025-05-14 19:59:13,491:INFO:_master_model_container: 17
2025-05-14 19:59:13,491:INFO:_display_container: 5
2025-05-14 19:59:13,491:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-14 19:59:13,491:INFO:create_model() successfully completed......................................
2025-05-14 19:59:13,569:INFO:SubProcess create_model() end ==================================
2025-05-14 19:59:13,570:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.6952
2025-05-14 19:59:13,570:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.7381
2025-05-14 19:59:13,571:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2025-05-14 19:59:13,571:INFO:choose_better completed
2025-05-14 19:59:13,585:INFO:_master_model_container: 17
2025-05-14 19:59:13,585:INFO:_display_container: 4
2025-05-14 19:59:13,587:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-14 19:59:13,587:INFO:tune_model() successfully completed......................................
2025-05-14 19:59:13,668:INFO:Initializing plot_model()
2025-05-14 19:59:13,668:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 19:59:13,668:INFO:Checking exceptions
2025-05-14 19:59:13,672:INFO:Preloading libraries
2025-05-14 19:59:13,681:INFO:Copying training dataset
2025-05-14 19:59:13,681:INFO:Plot type: confusion_matrix
2025-05-14 19:59:13,836:INFO:Fitting Model
2025-05-14 19:59:13,870:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-05-14 19:59:13,870:INFO:Scoring test/hold-out set
2025-05-14 19:59:14,070:INFO:Visual Rendered Successfully
2025-05-14 19:59:14,149:INFO:plot_model() successfully completed......................................
2025-05-14 19:59:14,150:INFO:Initializing plot_model()
2025-05-14 19:59:14,150:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 19:59:14,150:INFO:Checking exceptions
2025-05-14 19:59:14,153:INFO:Preloading libraries
2025-05-14 19:59:14,161:INFO:Copying training dataset
2025-05-14 19:59:14,161:INFO:Plot type: feature
2025-05-14 19:59:14,161:WARNING:No coef_ found. Trying feature_importances_
2025-05-14 19:59:14,362:INFO:Visual Rendered Successfully
2025-05-14 19:59:14,438:INFO:plot_model() successfully completed......................................
2025-05-14 19:59:14,438:INFO:Initializing evaluate_model()
2025-05-14 19:59:14,438:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 19:59:14,448:INFO:Initializing plot_model()
2025-05-14 19:59:14,448:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 19:59:14,449:INFO:Checking exceptions
2025-05-14 19:59:14,451:INFO:Preloading libraries
2025-05-14 19:59:14,456:INFO:Copying training dataset
2025-05-14 19:59:14,456:INFO:Plot type: pipeline
2025-05-14 19:59:14,672:INFO:Visual Rendered Successfully
2025-05-14 19:59:14,751:INFO:plot_model() successfully completed......................................
2025-05-14 19:59:14,755:INFO:Initializing predict_model()
2025-05-14 19:59:14,755:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA047C9510>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BA04CB8680>)
2025-05-14 19:59:14,755:INFO:Checking exceptions
2025-05-14 19:59:14,755:INFO:Preloading libraries
2025-05-14 19:59:14,891:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 19:59:14,980:INFO:Initializing save_model()
2025-05-14 19:59:14,980:INFO:save_model(model=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), model_name=modelo_churn_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strate...
                 TransformerWrapper(exclude=None, include=['tipo_plan'],
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-14 19:59:14,980:INFO:Adding model into prep_pipe
2025-05-14 19:59:15,004:INFO:modelo_churn_final.pkl saved in current working directory
2025-05-14 19:59:15,012:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tra...
                 RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                                        class_weight={}, criterion='gini',
                                        max_depth=3, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.1,
                                        min_samples_leaf=4, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=70,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False)
2025-05-14 19:59:15,012:INFO:save_model() successfully completed......................................
2025-05-14 20:24:26,196:INFO:PyCaret ClassificationExperiment
2025-05-14 20:24:26,197:INFO:Logging name: clf-default-name
2025-05-14 20:24:26,197:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 20:24:26,197:INFO:version 3.3.2
2025-05-14 20:24:26,197:INFO:Initializing setup()
2025-05-14 20:24:26,197:INFO:self.USI: 5077
2025-05-14 20:24:26,197:INFO:self._variable_keys: {'_ml_usecase', 'gpu_param', 'fold_groups_param', 'html_param', '_available_plots', 'fold_shuffle_param', 'fix_imbalance', 'idx', 'y_test', 'X_train', 'pipeline', 'fold_generator', 'data', 'exp_id', 'memory', 'logging_param', 'X', 'y_train', 'is_multiclass', 'seed', 'n_jobs_param', 'X_test', 'y', 'USI', 'target_param', 'log_plots_param', 'gpu_n_jobs_param', 'exp_name_log'}
2025-05-14 20:24:26,197:INFO:Checking environment
2025-05-14 20:24:26,197:INFO:python_version: 3.11.8
2025-05-14 20:24:26,197:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-14 20:24:26,197:INFO:machine: AMD64
2025-05-14 20:24:26,197:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-14 20:24:26,201:INFO:Memory: svmem(total=16907886592, available=5063716864, percent=70.1, used=11844169728, free=5063716864)
2025-05-14 20:24:26,202:INFO:Physical Core: 4
2025-05-14 20:24:26,202:INFO:Logical Core: 8
2025-05-14 20:24:26,202:INFO:Checking libraries
2025-05-14 20:24:26,202:INFO:System:
2025-05-14 20:24:26,202:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-14 20:24:26,202:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-14 20:24:26,202:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-14 20:24:26,202:INFO:PyCaret required dependencies:
2025-05-14 20:24:26,202:INFO:                 pip: 24.0
2025-05-14 20:24:26,202:INFO:          setuptools: 65.5.0
2025-05-14 20:24:26,202:INFO:             pycaret: 3.3.2
2025-05-14 20:24:26,202:INFO:             IPython: 9.2.0
2025-05-14 20:24:26,202:INFO:          ipywidgets: 8.1.7
2025-05-14 20:24:26,202:INFO:                tqdm: 4.67.1
2025-05-14 20:24:26,202:INFO:               numpy: 1.26.4
2025-05-14 20:24:26,202:INFO:              pandas: 2.1.4
2025-05-14 20:24:26,202:INFO:              jinja2: 3.1.6
2025-05-14 20:24:26,202:INFO:               scipy: 1.11.4
2025-05-14 20:24:26,202:INFO:              joblib: 1.3.2
2025-05-14 20:24:26,202:INFO:             sklearn: 1.4.2
2025-05-14 20:24:26,202:INFO:                pyod: 2.0.5
2025-05-14 20:24:26,202:INFO:            imblearn: 0.13.0
2025-05-14 20:24:26,202:INFO:   category_encoders: 2.7.0
2025-05-14 20:24:26,202:INFO:            lightgbm: 4.6.0
2025-05-14 20:24:26,202:INFO:               numba: 0.61.2
2025-05-14 20:24:26,202:INFO:            requests: 2.32.3
2025-05-14 20:24:26,202:INFO:          matplotlib: 3.7.5
2025-05-14 20:24:26,202:INFO:          scikitplot: 0.3.7
2025-05-14 20:24:26,202:INFO:         yellowbrick: 1.5
2025-05-14 20:24:26,202:INFO:              plotly: 5.24.1
2025-05-14 20:24:26,202:INFO:    plotly-resampler: Not installed
2025-05-14 20:24:26,202:INFO:             kaleido: 0.2.1
2025-05-14 20:24:26,202:INFO:           schemdraw: 0.15
2025-05-14 20:24:26,202:INFO:         statsmodels: 0.14.4
2025-05-14 20:24:26,202:INFO:              sktime: 0.26.0
2025-05-14 20:24:26,202:INFO:               tbats: 1.1.3
2025-05-14 20:24:26,202:INFO:            pmdarima: 2.0.4
2025-05-14 20:24:26,202:INFO:              psutil: 7.0.0
2025-05-14 20:24:26,202:INFO:          markupsafe: 3.0.2
2025-05-14 20:24:26,202:INFO:             pickle5: Not installed
2025-05-14 20:24:26,202:INFO:         cloudpickle: 3.1.1
2025-05-14 20:24:26,204:INFO:         deprecation: 2.1.0
2025-05-14 20:24:26,204:INFO:              xxhash: 3.5.0
2025-05-14 20:24:26,204:INFO:           wurlitzer: Not installed
2025-05-14 20:24:26,204:INFO:PyCaret optional dependencies:
2025-05-14 20:24:26,204:INFO:                shap: Not installed
2025-05-14 20:24:26,204:INFO:           interpret: Not installed
2025-05-14 20:24:26,204:INFO:                umap: Not installed
2025-05-14 20:24:26,204:INFO:     ydata_profiling: Not installed
2025-05-14 20:24:26,204:INFO:  explainerdashboard: Not installed
2025-05-14 20:24:26,204:INFO:             autoviz: Not installed
2025-05-14 20:24:26,204:INFO:           fairlearn: Not installed
2025-05-14 20:24:26,204:INFO:          deepchecks: Not installed
2025-05-14 20:24:26,204:INFO:             xgboost: Not installed
2025-05-14 20:24:26,204:INFO:            catboost: Not installed
2025-05-14 20:24:26,204:INFO:              kmodes: Not installed
2025-05-14 20:24:26,204:INFO:             mlxtend: Not installed
2025-05-14 20:24:26,204:INFO:       statsforecast: Not installed
2025-05-14 20:24:26,204:INFO:        tune_sklearn: Not installed
2025-05-14 20:24:26,204:INFO:                 ray: Not installed
2025-05-14 20:24:26,204:INFO:            hyperopt: Not installed
2025-05-14 20:24:26,204:INFO:              optuna: Not installed
2025-05-14 20:24:26,204:INFO:               skopt: Not installed
2025-05-14 20:24:26,204:INFO:              mlflow: Not installed
2025-05-14 20:24:26,204:INFO:              gradio: Not installed
2025-05-14 20:24:26,204:INFO:             fastapi: Not installed
2025-05-14 20:24:26,204:INFO:             uvicorn: Not installed
2025-05-14 20:24:26,204:INFO:              m2cgen: Not installed
2025-05-14 20:24:26,205:INFO:           evidently: Not installed
2025-05-14 20:24:26,205:INFO:               fugue: Not installed
2025-05-14 20:24:26,205:INFO:           streamlit: Not installed
2025-05-14 20:24:26,205:INFO:             prophet: Not installed
2025-05-14 20:24:26,205:INFO:None
2025-05-14 20:24:26,205:INFO:Set up data.
2025-05-14 20:24:26,208:INFO:Set up folding strategy.
2025-05-14 20:24:26,208:INFO:Set up train/test split.
2025-05-14 20:24:26,212:INFO:Set up index.
2025-05-14 20:24:26,212:INFO:Assigning column types.
2025-05-14 20:24:26,216:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 20:24:26,257:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 20:24:26,258:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 20:24:26,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,317:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 20:24:26,318:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 20:24:26,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,339:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,339:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 20:24:26,374:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 20:24:26,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,431:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 20:24:26,453:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,453:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,454:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 20:24:26,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,568:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,569:INFO:Preparing preprocessing pipeline...
2025-05-14 20:24:26,570:INFO:Set up simple imputation.
2025-05-14 20:24:26,571:INFO:Set up encoding of categorical features.
2025-05-14 20:24:26,572:INFO:Set up feature normalization.
2025-05-14 20:24:26,617:INFO:Finished creating preprocessing pipeline.
2025-05-14 20:24:26,621:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strate...
                 TransformerWrapper(exclude=None, include=['tipo_plan'],
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-14 20:24:26,621:INFO:Creating final display dataframe.
2025-05-14 20:24:26,734:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             churn
2                   Target type            Binary
3           Original data shape          (300, 7)
4        Transformed data shape          (300, 9)
5   Transformed train set shape          (210, 9)
6    Transformed test set shape           (90, 9)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              5077
2025-05-14 20:24:26,799:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,800:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,856:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:24:26,857:INFO:setup() successfully completed in 0.66s...............
2025-05-14 20:24:26,867:INFO:Initializing compare_models()
2025-05-14 20:24:26,868:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 20:24:26,868:INFO:Checking exceptions
2025-05-14 20:24:26,872:INFO:Preparing display monitor
2025-05-14 20:24:26,895:INFO:Initializing Logistic Regression
2025-05-14 20:24:26,895:INFO:Total runtime is 0.0 minutes
2025-05-14 20:24:26,899:INFO:SubProcess create_model() called ==================================
2025-05-14 20:24:26,899:INFO:Initializing create_model()
2025-05-14 20:24:26,899:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04CF6ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:26,899:INFO:Checking exceptions
2025-05-14 20:24:26,899:INFO:Importing libraries
2025-05-14 20:24:26,899:INFO:Copying training dataset
2025-05-14 20:24:26,902:INFO:Defining folds
2025-05-14 20:24:26,902:INFO:Declaring metric variables
2025-05-14 20:24:26,906:INFO:Importing untrained model
2025-05-14 20:24:26,909:INFO:Logistic Regression Imported successfully
2025-05-14 20:24:26,916:INFO:Starting cross validation
2025-05-14 20:24:26,917:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:24:37,051:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:37,680:INFO:Calculating mean and std
2025-05-14 20:24:37,682:INFO:Creating metrics dataframe
2025-05-14 20:24:37,685:INFO:Uploading results into container
2025-05-14 20:24:37,685:INFO:Uploading model into container now
2025-05-14 20:24:37,686:INFO:_master_model_container: 1
2025-05-14 20:24:37,687:INFO:_display_container: 2
2025-05-14 20:24:37,687:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 20:24:37,687:INFO:create_model() successfully completed......................................
2025-05-14 20:24:37,805:INFO:SubProcess create_model() end ==================================
2025-05-14 20:24:37,805:INFO:Creating metrics dataframe
2025-05-14 20:24:37,814:INFO:Initializing K Neighbors Classifier
2025-05-14 20:24:37,815:INFO:Total runtime is 0.18199372291564941 minutes
2025-05-14 20:24:37,819:INFO:SubProcess create_model() called ==================================
2025-05-14 20:24:37,819:INFO:Initializing create_model()
2025-05-14 20:24:37,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04CF6ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:37,819:INFO:Checking exceptions
2025-05-14 20:24:37,819:INFO:Importing libraries
2025-05-14 20:24:37,819:INFO:Copying training dataset
2025-05-14 20:24:37,824:INFO:Defining folds
2025-05-14 20:24:37,825:INFO:Declaring metric variables
2025-05-14 20:24:37,829:INFO:Importing untrained model
2025-05-14 20:24:37,835:INFO:K Neighbors Classifier Imported successfully
2025-05-14 20:24:37,875:INFO:Starting cross validation
2025-05-14 20:24:37,880:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:24:38,308:INFO:Calculating mean and std
2025-05-14 20:24:38,310:INFO:Creating metrics dataframe
2025-05-14 20:24:38,312:INFO:Uploading results into container
2025-05-14 20:24:38,312:INFO:Uploading model into container now
2025-05-14 20:24:38,312:INFO:_master_model_container: 2
2025-05-14 20:24:38,312:INFO:_display_container: 2
2025-05-14 20:24:38,314:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 20:24:38,314:INFO:create_model() successfully completed......................................
2025-05-14 20:24:38,397:INFO:SubProcess create_model() end ==================================
2025-05-14 20:24:38,397:INFO:Creating metrics dataframe
2025-05-14 20:24:38,410:INFO:Initializing Naive Bayes
2025-05-14 20:24:38,410:INFO:Total runtime is 0.19191420475641888 minutes
2025-05-14 20:24:38,415:INFO:SubProcess create_model() called ==================================
2025-05-14 20:24:38,416:INFO:Initializing create_model()
2025-05-14 20:24:38,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04CF6ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:38,416:INFO:Checking exceptions
2025-05-14 20:24:38,416:INFO:Importing libraries
2025-05-14 20:24:38,416:INFO:Copying training dataset
2025-05-14 20:24:38,422:INFO:Defining folds
2025-05-14 20:24:38,422:INFO:Declaring metric variables
2025-05-14 20:24:38,428:INFO:Importing untrained model
2025-05-14 20:24:38,434:INFO:Naive Bayes Imported successfully
2025-05-14 20:24:38,445:INFO:Starting cross validation
2025-05-14 20:24:38,447:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:24:38,770:INFO:Calculating mean and std
2025-05-14 20:24:38,772:INFO:Creating metrics dataframe
2025-05-14 20:24:38,775:INFO:Uploading results into container
2025-05-14 20:24:38,776:INFO:Uploading model into container now
2025-05-14 20:24:38,777:INFO:_master_model_container: 3
2025-05-14 20:24:38,778:INFO:_display_container: 2
2025-05-14 20:24:38,778:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 20:24:38,778:INFO:create_model() successfully completed......................................
2025-05-14 20:24:38,866:INFO:SubProcess create_model() end ==================================
2025-05-14 20:24:38,866:INFO:Creating metrics dataframe
2025-05-14 20:24:38,875:INFO:Initializing Decision Tree Classifier
2025-05-14 20:24:38,875:INFO:Total runtime is 0.19966253439585369 minutes
2025-05-14 20:24:38,879:INFO:SubProcess create_model() called ==================================
2025-05-14 20:24:38,880:INFO:Initializing create_model()
2025-05-14 20:24:38,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04CF6ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:38,881:INFO:Checking exceptions
2025-05-14 20:24:38,881:INFO:Importing libraries
2025-05-14 20:24:38,881:INFO:Copying training dataset
2025-05-14 20:24:38,887:INFO:Defining folds
2025-05-14 20:24:38,887:INFO:Declaring metric variables
2025-05-14 20:24:38,892:INFO:Importing untrained model
2025-05-14 20:24:38,898:INFO:Decision Tree Classifier Imported successfully
2025-05-14 20:24:38,908:INFO:Starting cross validation
2025-05-14 20:24:38,910:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:24:39,208:INFO:Calculating mean and std
2025-05-14 20:24:39,209:INFO:Creating metrics dataframe
2025-05-14 20:24:39,211:INFO:Uploading results into container
2025-05-14 20:24:39,212:INFO:Uploading model into container now
2025-05-14 20:24:39,212:INFO:_master_model_container: 4
2025-05-14 20:24:39,213:INFO:_display_container: 2
2025-05-14 20:24:39,214:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-14 20:24:39,214:INFO:create_model() successfully completed......................................
2025-05-14 20:24:39,305:INFO:SubProcess create_model() end ==================================
2025-05-14 20:24:39,305:INFO:Creating metrics dataframe
2025-05-14 20:24:39,315:INFO:Initializing SVM - Linear Kernel
2025-05-14 20:24:39,315:INFO:Total runtime is 0.20699644088745117 minutes
2025-05-14 20:24:39,319:INFO:SubProcess create_model() called ==================================
2025-05-14 20:24:39,319:INFO:Initializing create_model()
2025-05-14 20:24:39,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04CF6ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:39,319:INFO:Checking exceptions
2025-05-14 20:24:39,320:INFO:Importing libraries
2025-05-14 20:24:39,320:INFO:Copying training dataset
2025-05-14 20:24:39,328:INFO:Defining folds
2025-05-14 20:24:39,328:INFO:Declaring metric variables
2025-05-14 20:24:39,334:INFO:Importing untrained model
2025-05-14 20:24:39,339:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 20:24:39,348:INFO:Starting cross validation
2025-05-14 20:24:39,350:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:24:39,615:INFO:Calculating mean and std
2025-05-14 20:24:39,615:INFO:Creating metrics dataframe
2025-05-14 20:24:39,619:INFO:Uploading results into container
2025-05-14 20:24:39,620:INFO:Uploading model into container now
2025-05-14 20:24:39,620:INFO:_master_model_container: 5
2025-05-14 20:24:39,621:INFO:_display_container: 2
2025-05-14 20:24:39,621:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 20:24:39,621:INFO:create_model() successfully completed......................................
2025-05-14 20:24:39,701:INFO:SubProcess create_model() end ==================================
2025-05-14 20:24:39,701:INFO:Creating metrics dataframe
2025-05-14 20:24:39,710:INFO:Initializing Ridge Classifier
2025-05-14 20:24:39,710:INFO:Total runtime is 0.2135868509610494 minutes
2025-05-14 20:24:39,715:INFO:SubProcess create_model() called ==================================
2025-05-14 20:24:39,715:INFO:Initializing create_model()
2025-05-14 20:24:39,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04CF6ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:39,715:INFO:Checking exceptions
2025-05-14 20:24:39,715:INFO:Importing libraries
2025-05-14 20:24:39,715:INFO:Copying training dataset
2025-05-14 20:24:39,720:INFO:Defining folds
2025-05-14 20:24:39,720:INFO:Declaring metric variables
2025-05-14 20:24:39,726:INFO:Importing untrained model
2025-05-14 20:24:39,730:INFO:Ridge Classifier Imported successfully
2025-05-14 20:24:39,737:INFO:Starting cross validation
2025-05-14 20:24:39,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:24:39,879:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:39,890:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:39,973:INFO:Calculating mean and std
2025-05-14 20:24:39,975:INFO:Creating metrics dataframe
2025-05-14 20:24:39,976:INFO:Uploading results into container
2025-05-14 20:24:39,977:INFO:Uploading model into container now
2025-05-14 20:24:39,979:INFO:_master_model_container: 6
2025-05-14 20:24:39,979:INFO:_display_container: 2
2025-05-14 20:24:39,980:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-14 20:24:39,980:INFO:create_model() successfully completed......................................
2025-05-14 20:24:40,062:INFO:SubProcess create_model() end ==================================
2025-05-14 20:24:40,062:INFO:Creating metrics dataframe
2025-05-14 20:24:40,072:INFO:Initializing Random Forest Classifier
2025-05-14 20:24:40,072:INFO:Total runtime is 0.21962597767512004 minutes
2025-05-14 20:24:40,075:INFO:SubProcess create_model() called ==================================
2025-05-14 20:24:40,077:INFO:Initializing create_model()
2025-05-14 20:24:40,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04CF6ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:40,077:INFO:Checking exceptions
2025-05-14 20:24:40,077:INFO:Importing libraries
2025-05-14 20:24:40,077:INFO:Copying training dataset
2025-05-14 20:24:40,080:INFO:Defining folds
2025-05-14 20:24:40,080:INFO:Declaring metric variables
2025-05-14 20:24:40,085:INFO:Importing untrained model
2025-05-14 20:24:40,091:INFO:Random Forest Classifier Imported successfully
2025-05-14 20:24:40,098:INFO:Starting cross validation
2025-05-14 20:24:40,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:24:41,122:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:41,659:INFO:Calculating mean and std
2025-05-14 20:24:41,660:INFO:Creating metrics dataframe
2025-05-14 20:24:41,662:INFO:Uploading results into container
2025-05-14 20:24:41,664:INFO:Uploading model into container now
2025-05-14 20:24:41,665:INFO:_master_model_container: 7
2025-05-14 20:24:41,665:INFO:_display_container: 2
2025-05-14 20:24:41,665:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-14 20:24:41,666:INFO:create_model() successfully completed......................................
2025-05-14 20:24:41,755:INFO:SubProcess create_model() end ==================================
2025-05-14 20:24:41,755:INFO:Creating metrics dataframe
2025-05-14 20:24:41,768:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 20:24:41,768:INFO:Total runtime is 0.24788594245910645 minutes
2025-05-14 20:24:41,774:INFO:SubProcess create_model() called ==================================
2025-05-14 20:24:41,774:INFO:Initializing create_model()
2025-05-14 20:24:41,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04CF6ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:41,775:INFO:Checking exceptions
2025-05-14 20:24:41,775:INFO:Importing libraries
2025-05-14 20:24:41,775:INFO:Copying training dataset
2025-05-14 20:24:41,781:INFO:Defining folds
2025-05-14 20:24:41,781:INFO:Declaring metric variables
2025-05-14 20:24:41,787:INFO:Importing untrained model
2025-05-14 20:24:41,792:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 20:24:41,802:INFO:Starting cross validation
2025-05-14 20:24:41,805:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:24:41,909:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:24:41,910:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:24:41,911:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:24:41,920:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:24:41,921:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:24:41,938:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:24:41,944:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:24:42,006:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:24:42,070:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:24:42,075:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:24:42,134:INFO:Calculating mean and std
2025-05-14 20:24:42,137:INFO:Creating metrics dataframe
2025-05-14 20:24:42,140:INFO:Uploading results into container
2025-05-14 20:24:42,142:INFO:Uploading model into container now
2025-05-14 20:24:42,142:INFO:_master_model_container: 8
2025-05-14 20:24:42,143:INFO:_display_container: 2
2025-05-14 20:24:42,143:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 20:24:42,143:INFO:create_model() successfully completed......................................
2025-05-14 20:24:42,248:INFO:SubProcess create_model() end ==================================
2025-05-14 20:24:42,248:INFO:Creating metrics dataframe
2025-05-14 20:24:42,263:INFO:Initializing Ada Boost Classifier
2025-05-14 20:24:42,263:INFO:Total runtime is 0.2561425447463989 minutes
2025-05-14 20:24:42,272:INFO:SubProcess create_model() called ==================================
2025-05-14 20:24:42,273:INFO:Initializing create_model()
2025-05-14 20:24:42,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04CF6ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:42,273:INFO:Checking exceptions
2025-05-14 20:24:42,274:INFO:Importing libraries
2025-05-14 20:24:42,274:INFO:Copying training dataset
2025-05-14 20:24:42,282:INFO:Defining folds
2025-05-14 20:24:42,282:INFO:Declaring metric variables
2025-05-14 20:24:42,290:INFO:Importing untrained model
2025-05-14 20:24:42,300:INFO:Ada Boost Classifier Imported successfully
2025-05-14 20:24:42,318:INFO:Starting cross validation
2025-05-14 20:24:42,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:24:42,431:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:24:42,431:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:24:42,433:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:24:42,476:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:24:42,539:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:24:42,548:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:24:42,627:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:24:42,636:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:24:42,958:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:24:42,978:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:24:43,138:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:43,268:INFO:Calculating mean and std
2025-05-14 20:24:43,271:INFO:Creating metrics dataframe
2025-05-14 20:24:43,274:INFO:Uploading results into container
2025-05-14 20:24:43,275:INFO:Uploading model into container now
2025-05-14 20:24:43,276:INFO:_master_model_container: 9
2025-05-14 20:24:43,277:INFO:_display_container: 2
2025-05-14 20:24:43,278:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-14 20:24:43,278:INFO:create_model() successfully completed......................................
2025-05-14 20:24:43,384:INFO:SubProcess create_model() end ==================================
2025-05-14 20:24:43,384:INFO:Creating metrics dataframe
2025-05-14 20:24:43,397:INFO:Initializing Gradient Boosting Classifier
2025-05-14 20:24:43,397:INFO:Total runtime is 0.27503127257029214 minutes
2025-05-14 20:24:43,404:INFO:SubProcess create_model() called ==================================
2025-05-14 20:24:43,404:INFO:Initializing create_model()
2025-05-14 20:24:43,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04CF6ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:43,405:INFO:Checking exceptions
2025-05-14 20:24:43,405:INFO:Importing libraries
2025-05-14 20:24:43,405:INFO:Copying training dataset
2025-05-14 20:24:43,410:INFO:Defining folds
2025-05-14 20:24:43,411:INFO:Declaring metric variables
2025-05-14 20:24:43,420:INFO:Importing untrained model
2025-05-14 20:24:43,430:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 20:24:43,446:INFO:Starting cross validation
2025-05-14 20:24:43,448:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:24:44,380:INFO:Calculating mean and std
2025-05-14 20:24:44,382:INFO:Creating metrics dataframe
2025-05-14 20:24:44,388:INFO:Uploading results into container
2025-05-14 20:24:44,389:INFO:Uploading model into container now
2025-05-14 20:24:44,389:INFO:_master_model_container: 10
2025-05-14 20:24:44,390:INFO:_display_container: 2
2025-05-14 20:24:44,390:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 20:24:44,390:INFO:create_model() successfully completed......................................
2025-05-14 20:24:44,493:INFO:SubProcess create_model() end ==================================
2025-05-14 20:24:44,493:INFO:Creating metrics dataframe
2025-05-14 20:24:44,505:INFO:Initializing Linear Discriminant Analysis
2025-05-14 20:24:44,505:INFO:Total runtime is 0.29349772135416663 minutes
2025-05-14 20:24:44,512:INFO:SubProcess create_model() called ==================================
2025-05-14 20:24:44,512:INFO:Initializing create_model()
2025-05-14 20:24:44,513:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04CF6ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:44,513:INFO:Checking exceptions
2025-05-14 20:24:44,513:INFO:Importing libraries
2025-05-14 20:24:44,513:INFO:Copying training dataset
2025-05-14 20:24:44,519:INFO:Defining folds
2025-05-14 20:24:44,519:INFO:Declaring metric variables
2025-05-14 20:24:44,525:INFO:Importing untrained model
2025-05-14 20:24:44,531:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 20:24:44,542:INFO:Starting cross validation
2025-05-14 20:24:44,544:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:24:44,715:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:44,887:INFO:Calculating mean and std
2025-05-14 20:24:44,889:INFO:Creating metrics dataframe
2025-05-14 20:24:44,891:INFO:Uploading results into container
2025-05-14 20:24:44,892:INFO:Uploading model into container now
2025-05-14 20:24:44,893:INFO:_master_model_container: 11
2025-05-14 20:24:44,894:INFO:_display_container: 2
2025-05-14 20:24:44,894:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 20:24:44,894:INFO:create_model() successfully completed......................................
2025-05-14 20:24:45,045:INFO:SubProcess create_model() end ==================================
2025-05-14 20:24:45,045:INFO:Creating metrics dataframe
2025-05-14 20:24:45,058:INFO:Initializing Extra Trees Classifier
2025-05-14 20:24:45,058:INFO:Total runtime is 0.3027213891347249 minutes
2025-05-14 20:24:45,064:INFO:SubProcess create_model() called ==================================
2025-05-14 20:24:45,065:INFO:Initializing create_model()
2025-05-14 20:24:45,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04CF6ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:45,066:INFO:Checking exceptions
2025-05-14 20:24:45,066:INFO:Importing libraries
2025-05-14 20:24:45,066:INFO:Copying training dataset
2025-05-14 20:24:45,073:INFO:Defining folds
2025-05-14 20:24:45,074:INFO:Declaring metric variables
2025-05-14 20:24:45,079:INFO:Importing untrained model
2025-05-14 20:24:45,084:INFO:Extra Trees Classifier Imported successfully
2025-05-14 20:24:45,096:INFO:Starting cross validation
2025-05-14 20:24:45,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:24:45,952:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:46,258:INFO:Calculating mean and std
2025-05-14 20:24:46,258:INFO:Creating metrics dataframe
2025-05-14 20:24:46,261:INFO:Uploading results into container
2025-05-14 20:24:46,262:INFO:Uploading model into container now
2025-05-14 20:24:46,262:INFO:_master_model_container: 12
2025-05-14 20:24:46,264:INFO:_display_container: 2
2025-05-14 20:24:46,265:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-14 20:24:46,266:INFO:create_model() successfully completed......................................
2025-05-14 20:24:46,369:INFO:SubProcess create_model() end ==================================
2025-05-14 20:24:46,369:INFO:Creating metrics dataframe
2025-05-14 20:24:46,385:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 20:24:46,386:INFO:Total runtime is 0.32483096520106 minutes
2025-05-14 20:24:46,392:INFO:SubProcess create_model() called ==================================
2025-05-14 20:24:46,392:INFO:Initializing create_model()
2025-05-14 20:24:46,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04CF6ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:46,392:INFO:Checking exceptions
2025-05-14 20:24:46,392:INFO:Importing libraries
2025-05-14 20:24:46,392:INFO:Copying training dataset
2025-05-14 20:24:46,399:INFO:Defining folds
2025-05-14 20:24:46,399:INFO:Declaring metric variables
2025-05-14 20:24:46,405:INFO:Importing untrained model
2025-05-14 20:24:46,412:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 20:24:46,424:INFO:Starting cross validation
2025-05-14 20:24:46,426:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:24:47,015:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:47,423:INFO:Calculating mean and std
2025-05-14 20:24:47,428:INFO:Creating metrics dataframe
2025-05-14 20:24:47,434:INFO:Uploading results into container
2025-05-14 20:24:47,438:INFO:Uploading model into container now
2025-05-14 20:24:47,438:INFO:_master_model_container: 13
2025-05-14 20:24:47,438:INFO:_display_container: 2
2025-05-14 20:24:47,440:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 20:24:47,440:INFO:create_model() successfully completed......................................
2025-05-14 20:24:47,561:INFO:SubProcess create_model() end ==================================
2025-05-14 20:24:47,562:INFO:Creating metrics dataframe
2025-05-14 20:24:47,577:INFO:Initializing Dummy Classifier
2025-05-14 20:24:47,578:INFO:Total runtime is 0.34471157789230344 minutes
2025-05-14 20:24:47,584:INFO:SubProcess create_model() called ==================================
2025-05-14 20:24:47,585:INFO:Initializing create_model()
2025-05-14 20:24:47,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04CF6ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:47,585:INFO:Checking exceptions
2025-05-14 20:24:47,586:INFO:Importing libraries
2025-05-14 20:24:47,586:INFO:Copying training dataset
2025-05-14 20:24:47,595:INFO:Defining folds
2025-05-14 20:24:47,595:INFO:Declaring metric variables
2025-05-14 20:24:47,602:INFO:Importing untrained model
2025-05-14 20:24:47,614:INFO:Dummy Classifier Imported successfully
2025-05-14 20:24:47,626:INFO:Starting cross validation
2025-05-14 20:24:47,628:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:24:47,827:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:47,835:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:47,835:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:47,841:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:47,885:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:47,907:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:47,916:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:47,923:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:47,967:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:47,971:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:47,983:INFO:Calculating mean and std
2025-05-14 20:24:47,986:INFO:Creating metrics dataframe
2025-05-14 20:24:47,989:INFO:Uploading results into container
2025-05-14 20:24:47,991:INFO:Uploading model into container now
2025-05-14 20:24:47,992:INFO:_master_model_container: 14
2025-05-14 20:24:47,992:INFO:_display_container: 2
2025-05-14 20:24:47,992:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-14 20:24:47,992:INFO:create_model() successfully completed......................................
2025-05-14 20:24:48,095:INFO:SubProcess create_model() end ==================================
2025-05-14 20:24:48,095:INFO:Creating metrics dataframe
2025-05-14 20:24:48,121:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-14 20:24:48,142:INFO:Initializing create_model()
2025-05-14 20:24:48,142:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:48,142:INFO:Checking exceptions
2025-05-14 20:24:48,147:INFO:Importing libraries
2025-05-14 20:24:48,147:INFO:Copying training dataset
2025-05-14 20:24:48,156:INFO:Defining folds
2025-05-14 20:24:48,156:INFO:Declaring metric variables
2025-05-14 20:24:48,157:INFO:Importing untrained model
2025-05-14 20:24:48,157:INFO:Declaring custom model
2025-05-14 20:24:48,158:INFO:Ridge Classifier Imported successfully
2025-05-14 20:24:48,160:INFO:Cross validation set to False
2025-05-14 20:24:48,160:INFO:Fitting Model
2025-05-14 20:24:48,310:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-14 20:24:48,310:INFO:create_model() successfully completed......................................
2025-05-14 20:24:48,460:INFO:_master_model_container: 14
2025-05-14 20:24:48,460:INFO:_display_container: 2
2025-05-14 20:24:48,461:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-14 20:24:48,461:INFO:compare_models() successfully completed......................................
2025-05-14 20:24:48,485:INFO:Initializing create_model()
2025-05-14 20:24:48,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:24:48,486:INFO:Checking exceptions
2025-05-14 20:24:48,513:INFO:Importing libraries
2025-05-14 20:24:48,513:INFO:Copying training dataset
2025-05-14 20:24:48,521:INFO:Defining folds
2025-05-14 20:24:48,521:INFO:Declaring metric variables
2025-05-14 20:24:48,526:INFO:Importing untrained model
2025-05-14 20:24:48,532:INFO:Random Forest Classifier Imported successfully
2025-05-14 20:24:48,544:INFO:Starting cross validation
2025-05-14 20:24:48,548:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:24:49,169:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:24:49,701:INFO:Calculating mean and std
2025-05-14 20:24:49,702:INFO:Creating metrics dataframe
2025-05-14 20:24:49,712:INFO:Finalizing model
2025-05-14 20:24:49,982:INFO:Uploading results into container
2025-05-14 20:24:49,983:INFO:Uploading model into container now
2025-05-14 20:24:49,996:INFO:_master_model_container: 15
2025-05-14 20:24:49,996:INFO:_display_container: 3
2025-05-14 20:24:49,997:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-14 20:24:49,997:INFO:create_model() successfully completed......................................
2025-05-14 20:24:50,092:INFO:Initializing tune_model()
2025-05-14 20:24:50,092:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 20:24:50,092:INFO:Checking exceptions
2025-05-14 20:24:50,122:INFO:Copying training dataset
2025-05-14 20:24:50,154:INFO:Checking base model
2025-05-14 20:24:50,155:INFO:Base model : Random Forest Classifier
2025-05-14 20:24:50,166:INFO:Declaring metric variables
2025-05-14 20:24:50,175:INFO:Defining Hyperparameters
2025-05-14 20:24:50,277:INFO:Tuning with n_jobs=-1
2025-05-14 20:24:50,277:INFO:Initializing RandomizedSearchCV
2025-05-14 20:25:02,471:INFO:best_params: {'actual_estimator__n_estimators': 70, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': False}
2025-05-14 20:25:02,472:INFO:Hyperparameter search completed
2025-05-14 20:25:02,474:INFO:SubProcess create_model() called ==================================
2025-05-14 20:25:02,475:INFO:Initializing create_model()
2025-05-14 20:25:02,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04CBE990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 70, 'min_samples_split': 9, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 'sqrt', 'max_depth': 3, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': False})
2025-05-14 20:25:02,475:INFO:Checking exceptions
2025-05-14 20:25:02,475:INFO:Importing libraries
2025-05-14 20:25:02,476:INFO:Copying training dataset
2025-05-14 20:25:02,483:INFO:Defining folds
2025-05-14 20:25:02,484:INFO:Declaring metric variables
2025-05-14 20:25:02,489:INFO:Importing untrained model
2025-05-14 20:25:02,489:INFO:Declaring custom model
2025-05-14 20:25:02,496:INFO:Random Forest Classifier Imported successfully
2025-05-14 20:25:02,508:INFO:Starting cross validation
2025-05-14 20:25:02,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:25:02,985:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:25:02,988:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:25:03,000:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:25:03,024:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:25:03,039:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:25:03,041:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:25:03,050:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:25:03,118:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:25:03,454:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:25:03,487:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:25:03,511:INFO:Calculating mean and std
2025-05-14 20:25:03,516:INFO:Creating metrics dataframe
2025-05-14 20:25:03,527:INFO:Finalizing model
2025-05-14 20:25:03,747:INFO:Uploading results into container
2025-05-14 20:25:03,748:INFO:Uploading model into container now
2025-05-14 20:25:03,749:INFO:_master_model_container: 16
2025-05-14 20:25:03,749:INFO:_display_container: 4
2025-05-14 20:25:03,750:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-14 20:25:03,750:INFO:create_model() successfully completed......................................
2025-05-14 20:25:03,842:INFO:SubProcess create_model() end ==================================
2025-05-14 20:25:03,842:INFO:choose_better activated
2025-05-14 20:25:03,848:INFO:SubProcess create_model() called ==================================
2025-05-14 20:25:03,849:INFO:Initializing create_model()
2025-05-14 20:25:03,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:25:03,850:INFO:Checking exceptions
2025-05-14 20:25:03,853:INFO:Importing libraries
2025-05-14 20:25:03,853:INFO:Copying training dataset
2025-05-14 20:25:03,859:INFO:Defining folds
2025-05-14 20:25:03,859:INFO:Declaring metric variables
2025-05-14 20:25:03,859:INFO:Importing untrained model
2025-05-14 20:25:03,859:INFO:Declaring custom model
2025-05-14 20:25:03,860:INFO:Random Forest Classifier Imported successfully
2025-05-14 20:25:03,860:INFO:Starting cross validation
2025-05-14 20:25:03,862:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:25:04,906:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:25:05,474:INFO:Calculating mean and std
2025-05-14 20:25:05,474:INFO:Creating metrics dataframe
2025-05-14 20:25:05,478:INFO:Finalizing model
2025-05-14 20:25:05,698:INFO:Uploading results into container
2025-05-14 20:25:05,699:INFO:Uploading model into container now
2025-05-14 20:25:05,700:INFO:_master_model_container: 17
2025-05-14 20:25:05,700:INFO:_display_container: 5
2025-05-14 20:25:05,700:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-14 20:25:05,700:INFO:create_model() successfully completed......................................
2025-05-14 20:25:05,786:INFO:SubProcess create_model() end ==================================
2025-05-14 20:25:05,787:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.6952
2025-05-14 20:25:05,788:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.7381
2025-05-14 20:25:05,789:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2025-05-14 20:25:05,789:INFO:choose_better completed
2025-05-14 20:25:05,801:INFO:_master_model_container: 17
2025-05-14 20:25:05,802:INFO:_display_container: 4
2025-05-14 20:25:05,803:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-14 20:25:05,803:INFO:tune_model() successfully completed......................................
2025-05-14 20:25:05,908:INFO:Initializing plot_model()
2025-05-14 20:25:05,908:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 20:25:05,908:INFO:Checking exceptions
2025-05-14 20:25:05,915:INFO:Preloading libraries
2025-05-14 20:25:05,921:INFO:Copying training dataset
2025-05-14 20:25:05,921:INFO:Plot type: confusion_matrix
2025-05-14 20:25:06,102:INFO:Fitting Model
2025-05-14 20:25:06,102:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-05-14 20:25:06,102:INFO:Scoring test/hold-out set
2025-05-14 20:25:06,261:INFO:Visual Rendered Successfully
2025-05-14 20:25:06,348:INFO:plot_model() successfully completed......................................
2025-05-14 20:25:06,348:INFO:Initializing plot_model()
2025-05-14 20:25:06,348:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 20:25:06,348:INFO:Checking exceptions
2025-05-14 20:25:06,353:INFO:Preloading libraries
2025-05-14 20:25:06,359:INFO:Copying training dataset
2025-05-14 20:25:06,359:INFO:Plot type: feature
2025-05-14 20:25:06,360:WARNING:No coef_ found. Trying feature_importances_
2025-05-14 20:25:06,547:INFO:Visual Rendered Successfully
2025-05-14 20:25:06,627:INFO:plot_model() successfully completed......................................
2025-05-14 20:25:06,642:INFO:Initializing evaluate_model()
2025-05-14 20:25:06,644:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 20:25:06,656:INFO:Initializing plot_model()
2025-05-14 20:25:06,656:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 20:25:06,656:INFO:Checking exceptions
2025-05-14 20:25:06,660:INFO:Preloading libraries
2025-05-14 20:25:06,667:INFO:Copying training dataset
2025-05-14 20:25:06,667:INFO:Plot type: pipeline
2025-05-14 20:25:06,805:INFO:Visual Rendered Successfully
2025-05-14 20:25:06,912:INFO:plot_model() successfully completed......................................
2025-05-14 20:25:07,118:INFO:Initializing predict_model()
2025-05-14 20:25:07,118:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BA04D0CF40>)
2025-05-14 20:25:07,118:INFO:Checking exceptions
2025-05-14 20:25:07,118:INFO:Preloading libraries
2025-05-14 20:25:07,371:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:25:07,546:INFO:Initializing save_model()
2025-05-14 20:25:07,548:INFO:save_model(model=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=70, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), model_name=modelo_churn_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strate...
                 TransformerWrapper(exclude=None, include=['tipo_plan'],
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-14 20:25:07,548:INFO:Adding model into prep_pipe
2025-05-14 20:25:07,588:INFO:modelo_churn_final.pkl saved in current working directory
2025-05-14 20:25:07,600:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tra...
                 RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                                        class_weight={}, criterion='gini',
                                        max_depth=3, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.1,
                                        min_samples_leaf=4, min_samples_split=9,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=70,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False)
2025-05-14 20:25:07,600:INFO:save_model() successfully completed......................................
2025-05-14 20:25:21,168:INFO:Initializing create_model()
2025-05-14 20:25:21,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA607AF250>, estimator=nb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:25:21,168:INFO:Checking exceptions
2025-05-14 20:25:21,184:INFO:Importing libraries
2025-05-14 20:25:21,185:INFO:Copying training dataset
2025-05-14 20:25:21,189:INFO:Defining folds
2025-05-14 20:25:21,189:INFO:Declaring metric variables
2025-05-14 20:25:21,194:INFO:Importing untrained model
2025-05-14 20:25:21,198:INFO:Naive Bayes Imported successfully
2025-05-14 20:25:21,208:INFO:Starting cross validation
2025-05-14 20:25:21,209:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:25:21,399:INFO:Calculating mean and std
2025-05-14 20:25:21,399:INFO:Creating metrics dataframe
2025-05-14 20:25:21,402:INFO:Finalizing model
2025-05-14 20:25:21,429:INFO:Uploading results into container
2025-05-14 20:25:21,430:INFO:Uploading model into container now
2025-05-14 20:25:21,439:INFO:_master_model_container: 18
2025-05-14 20:25:21,439:INFO:_display_container: 6
2025-05-14 20:25:21,439:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 20:25:21,439:INFO:create_model() successfully completed......................................
2025-05-14 20:27:25,377:INFO:PyCaret ClassificationExperiment
2025-05-14 20:27:25,377:INFO:Logging name: clf-default-name
2025-05-14 20:27:25,377:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 20:27:25,377:INFO:version 3.3.2
2025-05-14 20:27:25,377:INFO:Initializing setup()
2025-05-14 20:27:25,377:INFO:self.USI: 78b9
2025-05-14 20:27:25,378:INFO:self._variable_keys: {'_ml_usecase', 'gpu_param', 'fold_groups_param', 'html_param', '_available_plots', 'fold_shuffle_param', 'fix_imbalance', 'idx', 'y_test', 'X_train', 'pipeline', 'fold_generator', 'data', 'exp_id', 'memory', 'logging_param', 'X', 'y_train', 'is_multiclass', 'seed', 'n_jobs_param', 'X_test', 'y', 'USI', 'target_param', 'log_plots_param', 'gpu_n_jobs_param', 'exp_name_log'}
2025-05-14 20:27:25,378:INFO:Checking environment
2025-05-14 20:27:25,378:INFO:python_version: 3.11.8
2025-05-14 20:27:25,378:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-14 20:27:25,378:INFO:machine: AMD64
2025-05-14 20:27:25,378:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-14 20:27:25,384:INFO:Memory: svmem(total=16907886592, available=3693031424, percent=78.2, used=13214855168, free=3693031424)
2025-05-14 20:27:25,384:INFO:Physical Core: 4
2025-05-14 20:27:25,384:INFO:Logical Core: 8
2025-05-14 20:27:25,384:INFO:Checking libraries
2025-05-14 20:27:25,384:INFO:System:
2025-05-14 20:27:25,385:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-14 20:27:25,385:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-14 20:27:25,385:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-14 20:27:25,385:INFO:PyCaret required dependencies:
2025-05-14 20:27:25,385:INFO:                 pip: 24.0
2025-05-14 20:27:25,385:INFO:          setuptools: 65.5.0
2025-05-14 20:27:25,385:INFO:             pycaret: 3.3.2
2025-05-14 20:27:25,385:INFO:             IPython: 9.2.0
2025-05-14 20:27:25,385:INFO:          ipywidgets: 8.1.7
2025-05-14 20:27:25,385:INFO:                tqdm: 4.67.1
2025-05-14 20:27:25,385:INFO:               numpy: 1.26.4
2025-05-14 20:27:25,385:INFO:              pandas: 2.1.4
2025-05-14 20:27:25,385:INFO:              jinja2: 3.1.6
2025-05-14 20:27:25,385:INFO:               scipy: 1.11.4
2025-05-14 20:27:25,385:INFO:              joblib: 1.3.2
2025-05-14 20:27:25,385:INFO:             sklearn: 1.4.2
2025-05-14 20:27:25,385:INFO:                pyod: 2.0.5
2025-05-14 20:27:25,386:INFO:            imblearn: 0.13.0
2025-05-14 20:27:25,386:INFO:   category_encoders: 2.7.0
2025-05-14 20:27:25,386:INFO:            lightgbm: 4.6.0
2025-05-14 20:27:25,386:INFO:               numba: 0.61.2
2025-05-14 20:27:25,386:INFO:            requests: 2.32.3
2025-05-14 20:27:25,386:INFO:          matplotlib: 3.7.5
2025-05-14 20:27:25,386:INFO:          scikitplot: 0.3.7
2025-05-14 20:27:25,386:INFO:         yellowbrick: 1.5
2025-05-14 20:27:25,386:INFO:              plotly: 5.24.1
2025-05-14 20:27:25,386:INFO:    plotly-resampler: Not installed
2025-05-14 20:27:25,386:INFO:             kaleido: 0.2.1
2025-05-14 20:27:25,386:INFO:           schemdraw: 0.15
2025-05-14 20:27:25,386:INFO:         statsmodels: 0.14.4
2025-05-14 20:27:25,386:INFO:              sktime: 0.26.0
2025-05-14 20:27:25,386:INFO:               tbats: 1.1.3
2025-05-14 20:27:25,386:INFO:            pmdarima: 2.0.4
2025-05-14 20:27:25,386:INFO:              psutil: 7.0.0
2025-05-14 20:27:25,386:INFO:          markupsafe: 3.0.2
2025-05-14 20:27:25,386:INFO:             pickle5: Not installed
2025-05-14 20:27:25,386:INFO:         cloudpickle: 3.1.1
2025-05-14 20:27:25,387:INFO:         deprecation: 2.1.0
2025-05-14 20:27:25,387:INFO:              xxhash: 3.5.0
2025-05-14 20:27:25,387:INFO:           wurlitzer: Not installed
2025-05-14 20:27:25,387:INFO:PyCaret optional dependencies:
2025-05-14 20:27:25,387:INFO:                shap: Not installed
2025-05-14 20:27:25,387:INFO:           interpret: Not installed
2025-05-14 20:27:25,387:INFO:                umap: Not installed
2025-05-14 20:27:25,387:INFO:     ydata_profiling: Not installed
2025-05-14 20:27:25,387:INFO:  explainerdashboard: Not installed
2025-05-14 20:27:25,387:INFO:             autoviz: Not installed
2025-05-14 20:27:25,387:INFO:           fairlearn: Not installed
2025-05-14 20:27:25,387:INFO:          deepchecks: Not installed
2025-05-14 20:27:25,387:INFO:             xgboost: Not installed
2025-05-14 20:27:25,387:INFO:            catboost: Not installed
2025-05-14 20:27:25,387:INFO:              kmodes: Not installed
2025-05-14 20:27:25,387:INFO:             mlxtend: Not installed
2025-05-14 20:27:25,387:INFO:       statsforecast: Not installed
2025-05-14 20:27:25,387:INFO:        tune_sklearn: Not installed
2025-05-14 20:27:25,387:INFO:                 ray: Not installed
2025-05-14 20:27:25,387:INFO:            hyperopt: Not installed
2025-05-14 20:27:25,388:INFO:              optuna: Not installed
2025-05-14 20:27:25,388:INFO:               skopt: Not installed
2025-05-14 20:27:25,388:INFO:              mlflow: Not installed
2025-05-14 20:27:25,388:INFO:              gradio: Not installed
2025-05-14 20:27:25,388:INFO:             fastapi: Not installed
2025-05-14 20:27:25,388:INFO:             uvicorn: Not installed
2025-05-14 20:27:25,388:INFO:              m2cgen: Not installed
2025-05-14 20:27:25,388:INFO:           evidently: Not installed
2025-05-14 20:27:25,388:INFO:               fugue: Not installed
2025-05-14 20:27:25,388:INFO:           streamlit: Not installed
2025-05-14 20:27:25,388:INFO:             prophet: Not installed
2025-05-14 20:27:25,388:INFO:None
2025-05-14 20:27:25,388:INFO:Set up data.
2025-05-14 20:27:25,399:INFO:Set up folding strategy.
2025-05-14 20:27:25,400:INFO:Set up train/test split.
2025-05-14 20:27:25,405:INFO:Set up index.
2025-05-14 20:27:25,406:INFO:Assigning column types.
2025-05-14 20:27:25,410:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 20:27:25,458:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 20:27:25,459:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 20:27:25,482:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:25,482:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:25,518:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 20:27:25,518:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 20:27:25,539:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:25,539:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:25,539:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 20:27:25,572:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 20:27:25,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:25,594:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:25,629:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 20:27:25,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:25,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:25,650:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 20:27:25,706:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:25,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:25,762:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:25,762:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:25,764:INFO:Preparing preprocessing pipeline...
2025-05-14 20:27:25,765:INFO:Set up simple imputation.
2025-05-14 20:27:25,766:INFO:Set up encoding of categorical features.
2025-05-14 20:27:25,766:INFO:Set up feature normalization.
2025-05-14 20:27:25,804:INFO:Finished creating preprocessing pipeline.
2025-05-14 20:27:25,808:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strate...
                 TransformerWrapper(exclude=None, include=['tipo_plan'],
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-14 20:27:25,808:INFO:Creating final display dataframe.
2025-05-14 20:27:25,916:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             churn
2                   Target type            Binary
3           Original data shape          (300, 7)
4        Transformed data shape          (300, 9)
5   Transformed train set shape          (210, 9)
6    Transformed test set shape           (90, 9)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              78b9
2025-05-14 20:27:25,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:25,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:26,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:26,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:27:26,036:INFO:setup() successfully completed in 0.66s...............
2025-05-14 20:27:26,048:INFO:Initializing compare_models()
2025-05-14 20:27:26,048:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 20:27:26,048:INFO:Checking exceptions
2025-05-14 20:27:26,052:INFO:Preparing display monitor
2025-05-14 20:27:26,072:INFO:Initializing Logistic Regression
2025-05-14 20:27:26,072:INFO:Total runtime is 0.0 minutes
2025-05-14 20:27:26,076:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:26,077:INFO:Initializing create_model()
2025-05-14 20:27:26,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A246ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:26,077:INFO:Checking exceptions
2025-05-14 20:27:26,077:INFO:Importing libraries
2025-05-14 20:27:26,077:INFO:Copying training dataset
2025-05-14 20:27:26,080:INFO:Defining folds
2025-05-14 20:27:26,080:INFO:Declaring metric variables
2025-05-14 20:27:26,082:INFO:Importing untrained model
2025-05-14 20:27:26,086:INFO:Logistic Regression Imported successfully
2025-05-14 20:27:26,092:INFO:Starting cross validation
2025-05-14 20:27:26,094:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:26,203:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:26,271:INFO:Calculating mean and std
2025-05-14 20:27:26,271:INFO:Creating metrics dataframe
2025-05-14 20:27:26,272:INFO:Uploading results into container
2025-05-14 20:27:26,273:INFO:Uploading model into container now
2025-05-14 20:27:26,273:INFO:_master_model_container: 1
2025-05-14 20:27:26,273:INFO:_display_container: 2
2025-05-14 20:27:26,273:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 20:27:26,273:INFO:create_model() successfully completed......................................
2025-05-14 20:27:26,345:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:26,345:INFO:Creating metrics dataframe
2025-05-14 20:27:26,353:INFO:Initializing K Neighbors Classifier
2025-05-14 20:27:26,353:INFO:Total runtime is 0.004675157864888509 minutes
2025-05-14 20:27:26,357:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:26,358:INFO:Initializing create_model()
2025-05-14 20:27:26,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A246ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:26,358:INFO:Checking exceptions
2025-05-14 20:27:26,358:INFO:Importing libraries
2025-05-14 20:27:26,358:INFO:Copying training dataset
2025-05-14 20:27:26,361:INFO:Defining folds
2025-05-14 20:27:26,361:INFO:Declaring metric variables
2025-05-14 20:27:26,364:INFO:Importing untrained model
2025-05-14 20:27:26,367:INFO:K Neighbors Classifier Imported successfully
2025-05-14 20:27:26,371:INFO:Starting cross validation
2025-05-14 20:27:26,372:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:26,597:INFO:Calculating mean and std
2025-05-14 20:27:26,597:INFO:Creating metrics dataframe
2025-05-14 20:27:26,598:INFO:Uploading results into container
2025-05-14 20:27:26,598:INFO:Uploading model into container now
2025-05-14 20:27:26,598:INFO:_master_model_container: 2
2025-05-14 20:27:26,599:INFO:_display_container: 2
2025-05-14 20:27:26,599:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 20:27:26,599:INFO:create_model() successfully completed......................................
2025-05-14 20:27:26,668:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:26,668:INFO:Creating metrics dataframe
2025-05-14 20:27:26,673:INFO:Initializing Naive Bayes
2025-05-14 20:27:26,673:INFO:Total runtime is 0.010008672873179119 minutes
2025-05-14 20:27:26,677:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:26,677:INFO:Initializing create_model()
2025-05-14 20:27:26,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A246ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:26,677:INFO:Checking exceptions
2025-05-14 20:27:26,677:INFO:Importing libraries
2025-05-14 20:27:26,677:INFO:Copying training dataset
2025-05-14 20:27:26,679:INFO:Defining folds
2025-05-14 20:27:26,680:INFO:Declaring metric variables
2025-05-14 20:27:26,682:INFO:Importing untrained model
2025-05-14 20:27:26,686:INFO:Naive Bayes Imported successfully
2025-05-14 20:27:26,692:INFO:Starting cross validation
2025-05-14 20:27:26,693:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:26,844:INFO:Calculating mean and std
2025-05-14 20:27:26,844:INFO:Creating metrics dataframe
2025-05-14 20:27:26,845:INFO:Uploading results into container
2025-05-14 20:27:26,845:INFO:Uploading model into container now
2025-05-14 20:27:26,845:INFO:_master_model_container: 3
2025-05-14 20:27:26,845:INFO:_display_container: 2
2025-05-14 20:27:26,845:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 20:27:26,845:INFO:create_model() successfully completed......................................
2025-05-14 20:27:26,912:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:26,912:INFO:Creating metrics dataframe
2025-05-14 20:27:26,917:INFO:Initializing Decision Tree Classifier
2025-05-14 20:27:26,917:INFO:Total runtime is 0.014077389240264894 minutes
2025-05-14 20:27:26,919:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:26,920:INFO:Initializing create_model()
2025-05-14 20:27:26,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A246ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:26,920:INFO:Checking exceptions
2025-05-14 20:27:26,920:INFO:Importing libraries
2025-05-14 20:27:26,920:INFO:Copying training dataset
2025-05-14 20:27:26,924:INFO:Defining folds
2025-05-14 20:27:26,924:INFO:Declaring metric variables
2025-05-14 20:27:26,926:INFO:Importing untrained model
2025-05-14 20:27:26,928:INFO:Decision Tree Classifier Imported successfully
2025-05-14 20:27:26,935:INFO:Starting cross validation
2025-05-14 20:27:26,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:27,087:INFO:Calculating mean and std
2025-05-14 20:27:27,088:INFO:Creating metrics dataframe
2025-05-14 20:27:27,089:INFO:Uploading results into container
2025-05-14 20:27:27,089:INFO:Uploading model into container now
2025-05-14 20:27:27,090:INFO:_master_model_container: 4
2025-05-14 20:27:27,090:INFO:_display_container: 2
2025-05-14 20:27:27,090:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-14 20:27:27,090:INFO:create_model() successfully completed......................................
2025-05-14 20:27:27,154:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:27,154:INFO:Creating metrics dataframe
2025-05-14 20:27:27,161:INFO:Initializing SVM - Linear Kernel
2025-05-14 20:27:27,161:INFO:Total runtime is 0.018150305747985842 minutes
2025-05-14 20:27:27,165:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:27,165:INFO:Initializing create_model()
2025-05-14 20:27:27,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A246ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:27,165:INFO:Checking exceptions
2025-05-14 20:27:27,165:INFO:Importing libraries
2025-05-14 20:27:27,165:INFO:Copying training dataset
2025-05-14 20:27:27,168:INFO:Defining folds
2025-05-14 20:27:27,168:INFO:Declaring metric variables
2025-05-14 20:27:27,170:INFO:Importing untrained model
2025-05-14 20:27:27,172:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 20:27:27,178:INFO:Starting cross validation
2025-05-14 20:27:27,180:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:27,343:INFO:Calculating mean and std
2025-05-14 20:27:27,343:INFO:Creating metrics dataframe
2025-05-14 20:27:27,345:INFO:Uploading results into container
2025-05-14 20:27:27,345:INFO:Uploading model into container now
2025-05-14 20:27:27,345:INFO:_master_model_container: 5
2025-05-14 20:27:27,345:INFO:_display_container: 2
2025-05-14 20:27:27,347:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 20:27:27,347:INFO:create_model() successfully completed......................................
2025-05-14 20:27:27,413:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:27,414:INFO:Creating metrics dataframe
2025-05-14 20:27:27,419:INFO:Initializing Ridge Classifier
2025-05-14 20:27:27,419:INFO:Total runtime is 0.022452636559804284 minutes
2025-05-14 20:27:27,422:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:27,422:INFO:Initializing create_model()
2025-05-14 20:27:27,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A246ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:27,422:INFO:Checking exceptions
2025-05-14 20:27:27,422:INFO:Importing libraries
2025-05-14 20:27:27,422:INFO:Copying training dataset
2025-05-14 20:27:27,426:INFO:Defining folds
2025-05-14 20:27:27,426:INFO:Declaring metric variables
2025-05-14 20:27:27,428:INFO:Importing untrained model
2025-05-14 20:27:27,430:INFO:Ridge Classifier Imported successfully
2025-05-14 20:27:27,436:INFO:Starting cross validation
2025-05-14 20:27:27,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:27,526:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:27,530:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:27,539:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:27,592:INFO:Calculating mean and std
2025-05-14 20:27:27,592:INFO:Creating metrics dataframe
2025-05-14 20:27:27,595:INFO:Uploading results into container
2025-05-14 20:27:27,595:INFO:Uploading model into container now
2025-05-14 20:27:27,595:INFO:_master_model_container: 6
2025-05-14 20:27:27,595:INFO:_display_container: 2
2025-05-14 20:27:27,596:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-14 20:27:27,596:INFO:create_model() successfully completed......................................
2025-05-14 20:27:27,661:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:27,661:INFO:Creating metrics dataframe
2025-05-14 20:27:27,668:INFO:Initializing Random Forest Classifier
2025-05-14 20:27:27,668:INFO:Total runtime is 0.026595302422841395 minutes
2025-05-14 20:27:27,671:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:27,674:INFO:Initializing create_model()
2025-05-14 20:27:27,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A246ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:27,674:INFO:Checking exceptions
2025-05-14 20:27:27,674:INFO:Importing libraries
2025-05-14 20:27:27,675:INFO:Copying training dataset
2025-05-14 20:27:27,679:INFO:Defining folds
2025-05-14 20:27:27,679:INFO:Declaring metric variables
2025-05-14 20:27:27,705:INFO:Importing untrained model
2025-05-14 20:27:27,713:INFO:Random Forest Classifier Imported successfully
2025-05-14 20:27:27,720:INFO:Starting cross validation
2025-05-14 20:27:27,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:28,132:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:28,344:INFO:Calculating mean and std
2025-05-14 20:27:28,344:INFO:Creating metrics dataframe
2025-05-14 20:27:28,346:INFO:Uploading results into container
2025-05-14 20:27:28,347:INFO:Uploading model into container now
2025-05-14 20:27:28,348:INFO:_master_model_container: 7
2025-05-14 20:27:28,348:INFO:_display_container: 2
2025-05-14 20:27:28,348:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-14 20:27:28,348:INFO:create_model() successfully completed......................................
2025-05-14 20:27:28,412:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:28,414:INFO:Creating metrics dataframe
2025-05-14 20:27:28,420:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 20:27:28,420:INFO:Total runtime is 0.03912545045216879 minutes
2025-05-14 20:27:28,423:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:28,423:INFO:Initializing create_model()
2025-05-14 20:27:28,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A246ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:28,423:INFO:Checking exceptions
2025-05-14 20:27:28,423:INFO:Importing libraries
2025-05-14 20:27:28,423:INFO:Copying training dataset
2025-05-14 20:27:28,426:INFO:Defining folds
2025-05-14 20:27:28,426:INFO:Declaring metric variables
2025-05-14 20:27:28,428:INFO:Importing untrained model
2025-05-14 20:27:28,433:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 20:27:28,438:INFO:Starting cross validation
2025-05-14 20:27:28,440:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:28,490:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:27:28,493:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:27:28,494:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:27:28,496:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:27:28,497:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:27:28,499:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:27:28,501:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:27:28,514:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:27:28,563:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:27:28,565:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:27:28,592:INFO:Calculating mean and std
2025-05-14 20:27:28,593:INFO:Creating metrics dataframe
2025-05-14 20:27:28,594:INFO:Uploading results into container
2025-05-14 20:27:28,595:INFO:Uploading model into container now
2025-05-14 20:27:28,595:INFO:_master_model_container: 8
2025-05-14 20:27:28,595:INFO:_display_container: 2
2025-05-14 20:27:28,595:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 20:27:28,595:INFO:create_model() successfully completed......................................
2025-05-14 20:27:28,661:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:28,661:INFO:Creating metrics dataframe
2025-05-14 20:27:28,667:INFO:Initializing Ada Boost Classifier
2025-05-14 20:27:28,668:INFO:Total runtime is 0.04326061407725017 minutes
2025-05-14 20:27:28,671:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:28,672:INFO:Initializing create_model()
2025-05-14 20:27:28,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A246ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:28,672:INFO:Checking exceptions
2025-05-14 20:27:28,672:INFO:Importing libraries
2025-05-14 20:27:28,672:INFO:Copying training dataset
2025-05-14 20:27:28,675:INFO:Defining folds
2025-05-14 20:27:28,675:INFO:Declaring metric variables
2025-05-14 20:27:28,677:INFO:Importing untrained model
2025-05-14 20:27:28,680:INFO:Ada Boost Classifier Imported successfully
2025-05-14 20:27:28,685:INFO:Starting cross validation
2025-05-14 20:27:28,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:28,731:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:27:28,734:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:27:28,738:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:27:28,738:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:27:28,742:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:27:28,744:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:27:28,760:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:27:28,766:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:27:28,931:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:28,940:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:27:28,947:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:27:29,033:INFO:Calculating mean and std
2025-05-14 20:27:29,034:INFO:Creating metrics dataframe
2025-05-14 20:27:29,035:INFO:Uploading results into container
2025-05-14 20:27:29,035:INFO:Uploading model into container now
2025-05-14 20:27:29,036:INFO:_master_model_container: 9
2025-05-14 20:27:29,036:INFO:_display_container: 2
2025-05-14 20:27:29,036:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-14 20:27:29,037:INFO:create_model() successfully completed......................................
2025-05-14 20:27:29,105:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:29,105:INFO:Creating metrics dataframe
2025-05-14 20:27:29,112:INFO:Initializing Gradient Boosting Classifier
2025-05-14 20:27:29,112:INFO:Total runtime is 0.05066006978352865 minutes
2025-05-14 20:27:29,115:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:29,115:INFO:Initializing create_model()
2025-05-14 20:27:29,115:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A246ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:29,115:INFO:Checking exceptions
2025-05-14 20:27:29,115:INFO:Importing libraries
2025-05-14 20:27:29,115:INFO:Copying training dataset
2025-05-14 20:27:29,119:INFO:Defining folds
2025-05-14 20:27:29,119:INFO:Declaring metric variables
2025-05-14 20:27:29,122:INFO:Importing untrained model
2025-05-14 20:27:29,125:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 20:27:29,130:INFO:Starting cross validation
2025-05-14 20:27:29,131:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:29,511:INFO:Calculating mean and std
2025-05-14 20:27:29,512:INFO:Creating metrics dataframe
2025-05-14 20:27:29,513:INFO:Uploading results into container
2025-05-14 20:27:29,513:INFO:Uploading model into container now
2025-05-14 20:27:29,513:INFO:_master_model_container: 10
2025-05-14 20:27:29,513:INFO:_display_container: 2
2025-05-14 20:27:29,514:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 20:27:29,514:INFO:create_model() successfully completed......................................
2025-05-14 20:27:29,583:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:29,583:INFO:Creating metrics dataframe
2025-05-14 20:27:29,590:INFO:Initializing Linear Discriminant Analysis
2025-05-14 20:27:29,590:INFO:Total runtime is 0.05863540569941203 minutes
2025-05-14 20:27:29,592:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:29,592:INFO:Initializing create_model()
2025-05-14 20:27:29,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A246ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:29,592:INFO:Checking exceptions
2025-05-14 20:27:29,592:INFO:Importing libraries
2025-05-14 20:27:29,594:INFO:Copying training dataset
2025-05-14 20:27:29,597:INFO:Defining folds
2025-05-14 20:27:29,597:INFO:Declaring metric variables
2025-05-14 20:27:29,599:INFO:Importing untrained model
2025-05-14 20:27:29,601:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 20:27:29,608:INFO:Starting cross validation
2025-05-14 20:27:29,610:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:29,698:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:29,770:INFO:Calculating mean and std
2025-05-14 20:27:29,771:INFO:Creating metrics dataframe
2025-05-14 20:27:29,772:INFO:Uploading results into container
2025-05-14 20:27:29,772:INFO:Uploading model into container now
2025-05-14 20:27:29,772:INFO:_master_model_container: 11
2025-05-14 20:27:29,774:INFO:_display_container: 2
2025-05-14 20:27:29,774:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 20:27:29,774:INFO:create_model() successfully completed......................................
2025-05-14 20:27:29,842:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:29,842:INFO:Creating metrics dataframe
2025-05-14 20:27:29,851:INFO:Initializing Extra Trees Classifier
2025-05-14 20:27:29,851:INFO:Total runtime is 0.06298643747965495 minutes
2025-05-14 20:27:29,855:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:29,855:INFO:Initializing create_model()
2025-05-14 20:27:29,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A246ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:29,855:INFO:Checking exceptions
2025-05-14 20:27:29,855:INFO:Importing libraries
2025-05-14 20:27:29,855:INFO:Copying training dataset
2025-05-14 20:27:29,860:INFO:Defining folds
2025-05-14 20:27:29,860:INFO:Declaring metric variables
2025-05-14 20:27:29,863:INFO:Importing untrained model
2025-05-14 20:27:29,866:INFO:Extra Trees Classifier Imported successfully
2025-05-14 20:27:29,873:INFO:Starting cross validation
2025-05-14 20:27:29,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:30,376:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:30,689:INFO:Calculating mean and std
2025-05-14 20:27:30,690:INFO:Creating metrics dataframe
2025-05-14 20:27:30,692:INFO:Uploading results into container
2025-05-14 20:27:30,693:INFO:Uploading model into container now
2025-05-14 20:27:30,693:INFO:_master_model_container: 12
2025-05-14 20:27:30,694:INFO:_display_container: 2
2025-05-14 20:27:30,695:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-14 20:27:30,695:INFO:create_model() successfully completed......................................
2025-05-14 20:27:30,772:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:30,773:INFO:Creating metrics dataframe
2025-05-14 20:27:30,782:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 20:27:30,783:INFO:Total runtime is 0.0785124937693278 minutes
2025-05-14 20:27:30,787:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:30,788:INFO:Initializing create_model()
2025-05-14 20:27:30,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A246ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:30,788:INFO:Checking exceptions
2025-05-14 20:27:30,788:INFO:Importing libraries
2025-05-14 20:27:30,788:INFO:Copying training dataset
2025-05-14 20:27:30,793:INFO:Defining folds
2025-05-14 20:27:30,793:INFO:Declaring metric variables
2025-05-14 20:27:30,797:INFO:Importing untrained model
2025-05-14 20:27:30,802:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 20:27:30,809:INFO:Starting cross validation
2025-05-14 20:27:30,811:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:31,292:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:31,453:INFO:Calculating mean and std
2025-05-14 20:27:31,455:INFO:Creating metrics dataframe
2025-05-14 20:27:31,459:INFO:Uploading results into container
2025-05-14 20:27:31,460:INFO:Uploading model into container now
2025-05-14 20:27:31,461:INFO:_master_model_container: 13
2025-05-14 20:27:31,461:INFO:_display_container: 2
2025-05-14 20:27:31,462:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 20:27:31,462:INFO:create_model() successfully completed......................................
2025-05-14 20:27:31,559:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:31,560:INFO:Creating metrics dataframe
2025-05-14 20:27:31,571:INFO:Initializing Dummy Classifier
2025-05-14 20:27:31,571:INFO:Total runtime is 0.09165594180425007 minutes
2025-05-14 20:27:31,574:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:31,575:INFO:Initializing create_model()
2025-05-14 20:27:31,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A246ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:31,575:INFO:Checking exceptions
2025-05-14 20:27:31,575:INFO:Importing libraries
2025-05-14 20:27:31,575:INFO:Copying training dataset
2025-05-14 20:27:31,580:INFO:Defining folds
2025-05-14 20:27:31,580:INFO:Declaring metric variables
2025-05-14 20:27:31,585:INFO:Importing untrained model
2025-05-14 20:27:31,591:INFO:Dummy Classifier Imported successfully
2025-05-14 20:27:31,598:INFO:Starting cross validation
2025-05-14 20:27:31,600:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:31,711:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:31,715:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:31,716:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:31,723:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:31,723:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:31,725:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:31,732:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:31,744:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:31,791:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:31,794:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:27:31,801:INFO:Calculating mean and std
2025-05-14 20:27:31,802:INFO:Creating metrics dataframe
2025-05-14 20:27:31,805:INFO:Uploading results into container
2025-05-14 20:27:31,805:INFO:Uploading model into container now
2025-05-14 20:27:31,806:INFO:_master_model_container: 14
2025-05-14 20:27:31,806:INFO:_display_container: 2
2025-05-14 20:27:31,806:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-14 20:27:31,806:INFO:create_model() successfully completed......................................
2025-05-14 20:27:31,882:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:31,882:INFO:Creating metrics dataframe
2025-05-14 20:27:31,896:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-14 20:27:31,904:INFO:Initializing create_model()
2025-05-14 20:27:31,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:31,905:INFO:Checking exceptions
2025-05-14 20:27:31,907:INFO:Importing libraries
2025-05-14 20:27:31,907:INFO:Copying training dataset
2025-05-14 20:27:31,911:INFO:Defining folds
2025-05-14 20:27:31,911:INFO:Declaring metric variables
2025-05-14 20:27:31,911:INFO:Importing untrained model
2025-05-14 20:27:31,911:INFO:Declaring custom model
2025-05-14 20:27:31,911:INFO:Ridge Classifier Imported successfully
2025-05-14 20:27:31,912:INFO:Cross validation set to False
2025-05-14 20:27:31,912:INFO:Fitting Model
2025-05-14 20:27:31,941:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-14 20:27:31,941:INFO:create_model() successfully completed......................................
2025-05-14 20:27:32,037:INFO:_master_model_container: 14
2025-05-14 20:27:32,037:INFO:_display_container: 2
2025-05-14 20:27:32,038:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-14 20:27:32,038:INFO:compare_models() successfully completed......................................
2025-05-14 20:27:32,070:INFO:Initializing create_model()
2025-05-14 20:27:32,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=nb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:32,071:INFO:Checking exceptions
2025-05-14 20:27:32,092:INFO:Importing libraries
2025-05-14 20:27:32,092:INFO:Copying training dataset
2025-05-14 20:27:32,101:INFO:Defining folds
2025-05-14 20:27:32,101:INFO:Declaring metric variables
2025-05-14 20:27:32,107:INFO:Importing untrained model
2025-05-14 20:27:32,115:INFO:Naive Bayes Imported successfully
2025-05-14 20:27:32,129:INFO:Starting cross validation
2025-05-14 20:27:32,131:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:32,414:INFO:Calculating mean and std
2025-05-14 20:27:32,415:INFO:Creating metrics dataframe
2025-05-14 20:27:32,420:INFO:Finalizing model
2025-05-14 20:27:32,463:INFO:Uploading results into container
2025-05-14 20:27:32,464:INFO:Uploading model into container now
2025-05-14 20:27:32,477:INFO:_master_model_container: 15
2025-05-14 20:27:32,477:INFO:_display_container: 3
2025-05-14 20:27:32,478:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 20:27:32,478:INFO:create_model() successfully completed......................................
2025-05-14 20:27:32,578:INFO:Initializing tune_model()
2025-05-14 20:27:32,578:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 20:27:32,579:INFO:Checking exceptions
2025-05-14 20:27:32,599:INFO:Copying training dataset
2025-05-14 20:27:32,604:INFO:Checking base model
2025-05-14 20:27:32,604:INFO:Base model : Naive Bayes
2025-05-14 20:27:32,609:INFO:Declaring metric variables
2025-05-14 20:27:32,614:INFO:Defining Hyperparameters
2025-05-14 20:27:32,702:INFO:Tuning with n_jobs=-1
2025-05-14 20:27:32,702:INFO:Initializing RandomizedSearchCV
2025-05-14 20:27:34,700:INFO:best_params: {'actual_estimator__var_smoothing': 2e-09}
2025-05-14 20:27:34,704:INFO:Hyperparameter search completed
2025-05-14 20:27:34,705:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:34,706:INFO:Initializing create_model()
2025-05-14 20:27:34,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA04B22150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 2e-09})
2025-05-14 20:27:34,706:INFO:Checking exceptions
2025-05-14 20:27:34,707:INFO:Importing libraries
2025-05-14 20:27:34,707:INFO:Copying training dataset
2025-05-14 20:27:34,715:INFO:Defining folds
2025-05-14 20:27:34,716:INFO:Declaring metric variables
2025-05-14 20:27:34,725:INFO:Importing untrained model
2025-05-14 20:27:34,725:INFO:Declaring custom model
2025-05-14 20:27:34,734:INFO:Naive Bayes Imported successfully
2025-05-14 20:27:34,750:INFO:Starting cross validation
2025-05-14 20:27:34,753:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:35,079:INFO:Calculating mean and std
2025-05-14 20:27:35,081:INFO:Creating metrics dataframe
2025-05-14 20:27:35,089:INFO:Finalizing model
2025-05-14 20:27:35,138:INFO:Uploading results into container
2025-05-14 20:27:35,139:INFO:Uploading model into container now
2025-05-14 20:27:35,140:INFO:_master_model_container: 16
2025-05-14 20:27:35,140:INFO:_display_container: 4
2025-05-14 20:27:35,140:INFO:GaussianNB(priors=None, var_smoothing=2e-09)
2025-05-14 20:27:35,140:INFO:create_model() successfully completed......................................
2025-05-14 20:27:35,227:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:35,227:INFO:choose_better activated
2025-05-14 20:27:35,230:INFO:SubProcess create_model() called ==================================
2025-05-14 20:27:35,230:INFO:Initializing create_model()
2025-05-14 20:27:35,231:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:27:35,231:INFO:Checking exceptions
2025-05-14 20:27:35,234:INFO:Importing libraries
2025-05-14 20:27:35,234:INFO:Copying training dataset
2025-05-14 20:27:35,238:INFO:Defining folds
2025-05-14 20:27:35,238:INFO:Declaring metric variables
2025-05-14 20:27:35,238:INFO:Importing untrained model
2025-05-14 20:27:35,238:INFO:Declaring custom model
2025-05-14 20:27:35,238:INFO:Naive Bayes Imported successfully
2025-05-14 20:27:35,238:INFO:Starting cross validation
2025-05-14 20:27:35,239:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:27:35,506:INFO:Calculating mean and std
2025-05-14 20:27:35,507:INFO:Creating metrics dataframe
2025-05-14 20:27:35,508:INFO:Finalizing model
2025-05-14 20:27:35,541:INFO:Uploading results into container
2025-05-14 20:27:35,542:INFO:Uploading model into container now
2025-05-14 20:27:35,542:INFO:_master_model_container: 17
2025-05-14 20:27:35,542:INFO:_display_container: 5
2025-05-14 20:27:35,542:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 20:27:35,542:INFO:create_model() successfully completed......................................
2025-05-14 20:27:35,621:INFO:SubProcess create_model() end ==================================
2025-05-14 20:27:35,621:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.35
2025-05-14 20:27:35,622:INFO:GaussianNB(priors=None, var_smoothing=2e-09) result for Recall is 0.35
2025-05-14 20:27:35,622:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2025-05-14 20:27:35,622:INFO:choose_better completed
2025-05-14 20:27:35,622:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-14 20:27:35,634:INFO:_master_model_container: 17
2025-05-14 20:27:35,634:INFO:_display_container: 4
2025-05-14 20:27:35,634:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 20:27:35,634:INFO:tune_model() successfully completed......................................
2025-05-14 20:27:35,728:INFO:Initializing plot_model()
2025-05-14 20:27:35,728:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 20:27:35,728:INFO:Checking exceptions
2025-05-14 20:27:35,733:INFO:Preloading libraries
2025-05-14 20:27:35,734:INFO:Copying training dataset
2025-05-14 20:27:35,734:INFO:Plot type: confusion_matrix
2025-05-14 20:27:35,889:INFO:Fitting Model
2025-05-14 20:27:35,889:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-05-14 20:27:35,889:INFO:Scoring test/hold-out set
2025-05-14 20:27:35,990:INFO:Visual Rendered Successfully
2025-05-14 20:27:36,069:INFO:plot_model() successfully completed......................................
2025-05-14 20:27:36,069:INFO:Initializing plot_model()
2025-05-14 20:27:36,069:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0A212E90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 20:27:36,069:INFO:Checking exceptions
2025-05-14 20:28:49,107:INFO:PyCaret ClassificationExperiment
2025-05-14 20:28:49,107:INFO:Logging name: clf-default-name
2025-05-14 20:28:49,108:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 20:28:49,108:INFO:version 3.3.2
2025-05-14 20:28:49,108:INFO:Initializing setup()
2025-05-14 20:28:49,108:INFO:self.USI: 440a
2025-05-14 20:28:49,108:INFO:self._variable_keys: {'_ml_usecase', 'gpu_param', 'fold_groups_param', 'html_param', '_available_plots', 'fold_shuffle_param', 'fix_imbalance', 'idx', 'y_test', 'X_train', 'pipeline', 'fold_generator', 'data', 'exp_id', 'memory', 'logging_param', 'X', 'y_train', 'is_multiclass', 'seed', 'n_jobs_param', 'X_test', 'y', 'USI', 'target_param', 'log_plots_param', 'gpu_n_jobs_param', 'exp_name_log'}
2025-05-14 20:28:49,108:INFO:Checking environment
2025-05-14 20:28:49,108:INFO:python_version: 3.11.8
2025-05-14 20:28:49,108:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-14 20:28:49,108:INFO:machine: AMD64
2025-05-14 20:28:49,108:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-14 20:28:49,112:INFO:Memory: svmem(total=16907886592, available=4032368640, percent=76.2, used=12875517952, free=4032368640)
2025-05-14 20:28:49,112:INFO:Physical Core: 4
2025-05-14 20:28:49,112:INFO:Logical Core: 8
2025-05-14 20:28:49,112:INFO:Checking libraries
2025-05-14 20:28:49,112:INFO:System:
2025-05-14 20:28:49,112:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-14 20:28:49,112:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-14 20:28:49,112:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-14 20:28:49,112:INFO:PyCaret required dependencies:
2025-05-14 20:28:49,112:INFO:                 pip: 24.0
2025-05-14 20:28:49,112:INFO:          setuptools: 65.5.0
2025-05-14 20:28:49,112:INFO:             pycaret: 3.3.2
2025-05-14 20:28:49,112:INFO:             IPython: 9.2.0
2025-05-14 20:28:49,112:INFO:          ipywidgets: 8.1.7
2025-05-14 20:28:49,114:INFO:                tqdm: 4.67.1
2025-05-14 20:28:49,114:INFO:               numpy: 1.26.4
2025-05-14 20:28:49,114:INFO:              pandas: 2.1.4
2025-05-14 20:28:49,114:INFO:              jinja2: 3.1.6
2025-05-14 20:28:49,114:INFO:               scipy: 1.11.4
2025-05-14 20:28:49,114:INFO:              joblib: 1.3.2
2025-05-14 20:28:49,114:INFO:             sklearn: 1.4.2
2025-05-14 20:28:49,114:INFO:                pyod: 2.0.5
2025-05-14 20:28:49,114:INFO:            imblearn: 0.13.0
2025-05-14 20:28:49,114:INFO:   category_encoders: 2.7.0
2025-05-14 20:28:49,114:INFO:            lightgbm: 4.6.0
2025-05-14 20:28:49,114:INFO:               numba: 0.61.2
2025-05-14 20:28:49,114:INFO:            requests: 2.32.3
2025-05-14 20:28:49,114:INFO:          matplotlib: 3.7.5
2025-05-14 20:28:49,114:INFO:          scikitplot: 0.3.7
2025-05-14 20:28:49,114:INFO:         yellowbrick: 1.5
2025-05-14 20:28:49,114:INFO:              plotly: 5.24.1
2025-05-14 20:28:49,114:INFO:    plotly-resampler: Not installed
2025-05-14 20:28:49,114:INFO:             kaleido: 0.2.1
2025-05-14 20:28:49,114:INFO:           schemdraw: 0.15
2025-05-14 20:28:49,114:INFO:         statsmodels: 0.14.4
2025-05-14 20:28:49,114:INFO:              sktime: 0.26.0
2025-05-14 20:28:49,114:INFO:               tbats: 1.1.3
2025-05-14 20:28:49,114:INFO:            pmdarima: 2.0.4
2025-05-14 20:28:49,114:INFO:              psutil: 7.0.0
2025-05-14 20:28:49,114:INFO:          markupsafe: 3.0.2
2025-05-14 20:28:49,114:INFO:             pickle5: Not installed
2025-05-14 20:28:49,114:INFO:         cloudpickle: 3.1.1
2025-05-14 20:28:49,114:INFO:         deprecation: 2.1.0
2025-05-14 20:28:49,114:INFO:              xxhash: 3.5.0
2025-05-14 20:28:49,114:INFO:           wurlitzer: Not installed
2025-05-14 20:28:49,114:INFO:PyCaret optional dependencies:
2025-05-14 20:28:49,114:INFO:                shap: Not installed
2025-05-14 20:28:49,114:INFO:           interpret: Not installed
2025-05-14 20:28:49,114:INFO:                umap: Not installed
2025-05-14 20:28:49,114:INFO:     ydata_profiling: Not installed
2025-05-14 20:28:49,114:INFO:  explainerdashboard: Not installed
2025-05-14 20:28:49,115:INFO:             autoviz: Not installed
2025-05-14 20:28:49,115:INFO:           fairlearn: Not installed
2025-05-14 20:28:49,115:INFO:          deepchecks: Not installed
2025-05-14 20:28:49,115:INFO:             xgboost: Not installed
2025-05-14 20:28:49,115:INFO:            catboost: Not installed
2025-05-14 20:28:49,115:INFO:              kmodes: Not installed
2025-05-14 20:28:49,115:INFO:             mlxtend: Not installed
2025-05-14 20:28:49,115:INFO:       statsforecast: Not installed
2025-05-14 20:28:49,115:INFO:        tune_sklearn: Not installed
2025-05-14 20:28:49,115:INFO:                 ray: Not installed
2025-05-14 20:28:49,115:INFO:            hyperopt: Not installed
2025-05-14 20:28:49,115:INFO:              optuna: Not installed
2025-05-14 20:28:49,115:INFO:               skopt: Not installed
2025-05-14 20:28:49,115:INFO:              mlflow: Not installed
2025-05-14 20:28:49,115:INFO:              gradio: Not installed
2025-05-14 20:28:49,115:INFO:             fastapi: Not installed
2025-05-14 20:28:49,115:INFO:             uvicorn: Not installed
2025-05-14 20:28:49,115:INFO:              m2cgen: Not installed
2025-05-14 20:28:49,115:INFO:           evidently: Not installed
2025-05-14 20:28:49,115:INFO:               fugue: Not installed
2025-05-14 20:28:49,115:INFO:           streamlit: Not installed
2025-05-14 20:28:49,115:INFO:             prophet: Not installed
2025-05-14 20:28:49,115:INFO:None
2025-05-14 20:28:49,115:INFO:Set up data.
2025-05-14 20:28:49,119:INFO:Set up folding strategy.
2025-05-14 20:28:49,119:INFO:Set up train/test split.
2025-05-14 20:28:49,121:INFO:Set up index.
2025-05-14 20:28:49,122:INFO:Assigning column types.
2025-05-14 20:28:49,123:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 20:28:49,158:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 20:28:49,158:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 20:28:49,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 20:28:49,215:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 20:28:49,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,238:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 20:28:49,274:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 20:28:49,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,330:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 20:28:49,353:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,354:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 20:28:49,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,410:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,469:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,469:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,470:INFO:Preparing preprocessing pipeline...
2025-05-14 20:28:49,471:INFO:Set up simple imputation.
2025-05-14 20:28:49,472:INFO:Set up encoding of categorical features.
2025-05-14 20:28:49,472:INFO:Set up feature normalization.
2025-05-14 20:28:49,512:INFO:Finished creating preprocessing pipeline.
2025-05-14 20:28:49,517:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strate...
                 TransformerWrapper(exclude=None, include=['tipo_plan'],
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-14 20:28:49,518:INFO:Creating final display dataframe.
2025-05-14 20:28:49,629:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             churn
2                   Target type            Binary
3           Original data shape          (300, 7)
4        Transformed data shape          (300, 9)
5   Transformed train set shape          (210, 9)
6    Transformed test set shape           (90, 9)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              440a
2025-05-14 20:28:49,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,758:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 20:28:49,759:INFO:setup() successfully completed in 0.65s...............
2025-05-14 20:28:49,772:INFO:Initializing compare_models()
2025-05-14 20:28:49,774:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 20:28:49,774:INFO:Checking exceptions
2025-05-14 20:28:49,778:INFO:Preparing display monitor
2025-05-14 20:28:49,814:INFO:Initializing Logistic Regression
2025-05-14 20:28:49,814:INFO:Total runtime is 0.0 minutes
2025-05-14 20:28:49,823:INFO:SubProcess create_model() called ==================================
2025-05-14 20:28:49,823:INFO:Initializing create_model()
2025-05-14 20:28:49,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A36D410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:49,823:INFO:Checking exceptions
2025-05-14 20:28:49,824:INFO:Importing libraries
2025-05-14 20:28:49,824:INFO:Copying training dataset
2025-05-14 20:28:49,829:INFO:Defining folds
2025-05-14 20:28:49,829:INFO:Declaring metric variables
2025-05-14 20:28:49,845:INFO:Importing untrained model
2025-05-14 20:28:49,860:INFO:Logistic Regression Imported successfully
2025-05-14 20:28:49,871:INFO:Starting cross validation
2025-05-14 20:28:49,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:28:49,987:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:50,055:INFO:Calculating mean and std
2025-05-14 20:28:50,055:INFO:Creating metrics dataframe
2025-05-14 20:28:50,055:INFO:Uploading results into container
2025-05-14 20:28:50,057:INFO:Uploading model into container now
2025-05-14 20:28:50,057:INFO:_master_model_container: 1
2025-05-14 20:28:50,057:INFO:_display_container: 2
2025-05-14 20:28:50,057:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 20:28:50,057:INFO:create_model() successfully completed......................................
2025-05-14 20:28:50,171:INFO:SubProcess create_model() end ==================================
2025-05-14 20:28:50,171:INFO:Creating metrics dataframe
2025-05-14 20:28:50,177:INFO:Initializing K Neighbors Classifier
2025-05-14 20:28:50,177:INFO:Total runtime is 0.00604784886042277 minutes
2025-05-14 20:28:50,181:INFO:SubProcess create_model() called ==================================
2025-05-14 20:28:50,181:INFO:Initializing create_model()
2025-05-14 20:28:50,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A36D410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:50,181:INFO:Checking exceptions
2025-05-14 20:28:50,181:INFO:Importing libraries
2025-05-14 20:28:50,181:INFO:Copying training dataset
2025-05-14 20:28:50,183:INFO:Defining folds
2025-05-14 20:28:50,184:INFO:Declaring metric variables
2025-05-14 20:28:50,186:INFO:Importing untrained model
2025-05-14 20:28:50,190:INFO:K Neighbors Classifier Imported successfully
2025-05-14 20:28:50,197:INFO:Starting cross validation
2025-05-14 20:28:50,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:28:50,455:INFO:Calculating mean and std
2025-05-14 20:28:50,455:INFO:Creating metrics dataframe
2025-05-14 20:28:50,457:INFO:Uploading results into container
2025-05-14 20:28:50,457:INFO:Uploading model into container now
2025-05-14 20:28:50,458:INFO:_master_model_container: 2
2025-05-14 20:28:50,458:INFO:_display_container: 2
2025-05-14 20:28:50,458:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 20:28:50,458:INFO:create_model() successfully completed......................................
2025-05-14 20:28:50,544:INFO:SubProcess create_model() end ==================================
2025-05-14 20:28:50,544:INFO:Creating metrics dataframe
2025-05-14 20:28:50,549:INFO:Initializing Naive Bayes
2025-05-14 20:28:50,549:INFO:Total runtime is 0.012249926726023357 minutes
2025-05-14 20:28:50,552:INFO:SubProcess create_model() called ==================================
2025-05-14 20:28:50,553:INFO:Initializing create_model()
2025-05-14 20:28:50,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A36D410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:50,553:INFO:Checking exceptions
2025-05-14 20:28:50,553:INFO:Importing libraries
2025-05-14 20:28:50,553:INFO:Copying training dataset
2025-05-14 20:28:50,555:INFO:Defining folds
2025-05-14 20:28:50,556:INFO:Declaring metric variables
2025-05-14 20:28:50,558:INFO:Importing untrained model
2025-05-14 20:28:50,561:INFO:Naive Bayes Imported successfully
2025-05-14 20:28:50,566:INFO:Starting cross validation
2025-05-14 20:28:50,568:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:28:50,731:INFO:Calculating mean and std
2025-05-14 20:28:50,731:INFO:Creating metrics dataframe
2025-05-14 20:28:50,732:INFO:Uploading results into container
2025-05-14 20:28:50,732:INFO:Uploading model into container now
2025-05-14 20:28:50,732:INFO:_master_model_container: 3
2025-05-14 20:28:50,732:INFO:_display_container: 2
2025-05-14 20:28:50,734:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 20:28:50,734:INFO:create_model() successfully completed......................................
2025-05-14 20:28:50,827:INFO:SubProcess create_model() end ==================================
2025-05-14 20:28:50,827:INFO:Creating metrics dataframe
2025-05-14 20:28:50,833:INFO:Initializing Decision Tree Classifier
2025-05-14 20:28:50,833:INFO:Total runtime is 0.01697971026102702 minutes
2025-05-14 20:28:50,835:INFO:SubProcess create_model() called ==================================
2025-05-14 20:28:50,835:INFO:Initializing create_model()
2025-05-14 20:28:50,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A36D410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:50,835:INFO:Checking exceptions
2025-05-14 20:28:50,835:INFO:Importing libraries
2025-05-14 20:28:50,835:INFO:Copying training dataset
2025-05-14 20:28:50,840:INFO:Defining folds
2025-05-14 20:28:50,840:INFO:Declaring metric variables
2025-05-14 20:28:50,845:INFO:Importing untrained model
2025-05-14 20:28:50,848:INFO:Decision Tree Classifier Imported successfully
2025-05-14 20:28:50,852:INFO:Starting cross validation
2025-05-14 20:28:50,855:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:28:51,019:INFO:Calculating mean and std
2025-05-14 20:28:51,020:INFO:Creating metrics dataframe
2025-05-14 20:28:51,021:INFO:Uploading results into container
2025-05-14 20:28:51,022:INFO:Uploading model into container now
2025-05-14 20:28:51,022:INFO:_master_model_container: 4
2025-05-14 20:28:51,022:INFO:_display_container: 2
2025-05-14 20:28:51,022:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-14 20:28:51,022:INFO:create_model() successfully completed......................................
2025-05-14 20:28:51,119:INFO:SubProcess create_model() end ==================================
2025-05-14 20:28:51,119:INFO:Creating metrics dataframe
2025-05-14 20:28:51,127:INFO:Initializing SVM - Linear Kernel
2025-05-14 20:28:51,127:INFO:Total runtime is 0.021879510084788008 minutes
2025-05-14 20:28:51,130:INFO:SubProcess create_model() called ==================================
2025-05-14 20:28:51,130:INFO:Initializing create_model()
2025-05-14 20:28:51,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A36D410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:51,130:INFO:Checking exceptions
2025-05-14 20:28:51,131:INFO:Importing libraries
2025-05-14 20:28:51,131:INFO:Copying training dataset
2025-05-14 20:28:51,135:INFO:Defining folds
2025-05-14 20:28:51,135:INFO:Declaring metric variables
2025-05-14 20:28:51,138:INFO:Importing untrained model
2025-05-14 20:28:51,142:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 20:28:51,150:INFO:Starting cross validation
2025-05-14 20:28:51,151:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:28:51,321:INFO:Calculating mean and std
2025-05-14 20:28:51,322:INFO:Creating metrics dataframe
2025-05-14 20:28:51,324:INFO:Uploading results into container
2025-05-14 20:28:51,325:INFO:Uploading model into container now
2025-05-14 20:28:51,325:INFO:_master_model_container: 5
2025-05-14 20:28:51,325:INFO:_display_container: 2
2025-05-14 20:28:51,326:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 20:28:51,326:INFO:create_model() successfully completed......................................
2025-05-14 20:28:51,409:INFO:SubProcess create_model() end ==================================
2025-05-14 20:28:51,409:INFO:Creating metrics dataframe
2025-05-14 20:28:51,415:INFO:Initializing Ridge Classifier
2025-05-14 20:28:51,415:INFO:Total runtime is 0.02668121655782064 minutes
2025-05-14 20:28:51,417:INFO:SubProcess create_model() called ==================================
2025-05-14 20:28:51,418:INFO:Initializing create_model()
2025-05-14 20:28:51,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A36D410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:51,418:INFO:Checking exceptions
2025-05-14 20:28:51,418:INFO:Importing libraries
2025-05-14 20:28:51,418:INFO:Copying training dataset
2025-05-14 20:28:51,421:INFO:Defining folds
2025-05-14 20:28:51,422:INFO:Declaring metric variables
2025-05-14 20:28:51,424:INFO:Importing untrained model
2025-05-14 20:28:51,427:INFO:Ridge Classifier Imported successfully
2025-05-14 20:28:51,434:INFO:Starting cross validation
2025-05-14 20:28:51,435:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:28:51,546:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:51,545:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:51,549:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:51,612:INFO:Calculating mean and std
2025-05-14 20:28:51,612:INFO:Creating metrics dataframe
2025-05-14 20:28:51,614:INFO:Uploading results into container
2025-05-14 20:28:51,615:INFO:Uploading model into container now
2025-05-14 20:28:51,616:INFO:_master_model_container: 6
2025-05-14 20:28:51,616:INFO:_display_container: 2
2025-05-14 20:28:51,617:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-14 20:28:51,617:INFO:create_model() successfully completed......................................
2025-05-14 20:28:51,701:INFO:SubProcess create_model() end ==================================
2025-05-14 20:28:51,701:INFO:Creating metrics dataframe
2025-05-14 20:28:51,709:INFO:Initializing Random Forest Classifier
2025-05-14 20:28:51,709:INFO:Total runtime is 0.031582136948903404 minutes
2025-05-14 20:28:51,712:INFO:SubProcess create_model() called ==================================
2025-05-14 20:28:51,712:INFO:Initializing create_model()
2025-05-14 20:28:51,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A36D410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:51,713:INFO:Checking exceptions
2025-05-14 20:28:51,713:INFO:Importing libraries
2025-05-14 20:28:51,713:INFO:Copying training dataset
2025-05-14 20:28:51,716:INFO:Defining folds
2025-05-14 20:28:51,716:INFO:Declaring metric variables
2025-05-14 20:28:51,718:INFO:Importing untrained model
2025-05-14 20:28:51,721:INFO:Random Forest Classifier Imported successfully
2025-05-14 20:28:51,730:INFO:Starting cross validation
2025-05-14 20:28:51,731:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:28:52,155:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:52,396:INFO:Calculating mean and std
2025-05-14 20:28:52,396:INFO:Creating metrics dataframe
2025-05-14 20:28:52,398:INFO:Uploading results into container
2025-05-14 20:28:52,398:INFO:Uploading model into container now
2025-05-14 20:28:52,399:INFO:_master_model_container: 7
2025-05-14 20:28:52,399:INFO:_display_container: 2
2025-05-14 20:28:52,399:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-14 20:28:52,399:INFO:create_model() successfully completed......................................
2025-05-14 20:28:52,479:INFO:SubProcess create_model() end ==================================
2025-05-14 20:28:52,480:INFO:Creating metrics dataframe
2025-05-14 20:28:52,486:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 20:28:52,486:INFO:Total runtime is 0.04453179836273194 minutes
2025-05-14 20:28:52,490:INFO:SubProcess create_model() called ==================================
2025-05-14 20:28:52,490:INFO:Initializing create_model()
2025-05-14 20:28:52,490:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A36D410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:52,491:INFO:Checking exceptions
2025-05-14 20:28:52,491:INFO:Importing libraries
2025-05-14 20:28:52,491:INFO:Copying training dataset
2025-05-14 20:28:52,493:INFO:Defining folds
2025-05-14 20:28:52,493:INFO:Declaring metric variables
2025-05-14 20:28:52,496:INFO:Importing untrained model
2025-05-14 20:28:52,499:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 20:28:52,506:INFO:Starting cross validation
2025-05-14 20:28:52,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:28:52,561:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:28:52,562:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:28:52,562:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:28:52,562:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:28:52,564:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:28:52,566:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:28:52,567:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:28:52,572:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:28:52,629:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:28:52,631:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 20:28:52,654:INFO:Calculating mean and std
2025-05-14 20:28:52,654:INFO:Creating metrics dataframe
2025-05-14 20:28:52,656:INFO:Uploading results into container
2025-05-14 20:28:52,657:INFO:Uploading model into container now
2025-05-14 20:28:52,657:INFO:_master_model_container: 8
2025-05-14 20:28:52,657:INFO:_display_container: 2
2025-05-14 20:28:52,658:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 20:28:52,658:INFO:create_model() successfully completed......................................
2025-05-14 20:28:52,738:INFO:SubProcess create_model() end ==================================
2025-05-14 20:28:52,738:INFO:Creating metrics dataframe
2025-05-14 20:28:52,747:INFO:Initializing Ada Boost Classifier
2025-05-14 20:28:52,748:INFO:Total runtime is 0.04889654318491618 minutes
2025-05-14 20:28:52,751:INFO:SubProcess create_model() called ==================================
2025-05-14 20:28:52,752:INFO:Initializing create_model()
2025-05-14 20:28:52,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A36D410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:52,752:INFO:Checking exceptions
2025-05-14 20:28:52,752:INFO:Importing libraries
2025-05-14 20:28:52,752:INFO:Copying training dataset
2025-05-14 20:28:52,754:INFO:Defining folds
2025-05-14 20:28:52,754:INFO:Declaring metric variables
2025-05-14 20:28:52,758:INFO:Importing untrained model
2025-05-14 20:28:52,760:INFO:Ada Boost Classifier Imported successfully
2025-05-14 20:28:52,796:INFO:Starting cross validation
2025-05-14 20:28:52,798:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:28:52,857:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:28:52,863:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:28:52,871:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:28:52,877:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:28:52,880:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:28:52,882:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:28:52,885:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:28:52,886:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:28:53,094:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:53,140:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:28:53,147:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 20:28:53,293:INFO:Calculating mean and std
2025-05-14 20:28:53,294:INFO:Creating metrics dataframe
2025-05-14 20:28:53,296:INFO:Uploading results into container
2025-05-14 20:28:53,298:INFO:Uploading model into container now
2025-05-14 20:28:53,298:INFO:_master_model_container: 9
2025-05-14 20:28:53,298:INFO:_display_container: 2
2025-05-14 20:28:53,298:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-14 20:28:53,298:INFO:create_model() successfully completed......................................
2025-05-14 20:28:53,389:INFO:SubProcess create_model() end ==================================
2025-05-14 20:28:53,389:INFO:Creating metrics dataframe
2025-05-14 20:28:53,398:INFO:Initializing Gradient Boosting Classifier
2025-05-14 20:28:53,398:INFO:Total runtime is 0.05974118709564209 minutes
2025-05-14 20:28:53,402:INFO:SubProcess create_model() called ==================================
2025-05-14 20:28:53,402:INFO:Initializing create_model()
2025-05-14 20:28:53,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A36D410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:53,402:INFO:Checking exceptions
2025-05-14 20:28:53,402:INFO:Importing libraries
2025-05-14 20:28:53,402:INFO:Copying training dataset
2025-05-14 20:28:53,406:INFO:Defining folds
2025-05-14 20:28:53,407:INFO:Declaring metric variables
2025-05-14 20:28:53,410:INFO:Importing untrained model
2025-05-14 20:28:53,414:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 20:28:53,424:INFO:Starting cross validation
2025-05-14 20:28:53,426:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:28:54,057:INFO:Calculating mean and std
2025-05-14 20:28:54,058:INFO:Creating metrics dataframe
2025-05-14 20:28:54,061:INFO:Uploading results into container
2025-05-14 20:28:54,061:INFO:Uploading model into container now
2025-05-14 20:28:54,062:INFO:_master_model_container: 10
2025-05-14 20:28:54,062:INFO:_display_container: 2
2025-05-14 20:28:54,062:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 20:28:54,062:INFO:create_model() successfully completed......................................
2025-05-14 20:28:54,161:INFO:SubProcess create_model() end ==================================
2025-05-14 20:28:54,162:INFO:Creating metrics dataframe
2025-05-14 20:28:54,174:INFO:Initializing Linear Discriminant Analysis
2025-05-14 20:28:54,174:INFO:Total runtime is 0.07266746362050375 minutes
2025-05-14 20:28:54,178:INFO:SubProcess create_model() called ==================================
2025-05-14 20:28:54,178:INFO:Initializing create_model()
2025-05-14 20:28:54,179:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A36D410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:54,179:INFO:Checking exceptions
2025-05-14 20:28:54,179:INFO:Importing libraries
2025-05-14 20:28:54,179:INFO:Copying training dataset
2025-05-14 20:28:54,182:INFO:Defining folds
2025-05-14 20:28:54,182:INFO:Declaring metric variables
2025-05-14 20:28:54,186:INFO:Importing untrained model
2025-05-14 20:28:54,192:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 20:28:54,202:INFO:Starting cross validation
2025-05-14 20:28:54,203:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:28:54,352:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:54,443:INFO:Calculating mean and std
2025-05-14 20:28:54,443:INFO:Creating metrics dataframe
2025-05-14 20:28:54,447:INFO:Uploading results into container
2025-05-14 20:28:54,447:INFO:Uploading model into container now
2025-05-14 20:28:54,448:INFO:_master_model_container: 11
2025-05-14 20:28:54,448:INFO:_display_container: 2
2025-05-14 20:28:54,448:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 20:28:54,448:INFO:create_model() successfully completed......................................
2025-05-14 20:28:54,548:INFO:SubProcess create_model() end ==================================
2025-05-14 20:28:54,548:INFO:Creating metrics dataframe
2025-05-14 20:28:54,558:INFO:Initializing Extra Trees Classifier
2025-05-14 20:28:54,559:INFO:Total runtime is 0.07906904617945354 minutes
2025-05-14 20:28:54,563:INFO:SubProcess create_model() called ==================================
2025-05-14 20:28:54,563:INFO:Initializing create_model()
2025-05-14 20:28:54,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A36D410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:54,563:INFO:Checking exceptions
2025-05-14 20:28:54,563:INFO:Importing libraries
2025-05-14 20:28:54,565:INFO:Copying training dataset
2025-05-14 20:28:54,568:INFO:Defining folds
2025-05-14 20:28:54,568:INFO:Declaring metric variables
2025-05-14 20:28:54,572:INFO:Importing untrained model
2025-05-14 20:28:54,577:INFO:Extra Trees Classifier Imported successfully
2025-05-14 20:28:54,587:INFO:Starting cross validation
2025-05-14 20:28:54,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:28:55,416:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:55,995:INFO:Calculating mean and std
2025-05-14 20:28:55,996:INFO:Creating metrics dataframe
2025-05-14 20:28:56,001:INFO:Uploading results into container
2025-05-14 20:28:56,002:INFO:Uploading model into container now
2025-05-14 20:28:56,004:INFO:_master_model_container: 12
2025-05-14 20:28:56,004:INFO:_display_container: 2
2025-05-14 20:28:56,005:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-14 20:28:56,006:INFO:create_model() successfully completed......................................
2025-05-14 20:28:56,132:INFO:SubProcess create_model() end ==================================
2025-05-14 20:28:56,132:INFO:Creating metrics dataframe
2025-05-14 20:28:56,155:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 20:28:56,155:INFO:Total runtime is 0.10567802985509238 minutes
2025-05-14 20:28:56,164:INFO:SubProcess create_model() called ==================================
2025-05-14 20:28:56,165:INFO:Initializing create_model()
2025-05-14 20:28:56,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A36D410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:56,165:INFO:Checking exceptions
2025-05-14 20:28:56,166:INFO:Importing libraries
2025-05-14 20:28:56,166:INFO:Copying training dataset
2025-05-14 20:28:56,177:INFO:Defining folds
2025-05-14 20:28:56,177:INFO:Declaring metric variables
2025-05-14 20:28:56,186:INFO:Importing untrained model
2025-05-14 20:28:56,197:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 20:28:56,214:INFO:Starting cross validation
2025-05-14 20:28:56,218:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:28:57,050:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:57,289:INFO:Calculating mean and std
2025-05-14 20:28:57,291:INFO:Creating metrics dataframe
2025-05-14 20:28:57,295:INFO:Uploading results into container
2025-05-14 20:28:57,297:INFO:Uploading model into container now
2025-05-14 20:28:57,297:INFO:_master_model_container: 13
2025-05-14 20:28:57,298:INFO:_display_container: 2
2025-05-14 20:28:57,298:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 20:28:57,300:INFO:create_model() successfully completed......................................
2025-05-14 20:28:57,491:INFO:SubProcess create_model() end ==================================
2025-05-14 20:28:57,491:INFO:Creating metrics dataframe
2025-05-14 20:28:57,502:INFO:Initializing Dummy Classifier
2025-05-14 20:28:57,502:INFO:Total runtime is 0.12814298868179322 minutes
2025-05-14 20:28:57,507:INFO:SubProcess create_model() called ==================================
2025-05-14 20:28:57,507:INFO:Initializing create_model()
2025-05-14 20:28:57,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A36D410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:57,507:INFO:Checking exceptions
2025-05-14 20:28:57,507:INFO:Importing libraries
2025-05-14 20:28:57,507:INFO:Copying training dataset
2025-05-14 20:28:57,515:INFO:Defining folds
2025-05-14 20:28:57,515:INFO:Declaring metric variables
2025-05-14 20:28:57,520:INFO:Importing untrained model
2025-05-14 20:28:57,526:INFO:Dummy Classifier Imported successfully
2025-05-14 20:28:57,535:INFO:Starting cross validation
2025-05-14 20:28:57,538:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:28:57,663:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:57,665:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:57,671:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:57,671:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:57,671:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:57,675:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:57,694:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:57,708:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:57,778:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:57,781:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 20:28:57,794:INFO:Calculating mean and std
2025-05-14 20:28:57,795:INFO:Creating metrics dataframe
2025-05-14 20:28:57,798:INFO:Uploading results into container
2025-05-14 20:28:57,798:INFO:Uploading model into container now
2025-05-14 20:28:57,799:INFO:_master_model_container: 14
2025-05-14 20:28:57,799:INFO:_display_container: 2
2025-05-14 20:28:57,800:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-05-14 20:28:57,800:INFO:create_model() successfully completed......................................
2025-05-14 20:28:57,917:INFO:SubProcess create_model() end ==================================
2025-05-14 20:28:57,918:INFO:Creating metrics dataframe
2025-05-14 20:28:57,931:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-14 20:28:57,945:INFO:Initializing create_model()
2025-05-14 20:28:57,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:57,945:INFO:Checking exceptions
2025-05-14 20:28:57,947:INFO:Importing libraries
2025-05-14 20:28:57,947:INFO:Copying training dataset
2025-05-14 20:28:57,951:INFO:Defining folds
2025-05-14 20:28:57,952:INFO:Declaring metric variables
2025-05-14 20:28:57,952:INFO:Importing untrained model
2025-05-14 20:28:57,952:INFO:Declaring custom model
2025-05-14 20:28:57,953:INFO:Ridge Classifier Imported successfully
2025-05-14 20:28:57,955:INFO:Cross validation set to False
2025-05-14 20:28:57,955:INFO:Fitting Model
2025-05-14 20:28:57,994:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-14 20:28:57,994:INFO:create_model() successfully completed......................................
2025-05-14 20:28:58,129:INFO:_master_model_container: 14
2025-05-14 20:28:58,129:INFO:_display_container: 2
2025-05-14 20:28:58,130:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-14 20:28:58,130:INFO:compare_models() successfully completed......................................
2025-05-14 20:28:58,149:INFO:Initializing create_model()
2025-05-14 20:28:58,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=nb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:28:58,149:INFO:Checking exceptions
2025-05-14 20:28:58,176:INFO:Importing libraries
2025-05-14 20:28:58,176:INFO:Copying training dataset
2025-05-14 20:28:58,183:INFO:Defining folds
2025-05-14 20:28:58,184:INFO:Declaring metric variables
2025-05-14 20:28:58,192:INFO:Importing untrained model
2025-05-14 20:28:58,199:INFO:Naive Bayes Imported successfully
2025-05-14 20:28:58,209:INFO:Starting cross validation
2025-05-14 20:28:58,211:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:28:58,536:INFO:Calculating mean and std
2025-05-14 20:28:58,537:INFO:Creating metrics dataframe
2025-05-14 20:28:58,544:INFO:Finalizing model
2025-05-14 20:28:58,593:INFO:Uploading results into container
2025-05-14 20:28:58,595:INFO:Uploading model into container now
2025-05-14 20:28:58,609:INFO:_master_model_container: 15
2025-05-14 20:28:58,610:INFO:_display_container: 3
2025-05-14 20:28:58,610:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 20:28:58,610:INFO:create_model() successfully completed......................................
2025-05-14 20:28:58,741:INFO:Initializing tune_model()
2025-05-14 20:28:58,742:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 20:28:58,742:INFO:Checking exceptions
2025-05-14 20:28:58,816:INFO:Copying training dataset
2025-05-14 20:28:58,848:INFO:Checking base model
2025-05-14 20:28:58,848:INFO:Base model : Naive Bayes
2025-05-14 20:28:58,856:INFO:Declaring metric variables
2025-05-14 20:28:58,863:INFO:Defining Hyperparameters
2025-05-14 20:28:59,002:INFO:Tuning with n_jobs=-1
2025-05-14 20:28:59,002:INFO:Initializing RandomizedSearchCV
2025-05-14 20:29:01,588:INFO:best_params: {'actual_estimator__var_smoothing': 2e-09}
2025-05-14 20:29:01,589:INFO:Hyperparameter search completed
2025-05-14 20:29:01,589:INFO:SubProcess create_model() called ==================================
2025-05-14 20:29:01,590:INFO:Initializing create_model()
2025-05-14 20:29:01,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0A426ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 2e-09})
2025-05-14 20:29:01,590:INFO:Checking exceptions
2025-05-14 20:29:01,590:INFO:Importing libraries
2025-05-14 20:29:01,591:INFO:Copying training dataset
2025-05-14 20:29:01,597:INFO:Defining folds
2025-05-14 20:29:01,597:INFO:Declaring metric variables
2025-05-14 20:29:01,601:INFO:Importing untrained model
2025-05-14 20:29:01,601:INFO:Declaring custom model
2025-05-14 20:29:01,606:INFO:Naive Bayes Imported successfully
2025-05-14 20:29:01,616:INFO:Starting cross validation
2025-05-14 20:29:01,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:29:01,870:INFO:Calculating mean and std
2025-05-14 20:29:01,872:INFO:Creating metrics dataframe
2025-05-14 20:29:01,882:INFO:Finalizing model
2025-05-14 20:29:01,944:INFO:Uploading results into container
2025-05-14 20:29:01,945:INFO:Uploading model into container now
2025-05-14 20:29:01,946:INFO:_master_model_container: 16
2025-05-14 20:29:01,947:INFO:_display_container: 4
2025-05-14 20:29:01,947:INFO:GaussianNB(priors=None, var_smoothing=2e-09)
2025-05-14 20:29:01,947:INFO:create_model() successfully completed......................................
2025-05-14 20:29:02,071:INFO:SubProcess create_model() end ==================================
2025-05-14 20:29:02,072:INFO:choose_better activated
2025-05-14 20:29:02,076:INFO:SubProcess create_model() called ==================================
2025-05-14 20:29:02,076:INFO:Initializing create_model()
2025-05-14 20:29:02,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:29:02,077:INFO:Checking exceptions
2025-05-14 20:29:02,079:INFO:Importing libraries
2025-05-14 20:29:02,079:INFO:Copying training dataset
2025-05-14 20:29:02,083:INFO:Defining folds
2025-05-14 20:29:02,083:INFO:Declaring metric variables
2025-05-14 20:29:02,083:INFO:Importing untrained model
2025-05-14 20:29:02,084:INFO:Declaring custom model
2025-05-14 20:29:02,084:INFO:Naive Bayes Imported successfully
2025-05-14 20:29:02,084:INFO:Starting cross validation
2025-05-14 20:29:02,085:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:29:02,328:INFO:Calculating mean and std
2025-05-14 20:29:02,329:INFO:Creating metrics dataframe
2025-05-14 20:29:02,331:INFO:Finalizing model
2025-05-14 20:29:02,365:INFO:Uploading results into container
2025-05-14 20:29:02,365:INFO:Uploading model into container now
2025-05-14 20:29:02,366:INFO:_master_model_container: 17
2025-05-14 20:29:02,366:INFO:_display_container: 5
2025-05-14 20:29:02,366:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 20:29:02,366:INFO:create_model() successfully completed......................................
2025-05-14 20:29:02,459:INFO:SubProcess create_model() end ==================================
2025-05-14 20:29:02,459:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.35
2025-05-14 20:29:02,459:INFO:GaussianNB(priors=None, var_smoothing=2e-09) result for Recall is 0.35
2025-05-14 20:29:02,459:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2025-05-14 20:29:02,459:INFO:choose_better completed
2025-05-14 20:29:02,460:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-14 20:29:02,470:INFO:_master_model_container: 17
2025-05-14 20:29:02,470:INFO:_display_container: 4
2025-05-14 20:29:02,470:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 20:29:02,470:INFO:tune_model() successfully completed......................................
2025-05-14 20:29:02,579:INFO:Initializing plot_model()
2025-05-14 20:29:02,579:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 20:29:02,579:INFO:Checking exceptions
2025-05-14 20:29:02,585:INFO:Preloading libraries
2025-05-14 20:29:02,585:INFO:Copying training dataset
2025-05-14 20:29:02,586:INFO:Plot type: confusion_matrix
2025-05-14 20:29:02,790:INFO:Fitting Model
2025-05-14 20:29:02,790:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-05-14 20:29:02,791:INFO:Scoring test/hold-out set
2025-05-14 20:29:02,893:INFO:Visual Rendered Successfully
2025-05-14 20:29:02,984:INFO:plot_model() successfully completed......................................
2025-05-14 20:29:03,002:INFO:Initializing evaluate_model()
2025-05-14 20:29:03,002:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 20:29:03,014:INFO:Initializing plot_model()
2025-05-14 20:29:03,014:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 20:29:03,014:INFO:Checking exceptions
2025-05-14 20:29:03,017:INFO:Preloading libraries
2025-05-14 20:29:03,017:INFO:Copying training dataset
2025-05-14 20:29:03,017:INFO:Plot type: pipeline
2025-05-14 20:29:03,130:INFO:Visual Rendered Successfully
2025-05-14 20:29:03,223:INFO:plot_model() successfully completed......................................
2025-05-14 20:29:03,239:INFO:Initializing predict_model()
2025-05-14 20:29:03,239:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BA0B40CE00>)
2025-05-14 20:29:03,239:INFO:Checking exceptions
2025-05-14 20:29:03,239:INFO:Preloading libraries
2025-05-14 20:29:03,445:INFO:Initializing save_model()
2025-05-14 20:29:03,445:INFO:save_model(model=GaussianNB(priors=None, var_smoothing=1e-09), model_name=modelo_churn_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strate...
                 TransformerWrapper(exclude=None, include=['tipo_plan'],
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-14 20:29:03,445:INFO:Adding model into prep_pipe
2025-05-14 20:29:03,455:INFO:modelo_churn_final.pkl saved in current working directory
2025-05-14 20:29:03,461:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tra...
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2025-05-14 20:29:03,461:INFO:save_model() successfully completed......................................
2025-05-14 20:29:22,247:INFO:Initializing tune_model()
2025-05-14 20:29:22,247:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 20:29:22,247:INFO:Checking exceptions
2025-05-14 20:29:22,265:INFO:Copying training dataset
2025-05-14 20:29:22,268:INFO:Checking base model
2025-05-14 20:29:22,269:INFO:Base model : Naive Bayes
2025-05-14 20:29:22,273:INFO:Declaring metric variables
2025-05-14 20:29:22,280:INFO:Defining Hyperparameters
2025-05-14 20:29:22,381:INFO:Tuning with n_jobs=-1
2025-05-14 20:29:22,381:INFO:Initializing RandomizedSearchCV
2025-05-14 20:29:23,602:INFO:best_params: {'actual_estimator__var_smoothing': 2e-09}
2025-05-14 20:29:23,603:INFO:Hyperparameter search completed
2025-05-14 20:29:23,603:INFO:SubProcess create_model() called ==================================
2025-05-14 20:29:23,604:INFO:Initializing create_model()
2025-05-14 20:29:23,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BA0B24EED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 2e-09})
2025-05-14 20:29:23,604:INFO:Checking exceptions
2025-05-14 20:29:23,604:INFO:Importing libraries
2025-05-14 20:29:23,604:INFO:Copying training dataset
2025-05-14 20:29:23,611:INFO:Defining folds
2025-05-14 20:29:23,611:INFO:Declaring metric variables
2025-05-14 20:29:23,614:INFO:Importing untrained model
2025-05-14 20:29:23,614:INFO:Declaring custom model
2025-05-14 20:29:23,618:INFO:Naive Bayes Imported successfully
2025-05-14 20:29:23,628:INFO:Starting cross validation
2025-05-14 20:29:23,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:29:23,827:INFO:Calculating mean and std
2025-05-14 20:29:23,828:INFO:Creating metrics dataframe
2025-05-14 20:29:23,834:INFO:Finalizing model
2025-05-14 20:29:23,880:INFO:Uploading results into container
2025-05-14 20:29:23,881:INFO:Uploading model into container now
2025-05-14 20:29:23,882:INFO:_master_model_container: 18
2025-05-14 20:29:23,882:INFO:_display_container: 6
2025-05-14 20:29:23,882:INFO:GaussianNB(priors=None, var_smoothing=2e-09)
2025-05-14 20:29:23,882:INFO:create_model() successfully completed......................................
2025-05-14 20:29:24,017:INFO:SubProcess create_model() end ==================================
2025-05-14 20:29:24,017:INFO:choose_better activated
2025-05-14 20:29:24,020:INFO:SubProcess create_model() called ==================================
2025-05-14 20:29:24,021:INFO:Initializing create_model()
2025-05-14 20:29:24,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 20:29:24,021:INFO:Checking exceptions
2025-05-14 20:29:24,024:INFO:Importing libraries
2025-05-14 20:29:24,024:INFO:Copying training dataset
2025-05-14 20:29:24,029:INFO:Defining folds
2025-05-14 20:29:24,029:INFO:Declaring metric variables
2025-05-14 20:29:24,029:INFO:Importing untrained model
2025-05-14 20:29:24,029:INFO:Declaring custom model
2025-05-14 20:29:24,030:INFO:Naive Bayes Imported successfully
2025-05-14 20:29:24,030:INFO:Starting cross validation
2025-05-14 20:29:24,031:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 20:29:24,333:INFO:Calculating mean and std
2025-05-14 20:29:24,334:INFO:Creating metrics dataframe
2025-05-14 20:29:24,337:INFO:Finalizing model
2025-05-14 20:29:24,383:INFO:Uploading results into container
2025-05-14 20:29:24,383:INFO:Uploading model into container now
2025-05-14 20:29:24,384:INFO:_master_model_container: 19
2025-05-14 20:29:24,384:INFO:_display_container: 7
2025-05-14 20:29:24,384:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 20:29:24,384:INFO:create_model() successfully completed......................................
2025-05-14 20:29:24,502:INFO:SubProcess create_model() end ==================================
2025-05-14 20:29:24,502:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.35
2025-05-14 20:29:24,504:INFO:GaussianNB(priors=None, var_smoothing=2e-09) result for Recall is 0.35
2025-05-14 20:29:24,504:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2025-05-14 20:29:24,504:INFO:choose_better completed
2025-05-14 20:29:24,504:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-14 20:29:24,520:INFO:_master_model_container: 19
2025-05-14 20:29:24,521:INFO:_display_container: 6
2025-05-14 20:29:24,521:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 20:29:24,521:INFO:tune_model() successfully completed......................................
2025-05-14 20:29:24,709:INFO:Initializing plot_model()
2025-05-14 20:29:24,710:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 20:29:24,710:INFO:Checking exceptions
2025-05-14 20:29:24,717:INFO:Preloading libraries
2025-05-14 20:29:24,718:INFO:Copying training dataset
2025-05-14 20:29:24,718:INFO:Plot type: confusion_matrix
2025-05-14 20:29:24,936:INFO:Fitting Model
2025-05-14 20:29:24,936:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-05-14 20:29:24,936:INFO:Scoring test/hold-out set
2025-05-14 20:29:25,046:INFO:Visual Rendered Successfully
2025-05-14 20:29:25,145:INFO:plot_model() successfully completed......................................
2025-05-14 20:29:25,159:INFO:Initializing evaluate_model()
2025-05-14 20:29:25,160:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 20:29:25,175:INFO:Initializing plot_model()
2025-05-14 20:29:25,175:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 20:29:25,175:INFO:Checking exceptions
2025-05-14 20:29:25,179:INFO:Preloading libraries
2025-05-14 20:29:25,179:INFO:Copying training dataset
2025-05-14 20:29:25,179:INFO:Plot type: pipeline
2025-05-14 20:29:25,406:INFO:Visual Rendered Successfully
2025-05-14 20:29:25,507:INFO:plot_model() successfully completed......................................
2025-05-14 20:29:25,524:INFO:Initializing predict_model()
2025-05-14 20:29:25,524:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BA0AE62700>)
2025-05-14 20:29:25,524:INFO:Checking exceptions
2025-05-14 20:29:25,524:INFO:Preloading libraries
2025-05-14 20:29:25,760:INFO:Initializing save_model()
2025-05-14 20:29:25,760:INFO:save_model(model=GaussianNB(priors=None, var_smoothing=1e-09), model_name=modelo_churn_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strate...
                 TransformerWrapper(exclude=None, include=['tipo_plan'],
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-14 20:29:25,761:INFO:Adding model into prep_pipe
2025-05-14 20:29:25,769:INFO:modelo_churn_final.pkl saved in current working directory
2025-05-14 20:29:25,776:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tra...
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2025-05-14 20:29:25,776:INFO:save_model() successfully completed......................................
2025-05-14 20:29:34,925:INFO:Initializing plot_model()
2025-05-14 20:29:34,925:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 20:29:34,925:INFO:Checking exceptions
2025-05-14 20:29:34,930:INFO:Preloading libraries
2025-05-14 20:29:34,931:INFO:Copying training dataset
2025-05-14 20:29:34,931:INFO:Plot type: confusion_matrix
2025-05-14 20:29:35,110:INFO:Fitting Model
2025-05-14 20:29:35,111:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-05-14 20:29:35,111:INFO:Scoring test/hold-out set
2025-05-14 20:29:35,197:INFO:Visual Rendered Successfully
2025-05-14 20:29:35,291:INFO:plot_model() successfully completed......................................
2025-05-14 20:29:35,311:INFO:Initializing evaluate_model()
2025-05-14 20:29:35,312:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 20:29:35,322:INFO:Initializing plot_model()
2025-05-14 20:29:35,322:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 20:29:35,322:INFO:Checking exceptions
2025-05-14 20:29:35,324:INFO:Preloading libraries
2025-05-14 20:29:35,325:INFO:Copying training dataset
2025-05-14 20:29:35,325:INFO:Plot type: pipeline
2025-05-14 20:29:35,432:INFO:Visual Rendered Successfully
2025-05-14 20:29:35,525:INFO:plot_model() successfully completed......................................
2025-05-14 20:29:35,542:INFO:Initializing predict_model()
2025-05-14 20:29:35,542:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BA0B40D580>)
2025-05-14 20:29:35,542:INFO:Checking exceptions
2025-05-14 20:29:35,542:INFO:Preloading libraries
2025-05-14 20:29:35,765:INFO:Initializing save_model()
2025-05-14 20:29:35,765:INFO:save_model(model=GaussianNB(priors=None, var_smoothing=1e-09), model_name=modelo_churn_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strate...
                 TransformerWrapper(exclude=None, include=['tipo_plan'],
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-14 20:29:35,766:INFO:Adding model into prep_pipe
2025-05-14 20:29:35,772:INFO:modelo_churn_final.pkl saved in current working directory
2025-05-14 20:29:35,778:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tra...
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2025-05-14 20:29:35,778:INFO:save_model() successfully completed......................................
2025-05-14 20:29:46,033:INFO:Initializing evaluate_model()
2025-05-14 20:29:46,033:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-14 20:29:46,044:INFO:Initializing plot_model()
2025-05-14 20:29:46,044:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 20:29:46,044:INFO:Checking exceptions
2025-05-14 20:29:46,046:INFO:Preloading libraries
2025-05-14 20:29:46,046:INFO:Copying training dataset
2025-05-14 20:29:46,046:INFO:Plot type: pipeline
2025-05-14 20:29:46,145:INFO:Visual Rendered Successfully
2025-05-14 20:29:46,232:INFO:plot_model() successfully completed......................................
2025-05-14 20:29:46,254:INFO:Initializing predict_model()
2025-05-14 20:29:46,254:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001BA0B6C67A0>)
2025-05-14 20:29:46,254:INFO:Checking exceptions
2025-05-14 20:29:46,254:INFO:Preloading libraries
2025-05-14 20:29:46,489:INFO:Initializing save_model()
2025-05-14 20:29:46,489:INFO:save_model(model=GaussianNB(priors=None, var_smoothing=1e-09), model_name=modelo_churn_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strate...
                 TransformerWrapper(exclude=None, include=['tipo_plan'],
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-14 20:29:46,490:INFO:Adding model into prep_pipe
2025-05-14 20:29:46,495:INFO:modelo_churn_final.pkl saved in current working directory
2025-05-14 20:29:46,500:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas',
                                             'usa_app_movil'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Tra...
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2025-05-14 20:29:46,500:INFO:save_model() successfully completed......................................
2025-05-14 20:29:56,607:INFO:Initializing plot_model()
2025-05-14 20:29:56,607:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BA0B213510>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-14 20:29:56,607:INFO:Checking exceptions
2025-05-14 20:29:56,608:INFO:Preloading libraries
2025-05-14 20:29:56,609:INFO:Copying training dataset
2025-05-14 20:29:56,609:INFO:Plot type: auc
2025-05-14 20:29:56,722:INFO:Fitting Model
2025-05-14 20:29:56,722:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-05-14 20:29:56,722:INFO:Scoring test/hold-out set
2025-05-14 20:29:56,845:INFO:Visual Rendered Successfully
2025-05-14 20:29:56,925:INFO:plot_model() successfully completed......................................
2025-05-14 20:57:55,938:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 20:57:55,938:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 20:57:55,938:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 20:57:55,939:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 20:59:41,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 20:59:41,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 20:59:41,110:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 20:59:41,111:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 21:01:03,953:INFO:PyCaret ClassificationExperiment
2025-05-14 21:01:03,953:INFO:Logging name: clf-default-name
2025-05-14 21:01:03,953:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 21:01:03,953:INFO:version 3.3.2
2025-05-14 21:01:03,953:INFO:Initializing setup()
2025-05-14 21:01:03,954:INFO:self.USI: 18dc
2025-05-14 21:01:03,954:INFO:self._variable_keys: {'n_jobs_param', 'data', 'exp_name_log', 'is_multiclass', 'gpu_n_jobs_param', 'y_train', 'idx', 'USI', 'memory', 'fold_groups_param', 'logging_param', 'seed', 'target_param', 'fix_imbalance', 'y_test', 'pipeline', 'X_train', 'exp_id', '_ml_usecase', 'log_plots_param', 'fold_shuffle_param', '_available_plots', 'fold_generator', 'X', 'y', 'gpu_param', 'html_param', 'X_test'}
2025-05-14 21:01:03,954:INFO:Checking environment
2025-05-14 21:01:03,954:INFO:python_version: 3.11.8
2025-05-14 21:01:03,954:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-14 21:01:03,954:INFO:machine: AMD64
2025-05-14 21:01:03,954:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-14 21:01:03,963:INFO:Memory: svmem(total=16907886592, available=4088680448, percent=75.8, used=12819206144, free=4088680448)
2025-05-14 21:01:03,963:INFO:Physical Core: 4
2025-05-14 21:01:03,963:INFO:Logical Core: 8
2025-05-14 21:01:03,964:INFO:Checking libraries
2025-05-14 21:01:03,964:INFO:System:
2025-05-14 21:01:03,964:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-14 21:01:03,964:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-14 21:01:03,964:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-14 21:01:03,964:INFO:PyCaret required dependencies:
2025-05-14 21:01:04,015:INFO:                 pip: 24.0
2025-05-14 21:01:04,015:INFO:          setuptools: 65.5.0
2025-05-14 21:01:04,015:INFO:             pycaret: 3.3.2
2025-05-14 21:01:04,015:INFO:             IPython: 9.2.0
2025-05-14 21:01:04,016:INFO:          ipywidgets: 8.1.7
2025-05-14 21:01:04,016:INFO:                tqdm: 4.67.1
2025-05-14 21:01:04,016:INFO:               numpy: 1.26.4
2025-05-14 21:01:04,016:INFO:              pandas: 2.1.4
2025-05-14 21:01:04,016:INFO:              jinja2: 3.1.6
2025-05-14 21:01:04,016:INFO:               scipy: 1.11.4
2025-05-14 21:01:04,016:INFO:              joblib: 1.3.2
2025-05-14 21:01:04,016:INFO:             sklearn: 1.4.2
2025-05-14 21:01:04,016:INFO:                pyod: 2.0.5
2025-05-14 21:01:04,016:INFO:            imblearn: 0.13.0
2025-05-14 21:01:04,016:INFO:   category_encoders: 2.7.0
2025-05-14 21:01:04,016:INFO:            lightgbm: 4.6.0
2025-05-14 21:01:04,016:INFO:               numba: 0.61.2
2025-05-14 21:01:04,016:INFO:            requests: 2.32.3
2025-05-14 21:01:04,017:INFO:          matplotlib: 3.7.5
2025-05-14 21:01:04,017:INFO:          scikitplot: 0.3.7
2025-05-14 21:01:04,017:INFO:         yellowbrick: 1.5
2025-05-14 21:01:04,017:INFO:              plotly: 5.24.1
2025-05-14 21:01:04,017:INFO:    plotly-resampler: Not installed
2025-05-14 21:01:04,017:INFO:             kaleido: 0.2.1
2025-05-14 21:01:04,017:INFO:           schemdraw: 0.15
2025-05-14 21:01:04,017:INFO:         statsmodels: 0.14.4
2025-05-14 21:01:04,017:INFO:              sktime: 0.26.0
2025-05-14 21:01:04,018:INFO:               tbats: 1.1.3
2025-05-14 21:01:04,018:INFO:            pmdarima: 2.0.4
2025-05-14 21:01:04,018:INFO:              psutil: 7.0.0
2025-05-14 21:01:04,018:INFO:          markupsafe: 3.0.2
2025-05-14 21:01:04,018:INFO:             pickle5: Not installed
2025-05-14 21:01:04,018:INFO:         cloudpickle: 3.1.1
2025-05-14 21:01:04,018:INFO:         deprecation: 2.1.0
2025-05-14 21:01:04,018:INFO:              xxhash: 3.5.0
2025-05-14 21:01:04,018:INFO:           wurlitzer: Not installed
2025-05-14 21:01:04,018:INFO:PyCaret optional dependencies:
2025-05-14 21:01:04,043:INFO:                shap: Not installed
2025-05-14 21:01:04,044:INFO:           interpret: Not installed
2025-05-14 21:01:04,044:INFO:                umap: Not installed
2025-05-14 21:01:04,044:INFO:     ydata_profiling: Not installed
2025-05-14 21:01:04,044:INFO:  explainerdashboard: Not installed
2025-05-14 21:01:04,044:INFO:             autoviz: Not installed
2025-05-14 21:01:04,044:INFO:           fairlearn: Not installed
2025-05-14 21:01:04,044:INFO:          deepchecks: Not installed
2025-05-14 21:01:04,044:INFO:             xgboost: Not installed
2025-05-14 21:01:04,044:INFO:            catboost: Not installed
2025-05-14 21:01:04,044:INFO:              kmodes: Not installed
2025-05-14 21:01:04,045:INFO:             mlxtend: Not installed
2025-05-14 21:01:04,045:INFO:       statsforecast: Not installed
2025-05-14 21:01:04,045:INFO:        tune_sklearn: Not installed
2025-05-14 21:01:04,045:INFO:                 ray: Not installed
2025-05-14 21:01:04,045:INFO:            hyperopt: Not installed
2025-05-14 21:01:04,045:INFO:              optuna: Not installed
2025-05-14 21:01:04,046:INFO:               skopt: Not installed
2025-05-14 21:01:04,046:INFO:              mlflow: Not installed
2025-05-14 21:01:04,046:INFO:              gradio: Not installed
2025-05-14 21:01:04,046:INFO:             fastapi: Not installed
2025-05-14 21:01:04,047:INFO:             uvicorn: Not installed
2025-05-14 21:01:04,047:INFO:              m2cgen: Not installed
2025-05-14 21:01:04,047:INFO:           evidently: Not installed
2025-05-14 21:01:04,047:INFO:               fugue: Not installed
2025-05-14 21:01:04,048:INFO:           streamlit: Not installed
2025-05-14 21:01:04,048:INFO:             prophet: Not installed
2025-05-14 21:01:04,048:INFO:None
2025-05-14 21:01:04,048:INFO:Set up data.
2025-05-14 21:01:04,057:INFO:Set up folding strategy.
2025-05-14 21:01:04,057:INFO:Set up train/test split.
2025-05-14 21:01:04,069:INFO:Set up index.
2025-05-14 21:01:04,070:INFO:Assigning column types.
2025-05-14 21:01:04,077:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 21:01:04,202:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 21:01:04,209:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:01:04,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:04,293:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:04,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 21:01:04,428:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:01:04,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:04,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:04,512:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 21:01:04,604:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:01:04,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:04,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:04,764:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:01:04,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:04,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:04,820:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 21:01:05,064:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:05,065:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:05,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:05,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:05,303:INFO:Preparing preprocessing pipeline...
2025-05-14 21:01:05,306:INFO:Set up simple imputation.
2025-05-14 21:01:05,312:INFO:Set up encoding of ordinal features.
2025-05-14 21:01:05,320:INFO:Set up encoding of categorical features.
2025-05-14 21:01:05,320:INFO:Set up removing multicollinearity.
2025-05-14 21:01:05,320:INFO:Set up feature normalization.
2025-05-14 21:01:05,651:INFO:Finished creating preprocessing pipeline.
2025-05-14 21:01:05,737:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['monto_credito',
                                             'mujer_emprendedora', 'hijos'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer'...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-14 21:01:05,738:INFO:Creating final display dataframe.
2025-05-14 21:01:06,457:INFO:Setup _display_container:                     Description             Value
0                    Session id               999
1                        Target           default
2                   Target type            Binary
3           Original data shape          (144, 7)
4        Transformed data shape          (144, 8)
5   Transformed train set shape          (100, 8)
6    Transformed test set shape           (44, 8)
7               Ignore features                 1
8              Numeric features                 3
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.8
18                    Normalize              True
19             Normalize method            zscore
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              18dc
2025-05-14 21:01:06,646:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:06,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:06,815:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:06,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:01:06,818:INFO:setup() successfully completed in 2.87s...............
2025-05-14 21:01:06,831:INFO:Initializing compare_models()
2025-05-14 21:01:06,831:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 21:01:06,832:INFO:Checking exceptions
2025-05-14 21:01:06,838:INFO:Preparing display monitor
2025-05-14 21:01:06,973:INFO:Initializing Logistic Regression
2025-05-14 21:01:06,973:INFO:Total runtime is 1.6689300537109375e-05 minutes
2025-05-14 21:01:06,980:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:06,981:INFO:Initializing create_model()
2025-05-14 21:01:06,981:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07DA6BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:06,982:INFO:Checking exceptions
2025-05-14 21:01:06,982:INFO:Importing libraries
2025-05-14 21:01:06,982:INFO:Copying training dataset
2025-05-14 21:01:06,988:INFO:Defining folds
2025-05-14 21:01:06,989:INFO:Declaring metric variables
2025-05-14 21:01:06,996:INFO:Importing untrained model
2025-05-14 21:01:07,003:INFO:Logistic Regression Imported successfully
2025-05-14 21:01:07,018:INFO:Starting cross validation
2025-05-14 21:01:07,021:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:07,090:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:17,320:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:17,376:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:17,563:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:17,656:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:17,702:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:17,732:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:17,740:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:17,742:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:17,751:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:17,752:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:17,758:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:17,763:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:17,765:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:17,769:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:17,770:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:01:17,776:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:17,790:INFO:Calculating mean and std
2025-05-14 21:01:17,794:INFO:Creating metrics dataframe
2025-05-14 21:01:17,800:INFO:Uploading results into container
2025-05-14 21:01:17,802:INFO:Uploading model into container now
2025-05-14 21:01:17,803:INFO:_master_model_container: 1
2025-05-14 21:01:17,804:INFO:_display_container: 2
2025-05-14 21:01:17,805:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 21:01:17,805:INFO:create_model() successfully completed......................................
2025-05-14 21:01:17,980:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:17,980:INFO:Creating metrics dataframe
2025-05-14 21:01:17,995:INFO:Initializing K Neighbors Classifier
2025-05-14 21:01:17,996:INFO:Total runtime is 0.18370758295059203 minutes
2025-05-14 21:01:18,003:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:18,004:INFO:Initializing create_model()
2025-05-14 21:01:18,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07DA6BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:18,004:INFO:Checking exceptions
2025-05-14 21:01:18,004:INFO:Importing libraries
2025-05-14 21:01:18,005:INFO:Copying training dataset
2025-05-14 21:01:18,013:INFO:Defining folds
2025-05-14 21:01:18,014:INFO:Declaring metric variables
2025-05-14 21:01:18,023:INFO:Importing untrained model
2025-05-14 21:01:18,031:INFO:K Neighbors Classifier Imported successfully
2025-05-14 21:01:18,053:INFO:Starting cross validation
2025-05-14 21:01:18,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:18,065:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:18,392:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:18,399:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:18,403:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:18,408:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:18,415:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:18,417:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:18,421:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:18,422:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:01:18,430:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:18,438:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:18,446:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:18,446:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:18,455:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:18,488:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:18,632:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:18,676:INFO:Calculating mean and std
2025-05-14 21:01:18,680:INFO:Creating metrics dataframe
2025-05-14 21:01:18,685:INFO:Uploading results into container
2025-05-14 21:01:18,688:INFO:Uploading model into container now
2025-05-14 21:01:18,689:INFO:_master_model_container: 2
2025-05-14 21:01:18,689:INFO:_display_container: 2
2025-05-14 21:01:18,690:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 21:01:18,690:INFO:create_model() successfully completed......................................
2025-05-14 21:01:18,811:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:18,811:INFO:Creating metrics dataframe
2025-05-14 21:01:18,822:INFO:Initializing Naive Bayes
2025-05-14 21:01:18,822:INFO:Total runtime is 0.1974900722503662 minutes
2025-05-14 21:01:18,826:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:18,828:INFO:Initializing create_model()
2025-05-14 21:01:18,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07DA6BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:18,828:INFO:Checking exceptions
2025-05-14 21:01:18,828:INFO:Importing libraries
2025-05-14 21:01:18,828:INFO:Copying training dataset
2025-05-14 21:01:18,833:INFO:Defining folds
2025-05-14 21:01:18,834:INFO:Declaring metric variables
2025-05-14 21:01:18,838:INFO:Importing untrained model
2025-05-14 21:01:18,844:INFO:Naive Bayes Imported successfully
2025-05-14 21:01:18,855:INFO:Starting cross validation
2025-05-14 21:01:18,859:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:18,863:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:19,062:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:19,063:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:19,068:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:19,070:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:19,093:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:19,115:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:19,220:INFO:Calculating mean and std
2025-05-14 21:01:19,221:INFO:Creating metrics dataframe
2025-05-14 21:01:19,224:INFO:Uploading results into container
2025-05-14 21:01:19,225:INFO:Uploading model into container now
2025-05-14 21:01:19,226:INFO:_master_model_container: 3
2025-05-14 21:01:19,226:INFO:_display_container: 2
2025-05-14 21:01:19,227:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:01:19,227:INFO:create_model() successfully completed......................................
2025-05-14 21:01:19,315:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:19,315:INFO:Creating metrics dataframe
2025-05-14 21:01:19,327:INFO:Initializing Decision Tree Classifier
2025-05-14 21:01:19,327:INFO:Total runtime is 0.20590478976567583 minutes
2025-05-14 21:01:19,331:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:19,332:INFO:Initializing create_model()
2025-05-14 21:01:19,332:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07DA6BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:19,332:INFO:Checking exceptions
2025-05-14 21:01:19,332:INFO:Importing libraries
2025-05-14 21:01:19,332:INFO:Copying training dataset
2025-05-14 21:01:19,337:INFO:Defining folds
2025-05-14 21:01:19,338:INFO:Declaring metric variables
2025-05-14 21:01:19,342:INFO:Importing untrained model
2025-05-14 21:01:19,347:INFO:Decision Tree Classifier Imported successfully
2025-05-14 21:01:19,359:INFO:Starting cross validation
2025-05-14 21:01:19,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:19,363:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:19,525:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:19,526:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:19,532:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:19,540:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:19,547:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:19,635:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:19,649:INFO:Calculating mean and std
2025-05-14 21:01:19,651:INFO:Creating metrics dataframe
2025-05-14 21:01:19,653:INFO:Uploading results into container
2025-05-14 21:01:19,654:INFO:Uploading model into container now
2025-05-14 21:01:19,655:INFO:_master_model_container: 4
2025-05-14 21:01:19,655:INFO:_display_container: 2
2025-05-14 21:01:19,655:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best')
2025-05-14 21:01:19,655:INFO:create_model() successfully completed......................................
2025-05-14 21:01:19,749:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:19,750:INFO:Creating metrics dataframe
2025-05-14 21:01:19,761:INFO:Initializing SVM - Linear Kernel
2025-05-14 21:01:19,761:INFO:Total runtime is 0.21315368811289467 minutes
2025-05-14 21:01:19,765:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:19,766:INFO:Initializing create_model()
2025-05-14 21:01:19,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07DA6BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:19,766:INFO:Checking exceptions
2025-05-14 21:01:19,766:INFO:Importing libraries
2025-05-14 21:01:19,768:INFO:Copying training dataset
2025-05-14 21:01:19,774:INFO:Defining folds
2025-05-14 21:01:19,775:INFO:Declaring metric variables
2025-05-14 21:01:19,780:INFO:Importing untrained model
2025-05-14 21:01:19,787:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 21:01:19,796:INFO:Starting cross validation
2025-05-14 21:01:19,797:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:19,802:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:19,993:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:19,999:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,005:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,010:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,010:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,012:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:20,013:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:01:20,015:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,015:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,016:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:20,026:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,042:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,050:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,210:INFO:Calculating mean and std
2025-05-14 21:01:20,212:INFO:Creating metrics dataframe
2025-05-14 21:01:20,216:INFO:Uploading results into container
2025-05-14 21:01:20,217:INFO:Uploading model into container now
2025-05-14 21:01:20,219:INFO:_master_model_container: 5
2025-05-14 21:01:20,219:INFO:_display_container: 2
2025-05-14 21:01:20,220:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=999, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 21:01:20,220:INFO:create_model() successfully completed......................................
2025-05-14 21:01:20,320:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:20,320:INFO:Creating metrics dataframe
2025-05-14 21:01:20,329:INFO:Initializing Ridge Classifier
2025-05-14 21:01:20,329:INFO:Total runtime is 0.22261486848195391 minutes
2025-05-14 21:01:20,334:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:20,335:INFO:Initializing create_model()
2025-05-14 21:01:20,335:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07DA6BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:20,335:INFO:Checking exceptions
2025-05-14 21:01:20,335:INFO:Importing libraries
2025-05-14 21:01:20,335:INFO:Copying training dataset
2025-05-14 21:01:20,341:INFO:Defining folds
2025-05-14 21:01:20,341:INFO:Declaring metric variables
2025-05-14 21:01:20,347:INFO:Importing untrained model
2025-05-14 21:01:20,352:INFO:Ridge Classifier Imported successfully
2025-05-14 21:01:20,360:INFO:Starting cross validation
2025-05-14 21:01:20,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:20,365:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:20,529:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,531:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:20,538:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,541:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,542:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,542:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,547:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,548:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:20,550:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:01:20,551:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,552:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:20,554:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,555:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,571:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,681:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,696:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:20,715:INFO:Calculating mean and std
2025-05-14 21:01:20,718:INFO:Creating metrics dataframe
2025-05-14 21:01:20,722:INFO:Uploading results into container
2025-05-14 21:01:20,723:INFO:Uploading model into container now
2025-05-14 21:01:20,724:INFO:_master_model_container: 6
2025-05-14 21:01:20,724:INFO:_display_container: 2
2025-05-14 21:01:20,725:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=999, solver='auto',
                tol=0.0001)
2025-05-14 21:01:20,725:INFO:create_model() successfully completed......................................
2025-05-14 21:01:20,826:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:20,826:INFO:Creating metrics dataframe
2025-05-14 21:01:20,841:INFO:Initializing Random Forest Classifier
2025-05-14 21:01:20,841:INFO:Total runtime is 0.23114943901697793 minutes
2025-05-14 21:01:20,845:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:20,846:INFO:Initializing create_model()
2025-05-14 21:01:20,846:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07DA6BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:20,846:INFO:Checking exceptions
2025-05-14 21:01:20,846:INFO:Importing libraries
2025-05-14 21:01:20,846:INFO:Copying training dataset
2025-05-14 21:01:20,855:INFO:Defining folds
2025-05-14 21:01:20,856:INFO:Declaring metric variables
2025-05-14 21:01:20,864:INFO:Importing untrained model
2025-05-14 21:01:20,875:INFO:Random Forest Classifier Imported successfully
2025-05-14 21:01:20,893:INFO:Starting cross validation
2025-05-14 21:01:20,896:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:20,900:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:21,689:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:21,704:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:21,733:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:21,736:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:21,738:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:21,745:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:21,752:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:21,758:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:21,761:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:21,761:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:01:21,766:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:21,826:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:21,841:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:21,844:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:22,165:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:22,186:INFO:Calculating mean and std
2025-05-14 21:01:22,187:INFO:Creating metrics dataframe
2025-05-14 21:01:22,191:INFO:Uploading results into container
2025-05-14 21:01:22,191:INFO:Uploading model into container now
2025-05-14 21:01:22,192:INFO:_master_model_container: 7
2025-05-14 21:01:22,192:INFO:_display_container: 2
2025-05-14 21:01:22,193:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=999, verbose=0,
                       warm_start=False)
2025-05-14 21:01:22,193:INFO:create_model() successfully completed......................................
2025-05-14 21:01:22,275:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:22,275:INFO:Creating metrics dataframe
2025-05-14 21:01:22,284:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 21:01:22,284:INFO:Total runtime is 0.2552000880241394 minutes
2025-05-14 21:01:22,289:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:22,289:INFO:Initializing create_model()
2025-05-14 21:01:22,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07DA6BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:22,289:INFO:Checking exceptions
2025-05-14 21:01:22,289:INFO:Importing libraries
2025-05-14 21:01:22,289:INFO:Copying training dataset
2025-05-14 21:01:22,293:INFO:Defining folds
2025-05-14 21:01:22,293:INFO:Declaring metric variables
2025-05-14 21:01:22,297:INFO:Importing untrained model
2025-05-14 21:01:22,303:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 21:01:22,311:INFO:Starting cross validation
2025-05-14 21:01:22,312:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:22,316:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:22,420:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:01:22,425:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:01:22,430:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:01:22,430:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:01:22,431:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:01:22,435:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:01:22,453:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:01:22,475:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:01:22,491:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:22,492:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:22,495:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:22,498:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:22,505:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:22,510:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:22,512:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:22,513:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:01:22,516:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:22,572:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:01:22,584:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:01:22,611:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:22,632:INFO:Calculating mean and std
2025-05-14 21:01:22,633:INFO:Creating metrics dataframe
2025-05-14 21:01:22,636:INFO:Uploading results into container
2025-05-14 21:01:22,637:INFO:Uploading model into container now
2025-05-14 21:01:22,638:INFO:_master_model_container: 8
2025-05-14 21:01:22,638:INFO:_display_container: 2
2025-05-14 21:01:22,638:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 21:01:22,638:INFO:create_model() successfully completed......................................
2025-05-14 21:01:22,728:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:22,729:INFO:Creating metrics dataframe
2025-05-14 21:01:22,739:INFO:Initializing Ada Boost Classifier
2025-05-14 21:01:22,739:INFO:Total runtime is 0.26278330087661744 minutes
2025-05-14 21:01:22,744:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:22,745:INFO:Initializing create_model()
2025-05-14 21:01:22,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07DA6BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:22,745:INFO:Checking exceptions
2025-05-14 21:01:22,745:INFO:Importing libraries
2025-05-14 21:01:22,745:INFO:Copying training dataset
2025-05-14 21:01:22,752:INFO:Defining folds
2025-05-14 21:01:22,754:INFO:Declaring metric variables
2025-05-14 21:01:22,791:INFO:Importing untrained model
2025-05-14 21:01:22,802:INFO:Ada Boost Classifier Imported successfully
2025-05-14 21:01:22,820:INFO:Starting cross validation
2025-05-14 21:01:22,822:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:22,826:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:22,986:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:01:22,988:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:01:22,991:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:01:22,993:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:01:23,010:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:01:23,013:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:01:23,026:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:01:23,099:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:01:23,306:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:23,362:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:23,402:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:23,406:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:23,431:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:01:23,432:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:01:23,464:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:23,634:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:23,649:INFO:Calculating mean and std
2025-05-14 21:01:23,650:INFO:Creating metrics dataframe
2025-05-14 21:01:23,653:INFO:Uploading results into container
2025-05-14 21:01:23,654:INFO:Uploading model into container now
2025-05-14 21:01:23,655:INFO:_master_model_container: 9
2025-05-14 21:01:23,655:INFO:_display_container: 2
2025-05-14 21:01:23,655:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=999)
2025-05-14 21:01:23,655:INFO:create_model() successfully completed......................................
2025-05-14 21:01:23,735:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:23,736:INFO:Creating metrics dataframe
2025-05-14 21:01:23,745:INFO:Initializing Gradient Boosting Classifier
2025-05-14 21:01:23,745:INFO:Total runtime is 0.2795404036839803 minutes
2025-05-14 21:01:23,750:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:23,751:INFO:Initializing create_model()
2025-05-14 21:01:23,751:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07DA6BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:23,751:INFO:Checking exceptions
2025-05-14 21:01:23,751:INFO:Importing libraries
2025-05-14 21:01:23,751:INFO:Copying training dataset
2025-05-14 21:01:23,754:INFO:Defining folds
2025-05-14 21:01:23,754:INFO:Declaring metric variables
2025-05-14 21:01:23,758:INFO:Importing untrained model
2025-05-14 21:01:23,762:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 21:01:23,771:INFO:Starting cross validation
2025-05-14 21:01:23,772:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:23,774:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:24,163:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,207:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:24,208:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,216:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,241:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,458:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,476:INFO:Calculating mean and std
2025-05-14 21:01:24,478:INFO:Creating metrics dataframe
2025-05-14 21:01:24,480:INFO:Uploading results into container
2025-05-14 21:01:24,481:INFO:Uploading model into container now
2025-05-14 21:01:24,481:INFO:_master_model_container: 10
2025-05-14 21:01:24,481:INFO:_display_container: 2
2025-05-14 21:01:24,482:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=999, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 21:01:24,482:INFO:create_model() successfully completed......................................
2025-05-14 21:01:24,566:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:24,566:INFO:Creating metrics dataframe
2025-05-14 21:01:24,576:INFO:Initializing Linear Discriminant Analysis
2025-05-14 21:01:24,576:INFO:Total runtime is 0.29340184132258096 minutes
2025-05-14 21:01:24,580:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:24,580:INFO:Initializing create_model()
2025-05-14 21:01:24,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07DA6BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:24,581:INFO:Checking exceptions
2025-05-14 21:01:24,581:INFO:Importing libraries
2025-05-14 21:01:24,581:INFO:Copying training dataset
2025-05-14 21:01:24,585:INFO:Defining folds
2025-05-14 21:01:24,585:INFO:Declaring metric variables
2025-05-14 21:01:24,588:INFO:Importing untrained model
2025-05-14 21:01:24,593:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 21:01:24,602:INFO:Starting cross validation
2025-05-14 21:01:24,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:24,607:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:24,768:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:24,772:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,777:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,777:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,780:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,781:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,782:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,785:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:24,785:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:01:24,786:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,791:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:24,795:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,801:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,810:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,921:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:24,936:INFO:Calculating mean and std
2025-05-14 21:01:24,938:INFO:Creating metrics dataframe
2025-05-14 21:01:24,940:INFO:Uploading results into container
2025-05-14 21:01:24,941:INFO:Uploading model into container now
2025-05-14 21:01:24,941:INFO:_master_model_container: 11
2025-05-14 21:01:24,942:INFO:_display_container: 2
2025-05-14 21:01:24,942:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 21:01:24,942:INFO:create_model() successfully completed......................................
2025-05-14 21:01:25,032:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:25,032:INFO:Creating metrics dataframe
2025-05-14 21:01:25,043:INFO:Initializing Extra Trees Classifier
2025-05-14 21:01:25,044:INFO:Total runtime is 0.30120078325271604 minutes
2025-05-14 21:01:25,051:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:25,051:INFO:Initializing create_model()
2025-05-14 21:01:25,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07DA6BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:25,051:INFO:Checking exceptions
2025-05-14 21:01:25,051:INFO:Importing libraries
2025-05-14 21:01:25,051:INFO:Copying training dataset
2025-05-14 21:01:25,055:INFO:Defining folds
2025-05-14 21:01:25,056:INFO:Declaring metric variables
2025-05-14 21:01:25,060:INFO:Importing untrained model
2025-05-14 21:01:25,068:INFO:Extra Trees Classifier Imported successfully
2025-05-14 21:01:25,078:INFO:Starting cross validation
2025-05-14 21:01:25,080:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:25,084:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:25,579:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:25,591:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:25,624:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:25,625:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:25,646:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:25,682:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:25,733:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:25,795:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:26,020:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:26,032:INFO:Calculating mean and std
2025-05-14 21:01:26,033:INFO:Creating metrics dataframe
2025-05-14 21:01:26,035:INFO:Uploading results into container
2025-05-14 21:01:26,037:INFO:Uploading model into container now
2025-05-14 21:01:26,037:INFO:_master_model_container: 12
2025-05-14 21:01:26,037:INFO:_display_container: 2
2025-05-14 21:01:26,038:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=999, verbose=0,
                     warm_start=False)
2025-05-14 21:01:26,038:INFO:create_model() successfully completed......................................
2025-05-14 21:01:26,120:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:26,120:INFO:Creating metrics dataframe
2025-05-14 21:01:26,130:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 21:01:26,131:INFO:Total runtime is 0.3193091511726379 minutes
2025-05-14 21:01:26,134:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:26,134:INFO:Initializing create_model()
2025-05-14 21:01:26,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07DA6BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:26,134:INFO:Checking exceptions
2025-05-14 21:01:26,134:INFO:Importing libraries
2025-05-14 21:01:26,134:INFO:Copying training dataset
2025-05-14 21:01:26,142:INFO:Defining folds
2025-05-14 21:01:26,142:INFO:Declaring metric variables
2025-05-14 21:01:26,146:INFO:Importing untrained model
2025-05-14 21:01:26,154:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 21:01:26,165:INFO:Starting cross validation
2025-05-14 21:01:26,167:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:26,169:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:26,513:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:26,520:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:26,542:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:26,548:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:26,575:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:26,662:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:26,683:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:26,687:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:26,692:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:26,697:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:26,700:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:26,701:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:01:26,704:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:26,858:INFO:Calculating mean and std
2025-05-14 21:01:26,861:INFO:Creating metrics dataframe
2025-05-14 21:01:26,866:INFO:Uploading results into container
2025-05-14 21:01:26,866:INFO:Uploading model into container now
2025-05-14 21:01:26,868:INFO:_master_model_container: 13
2025-05-14 21:01:26,869:INFO:_display_container: 2
2025-05-14 21:01:26,872:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=999, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 21:01:26,872:INFO:create_model() successfully completed......................................
2025-05-14 21:01:26,987:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:26,988:INFO:Creating metrics dataframe
2025-05-14 21:01:27,000:INFO:Initializing Dummy Classifier
2025-05-14 21:01:27,000:INFO:Total runtime is 0.33380387226740516 minutes
2025-05-14 21:01:27,007:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:27,007:INFO:Initializing create_model()
2025-05-14 21:01:27,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07DA6BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:27,008:INFO:Checking exceptions
2025-05-14 21:01:27,008:INFO:Importing libraries
2025-05-14 21:01:27,008:INFO:Copying training dataset
2025-05-14 21:01:27,014:INFO:Defining folds
2025-05-14 21:01:27,015:INFO:Declaring metric variables
2025-05-14 21:01:27,020:INFO:Importing untrained model
2025-05-14 21:01:27,026:INFO:Dummy Classifier Imported successfully
2025-05-14 21:01:27,035:INFO:Starting cross validation
2025-05-14 21:01:27,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:27,041:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:27,218:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:27,223:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:27,224:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:27,232:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:27,234:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:27,234:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:27,239:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:27,241:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:27,244:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:01:27,249:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:27,250:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:27,254:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:27,257:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:27,260:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:27,344:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:27,346:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:27,353:INFO:Calculating mean and std
2025-05-14 21:01:27,354:INFO:Creating metrics dataframe
2025-05-14 21:01:27,357:INFO:Uploading results into container
2025-05-14 21:01:27,358:INFO:Uploading model into container now
2025-05-14 21:01:27,359:INFO:_master_model_container: 14
2025-05-14 21:01:27,359:INFO:_display_container: 2
2025-05-14 21:01:27,360:INFO:DummyClassifier(constant=None, random_state=999, strategy='prior')
2025-05-14 21:01:27,360:INFO:create_model() successfully completed......................................
2025-05-14 21:01:27,447:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:27,448:INFO:Creating metrics dataframe
2025-05-14 21:01:27,461:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-14 21:01:27,470:INFO:Initializing create_model()
2025-05-14 21:01:27,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:27,470:INFO:Checking exceptions
2025-05-14 21:01:27,472:INFO:Importing libraries
2025-05-14 21:01:27,472:INFO:Copying training dataset
2025-05-14 21:01:27,476:INFO:Defining folds
2025-05-14 21:01:27,476:INFO:Declaring metric variables
2025-05-14 21:01:27,476:INFO:Importing untrained model
2025-05-14 21:01:27,476:INFO:Declaring custom model
2025-05-14 21:01:27,477:INFO:Decision Tree Classifier Imported successfully
2025-05-14 21:01:27,479:INFO:Cross validation set to False
2025-05-14 21:01:27,479:INFO:Fitting Model
2025-05-14 21:01:27,516:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best')
2025-05-14 21:01:27,516:INFO:create_model() successfully completed......................................
2025-05-14 21:01:27,613:INFO:_master_model_container: 14
2025-05-14 21:01:27,613:INFO:_display_container: 2
2025-05-14 21:01:27,614:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best')
2025-05-14 21:01:27,614:INFO:compare_models() successfully completed......................................
2025-05-14 21:01:27,642:INFO:Initializing tune_model()
2025-05-14 21:01:27,642:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 21:01:27,642:INFO:Checking exceptions
2025-05-14 21:01:27,663:INFO:Copying training dataset
2025-05-14 21:01:27,676:INFO:Checking base model
2025-05-14 21:01:27,676:INFO:Base model : Decision Tree Classifier
2025-05-14 21:01:27,685:INFO:Declaring metric variables
2025-05-14 21:01:27,692:INFO:Defining Hyperparameters
2025-05-14 21:01:27,788:INFO:Tuning with n_jobs=-1
2025-05-14 21:01:27,789:INFO:Initializing RandomizedSearchCV
2025-05-14 21:01:27,792:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:27,939:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:28,144:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:28,386:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:28,451:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:28,967:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:29,570:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:29,772:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:30,024:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:30,512:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:30,804:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:31,110:INFO:best_params: {'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'entropy'}
2025-05-14 21:01:31,111:INFO:Hyperparameter search completed
2025-05-14 21:01:31,112:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:31,112:INFO:Initializing create_model()
2025-05-14 21:01:31,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07D603BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 7, 'min_samples_leaf': 2, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 7, 'criterion': 'entropy'})
2025-05-14 21:01:31,113:INFO:Checking exceptions
2025-05-14 21:01:31,113:INFO:Importing libraries
2025-05-14 21:01:31,114:INFO:Copying training dataset
2025-05-14 21:01:31,119:INFO:Defining folds
2025-05-14 21:01:31,119:INFO:Declaring metric variables
2025-05-14 21:01:31,125:INFO:Importing untrained model
2025-05-14 21:01:31,125:INFO:Declaring custom model
2025-05-14 21:01:31,132:INFO:Decision Tree Classifier Imported successfully
2025-05-14 21:01:31,147:INFO:Starting cross validation
2025-05-14 21:01:31,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:31,155:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:31,592:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:31,598:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:31,602:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:31,612:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:31,614:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:31,615:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:01:31,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:01:31,726:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:31,741:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:31,749:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:31,865:INFO:Calculating mean and std
2025-05-14 21:01:31,869:INFO:Creating metrics dataframe
2025-05-14 21:01:31,881:INFO:Finalizing model
2025-05-14 21:01:31,951:INFO:Uploading results into container
2025-05-14 21:01:31,952:INFO:Uploading model into container now
2025-05-14 21:01:31,952:INFO:_master_model_container: 15
2025-05-14 21:01:31,953:INFO:_display_container: 3
2025-05-14 21:01:31,953:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best')
2025-05-14 21:01:31,953:INFO:create_model() successfully completed......................................
2025-05-14 21:01:32,043:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:32,043:INFO:choose_better activated
2025-05-14 21:01:32,048:INFO:SubProcess create_model() called ==================================
2025-05-14 21:01:32,049:INFO:Initializing create_model()
2025-05-14 21:01:32,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:01:32,049:INFO:Checking exceptions
2025-05-14 21:01:32,051:INFO:Importing libraries
2025-05-14 21:01:32,051:INFO:Copying training dataset
2025-05-14 21:01:32,054:INFO:Defining folds
2025-05-14 21:01:32,054:INFO:Declaring metric variables
2025-05-14 21:01:32,054:INFO:Importing untrained model
2025-05-14 21:01:32,054:INFO:Declaring custom model
2025-05-14 21:01:32,055:INFO:Decision Tree Classifier Imported successfully
2025-05-14 21:01:32,055:INFO:Starting cross validation
2025-05-14 21:01:32,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:01:32,059:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:01:32,242:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:01:32,246:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:32,248:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:32,250:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:32,273:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:32,352:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:01:32,363:INFO:Calculating mean and std
2025-05-14 21:01:32,364:INFO:Creating metrics dataframe
2025-05-14 21:01:32,365:INFO:Finalizing model
2025-05-14 21:01:32,413:INFO:Uploading results into container
2025-05-14 21:01:32,413:INFO:Uploading model into container now
2025-05-14 21:01:32,414:INFO:_master_model_container: 16
2025-05-14 21:01:32,414:INFO:_display_container: 4
2025-05-14 21:01:32,414:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best')
2025-05-14 21:01:32,414:INFO:create_model() successfully completed......................................
2025-05-14 21:01:32,492:INFO:SubProcess create_model() end ==================================
2025-05-14 21:01:32,494:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best') result for Recall is 0.1
2025-05-14 21:01:32,494:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best') result for Recall is 0.3
2025-05-14 21:01:32,494:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best') is best model
2025-05-14 21:01:32,494:INFO:choose_better completed
2025-05-14 21:01:32,503:INFO:_master_model_container: 16
2025-05-14 21:01:32,503:INFO:_display_container: 3
2025-05-14 21:01:32,505:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best')
2025-05-14 21:01:32,505:INFO:tune_model() successfully completed......................................
2025-05-14 21:01:32,580:INFO:Initializing plot_model()
2025-05-14 21:01:32,580:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 21:01:32,580:INFO:Checking exceptions
2025-05-14 21:01:32,583:INFO:Preloading libraries
2025-05-14 21:01:32,583:INFO:Copying training dataset
2025-05-14 21:01:32,583:INFO:Plot type: confusion_matrix
2025-05-14 21:01:32,647:INFO:Fitting Model
2025-05-14 21:01:32,647:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-05-14 21:01:32,649:INFO:Scoring test/hold-out set
2025-05-14 21:01:32,746:INFO:Visual Rendered Successfully
2025-05-14 21:01:32,821:INFO:plot_model() successfully completed......................................
2025-05-14 21:01:32,822:INFO:Initializing plot_model()
2025-05-14 21:01:32,822:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best'), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 21:01:32,822:INFO:Checking exceptions
2025-05-14 21:01:32,825:INFO:Preloading libraries
2025-05-14 21:01:32,826:INFO:Copying training dataset
2025-05-14 21:01:32,826:INFO:Plot type: feature
2025-05-14 21:01:32,826:WARNING:No coef_ found. Trying feature_importances_
2025-05-14 21:01:32,974:INFO:Visual Rendered Successfully
2025-05-14 21:01:33,054:INFO:plot_model() successfully completed......................................
2025-05-14 21:01:33,073:INFO:Initializing interpret_model()
2025-05-14 21:01:33,073:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B505950>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=7, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=2,
                       min_samples_split=7, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best'), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 21:01:33,073:INFO:Checking exceptions
2025-05-14 21:01:33,074:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-05-14 21:10:14,576:INFO:PyCaret ClassificationExperiment
2025-05-14 21:10:14,576:INFO:Logging name: clf-default-name
2025-05-14 21:10:14,577:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 21:10:14,578:INFO:version 3.3.2
2025-05-14 21:10:14,578:INFO:Initializing setup()
2025-05-14 21:10:14,579:INFO:self.USI: 7f92
2025-05-14 21:10:14,579:INFO:self._variable_keys: {'n_jobs_param', 'data', 'exp_name_log', 'is_multiclass', 'gpu_n_jobs_param', 'y_train', 'idx', 'USI', 'memory', 'fold_groups_param', 'logging_param', 'seed', 'target_param', 'fix_imbalance', 'y_test', 'pipeline', 'X_train', 'exp_id', '_ml_usecase', 'log_plots_param', 'fold_shuffle_param', '_available_plots', 'fold_generator', 'X', 'y', 'gpu_param', 'html_param', 'X_test'}
2025-05-14 21:10:14,579:INFO:Checking environment
2025-05-14 21:10:14,579:INFO:python_version: 3.11.8
2025-05-14 21:10:14,579:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-14 21:10:14,579:INFO:machine: AMD64
2025-05-14 21:10:14,580:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-14 21:10:14,587:INFO:Memory: svmem(total=16907886592, available=4165312512, percent=75.4, used=12742574080, free=4165312512)
2025-05-14 21:10:14,587:INFO:Physical Core: 4
2025-05-14 21:10:14,587:INFO:Logical Core: 8
2025-05-14 21:10:14,587:INFO:Checking libraries
2025-05-14 21:10:14,587:INFO:System:
2025-05-14 21:10:14,587:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-14 21:10:14,588:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-14 21:10:14,588:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-14 21:10:14,588:INFO:PyCaret required dependencies:
2025-05-14 21:10:14,588:INFO:                 pip: 24.0
2025-05-14 21:10:14,588:INFO:          setuptools: 65.5.0
2025-05-14 21:10:14,588:INFO:             pycaret: 3.3.2
2025-05-14 21:10:14,588:INFO:             IPython: 9.2.0
2025-05-14 21:10:14,588:INFO:          ipywidgets: 8.1.7
2025-05-14 21:10:14,588:INFO:                tqdm: 4.67.1
2025-05-14 21:10:14,588:INFO:               numpy: 1.26.4
2025-05-14 21:10:14,589:INFO:              pandas: 2.1.4
2025-05-14 21:10:14,589:INFO:              jinja2: 3.1.6
2025-05-14 21:10:14,589:INFO:               scipy: 1.11.4
2025-05-14 21:10:14,589:INFO:              joblib: 1.3.2
2025-05-14 21:10:14,589:INFO:             sklearn: 1.4.2
2025-05-14 21:10:14,589:INFO:                pyod: 2.0.5
2025-05-14 21:10:14,589:INFO:            imblearn: 0.13.0
2025-05-14 21:10:14,589:INFO:   category_encoders: 2.7.0
2025-05-14 21:10:14,589:INFO:            lightgbm: 4.6.0
2025-05-14 21:10:14,590:INFO:               numba: 0.61.2
2025-05-14 21:10:14,590:INFO:            requests: 2.32.3
2025-05-14 21:10:14,590:INFO:          matplotlib: 3.7.5
2025-05-14 21:10:14,590:INFO:          scikitplot: 0.3.7
2025-05-14 21:10:14,590:INFO:         yellowbrick: 1.5
2025-05-14 21:10:14,590:INFO:              plotly: 5.24.1
2025-05-14 21:10:14,590:INFO:    plotly-resampler: Not installed
2025-05-14 21:10:14,590:INFO:             kaleido: 0.2.1
2025-05-14 21:10:14,590:INFO:           schemdraw: 0.15
2025-05-14 21:10:14,591:INFO:         statsmodels: 0.14.4
2025-05-14 21:10:14,591:INFO:              sktime: 0.26.0
2025-05-14 21:10:14,591:INFO:               tbats: 1.1.3
2025-05-14 21:10:14,591:INFO:            pmdarima: 2.0.4
2025-05-14 21:10:14,591:INFO:              psutil: 7.0.0
2025-05-14 21:10:14,592:INFO:          markupsafe: 3.0.2
2025-05-14 21:10:14,592:INFO:             pickle5: Not installed
2025-05-14 21:10:14,592:INFO:         cloudpickle: 3.1.1
2025-05-14 21:10:14,592:INFO:         deprecation: 2.1.0
2025-05-14 21:10:14,592:INFO:              xxhash: 3.5.0
2025-05-14 21:10:14,592:INFO:           wurlitzer: Not installed
2025-05-14 21:10:14,592:INFO:PyCaret optional dependencies:
2025-05-14 21:10:14,593:INFO:                shap: Not installed
2025-05-14 21:10:14,593:INFO:           interpret: Not installed
2025-05-14 21:10:14,593:INFO:                umap: Not installed
2025-05-14 21:10:14,593:INFO:     ydata_profiling: Not installed
2025-05-14 21:10:14,593:INFO:  explainerdashboard: Not installed
2025-05-14 21:10:14,593:INFO:             autoviz: Not installed
2025-05-14 21:10:14,593:INFO:           fairlearn: Not installed
2025-05-14 21:10:14,593:INFO:          deepchecks: Not installed
2025-05-14 21:10:14,593:INFO:             xgboost: Not installed
2025-05-14 21:10:14,594:INFO:            catboost: Not installed
2025-05-14 21:10:14,594:INFO:              kmodes: Not installed
2025-05-14 21:10:14,594:INFO:             mlxtend: Not installed
2025-05-14 21:10:14,594:INFO:       statsforecast: Not installed
2025-05-14 21:10:14,594:INFO:        tune_sklearn: Not installed
2025-05-14 21:10:14,594:INFO:                 ray: Not installed
2025-05-14 21:10:14,594:INFO:            hyperopt: Not installed
2025-05-14 21:10:14,594:INFO:              optuna: Not installed
2025-05-14 21:10:14,595:INFO:               skopt: Not installed
2025-05-14 21:10:14,595:INFO:              mlflow: Not installed
2025-05-14 21:10:14,595:INFO:              gradio: Not installed
2025-05-14 21:10:14,595:INFO:             fastapi: Not installed
2025-05-14 21:10:14,595:INFO:             uvicorn: Not installed
2025-05-14 21:10:14,595:INFO:              m2cgen: Not installed
2025-05-14 21:10:14,595:INFO:           evidently: Not installed
2025-05-14 21:10:14,596:INFO:               fugue: Not installed
2025-05-14 21:10:14,596:INFO:           streamlit: Not installed
2025-05-14 21:10:14,596:INFO:             prophet: Not installed
2025-05-14 21:10:14,596:INFO:None
2025-05-14 21:10:14,596:INFO:Set up data.
2025-05-14 21:10:14,618:INFO:Set up folding strategy.
2025-05-14 21:10:14,623:INFO:Set up train/test split.
2025-05-14 21:10:14,639:INFO:Set up index.
2025-05-14 21:10:14,639:INFO:Assigning column types.
2025-05-14 21:10:14,652:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 21:10:14,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 21:10:14,885:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:10:14,971:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:14,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:15,085:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 21:10:15,086:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:10:15,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:15,141:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:15,141:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 21:10:15,224:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:10:15,282:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:15,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:15,422:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:10:15,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:15,522:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:15,522:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 21:10:15,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:15,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:15,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:15,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:15,875:INFO:Preparing preprocessing pipeline...
2025-05-14 21:10:15,877:INFO:Set up simple imputation.
2025-05-14 21:10:15,882:INFO:Set up encoding of ordinal features.
2025-05-14 21:10:15,884:INFO:Set up encoding of categorical features.
2025-05-14 21:10:15,885:INFO:Set up removing multicollinearity.
2025-05-14 21:10:15,885:INFO:Set up imbalanced handling.
2025-05-14 21:10:15,885:INFO:Set up feature normalization.
2025-05-14 21:10:16,403:INFO:Finished creating preprocessing pipeline.
2025-05-14 21:10:16,426:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['monto_credito',
                                             'mujer_emprendedora', 'hijos'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer'...
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=999,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-14 21:10:16,426:INFO:Creating final display dataframe.
2025-05-14 21:10:16,673:INFO:Setup _display_container:                     Description             Value
0                    Session id               999
1                        Target           default
2                   Target type            Binary
3           Original data shape          (144, 7)
4        Transformed data shape          (226, 8)
5   Transformed train set shape          (182, 8)
6    Transformed test set shape           (44, 8)
7               Ignore features                 1
8              Numeric features                 3
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.8
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                    Normalize              True
21             Normalize method            zscore
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              7f92
2025-05-14 21:10:16,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:16,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:16,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:16,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:10:16,964:INFO:setup() successfully completed in 2.39s...............
2025-05-14 21:10:16,988:INFO:Initializing compare_models()
2025-05-14 21:10:16,988:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 21:10:16,988:INFO:Checking exceptions
2025-05-14 21:10:16,991:INFO:Preparing display monitor
2025-05-14 21:10:17,021:INFO:Initializing Logistic Regression
2025-05-14 21:10:17,022:INFO:Total runtime is 1.6681353251139323e-05 minutes
2025-05-14 21:10:17,027:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:17,029:INFO:Initializing create_model()
2025-05-14 21:10:17,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E823850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:17,029:INFO:Checking exceptions
2025-05-14 21:10:17,029:INFO:Importing libraries
2025-05-14 21:10:17,030:INFO:Copying training dataset
2025-05-14 21:10:17,034:INFO:Defining folds
2025-05-14 21:10:17,034:INFO:Declaring metric variables
2025-05-14 21:10:17,039:INFO:Importing untrained model
2025-05-14 21:10:17,044:INFO:Logistic Regression Imported successfully
2025-05-14 21:10:17,054:INFO:Starting cross validation
2025-05-14 21:10:17,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:17,061:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:27,940:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:27,949:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:28,040:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:28,264:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:28,580:INFO:Calculating mean and std
2025-05-14 21:10:28,582:INFO:Creating metrics dataframe
2025-05-14 21:10:28,584:INFO:Uploading results into container
2025-05-14 21:10:28,585:INFO:Uploading model into container now
2025-05-14 21:10:28,585:INFO:_master_model_container: 1
2025-05-14 21:10:28,586:INFO:_display_container: 2
2025-05-14 21:10:28,586:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 21:10:28,586:INFO:create_model() successfully completed......................................
2025-05-14 21:10:28,685:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:28,685:INFO:Creating metrics dataframe
2025-05-14 21:10:28,692:INFO:Initializing K Neighbors Classifier
2025-05-14 21:10:28,692:INFO:Total runtime is 0.19451628923416137 minutes
2025-05-14 21:10:28,707:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:28,709:INFO:Initializing create_model()
2025-05-14 21:10:28,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E823850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:28,709:INFO:Checking exceptions
2025-05-14 21:10:28,709:INFO:Importing libraries
2025-05-14 21:10:28,709:INFO:Copying training dataset
2025-05-14 21:10:28,716:INFO:Defining folds
2025-05-14 21:10:28,716:INFO:Declaring metric variables
2025-05-14 21:10:28,721:INFO:Importing untrained model
2025-05-14 21:10:28,727:INFO:K Neighbors Classifier Imported successfully
2025-05-14 21:10:28,735:INFO:Starting cross validation
2025-05-14 21:10:28,738:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:28,742:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:28,994:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:28,999:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

lt))

2025-05-14 21:10:29,171:INFO:Calculating mean and std
2025-05-14 21:10:29,172:INFO:Creating metrics dataframe
2025-05-14 21:10:29,174:INFO:Uploading results into container
2025-05-14 21:10:29,175:INFO:Uploading model into container now
2025-05-14 21:10:29,175:INFO:_master_model_container: 2
2025-05-14 21:10:29,175:INFO:_display_container: 2
2025-05-14 21:10:29,175:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 21:10:29,176:INFO:create_model() successfully completed......................................
2025-05-14 21:10:29,270:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:29,270:INFO:Creating metrics dataframe
2025-05-14 21:10:29,278:INFO:Initializing Naive Bayes
2025-05-14 21:10:29,278:INFO:Total runtime is 0.204272186756134 minutes
2025-05-14 21:10:29,283:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:29,283:INFO:Initializing create_model()
2025-05-14 21:10:29,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E823850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:29,283:INFO:Checking exceptions
2025-05-14 21:10:29,283:INFO:Importing libraries
2025-05-14 21:10:29,284:INFO:Copying training dataset
2025-05-14 21:10:29,288:INFO:Defining folds
2025-05-14 21:10:29,288:INFO:Declaring metric variables
2025-05-14 21:10:29,291:INFO:Importing untrained model
2025-05-14 21:10:29,295:INFO:Naive Bayes Imported successfully
2025-05-14 21:10:29,317:INFO:Starting cross validation
2025-05-14 21:10:29,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:29,369:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:29,571:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:29,577:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:29,608:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:29,711:INFO:Calculating mean and std
2025-05-14 21:10:29,713:INFO:Creating metrics dataframe
2025-05-14 21:10:29,716:INFO:Uploading results into container
2025-05-14 21:10:29,717:INFO:Uploading model into container now
2025-05-14 21:10:29,717:INFO:_master_model_container: 3
2025-05-14 21:10:29,717:INFO:_display_container: 2
2025-05-14 21:10:29,717:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:10:29,717:INFO:create_model() successfully completed......................................
2025-05-14 21:10:29,813:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:29,814:INFO:Creating metrics dataframe
2025-05-14 21:10:29,823:INFO:Initializing Decision Tree Classifier
2025-05-14 21:10:29,823:INFO:Total runtime is 0.21336410840352374 minutes
2025-05-14 21:10:29,827:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:29,829:INFO:Initializing create_model()
2025-05-14 21:10:29,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E823850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:29,829:INFO:Checking exceptions
2025-05-14 21:10:29,829:INFO:Importing libraries
2025-05-14 21:10:29,829:INFO:Copying training dataset
2025-05-14 21:10:29,833:INFO:Defining folds
2025-05-14 21:10:29,833:INFO:Declaring metric variables
2025-05-14 21:10:29,838:INFO:Importing untrained model
2025-05-14 21:10:29,842:INFO:Decision Tree Classifier Imported successfully
2025-05-14 21:10:29,852:INFO:Starting cross validation
2025-05-14 21:10:29,853:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:29,856:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:30,022:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:30,028:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:30,037:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:30,045:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:30,166:INFO:Calculating mean and std
2025-05-14 21:10:30,167:INFO:Creating metrics dataframe
2025-05-14 21:10:30,169:INFO:Uploading results into container
2025-05-14 21:10:30,169:INFO:Uploading model into container now
2025-05-14 21:10:30,170:INFO:_master_model_container: 4
2025-05-14 21:10:30,170:INFO:_display_container: 2
2025-05-14 21:10:30,170:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best')
2025-05-14 21:10:30,171:INFO:create_model() successfully completed......................................
2025-05-14 21:10:30,270:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:30,270:INFO:Creating metrics dataframe
2025-05-14 21:10:30,281:INFO:Initializing SVM - Linear Kernel
2025-05-14 21:10:30,281:INFO:Total runtime is 0.22099097172419227 minutes
2025-05-14 21:10:30,284:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:30,284:INFO:Initializing create_model()
2025-05-14 21:10:30,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E823850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:30,285:INFO:Checking exceptions
2025-05-14 21:10:30,285:INFO:Importing libraries
2025-05-14 21:10:30,285:INFO:Copying training dataset
2025-05-14 21:10:30,290:INFO:Defining folds
2025-05-14 21:10:30,290:INFO:Declaring metric variables
2025-05-14 21:10:30,294:INFO:Importing untrained model
2025-05-14 21:10:30,300:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 21:10:30,309:INFO:Starting cross validation
2025-05-14 21:10:30,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:30,313:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:30,480:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:30,484:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:30,515:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:30,624:INFO:Calculating mean and std
2025-05-14 21:10:30,625:INFO:Creating metrics dataframe
2025-05-14 21:10:30,627:INFO:Uploading results into container
2025-05-14 21:10:30,628:INFO:Uploading model into container now
2025-05-14 21:10:30,628:INFO:_master_model_container: 5
2025-05-14 21:10:30,628:INFO:_display_container: 2
2025-05-14 21:10:30,630:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=999, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 21:10:30,630:INFO:create_model() successfully completed......................................
2025-05-14 21:10:30,727:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:30,727:INFO:Creating metrics dataframe
2025-05-14 21:10:30,736:INFO:Initializing Ridge Classifier
2025-05-14 21:10:30,736:INFO:Total runtime is 0.2285802086194356 minutes
2025-05-14 21:10:30,741:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:30,741:INFO:Initializing create_model()
2025-05-14 21:10:30,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E823850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:30,741:INFO:Checking exceptions
2025-05-14 21:10:30,741:INFO:Importing libraries
2025-05-14 21:10:30,741:INFO:Copying training dataset
2025-05-14 21:10:30,746:INFO:Defining folds
2025-05-14 21:10:30,746:INFO:Declaring metric variables
2025-05-14 21:10:30,752:INFO:Importing untrained model
2025-05-14 21:10:30,756:INFO:Ridge Classifier Imported successfully
2025-05-14 21:10:30,765:INFO:Starting cross validation
2025-05-14 21:10:30,768:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:30,771:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:30,937:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:30,940:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:30,943:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:30,952:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:31,066:INFO:Calculating mean and std
2025-05-14 21:10:31,067:INFO:Creating metrics dataframe
2025-05-14 21:10:31,072:INFO:Uploading results into container
2025-05-14 21:10:31,072:INFO:Uploading model into container now
2025-05-14 21:10:31,073:INFO:_master_model_container: 6
2025-05-14 21:10:31,073:INFO:_display_container: 2
2025-05-14 21:10:31,073:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=999, solver='auto',
                tol=0.0001)
2025-05-14 21:10:31,073:INFO:create_model() successfully completed......................................
2025-05-14 21:10:31,170:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:31,170:INFO:Creating metrics dataframe
2025-05-14 21:10:31,180:INFO:Initializing Random Forest Classifier
2025-05-14 21:10:31,180:INFO:Total runtime is 0.23596959511439003 minutes
2025-05-14 21:10:31,184:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:31,184:INFO:Initializing create_model()
2025-05-14 21:10:31,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E823850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:31,184:INFO:Checking exceptions
2025-05-14 21:10:31,184:INFO:Importing libraries
2025-05-14 21:10:31,184:INFO:Copying training dataset
2025-05-14 21:10:31,189:INFO:Defining folds
2025-05-14 21:10:31,189:INFO:Declaring metric variables
2025-05-14 21:10:31,196:INFO:Importing untrained model
2025-05-14 21:10:31,202:INFO:Random Forest Classifier Imported successfully
2025-05-14 21:10:31,214:INFO:Starting cross validation
2025-05-14 21:10:31,216:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:31,221:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:31,912:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:31,923:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:31,934:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:31,939:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:31,944:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:31,950:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:31,954:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:10:31,954:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:10:31,958:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:10:32,020:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:32,399:INFO:Calculating mean and std
2025-05-14 21:10:32,401:INFO:Creating metrics dataframe
2025-05-14 21:10:32,402:INFO:Uploading results into container
2025-05-14 21:10:32,403:INFO:Uploading model into container now
2025-05-14 21:10:32,403:INFO:_master_model_container: 7
2025-05-14 21:10:32,403:INFO:_display_container: 2
2025-05-14 21:10:32,405:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=999, verbose=0,
                       warm_start=False)
2025-05-14 21:10:32,405:INFO:create_model() successfully completed......................................
2025-05-14 21:10:32,513:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:32,513:INFO:Creating metrics dataframe
2025-05-14 21:10:32,525:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 21:10:32,525:INFO:Total runtime is 0.2583863298098246 minutes
2025-05-14 21:10:32,531:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:32,531:INFO:Initializing create_model()
2025-05-14 21:10:32,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E823850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:32,532:INFO:Checking exceptions
2025-05-14 21:10:32,532:INFO:Importing libraries
2025-05-14 21:10:32,532:INFO:Copying training dataset
2025-05-14 21:10:32,537:INFO:Defining folds
2025-05-14 21:10:32,537:INFO:Declaring metric variables
2025-05-14 21:10:32,543:INFO:Importing untrained model
2025-05-14 21:10:32,550:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 21:10:32,561:INFO:Starting cross validation
2025-05-14 21:10:32,563:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:32,570:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:32,705:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:10:32,710:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:10:32,713:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:10:32,717:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:10:32,718:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:10:32,723:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:10:32,728:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:10:32,742:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:10:32,775:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:32,784:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:32,794:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:32,822:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:32,891:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:10:32,897:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:10:32,951:INFO:Calculating mean and std
2025-05-14 21:10:32,952:INFO:Creating metrics dataframe
2025-05-14 21:10:32,954:INFO:Uploading results into container
2025-05-14 21:10:32,955:INFO:Uploading model into container now
2025-05-14 21:10:32,956:INFO:_master_model_container: 8
2025-05-14 21:10:32,956:INFO:_display_container: 2
2025-05-14 21:10:32,956:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 21:10:32,956:INFO:create_model() successfully completed......................................
2025-05-14 21:10:33,059:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:33,059:INFO:Creating metrics dataframe
2025-05-14 21:10:33,070:INFO:Initializing Ada Boost Classifier
2025-05-14 21:10:33,071:INFO:Total runtime is 0.2675002654393514 minutes
2025-05-14 21:10:33,076:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:33,078:INFO:Initializing create_model()
2025-05-14 21:10:33,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E823850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:33,078:INFO:Checking exceptions
2025-05-14 21:10:33,078:INFO:Importing libraries
2025-05-14 21:10:33,078:INFO:Copying training dataset
2025-05-14 21:10:33,082:INFO:Defining folds
2025-05-14 21:10:33,083:INFO:Declaring metric variables
2025-05-14 21:10:33,088:INFO:Importing untrained model
2025-05-14 21:10:33,094:INFO:Ada Boost Classifier Imported successfully
2025-05-14 21:10:33,104:INFO:Starting cross validation
2025-05-14 21:10:33,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:33,111:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:33,269:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:10:33,369:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:10:33,394:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:10:33,407:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:10:33,414:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:10:33,452:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:10:33,480:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:10:33,503:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:10:33,650:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:33,732:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:33,738:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:33,795:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:10:33,810:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:33,848:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:10:34,130:INFO:Calculating mean and std
2025-05-14 21:10:34,133:INFO:Creating metrics dataframe
2025-05-14 21:10:34,137:INFO:Uploading results into container
2025-05-14 21:10:34,138:INFO:Uploading model into container now
2025-05-14 21:10:34,140:INFO:_master_model_container: 9
2025-05-14 21:10:34,140:INFO:_display_container: 2
2025-05-14 21:10:34,140:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=999)
2025-05-14 21:10:34,140:INFO:create_model() successfully completed......................................
2025-05-14 21:10:34,280:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:34,280:INFO:Creating metrics dataframe
2025-05-14 21:10:34,295:INFO:Initializing Gradient Boosting Classifier
2025-05-14 21:10:34,296:INFO:Total runtime is 0.28791290521621704 minutes
2025-05-14 21:10:34,303:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:34,303:INFO:Initializing create_model()
2025-05-14 21:10:34,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E823850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:34,304:INFO:Checking exceptions
2025-05-14 21:10:34,304:INFO:Importing libraries
2025-05-14 21:10:34,304:INFO:Copying training dataset
2025-05-14 21:10:34,312:INFO:Defining folds
2025-05-14 21:10:34,312:INFO:Declaring metric variables
2025-05-14 21:10:34,319:INFO:Importing untrained model
2025-05-14 21:10:34,325:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 21:10:34,338:INFO:Starting cross validation
2025-05-14 21:10:34,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:34,344:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:34,773:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:34,778:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:34,779:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:34,789:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:34,793:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:34,794:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:34,799:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:10:34,799:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:10:34,809:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:10:35,169:INFO:Calculating mean and std
2025-05-14 21:10:35,172:INFO:Creating metrics dataframe
2025-05-14 21:10:35,176:INFO:Uploading results into container
2025-05-14 21:10:35,177:INFO:Uploading model into container now
2025-05-14 21:10:35,179:INFO:_master_model_container: 10
2025-05-14 21:10:35,179:INFO:_display_container: 2
2025-05-14 21:10:35,180:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=999, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 21:10:35,180:INFO:create_model() successfully completed......................................
2025-05-14 21:10:35,310:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:35,310:INFO:Creating metrics dataframe
2025-05-14 21:10:35,331:INFO:Initializing Linear Discriminant Analysis
2025-05-14 21:10:35,331:INFO:Total runtime is 0.3051576336224874 minutes
2025-05-14 21:10:35,337:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:35,339:INFO:Initializing create_model()
2025-05-14 21:10:35,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E823850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:35,339:INFO:Checking exceptions
2025-05-14 21:10:35,339:INFO:Importing libraries
2025-05-14 21:10:35,339:INFO:Copying training dataset
2025-05-14 21:10:35,350:INFO:Defining folds
2025-05-14 21:10:35,350:INFO:Declaring metric variables
2025-05-14 21:10:35,360:INFO:Importing untrained model
2025-05-14 21:10:35,367:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 21:10:35,379:INFO:Starting cross validation
2025-05-14 21:10:35,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:35,385:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:35,580:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:35,626:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:35,630:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:35,650:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:35,772:INFO:Calculating mean and std
2025-05-14 21:10:35,774:INFO:Creating metrics dataframe
2025-05-14 21:10:35,779:INFO:Uploading results into container
2025-05-14 21:10:35,780:INFO:Uploading model into container now
2025-05-14 21:10:35,782:INFO:_master_model_container: 11
2025-05-14 21:10:35,782:INFO:_display_container: 2
2025-05-14 21:10:35,782:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 21:10:35,783:INFO:create_model() successfully completed......................................
2025-05-14 21:10:35,915:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:35,915:INFO:Creating metrics dataframe
2025-05-14 21:10:35,938:INFO:Initializing Extra Trees Classifier
2025-05-14 21:10:35,938:INFO:Total runtime is 0.3152690450350443 minutes
2025-05-14 21:10:35,946:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:35,947:INFO:Initializing create_model()
2025-05-14 21:10:35,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E823850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:35,948:INFO:Checking exceptions
2025-05-14 21:10:35,948:INFO:Importing libraries
2025-05-14 21:10:35,948:INFO:Copying training dataset
2025-05-14 21:10:35,954:INFO:Defining folds
2025-05-14 21:10:35,954:INFO:Declaring metric variables
2025-05-14 21:10:35,963:INFO:Importing untrained model
2025-05-14 21:10:35,969:INFO:Extra Trees Classifier Imported successfully
2025-05-14 21:10:35,979:INFO:Starting cross validation
2025-05-14 21:10:35,982:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:35,987:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:36,639:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:36,638:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:36,644:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:36,645:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:36,652:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:36,658:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:36,662:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:36,665:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:10:36,665:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:10:36,670:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:10:36,755:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:37,167:INFO:Calculating mean and std
2025-05-14 21:10:37,169:INFO:Creating metrics dataframe
2025-05-14 21:10:37,173:INFO:Uploading results into container
2025-05-14 21:10:37,173:INFO:Uploading model into container now
2025-05-14 21:10:37,174:INFO:_master_model_container: 12
2025-05-14 21:10:37,174:INFO:_display_container: 2
2025-05-14 21:10:37,176:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=999, verbose=0,
                     warm_start=False)
2025-05-14 21:10:37,176:INFO:create_model() successfully completed......................................
2025-05-14 21:10:37,293:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:37,293:INFO:Creating metrics dataframe
2025-05-14 21:10:37,308:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 21:10:37,308:INFO:Total runtime is 0.3381086707115173 minutes
2025-05-14 21:10:37,312:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:37,313:INFO:Initializing create_model()
2025-05-14 21:10:37,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E823850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:37,313:INFO:Checking exceptions
2025-05-14 21:10:37,313:INFO:Importing libraries
2025-05-14 21:10:37,313:INFO:Copying training dataset
2025-05-14 21:10:37,320:INFO:Defining folds
2025-05-14 21:10:37,320:INFO:Declaring metric variables
2025-05-14 21:10:37,327:INFO:Importing untrained model
2025-05-14 21:10:37,335:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 21:10:37,346:INFO:Starting cross validation
2025-05-14 21:10:37,348:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:37,350:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:38,008:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:38,235:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:38,239:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:38,241:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:38,248:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:38,253:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:38,256:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:10:38,258:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:10:38,261:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:10:38,453:INFO:Calculating mean and std
2025-05-14 21:10:38,458:INFO:Creating metrics dataframe
2025-05-14 21:10:38,463:INFO:Uploading results into container
2025-05-14 21:10:38,464:INFO:Uploading model into container now
2025-05-14 21:10:38,465:INFO:_master_model_container: 13
2025-05-14 21:10:38,465:INFO:_display_container: 2
2025-05-14 21:10:38,468:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=999, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 21:10:38,469:INFO:create_model() successfully completed......................................
2025-05-14 21:10:38,620:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:38,620:INFO:Creating metrics dataframe
2025-05-14 21:10:38,642:INFO:Initializing Dummy Classifier
2025-05-14 21:10:38,643:INFO:Total runtime is 0.360366145769755 minutes
2025-05-14 21:10:38,649:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:38,650:INFO:Initializing create_model()
2025-05-14 21:10:38,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E823850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:38,651:INFO:Checking exceptions
2025-05-14 21:10:38,651:INFO:Importing libraries
2025-05-14 21:10:38,651:INFO:Copying training dataset
2025-05-14 21:10:38,660:INFO:Defining folds
2025-05-14 21:10:38,660:INFO:Declaring metric variables
2025-05-14 21:10:38,667:INFO:Importing untrained model
2025-05-14 21:10:38,675:INFO:Dummy Classifier Imported successfully
2025-05-14 21:10:38,686:INFO:Starting cross validation
2025-05-14 21:10:38,691:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:38,694:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:38,931:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:38,933:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:38,945:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:38,963:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:38,963:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:38,970:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:38,976:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:38,979:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:38,981:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:38,982:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:38,986:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:10:38,987:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:10:38,992:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:10:38,996:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:39,107:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:39,112:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:39,127:INFO:Calculating mean and std
2025-05-14 21:10:39,129:INFO:Creating metrics dataframe
2025-05-14 21:10:39,131:INFO:Uploading results into container
2025-05-14 21:10:39,132:INFO:Uploading model into container now
2025-05-14 21:10:39,132:INFO:_master_model_container: 14
2025-05-14 21:10:39,132:INFO:_display_container: 2
2025-05-14 21:10:39,133:INFO:DummyClassifier(constant=None, random_state=999, strategy='prior')
2025-05-14 21:10:39,133:INFO:create_model() successfully completed......................................
2025-05-14 21:10:39,274:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:39,276:INFO:Creating metrics dataframe
2025-05-14 21:10:39,294:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-14 21:10:39,312:INFO:Initializing create_model()
2025-05-14 21:10:39,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:39,313:INFO:Checking exceptions
2025-05-14 21:10:39,317:INFO:Importing libraries
2025-05-14 21:10:39,317:INFO:Copying training dataset
2025-05-14 21:10:39,325:INFO:Defining folds
2025-05-14 21:10:39,326:INFO:Declaring metric variables
2025-05-14 21:10:39,326:INFO:Importing untrained model
2025-05-14 21:10:39,326:INFO:Declaring custom model
2025-05-14 21:10:39,327:INFO:Naive Bayes Imported successfully
2025-05-14 21:10:39,330:INFO:Cross validation set to False
2025-05-14 21:10:39,330:INFO:Fitting Model
2025-05-14 21:10:39,405:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:10:39,405:INFO:create_model() successfully completed......................................
2025-05-14 21:10:39,577:INFO:_master_model_container: 14
2025-05-14 21:10:39,577:INFO:_display_container: 2
2025-05-14 21:10:39,579:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:10:39,579:INFO:compare_models() successfully completed......................................
2025-05-14 21:10:39,641:INFO:Initializing tune_model()
2025-05-14 21:10:39,642:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 21:10:39,642:INFO:Checking exceptions
2025-05-14 21:10:39,668:INFO:Copying training dataset
2025-05-14 21:10:39,673:INFO:Checking base model
2025-05-14 21:10:39,673:INFO:Base model : Naive Bayes
2025-05-14 21:10:39,679:INFO:Declaring metric variables
2025-05-14 21:10:39,686:INFO:Defining Hyperparameters
2025-05-14 21:10:39,814:INFO:Tuning with n_jobs=-1
2025-05-14 21:10:39,814:INFO:Initializing RandomizedSearchCV
2025-05-14 21:10:39,820:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:40,002:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:40,249:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:40,440:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:40,473:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:40,866:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:41,375:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:41,507:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:41,828:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:42,102:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:42,321:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:42,631:INFO:best_params: {'actual_estimator__var_smoothing': 1e-09}
2025-05-14 21:10:42,632:INFO:Hyperparameter search completed
2025-05-14 21:10:42,633:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:42,634:INFO:Initializing create_model()
2025-05-14 21:10:42,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07B516390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 1e-09})
2025-05-14 21:10:42,635:INFO:Checking exceptions
2025-05-14 21:10:42,635:INFO:Importing libraries
2025-05-14 21:10:42,635:INFO:Copying training dataset
2025-05-14 21:10:42,647:INFO:Defining folds
2025-05-14 21:10:42,647:INFO:Declaring metric variables
2025-05-14 21:10:42,655:INFO:Importing untrained model
2025-05-14 21:10:42,655:INFO:Declaring custom model
2025-05-14 21:10:42,663:INFO:Naive Bayes Imported successfully
2025-05-14 21:10:42,692:INFO:Starting cross validation
2025-05-14 21:10:42,696:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:42,702:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:42,969:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:42,978:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:43,007:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:43,152:INFO:Calculating mean and std
2025-05-14 21:10:43,155:INFO:Creating metrics dataframe
2025-05-14 21:10:43,164:INFO:Finalizing model
2025-05-14 21:10:43,272:INFO:Uploading results into container
2025-05-14 21:10:43,273:INFO:Uploading model into container now
2025-05-14 21:10:43,273:INFO:_master_model_container: 15
2025-05-14 21:10:43,274:INFO:_display_container: 3
2025-05-14 21:10:43,274:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:10:43,274:INFO:create_model() successfully completed......................................
2025-05-14 21:10:43,390:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:43,390:INFO:choose_better activated
2025-05-14 21:10:43,395:INFO:SubProcess create_model() called ==================================
2025-05-14 21:10:43,396:INFO:Initializing create_model()
2025-05-14 21:10:43,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:10:43,397:INFO:Checking exceptions
2025-05-14 21:10:43,399:INFO:Importing libraries
2025-05-14 21:10:43,399:INFO:Copying training dataset
2025-05-14 21:10:43,402:INFO:Defining folds
2025-05-14 21:10:43,402:INFO:Declaring metric variables
2025-05-14 21:10:43,403:INFO:Importing untrained model
2025-05-14 21:10:43,403:INFO:Declaring custom model
2025-05-14 21:10:43,403:INFO:Naive Bayes Imported successfully
2025-05-14 21:10:43,403:INFO:Starting cross validation
2025-05-14 21:10:43,405:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:10:43,408:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:10:43,565:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:10:43,570:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:43,583:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:10:43,733:INFO:Calculating mean and std
2025-05-14 21:10:43,734:INFO:Creating metrics dataframe
2025-05-14 21:10:43,737:INFO:Finalizing model
2025-05-14 21:10:43,809:INFO:Uploading results into container
2025-05-14 21:10:43,810:INFO:Uploading model into container now
2025-05-14 21:10:43,810:INFO:_master_model_container: 16
2025-05-14 21:10:43,811:INFO:_display_container: 4
2025-05-14 21:10:43,811:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:10:43,811:INFO:create_model() successfully completed......................................
2025-05-14 21:10:43,913:INFO:SubProcess create_model() end ==================================
2025-05-14 21:10:43,914:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5
2025-05-14 21:10:43,914:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5
2025-05-14 21:10:43,915:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2025-05-14 21:10:43,915:INFO:choose_better completed
2025-05-14 21:10:43,915:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-14 21:10:43,927:INFO:_master_model_container: 16
2025-05-14 21:10:43,927:INFO:_display_container: 3
2025-05-14 21:10:43,929:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:10:43,929:INFO:tune_model() successfully completed......................................
2025-05-14 21:10:44,030:INFO:Initializing plot_model()
2025-05-14 21:10:44,031:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 21:10:44,031:INFO:Checking exceptions
2025-05-14 21:10:44,035:INFO:Preloading libraries
2025-05-14 21:10:44,035:INFO:Copying training dataset
2025-05-14 21:10:44,035:INFO:Plot type: confusion_matrix
2025-05-14 21:10:44,354:INFO:Fitting Model
2025-05-14 21:10:44,354:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-05-14 21:10:44,355:INFO:Scoring test/hold-out set
2025-05-14 21:10:44,483:INFO:Visual Rendered Successfully
2025-05-14 21:10:44,588:INFO:plot_model() successfully completed......................................
2025-05-14 21:10:44,588:INFO:Initializing plot_model()
2025-05-14 21:10:44,589:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 21:10:44,589:INFO:Checking exceptions
2025-05-14 21:14:47,441:INFO:Initializing tune_model()
2025-05-14 21:14:47,441:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 21:14:47,441:INFO:Checking exceptions
2025-05-14 21:14:47,458:INFO:Copying training dataset
2025-05-14 21:14:47,461:INFO:Checking base model
2025-05-14 21:14:47,461:INFO:Base model : Naive Bayes
2025-05-14 21:14:47,464:INFO:Declaring metric variables
2025-05-14 21:14:47,469:INFO:Defining Hyperparameters
2025-05-14 21:14:47,624:INFO:Tuning with n_jobs=-1
2025-05-14 21:14:47,624:INFO:Initializing RandomizedSearchCV
2025-05-14 21:14:47,628:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:14:47,757:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:14:47,888:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:14:48,024:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:14:48,064:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:14:48,323:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:14:48,556:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:14:48,632:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:14:48,879:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:14:49,080:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:14:49,182:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:14:49,391:INFO:best_params: {'actual_estimator__var_smoothing': 1e-09}
2025-05-14 21:14:49,392:INFO:Hyperparameter search completed
2025-05-14 21:14:49,392:INFO:SubProcess create_model() called ==================================
2025-05-14 21:14:49,392:INFO:Initializing create_model()
2025-05-14 21:14:49,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E8F9850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 1e-09})
2025-05-14 21:14:49,393:INFO:Checking exceptions
2025-05-14 21:14:49,393:INFO:Importing libraries
2025-05-14 21:14:49,393:INFO:Copying training dataset
2025-05-14 21:14:49,397:INFO:Defining folds
2025-05-14 21:14:49,397:INFO:Declaring metric variables
2025-05-14 21:14:49,401:INFO:Importing untrained model
2025-05-14 21:14:49,401:INFO:Declaring custom model
2025-05-14 21:14:49,405:INFO:Naive Bayes Imported successfully
2025-05-14 21:14:49,412:INFO:Starting cross validation
2025-05-14 21:14:49,414:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:14:49,417:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:14:49,604:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:14:49,611:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:14:49,615:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:14:49,765:INFO:Calculating mean and std
2025-05-14 21:14:49,766:INFO:Creating metrics dataframe
2025-05-14 21:14:49,776:INFO:Finalizing model
2025-05-14 21:14:49,861:INFO:Uploading results into container
2025-05-14 21:14:49,862:INFO:Uploading model into container now
2025-05-14 21:14:49,863:INFO:_master_model_container: 17
2025-05-14 21:14:49,863:INFO:_display_container: 4
2025-05-14 21:14:49,863:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:14:49,863:INFO:create_model() successfully completed......................................
2025-05-14 21:14:49,998:INFO:SubProcess create_model() end ==================================
2025-05-14 21:14:49,999:INFO:choose_better activated
2025-05-14 21:14:50,003:INFO:SubProcess create_model() called ==================================
2025-05-14 21:14:50,003:INFO:Initializing create_model()
2025-05-14 21:14:50,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:14:50,003:INFO:Checking exceptions
2025-05-14 21:14:50,006:INFO:Importing libraries
2025-05-14 21:14:50,007:INFO:Copying training dataset
2025-05-14 21:14:50,013:INFO:Defining folds
2025-05-14 21:14:50,014:INFO:Declaring metric variables
2025-05-14 21:14:50,014:INFO:Importing untrained model
2025-05-14 21:14:50,014:INFO:Declaring custom model
2025-05-14 21:14:50,014:INFO:Naive Bayes Imported successfully
2025-05-14 21:14:50,015:INFO:Starting cross validation
2025-05-14 21:14:50,018:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:14:50,022:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:14:50,310:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:14:50,316:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:14:50,328:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:14:50,610:INFO:Calculating mean and std
2025-05-14 21:14:50,611:INFO:Creating metrics dataframe
2025-05-14 21:14:50,616:INFO:Finalizing model
2025-05-14 21:14:50,733:INFO:Uploading results into container
2025-05-14 21:14:50,734:INFO:Uploading model into container now
2025-05-14 21:14:50,735:INFO:_master_model_container: 18
2025-05-14 21:14:50,735:INFO:_display_container: 5
2025-05-14 21:14:50,735:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:14:50,735:INFO:create_model() successfully completed......................................
2025-05-14 21:14:50,884:INFO:SubProcess create_model() end ==================================
2025-05-14 21:14:50,885:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5
2025-05-14 21:14:50,886:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5
2025-05-14 21:14:50,886:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2025-05-14 21:14:50,886:INFO:choose_better completed
2025-05-14 21:14:50,887:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-14 21:14:50,907:INFO:_master_model_container: 18
2025-05-14 21:14:50,907:INFO:_display_container: 4
2025-05-14 21:14:50,908:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:14:50,908:INFO:tune_model() successfully completed......................................
2025-05-14 21:14:51,064:INFO:Initializing plot_model()
2025-05-14 21:14:51,064:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 21:14:51,064:INFO:Checking exceptions
2025-05-14 21:14:51,071:INFO:Preloading libraries
2025-05-14 21:14:51,072:INFO:Copying training dataset
2025-05-14 21:14:51,073:INFO:Plot type: confusion_matrix
2025-05-14 21:14:51,441:INFO:Fitting Model
2025-05-14 21:14:51,441:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-05-14 21:14:51,441:INFO:Scoring test/hold-out set
2025-05-14 21:14:51,605:INFO:Visual Rendered Successfully
2025-05-14 21:14:51,750:INFO:plot_model() successfully completed......................................
2025-05-14 21:14:51,751:INFO:Initializing plot_model()
2025-05-14 21:14:51,751:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 21:14:51,751:INFO:Checking exceptions
2025-05-14 21:15:47,462:INFO:Initializing tune_model()
2025-05-14 21:15:47,462:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 21:15:47,462:INFO:Checking exceptions
2025-05-14 21:15:47,479:INFO:Copying training dataset
2025-05-14 21:15:47,482:INFO:Checking base model
2025-05-14 21:15:47,482:INFO:Base model : Naive Bayes
2025-05-14 21:15:47,486:INFO:Declaring metric variables
2025-05-14 21:15:47,490:INFO:Defining Hyperparameters
2025-05-14 21:15:47,590:INFO:Tuning with n_jobs=-1
2025-05-14 21:15:47,591:INFO:Initializing RandomizedSearchCV
2025-05-14 21:15:47,594:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:15:47,710:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:15:47,865:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:15:47,987:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:15:48,002:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:15:48,278:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:15:48,526:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:15:48,609:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:15:49,237:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:15:49,601:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:15:49,734:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:15:50,031:INFO:best_params: {'actual_estimator__var_smoothing': 1e-09}
2025-05-14 21:15:50,032:INFO:Hyperparameter search completed
2025-05-14 21:15:50,032:INFO:SubProcess create_model() called ==================================
2025-05-14 21:15:50,033:INFO:Initializing create_model()
2025-05-14 21:15:50,033:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B07E695DD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 1e-09})
2025-05-14 21:15:50,034:INFO:Checking exceptions
2025-05-14 21:15:50,034:INFO:Importing libraries
2025-05-14 21:15:50,034:INFO:Copying training dataset
2025-05-14 21:15:50,040:INFO:Defining folds
2025-05-14 21:15:50,041:INFO:Declaring metric variables
2025-05-14 21:15:50,045:INFO:Importing untrained model
2025-05-14 21:15:50,045:INFO:Declaring custom model
2025-05-14 21:15:50,051:INFO:Naive Bayes Imported successfully
2025-05-14 21:15:50,059:INFO:Starting cross validation
2025-05-14 21:15:50,062:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:15:50,068:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:15:50,310:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:15:50,336:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:15:50,342:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:15:50,521:INFO:Calculating mean and std
2025-05-14 21:15:50,523:INFO:Creating metrics dataframe
2025-05-14 21:15:50,531:INFO:Finalizing model
2025-05-14 21:15:50,700:INFO:Uploading results into container
2025-05-14 21:15:50,702:INFO:Uploading model into container now
2025-05-14 21:15:50,703:INFO:_master_model_container: 19
2025-05-14 21:15:50,703:INFO:_display_container: 5
2025-05-14 21:15:50,703:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:15:50,704:INFO:create_model() successfully completed......................................
2025-05-14 21:15:50,833:INFO:SubProcess create_model() end ==================================
2025-05-14 21:15:50,833:INFO:choose_better activated
2025-05-14 21:15:50,839:INFO:SubProcess create_model() called ==================================
2025-05-14 21:15:50,841:INFO:Initializing create_model()
2025-05-14 21:15:50,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:15:50,841:INFO:Checking exceptions
2025-05-14 21:15:50,842:INFO:Importing libraries
2025-05-14 21:15:50,843:INFO:Copying training dataset
2025-05-14 21:15:50,846:INFO:Defining folds
2025-05-14 21:15:50,846:INFO:Declaring metric variables
2025-05-14 21:15:50,846:INFO:Importing untrained model
2025-05-14 21:15:50,846:INFO:Declaring custom model
2025-05-14 21:15:50,847:INFO:Naive Bayes Imported successfully
2025-05-14 21:15:50,847:INFO:Starting cross validation
2025-05-14 21:15:50,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:15:50,852:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:15:51,093:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:15:51,095:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:15:51,101:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:15:51,236:INFO:Calculating mean and std
2025-05-14 21:15:51,237:INFO:Creating metrics dataframe
2025-05-14 21:15:51,239:INFO:Finalizing model
2025-05-14 21:15:51,298:INFO:Uploading results into container
2025-05-14 21:15:51,299:INFO:Uploading model into container now
2025-05-14 21:15:51,299:INFO:_master_model_container: 20
2025-05-14 21:15:51,299:INFO:_display_container: 6
2025-05-14 21:15:51,300:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:15:51,300:INFO:create_model() successfully completed......................................
2025-05-14 21:15:51,396:INFO:SubProcess create_model() end ==================================
2025-05-14 21:15:51,396:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5
2025-05-14 21:15:51,398:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5
2025-05-14 21:15:51,398:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2025-05-14 21:15:51,398:INFO:choose_better completed
2025-05-14 21:15:51,398:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-14 21:15:51,408:INFO:_master_model_container: 20
2025-05-14 21:15:51,409:INFO:_display_container: 5
2025-05-14 21:15:51,409:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:15:51,409:INFO:tune_model() successfully completed......................................
2025-05-14 21:15:51,516:INFO:Initializing plot_model()
2025-05-14 21:15:51,517:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 21:15:51,517:INFO:Checking exceptions
2025-05-14 21:15:51,520:INFO:Preloading libraries
2025-05-14 21:15:51,520:INFO:Copying training dataset
2025-05-14 21:15:51,521:INFO:Plot type: confusion_matrix
2025-05-14 21:15:51,770:INFO:Fitting Model
2025-05-14 21:15:51,770:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-05-14 21:15:51,770:INFO:Scoring test/hold-out set
2025-05-14 21:15:51,863:INFO:Visual Rendered Successfully
2025-05-14 21:15:51,957:INFO:plot_model() successfully completed......................................
2025-05-14 21:15:51,983:INFO:Initializing interpret_model()
2025-05-14 21:15:51,983:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 21:15:51,984:INFO:Checking exceptions
2025-05-14 21:15:51,984:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-05-14 21:18:36,452:INFO:Initializing interpret_model()
2025-05-14 21:18:36,452:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 21:18:36,452:INFO:Checking exceptions
2025-05-14 21:18:36,452:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-05-14 21:18:37,949:INFO:Initializing interpret_model()
2025-05-14 21:18:37,949:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B07B1D69D0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 21:18:37,949:INFO:Checking exceptions
2025-05-14 21:18:37,949:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-05-14 21:19:25,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 21:19:25,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 21:19:25,208:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 21:19:25,208:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 21:19:27,203:INFO:PyCaret ClassificationExperiment
2025-05-14 21:19:27,203:INFO:Logging name: clf-default-name
2025-05-14 21:19:27,203:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 21:19:27,203:INFO:version 3.3.2
2025-05-14 21:19:27,204:INFO:Initializing setup()
2025-05-14 21:19:27,204:INFO:self.USI: c16e
2025-05-14 21:19:27,204:INFO:self._variable_keys: {'fold_groups_param', 'exp_name_log', 'X', 'USI', 'fix_imbalance', 'gpu_n_jobs_param', 'n_jobs_param', 'y', 'X_test', 'logging_param', 'y_test', 'exp_id', 'is_multiclass', 'memory', 'gpu_param', '_ml_usecase', 'idx', 'pipeline', '_available_plots', 'target_param', 'fold_shuffle_param', 'data', 'fold_generator', 'X_train', 'seed', 'y_train', 'log_plots_param', 'html_param'}
2025-05-14 21:19:27,204:INFO:Checking environment
2025-05-14 21:19:27,204:INFO:python_version: 3.11.8
2025-05-14 21:19:27,204:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-14 21:19:27,204:INFO:machine: AMD64
2025-05-14 21:19:27,205:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-14 21:19:27,212:INFO:Memory: svmem(total=16907886592, available=4106227712, percent=75.7, used=12801658880, free=4106227712)
2025-05-14 21:19:27,213:INFO:Physical Core: 4
2025-05-14 21:19:27,213:INFO:Logical Core: 8
2025-05-14 21:19:27,213:INFO:Checking libraries
2025-05-14 21:19:27,213:INFO:System:
2025-05-14 21:19:27,213:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-14 21:19:27,213:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-14 21:19:27,213:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-14 21:19:27,213:INFO:PyCaret required dependencies:
2025-05-14 21:19:27,275:INFO:                 pip: 24.0
2025-05-14 21:19:27,275:INFO:          setuptools: 65.5.0
2025-05-14 21:19:27,276:INFO:             pycaret: 3.3.2
2025-05-14 21:19:27,276:INFO:             IPython: 9.2.0
2025-05-14 21:19:27,276:INFO:          ipywidgets: 8.1.7
2025-05-14 21:19:27,276:INFO:                tqdm: 4.67.1
2025-05-14 21:19:27,276:INFO:               numpy: 1.26.4
2025-05-14 21:19:27,276:INFO:              pandas: 2.1.4
2025-05-14 21:19:27,276:INFO:              jinja2: 3.1.6
2025-05-14 21:19:27,276:INFO:               scipy: 1.11.4
2025-05-14 21:19:27,276:INFO:              joblib: 1.3.2
2025-05-14 21:19:27,276:INFO:             sklearn: 1.4.2
2025-05-14 21:19:27,276:INFO:                pyod: 2.0.5
2025-05-14 21:19:27,277:INFO:            imblearn: 0.13.0
2025-05-14 21:19:27,277:INFO:   category_encoders: 2.7.0
2025-05-14 21:19:27,277:INFO:            lightgbm: 4.6.0
2025-05-14 21:19:27,277:INFO:               numba: 0.61.0
2025-05-14 21:19:27,277:INFO:            requests: 2.32.3
2025-05-14 21:19:27,277:INFO:          matplotlib: 3.7.5
2025-05-14 21:19:27,277:INFO:          scikitplot: 0.3.7
2025-05-14 21:19:27,277:INFO:         yellowbrick: 1.5
2025-05-14 21:19:27,277:INFO:              plotly: 5.24.1
2025-05-14 21:19:27,277:INFO:    plotly-resampler: Not installed
2025-05-14 21:19:27,278:INFO:             kaleido: 0.2.1
2025-05-14 21:19:27,278:INFO:           schemdraw: 0.15
2025-05-14 21:19:27,278:INFO:         statsmodels: 0.14.4
2025-05-14 21:19:27,278:INFO:              sktime: 0.26.0
2025-05-14 21:19:27,278:INFO:               tbats: 1.1.3
2025-05-14 21:19:27,278:INFO:            pmdarima: 2.0.4
2025-05-14 21:19:27,278:INFO:              psutil: 7.0.0
2025-05-14 21:19:27,278:INFO:          markupsafe: 3.0.2
2025-05-14 21:19:27,278:INFO:             pickle5: Not installed
2025-05-14 21:19:27,278:INFO:         cloudpickle: 3.1.1
2025-05-14 21:19:27,278:INFO:         deprecation: 2.1.0
2025-05-14 21:19:27,278:INFO:              xxhash: 3.5.0
2025-05-14 21:19:27,278:INFO:           wurlitzer: Not installed
2025-05-14 21:19:27,278:INFO:PyCaret optional dependencies:
2025-05-14 21:19:27,309:INFO:                shap: Not installed
2025-05-14 21:19:27,310:INFO:           interpret: Not installed
2025-05-14 21:19:27,310:INFO:                umap: Not installed
2025-05-14 21:19:27,310:INFO:     ydata_profiling: Not installed
2025-05-14 21:19:27,310:INFO:  explainerdashboard: Not installed
2025-05-14 21:19:27,310:INFO:             autoviz: Not installed
2025-05-14 21:19:27,310:INFO:           fairlearn: Not installed
2025-05-14 21:19:27,310:INFO:          deepchecks: Not installed
2025-05-14 21:19:27,310:INFO:             xgboost: Not installed
2025-05-14 21:19:27,311:INFO:            catboost: Not installed
2025-05-14 21:19:27,311:INFO:              kmodes: Not installed
2025-05-14 21:19:27,311:INFO:             mlxtend: Not installed
2025-05-14 21:19:27,311:INFO:       statsforecast: Not installed
2025-05-14 21:19:27,311:INFO:        tune_sklearn: Not installed
2025-05-14 21:19:27,311:INFO:                 ray: Not installed
2025-05-14 21:19:27,311:INFO:            hyperopt: Not installed
2025-05-14 21:19:27,311:INFO:              optuna: Not installed
2025-05-14 21:19:27,311:INFO:               skopt: Not installed
2025-05-14 21:19:27,311:INFO:              mlflow: Not installed
2025-05-14 21:19:27,312:INFO:              gradio: Not installed
2025-05-14 21:19:27,312:INFO:             fastapi: Not installed
2025-05-14 21:19:27,312:INFO:             uvicorn: Not installed
2025-05-14 21:19:27,312:INFO:              m2cgen: Not installed
2025-05-14 21:19:27,312:INFO:           evidently: Not installed
2025-05-14 21:19:27,312:INFO:               fugue: Not installed
2025-05-14 21:19:27,312:INFO:           streamlit: Not installed
2025-05-14 21:19:27,312:INFO:             prophet: Not installed
2025-05-14 21:19:27,312:INFO:None
2025-05-14 21:19:27,312:INFO:Set up data.
2025-05-14 21:19:27,324:INFO:Set up folding strategy.
2025-05-14 21:19:27,324:INFO:Set up train/test split.
2025-05-14 21:19:27,340:INFO:Set up index.
2025-05-14 21:19:27,340:INFO:Assigning column types.
2025-05-14 21:19:27,347:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 21:19:27,461:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 21:19:27,472:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:19:27,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:27,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:27,689:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 21:19:27,691:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:19:27,763:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:27,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:27,764:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 21:19:27,894:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:19:27,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:27,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:28,145:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:19:28,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:28,242:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:28,243:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 21:19:28,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:28,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:28,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:28,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:28,556:INFO:Preparing preprocessing pipeline...
2025-05-14 21:19:28,557:INFO:Set up simple imputation.
2025-05-14 21:19:28,560:INFO:Set up encoding of ordinal features.
2025-05-14 21:19:28,561:INFO:Set up encoding of categorical features.
2025-05-14 21:19:28,561:INFO:Set up removing multicollinearity.
2025-05-14 21:19:28,561:INFO:Set up imbalanced handling.
2025-05-14 21:19:28,561:INFO:Set up feature normalization.
2025-05-14 21:19:28,688:INFO:Finished creating preprocessing pipeline.
2025-05-14 21:19:28,707:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['monto_credito',
                                             'mujer_emprendedora', 'hijos'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer'...
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=999,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-05-14 21:19:28,707:INFO:Creating final display dataframe.
2025-05-14 21:19:28,910:INFO:Setup _display_container:                     Description             Value
0                    Session id               999
1                        Target           default
2                   Target type            Binary
3           Original data shape          (144, 7)
4        Transformed data shape          (226, 8)
5   Transformed train set shape          (182, 8)
6    Transformed test set shape           (44, 8)
7               Ignore features                 1
8              Numeric features                 3
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.8
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20                    Normalize              True
21             Normalize method            zscore
22               Fold Generator   StratifiedKFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  clf-default-name
28                          USI              c16e
2025-05-14 21:19:28,992:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:28,992:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:29,065:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:29,065:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:19:29,069:INFO:setup() successfully completed in 1.87s...............
2025-05-14 21:19:29,079:INFO:Initializing compare_models()
2025-05-14 21:19:29,079:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 21:19:29,079:INFO:Checking exceptions
2025-05-14 21:19:29,083:INFO:Preparing display monitor
2025-05-14 21:19:29,111:INFO:Initializing Logistic Regression
2025-05-14 21:19:29,111:INFO:Total runtime is 0.0 minutes
2025-05-14 21:19:29,149:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:29,150:INFO:Initializing create_model()
2025-05-14 21:19:29,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246AC8D65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:29,150:INFO:Checking exceptions
2025-05-14 21:19:29,150:INFO:Importing libraries
2025-05-14 21:19:29,150:INFO:Copying training dataset
2025-05-14 21:19:29,155:INFO:Defining folds
2025-05-14 21:19:29,156:INFO:Declaring metric variables
2025-05-14 21:19:29,160:INFO:Importing untrained model
2025-05-14 21:19:29,170:INFO:Logistic Regression Imported successfully
2025-05-14 21:19:29,180:INFO:Starting cross validation
2025-05-14 21:19:29,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:29,193:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:38,328:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:38,336:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:38,511:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:38,702:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:38,718:INFO:Calculating mean and std
2025-05-14 21:19:38,719:INFO:Creating metrics dataframe
2025-05-14 21:19:38,722:INFO:Uploading results into container
2025-05-14 21:19:38,722:INFO:Uploading model into container now
2025-05-14 21:19:38,723:INFO:_master_model_container: 1
2025-05-14 21:19:38,723:INFO:_display_container: 2
2025-05-14 21:19:38,724:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 21:19:38,724:INFO:create_model() successfully completed......................................
2025-05-14 21:19:38,814:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:38,814:INFO:Creating metrics dataframe
2025-05-14 21:19:38,822:INFO:Initializing K Neighbors Classifier
2025-05-14 21:19:38,823:INFO:Total runtime is 0.16187500556310017 minutes
2025-05-14 21:19:38,829:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:38,830:INFO:Initializing create_model()
2025-05-14 21:19:38,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246AC8D65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:38,830:INFO:Checking exceptions
2025-05-14 21:19:38,830:INFO:Importing libraries
2025-05-14 21:19:38,832:INFO:Copying training dataset
2025-05-14 21:19:38,839:INFO:Defining folds
2025-05-14 21:19:38,839:INFO:Declaring metric variables
2025-05-14 21:19:38,843:INFO:Importing untrained model
2025-05-14 21:19:38,850:INFO:K Neighbors Classifier Imported successfully
2025-05-14 21:19:38,861:INFO:Starting cross validation
2025-05-14 21:19:38,864:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:38,868:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:39,100:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:39,105:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:39,153:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:39,328:INFO:Calculating mean and std
2025-05-14 21:19:39,329:INFO:Creating metrics dataframe
2025-05-14 21:19:39,332:INFO:Uploading results into container
2025-05-14 21:19:39,333:INFO:Uploading model into container now
2025-05-14 21:19:39,333:INFO:_master_model_container: 2
2025-05-14 21:19:39,334:INFO:_display_container: 2
2025-05-14 21:19:39,334:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 21:19:39,334:INFO:create_model() successfully completed......................................
2025-05-14 21:19:39,411:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:39,411:INFO:Creating metrics dataframe
2025-05-14 21:19:39,420:INFO:Initializing Naive Bayes
2025-05-14 21:19:39,420:INFO:Total runtime is 0.17183222373326618 minutes
2025-05-14 21:19:39,425:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:39,425:INFO:Initializing create_model()
2025-05-14 21:19:39,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246AC8D65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:39,426:INFO:Checking exceptions
2025-05-14 21:19:39,426:INFO:Importing libraries
2025-05-14 21:19:39,426:INFO:Copying training dataset
2025-05-14 21:19:39,431:INFO:Defining folds
2025-05-14 21:19:39,431:INFO:Declaring metric variables
2025-05-14 21:19:39,436:INFO:Importing untrained model
2025-05-14 21:19:39,442:INFO:Naive Bayes Imported successfully
2025-05-14 21:19:39,449:INFO:Starting cross validation
2025-05-14 21:19:39,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:39,454:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:39,618:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:39,624:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:39,689:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:39,793:INFO:Calculating mean and std
2025-05-14 21:19:39,794:INFO:Creating metrics dataframe
2025-05-14 21:19:39,798:INFO:Uploading results into container
2025-05-14 21:19:39,798:INFO:Uploading model into container now
2025-05-14 21:19:39,799:INFO:_master_model_container: 3
2025-05-14 21:19:39,799:INFO:_display_container: 2
2025-05-14 21:19:39,799:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:19:39,799:INFO:create_model() successfully completed......................................
2025-05-14 21:19:39,882:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:39,883:INFO:Creating metrics dataframe
2025-05-14 21:19:39,893:INFO:Initializing Decision Tree Classifier
2025-05-14 21:19:39,893:INFO:Total runtime is 0.17970921198527015 minutes
2025-05-14 21:19:39,898:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:39,899:INFO:Initializing create_model()
2025-05-14 21:19:39,899:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246AC8D65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:39,899:INFO:Checking exceptions
2025-05-14 21:19:39,899:INFO:Importing libraries
2025-05-14 21:19:39,899:INFO:Copying training dataset
2025-05-14 21:19:39,904:INFO:Defining folds
2025-05-14 21:19:39,905:INFO:Declaring metric variables
2025-05-14 21:19:39,911:INFO:Importing untrained model
2025-05-14 21:19:39,915:INFO:Decision Tree Classifier Imported successfully
2025-05-14 21:19:39,923:INFO:Starting cross validation
2025-05-14 21:19:39,926:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:39,930:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:40,092:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:40,099:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:40,103:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:40,110:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:40,242:INFO:Calculating mean and std
2025-05-14 21:19:40,243:INFO:Creating metrics dataframe
2025-05-14 21:19:40,247:INFO:Uploading results into container
2025-05-14 21:19:40,248:INFO:Uploading model into container now
2025-05-14 21:19:40,249:INFO:_master_model_container: 4
2025-05-14 21:19:40,249:INFO:_display_container: 2
2025-05-14 21:19:40,250:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=999, splitter='best')
2025-05-14 21:19:40,251:INFO:create_model() successfully completed......................................
2025-05-14 21:19:40,333:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:40,333:INFO:Creating metrics dataframe
2025-05-14 21:19:40,342:INFO:Initializing SVM - Linear Kernel
2025-05-14 21:19:40,342:INFO:Total runtime is 0.18719028631846107 minutes
2025-05-14 21:19:40,346:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:40,346:INFO:Initializing create_model()
2025-05-14 21:19:40,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246AC8D65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:40,346:INFO:Checking exceptions
2025-05-14 21:19:40,347:INFO:Importing libraries
2025-05-14 21:19:40,347:INFO:Copying training dataset
2025-05-14 21:19:40,353:INFO:Defining folds
2025-05-14 21:19:40,353:INFO:Declaring metric variables
2025-05-14 21:19:40,357:INFO:Importing untrained model
2025-05-14 21:19:40,364:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 21:19:40,372:INFO:Starting cross validation
2025-05-14 21:19:40,376:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:40,378:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:40,554:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:40,560:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:40,578:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:40,697:INFO:Calculating mean and std
2025-05-14 21:19:40,698:INFO:Creating metrics dataframe
2025-05-14 21:19:40,700:INFO:Uploading results into container
2025-05-14 21:19:40,701:INFO:Uploading model into container now
2025-05-14 21:19:40,702:INFO:_master_model_container: 5
2025-05-14 21:19:40,702:INFO:_display_container: 2
2025-05-14 21:19:40,703:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=999, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 21:19:40,704:INFO:create_model() successfully completed......................................
2025-05-14 21:19:40,782:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:40,782:INFO:Creating metrics dataframe
2025-05-14 21:19:40,791:INFO:Initializing Ridge Classifier
2025-05-14 21:19:40,791:INFO:Total runtime is 0.19467136859893797 minutes
2025-05-14 21:19:40,794:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:40,795:INFO:Initializing create_model()
2025-05-14 21:19:40,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246AC8D65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:40,796:INFO:Checking exceptions
2025-05-14 21:19:40,796:INFO:Importing libraries
2025-05-14 21:19:40,796:INFO:Copying training dataset
2025-05-14 21:19:40,801:INFO:Defining folds
2025-05-14 21:19:40,801:INFO:Declaring metric variables
2025-05-14 21:19:40,805:INFO:Importing untrained model
2025-05-14 21:19:40,812:INFO:Ridge Classifier Imported successfully
2025-05-14 21:19:40,820:INFO:Starting cross validation
2025-05-14 21:19:40,822:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:40,825:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:40,977:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:40,982:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:41,044:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:41,047:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:41,139:INFO:Calculating mean and std
2025-05-14 21:19:41,141:INFO:Creating metrics dataframe
2025-05-14 21:19:41,143:INFO:Uploading results into container
2025-05-14 21:19:41,144:INFO:Uploading model into container now
2025-05-14 21:19:41,145:INFO:_master_model_container: 6
2025-05-14 21:19:41,146:INFO:_display_container: 2
2025-05-14 21:19:41,147:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=999, solver='auto',
                tol=0.0001)
2025-05-14 21:19:41,147:INFO:create_model() successfully completed......................................
2025-05-14 21:19:41,259:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:41,260:INFO:Creating metrics dataframe
2025-05-14 21:19:41,269:INFO:Initializing Random Forest Classifier
2025-05-14 21:19:41,269:INFO:Total runtime is 0.20263991753260294 minutes
2025-05-14 21:19:41,273:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:41,273:INFO:Initializing create_model()
2025-05-14 21:19:41,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246AC8D65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:41,274:INFO:Checking exceptions
2025-05-14 21:19:41,274:INFO:Importing libraries
2025-05-14 21:19:41,274:INFO:Copying training dataset
2025-05-14 21:19:41,278:INFO:Defining folds
2025-05-14 21:19:41,279:INFO:Declaring metric variables
2025-05-14 21:19:41,284:INFO:Importing untrained model
2025-05-14 21:19:41,289:INFO:Random Forest Classifier Imported successfully
2025-05-14 21:19:41,296:INFO:Starting cross validation
2025-05-14 21:19:41,299:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:41,302:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:41,945:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:41,952:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:41,952:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:41,958:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:41,963:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:41,966:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:19:41,966:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:19:41,971:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:19:42,000:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:42,002:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:42,418:INFO:Calculating mean and std
2025-05-14 21:19:42,419:INFO:Creating metrics dataframe
2025-05-14 21:19:42,421:INFO:Uploading results into container
2025-05-14 21:19:42,421:INFO:Uploading model into container now
2025-05-14 21:19:42,422:INFO:_master_model_container: 7
2025-05-14 21:19:42,422:INFO:_display_container: 2
2025-05-14 21:19:42,423:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=999, verbose=0,
                       warm_start=False)
2025-05-14 21:19:42,423:INFO:create_model() successfully completed......................................
2025-05-14 21:19:42,497:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:42,497:INFO:Creating metrics dataframe
2025-05-14 21:19:42,506:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 21:19:42,507:INFO:Total runtime is 0.2232804298400879 minutes
2025-05-14 21:19:42,510:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:42,510:INFO:Initializing create_model()
2025-05-14 21:19:42,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246AC8D65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:42,510:INFO:Checking exceptions
2025-05-14 21:19:42,510:INFO:Importing libraries
2025-05-14 21:19:42,510:INFO:Copying training dataset
2025-05-14 21:19:42,515:INFO:Defining folds
2025-05-14 21:19:42,515:INFO:Declaring metric variables
2025-05-14 21:19:42,519:INFO:Importing untrained model
2025-05-14 21:19:42,522:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 21:19:42,529:INFO:Starting cross validation
2025-05-14 21:19:42,531:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:42,536:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:42,639:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:19:42,641:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:19:42,641:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:19:42,643:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:19:42,644:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:19:42,647:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:19:42,651:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:19:42,683:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:19:42,694:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:42,701:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:42,710:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:42,721:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:42,781:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:19:42,783:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:19:42,836:INFO:Calculating mean and std
2025-05-14 21:19:42,836:INFO:Creating metrics dataframe
2025-05-14 21:19:42,839:INFO:Uploading results into container
2025-05-14 21:19:42,840:INFO:Uploading model into container now
2025-05-14 21:19:42,840:INFO:_master_model_container: 8
2025-05-14 21:19:42,840:INFO:_display_container: 2
2025-05-14 21:19:42,841:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 21:19:42,841:INFO:create_model() successfully completed......................................
2025-05-14 21:19:42,912:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:42,912:INFO:Creating metrics dataframe
2025-05-14 21:19:42,924:INFO:Initializing Ada Boost Classifier
2025-05-14 21:19:42,924:INFO:Total runtime is 0.2302262306213379 minutes
2025-05-14 21:19:42,929:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:42,929:INFO:Initializing create_model()
2025-05-14 21:19:42,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246AC8D65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:42,929:INFO:Checking exceptions
2025-05-14 21:19:42,929:INFO:Importing libraries
2025-05-14 21:19:42,929:INFO:Copying training dataset
2025-05-14 21:19:42,932:INFO:Defining folds
2025-05-14 21:19:42,933:INFO:Declaring metric variables
2025-05-14 21:19:42,936:INFO:Importing untrained model
2025-05-14 21:19:42,942:INFO:Ada Boost Classifier Imported successfully
2025-05-14 21:19:42,951:INFO:Starting cross validation
2025-05-14 21:19:42,953:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:42,956:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:43,065:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:19:43,065:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:19:43,069:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:19:43,069:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:19:43,070:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:19:43,078:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:19:43,078:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:19:43,122:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:19:43,346:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:43,347:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:43,352:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:43,361:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:43,451:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:19:43,455:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:19:43,740:INFO:Calculating mean and std
2025-05-14 21:19:43,741:INFO:Creating metrics dataframe
2025-05-14 21:19:43,745:INFO:Uploading results into container
2025-05-14 21:19:43,746:INFO:Uploading model into container now
2025-05-14 21:19:43,747:INFO:_master_model_container: 9
2025-05-14 21:19:43,747:INFO:_display_container: 2
2025-05-14 21:19:43,747:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=999)
2025-05-14 21:19:43,749:INFO:create_model() successfully completed......................................
2025-05-14 21:19:43,837:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:43,837:INFO:Creating metrics dataframe
2025-05-14 21:19:43,848:INFO:Initializing Gradient Boosting Classifier
2025-05-14 21:19:43,848:INFO:Total runtime is 0.24562486410140993 minutes
2025-05-14 21:19:43,853:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:43,853:INFO:Initializing create_model()
2025-05-14 21:19:43,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246AC8D65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:43,854:INFO:Checking exceptions
2025-05-14 21:19:43,854:INFO:Importing libraries
2025-05-14 21:19:43,854:INFO:Copying training dataset
2025-05-14 21:19:43,860:INFO:Defining folds
2025-05-14 21:19:43,860:INFO:Declaring metric variables
2025-05-14 21:19:43,863:INFO:Importing untrained model
2025-05-14 21:19:43,869:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 21:19:43,882:INFO:Starting cross validation
2025-05-14 21:19:43,884:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:43,888:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:44,322:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:44,327:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:44,332:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:44,333:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:44,339:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:44,341:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:19:44,341:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:19:44,346:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:19:44,353:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:44,675:INFO:Calculating mean and std
2025-05-14 21:19:44,676:INFO:Creating metrics dataframe
2025-05-14 21:19:44,679:INFO:Uploading results into container
2025-05-14 21:19:44,680:INFO:Uploading model into container now
2025-05-14 21:19:44,681:INFO:_master_model_container: 10
2025-05-14 21:19:44,681:INFO:_display_container: 2
2025-05-14 21:19:44,682:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=999, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 21:19:44,682:INFO:create_model() successfully completed......................................
2025-05-14 21:19:44,758:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:44,758:INFO:Creating metrics dataframe
2025-05-14 21:19:44,767:INFO:Initializing Linear Discriminant Analysis
2025-05-14 21:19:44,767:INFO:Total runtime is 0.260948928197225 minutes
2025-05-14 21:19:44,771:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:44,771:INFO:Initializing create_model()
2025-05-14 21:19:44,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246AC8D65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:44,771:INFO:Checking exceptions
2025-05-14 21:19:44,771:INFO:Importing libraries
2025-05-14 21:19:44,771:INFO:Copying training dataset
2025-05-14 21:19:44,775:INFO:Defining folds
2025-05-14 21:19:44,775:INFO:Declaring metric variables
2025-05-14 21:19:44,779:INFO:Importing untrained model
2025-05-14 21:19:44,783:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 21:19:44,793:INFO:Starting cross validation
2025-05-14 21:19:44,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:44,798:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:44,956:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:44,982:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:45,003:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:45,008:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:45,100:INFO:Calculating mean and std
2025-05-14 21:19:45,100:INFO:Creating metrics dataframe
2025-05-14 21:19:45,103:INFO:Uploading results into container
2025-05-14 21:19:45,104:INFO:Uploading model into container now
2025-05-14 21:19:45,105:INFO:_master_model_container: 11
2025-05-14 21:19:45,105:INFO:_display_container: 2
2025-05-14 21:19:45,106:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 21:19:45,107:INFO:create_model() successfully completed......................................
2025-05-14 21:19:45,181:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:45,182:INFO:Creating metrics dataframe
2025-05-14 21:19:45,191:INFO:Initializing Extra Trees Classifier
2025-05-14 21:19:45,191:INFO:Total runtime is 0.26800725857416796 minutes
2025-05-14 21:19:45,194:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:45,194:INFO:Initializing create_model()
2025-05-14 21:19:45,194:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246AC8D65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:45,194:INFO:Checking exceptions
2025-05-14 21:19:45,194:INFO:Importing libraries
2025-05-14 21:19:45,194:INFO:Copying training dataset
2025-05-14 21:19:45,200:INFO:Defining folds
2025-05-14 21:19:45,200:INFO:Declaring metric variables
2025-05-14 21:19:45,203:INFO:Importing untrained model
2025-05-14 21:19:45,206:INFO:Extra Trees Classifier Imported successfully
2025-05-14 21:19:45,217:INFO:Starting cross validation
2025-05-14 21:19:45,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:45,222:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:45,848:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:45,849:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:45,850:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:45,855:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:45,860:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:45,866:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:45,871:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:45,875:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:19:45,875:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:19:45,878:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:19:45,930:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:46,306:INFO:Calculating mean and std
2025-05-14 21:19:46,307:INFO:Creating metrics dataframe
2025-05-14 21:19:46,310:INFO:Uploading results into container
2025-05-14 21:19:46,310:INFO:Uploading model into container now
2025-05-14 21:19:46,311:INFO:_master_model_container: 12
2025-05-14 21:19:46,311:INFO:_display_container: 2
2025-05-14 21:19:46,311:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=999, verbose=0,
                     warm_start=False)
2025-05-14 21:19:46,311:INFO:create_model() successfully completed......................................
2025-05-14 21:19:46,388:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:46,389:INFO:Creating metrics dataframe
2025-05-14 21:19:46,400:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 21:19:46,401:INFO:Total runtime is 0.2881707390149435 minutes
2025-05-14 21:19:46,405:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:46,405:INFO:Initializing create_model()
2025-05-14 21:19:46,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246AC8D65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:46,405:INFO:Checking exceptions
2025-05-14 21:19:46,405:INFO:Importing libraries
2025-05-14 21:19:46,405:INFO:Copying training dataset
2025-05-14 21:19:46,410:INFO:Defining folds
2025-05-14 21:19:46,410:INFO:Declaring metric variables
2025-05-14 21:19:46,414:INFO:Importing untrained model
2025-05-14 21:19:46,421:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 21:19:46,427:INFO:Starting cross validation
2025-05-14 21:19:46,429:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:46,432:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:46,871:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:46,892:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:46,896:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:46,904:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:46,910:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:46,912:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:19:46,912:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:19:46,915:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:19:46,972:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:47,207:INFO:Calculating mean and std
2025-05-14 21:19:47,209:INFO:Creating metrics dataframe
2025-05-14 21:19:47,212:INFO:Uploading results into container
2025-05-14 21:19:47,213:INFO:Uploading model into container now
2025-05-14 21:19:47,214:INFO:_master_model_container: 13
2025-05-14 21:19:47,214:INFO:_display_container: 2
2025-05-14 21:19:47,216:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=999, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 21:19:47,216:INFO:create_model() successfully completed......................................
2025-05-14 21:19:47,319:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:47,319:INFO:Creating metrics dataframe
2025-05-14 21:19:47,331:INFO:Initializing Dummy Classifier
2025-05-14 21:19:47,332:INFO:Total runtime is 0.3036902070045472 minutes
2025-05-14 21:19:47,337:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:47,337:INFO:Initializing create_model()
2025-05-14 21:19:47,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246AC8D65D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:47,338:INFO:Checking exceptions
2025-05-14 21:19:47,338:INFO:Importing libraries
2025-05-14 21:19:47,338:INFO:Copying training dataset
2025-05-14 21:19:47,343:INFO:Defining folds
2025-05-14 21:19:47,343:INFO:Declaring metric variables
2025-05-14 21:19:47,348:INFO:Importing untrained model
2025-05-14 21:19:47,353:INFO:Dummy Classifier Imported successfully
2025-05-14 21:19:47,362:INFO:Starting cross validation
2025-05-14 21:19:47,365:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:47,369:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:47,545:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:47,552:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:47,555:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:47,557:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:47,560:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:47,563:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:47,566:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:19:47,568:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-05-14 21:19:47,570:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:47,570:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:47,570:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:47,572:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-05-14 21:19:47,579:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:47,600:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:47,685:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:47,685:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:47,702:INFO:Calculating mean and std
2025-05-14 21:19:47,704:INFO:Creating metrics dataframe
2025-05-14 21:19:47,708:INFO:Uploading results into container
2025-05-14 21:19:47,709:INFO:Uploading model into container now
2025-05-14 21:19:47,709:INFO:_master_model_container: 14
2025-05-14 21:19:47,709:INFO:_display_container: 2
2025-05-14 21:19:47,709:INFO:DummyClassifier(constant=None, random_state=999, strategy='prior')
2025-05-14 21:19:47,709:INFO:create_model() successfully completed......................................
2025-05-14 21:19:47,794:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:47,794:INFO:Creating metrics dataframe
2025-05-14 21:19:47,807:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-14 21:19:47,816:INFO:Initializing create_model()
2025-05-14 21:19:47,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:47,817:INFO:Checking exceptions
2025-05-14 21:19:47,818:INFO:Importing libraries
2025-05-14 21:19:47,819:INFO:Copying training dataset
2025-05-14 21:19:47,822:INFO:Defining folds
2025-05-14 21:19:47,822:INFO:Declaring metric variables
2025-05-14 21:19:47,822:INFO:Importing untrained model
2025-05-14 21:19:47,822:INFO:Declaring custom model
2025-05-14 21:19:47,822:INFO:Naive Bayes Imported successfully
2025-05-14 21:19:47,823:INFO:Cross validation set to False
2025-05-14 21:19:47,823:INFO:Fitting Model
2025-05-14 21:19:48,047:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:19:48,047:INFO:create_model() successfully completed......................................
2025-05-14 21:19:48,147:INFO:_master_model_container: 14
2025-05-14 21:19:48,147:INFO:_display_container: 2
2025-05-14 21:19:48,147:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:19:48,147:INFO:compare_models() successfully completed......................................
2025-05-14 21:19:48,161:INFO:Initializing tune_model()
2025-05-14 21:19:48,162:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 21:19:48,162:INFO:Checking exceptions
2025-05-14 21:19:48,180:INFO:Copying training dataset
2025-05-14 21:19:48,184:INFO:Checking base model
2025-05-14 21:19:48,185:INFO:Base model : Naive Bayes
2025-05-14 21:19:48,191:INFO:Declaring metric variables
2025-05-14 21:19:48,197:INFO:Defining Hyperparameters
2025-05-14 21:19:48,342:INFO:Tuning with n_jobs=-1
2025-05-14 21:19:48,342:INFO:Initializing RandomizedSearchCV
2025-05-14 21:19:48,347:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:48,523:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:48,723:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:48,970:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:49,015:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:49,449:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:49,677:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:49,967:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:50,232:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:50,452:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:50,731:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:50,954:INFO:best_params: {'actual_estimator__var_smoothing': 1e-09}
2025-05-14 21:19:50,955:INFO:Hyperparameter search completed
2025-05-14 21:19:50,955:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:50,955:INFO:Initializing create_model()
2025-05-14 21:19:50,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246A977F650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 1e-09})
2025-05-14 21:19:50,955:INFO:Checking exceptions
2025-05-14 21:19:50,956:INFO:Importing libraries
2025-05-14 21:19:50,956:INFO:Copying training dataset
2025-05-14 21:19:50,962:INFO:Defining folds
2025-05-14 21:19:50,962:INFO:Declaring metric variables
2025-05-14 21:19:50,966:INFO:Importing untrained model
2025-05-14 21:19:50,966:INFO:Declaring custom model
2025-05-14 21:19:50,971:INFO:Naive Bayes Imported successfully
2025-05-14 21:19:50,979:INFO:Starting cross validation
2025-05-14 21:19:50,981:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:50,985:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:51,171:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:51,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:51,176:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:51,316:INFO:Calculating mean and std
2025-05-14 21:19:51,317:INFO:Creating metrics dataframe
2025-05-14 21:19:51,323:INFO:Finalizing model
2025-05-14 21:19:51,385:INFO:Uploading results into container
2025-05-14 21:19:51,386:INFO:Uploading model into container now
2025-05-14 21:19:51,387:INFO:_master_model_container: 15
2025-05-14 21:19:51,387:INFO:_display_container: 3
2025-05-14 21:19:51,387:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:19:51,387:INFO:create_model() successfully completed......................................
2025-05-14 21:19:51,464:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:51,464:INFO:choose_better activated
2025-05-14 21:19:51,468:INFO:SubProcess create_model() called ==================================
2025-05-14 21:19:51,468:INFO:Initializing create_model()
2025-05-14 21:19:51,468:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:19:51,468:INFO:Checking exceptions
2025-05-14 21:19:51,471:INFO:Importing libraries
2025-05-14 21:19:51,471:INFO:Copying training dataset
2025-05-14 21:19:51,473:INFO:Defining folds
2025-05-14 21:19:51,474:INFO:Declaring metric variables
2025-05-14 21:19:51,474:INFO:Importing untrained model
2025-05-14 21:19:51,474:INFO:Declaring custom model
2025-05-14 21:19:51,474:INFO:Naive Bayes Imported successfully
2025-05-14 21:19:51,474:INFO:Starting cross validation
2025-05-14 21:19:51,475:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:19:51,477:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.
  warnings.warn(

2025-05-14 21:19:51,635:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-05-14 21:19:51,640:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:51,657:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:19:51,777:INFO:Calculating mean and std
2025-05-14 21:19:51,777:INFO:Creating metrics dataframe
2025-05-14 21:19:51,779:INFO:Finalizing model
2025-05-14 21:19:51,842:INFO:Uploading results into container
2025-05-14 21:19:51,843:INFO:Uploading model into container now
2025-05-14 21:19:51,843:INFO:_master_model_container: 16
2025-05-14 21:19:51,843:INFO:_display_container: 4
2025-05-14 21:19:51,843:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:19:51,843:INFO:create_model() successfully completed......................................
2025-05-14 21:19:51,912:INFO:SubProcess create_model() end ==================================
2025-05-14 21:19:51,912:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5
2025-05-14 21:19:51,912:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5
2025-05-14 21:19:51,912:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2025-05-14 21:19:51,912:INFO:choose_better completed
2025-05-14 21:19:51,912:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-14 21:19:51,922:INFO:_master_model_container: 16
2025-05-14 21:19:51,922:INFO:_display_container: 3
2025-05-14 21:19:51,923:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:19:51,923:INFO:tune_model() successfully completed......................................
2025-05-14 21:19:51,992:INFO:Initializing plot_model()
2025-05-14 21:19:51,992:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-14 21:19:51,992:INFO:Checking exceptions
2025-05-14 21:19:51,994:INFO:Preloading libraries
2025-05-14 21:19:51,995:INFO:Copying training dataset
2025-05-14 21:19:51,995:INFO:Plot type: confusion_matrix
2025-05-14 21:19:52,193:INFO:Fitting Model
2025-05-14 21:19:52,194:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-05-14 21:19:52,194:INFO:Scoring test/hold-out set
2025-05-14 21:19:52,286:INFO:Visual Rendered Successfully
2025-05-14 21:19:52,357:INFO:plot_model() successfully completed......................................
2025-05-14 21:19:52,375:INFO:Initializing interpret_model()
2025-05-14 21:19:52,375:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 21:19:52,375:INFO:Checking exceptions
2025-05-14 21:19:52,375:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-05-14 21:20:18,450:INFO:Initializing interpret_model()
2025-05-14 21:20:18,450:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 21:20:18,450:INFO:Checking exceptions
2025-05-14 21:20:18,450:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-05-14 21:20:19,487:INFO:Initializing interpret_model()
2025-05-14 21:20:19,487:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 21:20:19,487:INFO:Checking exceptions
2025-05-14 21:20:19,487:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-05-14 21:22:13,042:INFO:Initializing interpret_model()
2025-05-14 21:22:13,042:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 21:22:13,042:INFO:Checking exceptions
2025-05-14 21:22:13,042:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-05-14 21:22:14,548:INFO:Initializing interpret_model()
2025-05-14 21:22:14,548:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 21:22:14,548:INFO:Checking exceptions
2025-05-14 21:22:14,548:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-05-14 21:22:22,220:INFO:Initializing predict_model()
2025-05-14 21:22:22,221:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246AA1EDF90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000246B0F171A0>)
2025-05-14 21:22:22,221:INFO:Checking exceptions
2025-05-14 21:22:22,221:INFO:Preloading libraries
2025-05-14 21:22:22,226:INFO:Set up data.
2025-05-14 21:22:22,232:INFO:Set up index.
2025-05-14 21:22:25,690:INFO:Initializing save_model()
2025-05-14 21:22:25,691:INFO:save_model(model=GaussianNB(priors=None, var_smoothing=1e-09), model_name=modelo_default_rural_selva, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['monto_credito',
                                             'mujer_emprendedora', 'hijos'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer'...
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=999,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-14 21:22:25,691:INFO:Adding model into prep_pipe
2025-05-14 21:22:25,697:INFO:modelo_default_rural_selva.pkl saved in current working directory
2025-05-14 21:22:25,710:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['monto_credito',
                                             'mujer_emprendedora', 'hijos'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    includ...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=999,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2025-05-14 21:22:25,710:INFO:save_model() successfully completed......................................
2025-05-14 21:44:56,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 21:44:56,628:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 21:44:56,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 21:44:56,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 21:50:48,909:INFO:PyCaret ClassificationExperiment
2025-05-14 21:50:48,910:INFO:Logging name: clf-default-name
2025-05-14 21:50:48,910:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 21:50:48,910:INFO:version 3.3.2
2025-05-14 21:50:48,911:INFO:Initializing setup()
2025-05-14 21:50:48,911:INFO:self.USI: fac1
2025-05-14 21:50:48,911:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'exp_name_log', 'seed', 'memory', 'USI', 'target_param', 'y', 'X_train', 'X_test', 'n_jobs_param', 'logging_param', '_available_plots', 'idx', '_ml_usecase', 'fold_shuffle_param', 'fix_imbalance', 'data', 'y_test', 'pipeline', 'X', 'fold_generator', 'gpu_param', 'gpu_n_jobs_param', 'y_train', 'html_param', 'log_plots_param', 'exp_id'}
2025-05-14 21:50:48,911:INFO:Checking environment
2025-05-14 21:50:48,911:INFO:python_version: 3.11.8
2025-05-14 21:50:48,911:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-14 21:50:48,911:INFO:machine: AMD64
2025-05-14 21:50:48,911:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-14 21:50:48,919:INFO:Memory: svmem(total=16907886592, available=4064223232, percent=76.0, used=12843663360, free=4064223232)
2025-05-14 21:50:48,919:INFO:Physical Core: 4
2025-05-14 21:50:48,919:INFO:Logical Core: 8
2025-05-14 21:50:48,919:INFO:Checking libraries
2025-05-14 21:50:48,919:INFO:System:
2025-05-14 21:50:48,919:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-14 21:50:48,919:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-14 21:50:48,919:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-14 21:50:48,919:INFO:PyCaret required dependencies:
2025-05-14 21:50:49,005:INFO:                 pip: 24.0
2025-05-14 21:50:49,006:INFO:          setuptools: 65.5.0
2025-05-14 21:50:49,006:INFO:             pycaret: 3.3.2
2025-05-14 21:50:49,006:INFO:             IPython: 9.2.0
2025-05-14 21:50:49,006:INFO:          ipywidgets: 8.1.7
2025-05-14 21:50:49,006:INFO:                tqdm: 4.67.1
2025-05-14 21:50:49,006:INFO:               numpy: 1.26.4
2025-05-14 21:50:49,006:INFO:              pandas: 2.1.4
2025-05-14 21:50:49,006:INFO:              jinja2: 3.1.6
2025-05-14 21:50:49,006:INFO:               scipy: 1.11.4
2025-05-14 21:50:49,006:INFO:              joblib: 1.3.2
2025-05-14 21:50:49,006:INFO:             sklearn: 1.4.2
2025-05-14 21:50:49,006:INFO:                pyod: 2.0.5
2025-05-14 21:50:49,006:INFO:            imblearn: 0.13.0
2025-05-14 21:50:49,006:INFO:   category_encoders: 2.7.0
2025-05-14 21:50:49,006:INFO:            lightgbm: 4.6.0
2025-05-14 21:50:49,006:INFO:               numba: 0.61.0
2025-05-14 21:50:49,006:INFO:            requests: 2.32.3
2025-05-14 21:50:49,006:INFO:          matplotlib: 3.7.5
2025-05-14 21:50:49,006:INFO:          scikitplot: 0.3.7
2025-05-14 21:50:49,006:INFO:         yellowbrick: 1.5
2025-05-14 21:50:49,006:INFO:              plotly: 5.24.1
2025-05-14 21:50:49,006:INFO:    plotly-resampler: Not installed
2025-05-14 21:50:49,006:INFO:             kaleido: 0.2.1
2025-05-14 21:50:49,006:INFO:           schemdraw: 0.15
2025-05-14 21:50:49,006:INFO:         statsmodels: 0.14.4
2025-05-14 21:50:49,006:INFO:              sktime: 0.26.0
2025-05-14 21:50:49,006:INFO:               tbats: 1.1.3
2025-05-14 21:50:49,007:INFO:            pmdarima: 2.0.4
2025-05-14 21:50:49,007:INFO:              psutil: 7.0.0
2025-05-14 21:50:49,007:INFO:          markupsafe: 3.0.2
2025-05-14 21:50:49,007:INFO:             pickle5: Not installed
2025-05-14 21:50:49,007:INFO:         cloudpickle: 3.1.1
2025-05-14 21:50:49,007:INFO:         deprecation: 2.1.0
2025-05-14 21:50:49,007:INFO:              xxhash: 3.5.0
2025-05-14 21:50:49,007:INFO:           wurlitzer: Not installed
2025-05-14 21:50:49,007:INFO:PyCaret optional dependencies:
2025-05-14 21:50:49,019:INFO:                shap: 0.44.1
2025-05-14 21:50:49,020:INFO:           interpret: 0.6.10
2025-05-14 21:50:49,020:INFO:                umap: 0.5.7
2025-05-14 21:50:49,020:INFO:     ydata_profiling: 4.16.1
2025-05-14 21:50:49,020:INFO:  explainerdashboard: 0.4.8
2025-05-14 21:50:49,020:INFO:             autoviz: Not installed
2025-05-14 21:50:49,020:INFO:           fairlearn: 0.7.0
2025-05-14 21:50:49,020:INFO:          deepchecks: Not installed
2025-05-14 21:50:49,020:INFO:             xgboost: Not installed
2025-05-14 21:50:49,020:INFO:            catboost: Not installed
2025-05-14 21:50:49,020:INFO:              kmodes: Not installed
2025-05-14 21:50:49,020:INFO:             mlxtend: Not installed
2025-05-14 21:50:49,020:INFO:       statsforecast: Not installed
2025-05-14 21:50:49,020:INFO:        tune_sklearn: Not installed
2025-05-14 21:50:49,020:INFO:                 ray: Not installed
2025-05-14 21:50:49,020:INFO:            hyperopt: Not installed
2025-05-14 21:50:49,020:INFO:              optuna: Not installed
2025-05-14 21:50:49,020:INFO:               skopt: Not installed
2025-05-14 21:50:49,020:INFO:              mlflow: Not installed
2025-05-14 21:50:49,021:INFO:              gradio: Not installed
2025-05-14 21:50:49,021:INFO:             fastapi: Not installed
2025-05-14 21:50:49,021:INFO:             uvicorn: Not installed
2025-05-14 21:50:49,021:INFO:              m2cgen: Not installed
2025-05-14 21:50:49,021:INFO:           evidently: Not installed
2025-05-14 21:50:49,021:INFO:               fugue: Not installed
2025-05-14 21:50:49,021:INFO:           streamlit: Not installed
2025-05-14 21:50:49,021:INFO:             prophet: Not installed
2025-05-14 21:50:49,021:INFO:None
2025-05-14 21:50:49,021:INFO:Set up data.
2025-05-14 21:50:49,031:INFO:Set up folding strategy.
2025-05-14 21:50:49,032:INFO:Set up train/test split.
2025-05-14 21:50:49,037:INFO:Set up index.
2025-05-14 21:50:49,039:INFO:Assigning column types.
2025-05-14 21:50:49,041:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 21:50:49,104:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 21:50:49,108:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:50:49,152:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:49,152:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:49,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 21:50:49,230:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:50:49,259:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:49,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:49,260:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 21:50:49,302:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:50:49,330:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:49,330:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:49,371:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 21:50:49,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:49,400:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:49,401:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 21:50:49,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:49,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:49,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:49,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:49,554:INFO:Preparing preprocessing pipeline...
2025-05-14 21:50:49,556:INFO:Set up simple imputation.
2025-05-14 21:50:49,560:INFO:Set up encoding of ordinal features.
2025-05-14 21:50:49,563:INFO:Set up encoding of categorical features.
2025-05-14 21:50:49,563:INFO:Set up polynomial features.
2025-05-14 21:50:49,563:INFO:Set up removing multicollinearity.
2025-05-14 21:50:49,563:INFO:Set up binning of numerical features.
2025-05-14 21:50:49,717:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:50:49,919:INFO:Finished creating preprocessing pipeline.
2025-05-14 21:50:49,956:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['antiguedad_meses', 'satisfaccion',
                                             'promociones', 'home_office'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('cat...
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.85))),
                ('bin_numeric_features',
                 TransformerWrapper(exclude=None,
                                    include=['antiguedad_meses',
                                             'satisfaccion'],
                                    transformer=KBinsDiscretizer(dtype=None,
                                                                 encode='ordinal',
                                                                 n_bins=5,
                                                                 random_state=None,
                                                                 strategy='kmeans',
                                                                 subsample='warn')))],
         verbose=False)
2025-05-14 21:50:49,957:INFO:Creating final display dataframe.
2025-05-14 21:50:50,234:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target          renuncia
2                   Target type            Binary
3           Original data shape          (280, 8)
4        Transformed data shape         (280, 39)
5   Transformed train set shape         (196, 39)
6    Transformed test set shape          (84, 39)
7               Ignore features                 1
8              Numeric features                 4
9          Categorical features                 2
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16          Polynomial features              True
17            Polynomial degree                 2
18     Remove multicollinearity              True
19  Multicollinearity threshold              0.85
20               Fold Generator   StratifiedKFold
21                  Fold Number                10
22                     CPU Jobs                -1
23                      Use GPU             False
24               Log Experiment             False
25              Experiment Name  clf-default-name
26                          USI              fac1
2025-05-14 21:50:50,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:50,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:50,402:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:50,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 21:50:50,403:INFO:setup() successfully completed in 1.5s...............
2025-05-14 21:50:50,412:INFO:Initializing compare_models()
2025-05-14 21:50:50,413:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 21:50:50,413:INFO:Checking exceptions
2025-05-14 21:50:50,417:INFO:Preparing display monitor
2025-05-14 21:50:50,453:INFO:Initializing Logistic Regression
2025-05-14 21:50:50,453:INFO:Total runtime is 0.0 minutes
2025-05-14 21:50:50,459:INFO:SubProcess create_model() called ==================================
2025-05-14 21:50:50,459:INFO:Initializing create_model()
2025-05-14 21:50:50,460:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15A6F0750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:50:50,460:INFO:Checking exceptions
2025-05-14 21:50:50,460:INFO:Importing libraries
2025-05-14 21:50:50,460:INFO:Copying training dataset
2025-05-14 21:50:50,464:INFO:Defining folds
2025-05-14 21:50:50,464:INFO:Declaring metric variables
2025-05-14 21:50:50,467:INFO:Importing untrained model
2025-05-14 21:50:50,471:INFO:Logistic Regression Imported successfully
2025-05-14 21:50:50,479:INFO:Starting cross validation
2025-05-14 21:50:50,481:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:01,483:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:01,564:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:01,654:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:01,874:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:02,106:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 21:51:02,107:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 21:51:02,119:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:02,280:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:02,402:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:02,427:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:02,461:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:02,546:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 21:51:02,608:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:02,680:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:02,827:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 21:51:02,835:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:02,852:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-14 21:51:02,939:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:03,009:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:03,105:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:03,126:INFO:Calculating mean and std
2025-05-14 21:51:03,128:INFO:Creating metrics dataframe
2025-05-14 21:51:03,134:INFO:Uploading results into container
2025-05-14 21:51:03,136:INFO:Uploading model into container now
2025-05-14 21:51:03,136:INFO:_master_model_container: 1
2025-05-14 21:51:03,137:INFO:_display_container: 2
2025-05-14 21:51:03,137:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 21:51:03,139:INFO:create_model() successfully completed......................................
2025-05-14 21:51:03,266:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:03,266:INFO:Creating metrics dataframe
2025-05-14 21:51:03,275:INFO:Initializing K Neighbors Classifier
2025-05-14 21:51:03,275:INFO:Total runtime is 0.2137020508448283 minutes
2025-05-14 21:51:03,280:INFO:SubProcess create_model() called ==================================
2025-05-14 21:51:03,281:INFO:Initializing create_model()
2025-05-14 21:51:03,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15A6F0750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:51:03,282:INFO:Checking exceptions
2025-05-14 21:51:03,282:INFO:Importing libraries
2025-05-14 21:51:03,282:INFO:Copying training dataset
2025-05-14 21:51:03,288:INFO:Defining folds
2025-05-14 21:51:03,288:INFO:Declaring metric variables
2025-05-14 21:51:03,294:INFO:Importing untrained model
2025-05-14 21:51:03,303:INFO:K Neighbors Classifier Imported successfully
2025-05-14 21:51:03,315:INFO:Starting cross validation
2025-05-14 21:51:03,320:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:03,539:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:03,542:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:03,552:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:03,554:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:03,558:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:03,563:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:03,577:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:03,594:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:03,673:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:03,678:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:03,700:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:03,708:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:03,710:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:03,734:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:03,740:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:03,809:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:03,820:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:03,952:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:03,961:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:03,969:INFO:Calculating mean and std
2025-05-14 21:51:03,970:INFO:Creating metrics dataframe
2025-05-14 21:51:03,973:INFO:Uploading results into container
2025-05-14 21:51:03,974:INFO:Uploading model into container now
2025-05-14 21:51:03,974:INFO:_master_model_container: 2
2025-05-14 21:51:03,974:INFO:_display_container: 2
2025-05-14 21:51:03,975:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 21:51:03,975:INFO:create_model() successfully completed......................................
2025-05-14 21:51:04,087:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:04,087:INFO:Creating metrics dataframe
2025-05-14 21:51:04,101:INFO:Initializing Naive Bayes
2025-05-14 21:51:04,103:INFO:Total runtime is 0.2275024135907491 minutes
2025-05-14 21:51:04,108:INFO:SubProcess create_model() called ==================================
2025-05-14 21:51:04,108:INFO:Initializing create_model()
2025-05-14 21:51:04,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15A6F0750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:51:04,109:INFO:Checking exceptions
2025-05-14 21:51:04,109:INFO:Importing libraries
2025-05-14 21:51:04,110:INFO:Copying training dataset
2025-05-14 21:51:04,118:INFO:Defining folds
2025-05-14 21:51:04,118:INFO:Declaring metric variables
2025-05-14 21:51:04,123:INFO:Importing untrained model
2025-05-14 21:51:04,133:INFO:Naive Bayes Imported successfully
2025-05-14 21:51:04,146:INFO:Starting cross validation
2025-05-14 21:51:04,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:04,316:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:04,323:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:04,335:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:04,338:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:04,340:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:04,342:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:04,350:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:04,362:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:04,580:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:04,592:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:04,677:INFO:Calculating mean and std
2025-05-14 21:51:04,679:INFO:Creating metrics dataframe
2025-05-14 21:51:04,682:INFO:Uploading results into container
2025-05-14 21:51:04,683:INFO:Uploading model into container now
2025-05-14 21:51:04,683:INFO:_master_model_container: 3
2025-05-14 21:51:04,684:INFO:_display_container: 2
2025-05-14 21:51:04,684:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:51:04,684:INFO:create_model() successfully completed......................................
2025-05-14 21:51:04,790:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:04,790:INFO:Creating metrics dataframe
2025-05-14 21:51:04,801:INFO:Initializing Decision Tree Classifier
2025-05-14 21:51:04,803:INFO:Total runtime is 0.2391713539759318 minutes
2025-05-14 21:51:04,809:INFO:SubProcess create_model() called ==================================
2025-05-14 21:51:04,809:INFO:Initializing create_model()
2025-05-14 21:51:04,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15A6F0750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:51:04,809:INFO:Checking exceptions
2025-05-14 21:51:04,809:INFO:Importing libraries
2025-05-14 21:51:04,809:INFO:Copying training dataset
2025-05-14 21:51:04,818:INFO:Defining folds
2025-05-14 21:51:04,818:INFO:Declaring metric variables
2025-05-14 21:51:04,826:INFO:Importing untrained model
2025-05-14 21:51:04,833:INFO:Decision Tree Classifier Imported successfully
2025-05-14 21:51:04,846:INFO:Starting cross validation
2025-05-14 21:51:04,850:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:05,021:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:05,024:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:05,033:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:05,036:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:05,039:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:05,040:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:05,080:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:05,084:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:05,291:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:05,293:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:05,413:INFO:Calculating mean and std
2025-05-14 21:51:05,416:INFO:Creating metrics dataframe
2025-05-14 21:51:05,420:INFO:Uploading results into container
2025-05-14 21:51:05,422:INFO:Uploading model into container now
2025-05-14 21:51:05,423:INFO:_master_model_container: 4
2025-05-14 21:51:05,423:INFO:_display_container: 2
2025-05-14 21:51:05,424:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-14 21:51:05,425:INFO:create_model() successfully completed......................................
2025-05-14 21:51:05,550:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:05,551:INFO:Creating metrics dataframe
2025-05-14 21:51:05,564:INFO:Initializing SVM - Linear Kernel
2025-05-14 21:51:05,565:INFO:Total runtime is 0.25187127192815145 minutes
2025-05-14 21:51:05,570:INFO:SubProcess create_model() called ==================================
2025-05-14 21:51:05,571:INFO:Initializing create_model()
2025-05-14 21:51:05,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15A6F0750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:51:05,571:INFO:Checking exceptions
2025-05-14 21:51:05,571:INFO:Importing libraries
2025-05-14 21:51:05,571:INFO:Copying training dataset
2025-05-14 21:51:05,578:INFO:Defining folds
2025-05-14 21:51:05,579:INFO:Declaring metric variables
2025-05-14 21:51:05,584:INFO:Importing untrained model
2025-05-14 21:51:05,593:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 21:51:05,610:INFO:Starting cross validation
2025-05-14 21:51:05,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:05,884:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:05,886:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:05,911:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:05,943:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:05,962:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:06,009:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:06,019:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:06,021:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:06,031:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:06,049:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:06,065:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:06,198:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:06,326:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:06,330:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:06,413:INFO:Calculating mean and std
2025-05-14 21:51:06,416:INFO:Creating metrics dataframe
2025-05-14 21:51:06,419:INFO:Uploading results into container
2025-05-14 21:51:06,420:INFO:Uploading model into container now
2025-05-14 21:51:06,420:INFO:_master_model_container: 5
2025-05-14 21:51:06,421:INFO:_display_container: 2
2025-05-14 21:51:06,423:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 21:51:06,423:INFO:create_model() successfully completed......................................
2025-05-14 21:51:06,546:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:06,546:INFO:Creating metrics dataframe
2025-05-14 21:51:06,557:INFO:Initializing Ridge Classifier
2025-05-14 21:51:06,557:INFO:Total runtime is 0.26840918461481733 minutes
2025-05-14 21:51:06,563:INFO:SubProcess create_model() called ==================================
2025-05-14 21:51:06,564:INFO:Initializing create_model()
2025-05-14 21:51:06,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15A6F0750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:51:06,565:INFO:Checking exceptions
2025-05-14 21:51:06,565:INFO:Importing libraries
2025-05-14 21:51:06,565:INFO:Copying training dataset
2025-05-14 21:51:06,570:INFO:Defining folds
2025-05-14 21:51:06,570:INFO:Declaring metric variables
2025-05-14 21:51:06,577:INFO:Importing untrained model
2025-05-14 21:51:06,584:INFO:Ridge Classifier Imported successfully
2025-05-14 21:51:06,595:INFO:Starting cross validation
2025-05-14 21:51:06,599:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:06,782:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:06,796:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:06,801:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:06,803:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:06,810:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:06,816:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:06,823:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:06,901:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:06,905:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:06,914:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:06,924:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:06,924:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:06,939:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:07,014:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:07,014:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:07,067:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:07,078:INFO:Calculating mean and std
2025-05-14 21:51:07,080:INFO:Creating metrics dataframe
2025-05-14 21:51:07,084:INFO:Uploading results into container
2025-05-14 21:51:07,085:INFO:Uploading model into container now
2025-05-14 21:51:07,086:INFO:_master_model_container: 6
2025-05-14 21:51:07,086:INFO:_display_container: 2
2025-05-14 21:51:07,087:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-05-14 21:51:07,087:INFO:create_model() successfully completed......................................
2025-05-14 21:51:07,187:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:07,187:INFO:Creating metrics dataframe
2025-05-14 21:51:07,198:INFO:Initializing Random Forest Classifier
2025-05-14 21:51:07,198:INFO:Total runtime is 0.27908283472061163 minutes
2025-05-14 21:51:07,202:INFO:SubProcess create_model() called ==================================
2025-05-14 21:51:07,202:INFO:Initializing create_model()
2025-05-14 21:51:07,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15A6F0750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:51:07,203:INFO:Checking exceptions
2025-05-14 21:51:07,203:INFO:Importing libraries
2025-05-14 21:51:07,203:INFO:Copying training dataset
2025-05-14 21:51:07,208:INFO:Defining folds
2025-05-14 21:51:07,209:INFO:Declaring metric variables
2025-05-14 21:51:07,214:INFO:Importing untrained model
2025-05-14 21:51:07,220:INFO:Random Forest Classifier Imported successfully
2025-05-14 21:51:07,230:INFO:Starting cross validation
2025-05-14 21:51:07,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:07,400:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:07,404:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:07,411:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:07,421:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:07,422:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:07,430:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:07,448:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:08,077:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:08,117:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:08,161:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:08,167:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:08,219:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:08,225:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:08,623:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:08,648:INFO:Calculating mean and std
2025-05-14 21:51:08,650:INFO:Creating metrics dataframe
2025-05-14 21:51:08,652:INFO:Uploading results into container
2025-05-14 21:51:08,652:INFO:Uploading model into container now
2025-05-14 21:51:08,652:INFO:_master_model_container: 7
2025-05-14 21:51:08,653:INFO:_display_container: 2
2025-05-14 21:51:08,653:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-05-14 21:51:08,653:INFO:create_model() successfully completed......................................
2025-05-14 21:51:08,743:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:08,743:INFO:Creating metrics dataframe
2025-05-14 21:51:08,753:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 21:51:08,753:INFO:Total runtime is 0.3050028443336487 minutes
2025-05-14 21:51:08,769:INFO:SubProcess create_model() called ==================================
2025-05-14 21:51:08,769:INFO:Initializing create_model()
2025-05-14 21:51:08,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15A6F0750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:51:08,770:INFO:Checking exceptions
2025-05-14 21:51:08,770:INFO:Importing libraries
2025-05-14 21:51:08,770:INFO:Copying training dataset
2025-05-14 21:51:08,781:INFO:Defining folds
2025-05-14 21:51:08,781:INFO:Declaring metric variables
2025-05-14 21:51:08,786:INFO:Importing untrained model
2025-05-14 21:51:08,791:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 21:51:08,801:INFO:Starting cross validation
2025-05-14 21:51:08,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:08,963:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:08,963:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:08,967:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:08,971:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:08,972:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:08,978:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:08,984:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:51:08,984:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:51:08,986:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:51:08,987:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:51:08,994:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:51:08,994:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:09,000:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:51:09,019:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:51:09,033:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:09,054:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:51:09,074:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:09,079:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:09,082:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:09,091:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:09,100:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:09,107:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:09,108:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:09,141:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:09,196:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:09,207:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:09,210:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:51:09,221:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-14 21:51:09,270:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:09,279:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:09,291:INFO:Calculating mean and std
2025-05-14 21:51:09,294:INFO:Creating metrics dataframe
2025-05-14 21:51:09,300:INFO:Uploading results into container
2025-05-14 21:51:09,301:INFO:Uploading model into container now
2025-05-14 21:51:09,301:INFO:_master_model_container: 8
2025-05-14 21:51:09,301:INFO:_display_container: 2
2025-05-14 21:51:09,302:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 21:51:09,302:INFO:create_model() successfully completed......................................
2025-05-14 21:51:09,427:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:09,427:INFO:Creating metrics dataframe
2025-05-14 21:51:09,439:INFO:Initializing Ada Boost Classifier
2025-05-14 21:51:09,439:INFO:Total runtime is 0.31644427776336675 minutes
2025-05-14 21:51:09,446:INFO:SubProcess create_model() called ==================================
2025-05-14 21:51:09,447:INFO:Initializing create_model()
2025-05-14 21:51:09,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15A6F0750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:51:09,447:INFO:Checking exceptions
2025-05-14 21:51:09,447:INFO:Importing libraries
2025-05-14 21:51:09,447:INFO:Copying training dataset
2025-05-14 21:51:09,454:INFO:Defining folds
2025-05-14 21:51:09,454:INFO:Declaring metric variables
2025-05-14 21:51:09,464:INFO:Importing untrained model
2025-05-14 21:51:09,471:INFO:Ada Boost Classifier Imported successfully
2025-05-14 21:51:09,486:INFO:Starting cross validation
2025-05-14 21:51:09,490:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:09,674:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:09,680:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:09,683:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:09,686:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:09,687:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:09,694:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:51:09,701:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:51:09,706:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:51:09,710:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:51:09,723:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:51:09,728:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:09,744:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:09,745:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:51:09,761:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:51:09,783:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:09,819:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:51:10,107:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:10,223:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:10,238:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:51:10,246:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:10,250:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:10,261:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 21:51:10,456:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:10,470:INFO:Calculating mean and std
2025-05-14 21:51:10,472:INFO:Creating metrics dataframe
2025-05-14 21:51:10,475:INFO:Uploading results into container
2025-05-14 21:51:10,477:INFO:Uploading model into container now
2025-05-14 21:51:10,477:INFO:_master_model_container: 9
2025-05-14 21:51:10,477:INFO:_display_container: 2
2025-05-14 21:51:10,477:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-14 21:51:10,477:INFO:create_model() successfully completed......................................
2025-05-14 21:51:10,585:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:10,585:INFO:Creating metrics dataframe
2025-05-14 21:51:10,602:INFO:Initializing Gradient Boosting Classifier
2025-05-14 21:51:10,602:INFO:Total runtime is 0.3358206629753113 minutes
2025-05-14 21:51:10,609:INFO:SubProcess create_model() called ==================================
2025-05-14 21:51:10,609:INFO:Initializing create_model()
2025-05-14 21:51:10,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15A6F0750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:51:10,610:INFO:Checking exceptions
2025-05-14 21:51:10,610:INFO:Importing libraries
2025-05-14 21:51:10,610:INFO:Copying training dataset
2025-05-14 21:51:10,615:INFO:Defining folds
2025-05-14 21:51:10,615:INFO:Declaring metric variables
2025-05-14 21:51:10,619:INFO:Importing untrained model
2025-05-14 21:51:10,624:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 21:51:10,634:INFO:Starting cross validation
2025-05-14 21:51:10,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:10,767:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:10,769:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:10,774:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:10,784:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:10,784:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:10,786:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:10,790:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:10,811:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:11,427:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:11,441:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:11,726:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:11,738:INFO:Calculating mean and std
2025-05-14 21:51:11,740:INFO:Creating metrics dataframe
2025-05-14 21:51:11,744:INFO:Uploading results into container
2025-05-14 21:51:11,745:INFO:Uploading model into container now
2025-05-14 21:51:11,746:INFO:_master_model_container: 10
2025-05-14 21:51:11,746:INFO:_display_container: 2
2025-05-14 21:51:11,747:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 21:51:11,747:INFO:create_model() successfully completed......................................
2025-05-14 21:51:11,843:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:11,844:INFO:Creating metrics dataframe
2025-05-14 21:51:11,856:INFO:Initializing Linear Discriminant Analysis
2025-05-14 21:51:11,857:INFO:Total runtime is 0.35673379898071295 minutes
2025-05-14 21:51:11,862:INFO:SubProcess create_model() called ==================================
2025-05-14 21:51:11,862:INFO:Initializing create_model()
2025-05-14 21:51:11,862:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15A6F0750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:51:11,863:INFO:Checking exceptions
2025-05-14 21:51:11,863:INFO:Importing libraries
2025-05-14 21:51:11,863:INFO:Copying training dataset
2025-05-14 21:51:11,868:INFO:Defining folds
2025-05-14 21:51:11,868:INFO:Declaring metric variables
2025-05-14 21:51:11,873:INFO:Importing untrained model
2025-05-14 21:51:11,880:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 21:51:11,890:INFO:Starting cross validation
2025-05-14 21:51:11,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:12,050:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,053:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,055:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,058:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,065:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,082:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,138:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,194:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:12,233:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:12,348:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,352:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,423:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:12,443:INFO:Calculating mean and std
2025-05-14 21:51:12,445:INFO:Creating metrics dataframe
2025-05-14 21:51:12,449:INFO:Uploading results into container
2025-05-14 21:51:12,450:INFO:Uploading model into container now
2025-05-14 21:51:12,451:INFO:_master_model_container: 11
2025-05-14 21:51:12,451:INFO:_display_container: 2
2025-05-14 21:51:12,453:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 21:51:12,453:INFO:create_model() successfully completed......................................
2025-05-14 21:51:12,564:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:12,564:INFO:Creating metrics dataframe
2025-05-14 21:51:12,577:INFO:Initializing Extra Trees Classifier
2025-05-14 21:51:12,578:INFO:Total runtime is 0.368755849202474 minutes
2025-05-14 21:51:12,583:INFO:SubProcess create_model() called ==================================
2025-05-14 21:51:12,583:INFO:Initializing create_model()
2025-05-14 21:51:12,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15A6F0750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:51:12,583:INFO:Checking exceptions
2025-05-14 21:51:12,583:INFO:Importing libraries
2025-05-14 21:51:12,583:INFO:Copying training dataset
2025-05-14 21:51:12,587:INFO:Defining folds
2025-05-14 21:51:12,588:INFO:Declaring metric variables
2025-05-14 21:51:12,595:INFO:Importing untrained model
2025-05-14 21:51:12,601:INFO:Extra Trees Classifier Imported successfully
2025-05-14 21:51:12,616:INFO:Starting cross validation
2025-05-14 21:51:12,619:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:12,798:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,806:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,826:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,828:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,835:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,840:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,857:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:12,877:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:13,360:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:13,479:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:13,503:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:13,815:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:13,829:INFO:Calculating mean and std
2025-05-14 21:51:13,830:INFO:Creating metrics dataframe
2025-05-14 21:51:13,833:INFO:Uploading results into container
2025-05-14 21:51:13,834:INFO:Uploading model into container now
2025-05-14 21:51:13,835:INFO:_master_model_container: 12
2025-05-14 21:51:13,836:INFO:_display_container: 2
2025-05-14 21:51:13,837:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-05-14 21:51:13,837:INFO:create_model() successfully completed......................................
2025-05-14 21:51:13,967:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:13,967:INFO:Creating metrics dataframe
2025-05-14 21:51:13,991:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 21:51:13,992:INFO:Total runtime is 0.3923207759857178 minutes
2025-05-14 21:51:14,002:INFO:SubProcess create_model() called ==================================
2025-05-14 21:51:14,004:INFO:Initializing create_model()
2025-05-14 21:51:14,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15A6F0750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:51:14,004:INFO:Checking exceptions
2025-05-14 21:51:14,004:INFO:Importing libraries
2025-05-14 21:51:14,004:INFO:Copying training dataset
2025-05-14 21:51:14,015:INFO:Defining folds
2025-05-14 21:51:14,016:INFO:Declaring metric variables
2025-05-14 21:51:14,027:INFO:Importing untrained model
2025-05-14 21:51:14,037:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 21:51:14,048:INFO:Starting cross validation
2025-05-14 21:51:14,051:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:14,220:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:14,223:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:14,224:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:14,228:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:14,232:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:14,241:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:14,270:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:14,276:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:14,780:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:14,965:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:14,992:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:15,456:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:15,456:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:15,471:INFO:Calculating mean and std
2025-05-14 21:51:15,473:INFO:Creating metrics dataframe
2025-05-14 21:51:15,478:INFO:Uploading results into container
2025-05-14 21:51:15,479:INFO:Uploading model into container now
2025-05-14 21:51:15,480:INFO:_master_model_container: 13
2025-05-14 21:51:15,480:INFO:_display_container: 2
2025-05-14 21:51:15,481:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 21:51:15,481:INFO:create_model() successfully completed......................................
2025-05-14 21:51:15,597:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:15,597:INFO:Creating metrics dataframe
2025-05-14 21:51:15,612:INFO:Initializing Dummy Classifier
2025-05-14 21:51:15,612:INFO:Total runtime is 0.41932363510131837 minutes
2025-05-14 21:51:15,619:INFO:SubProcess create_model() called ==================================
2025-05-14 21:51:15,620:INFO:Initializing create_model()
2025-05-14 21:51:15,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15A6F0750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:51:15,620:INFO:Checking exceptions
2025-05-14 21:51:15,620:INFO:Importing libraries
2025-05-14 21:51:15,620:INFO:Copying training dataset
2025-05-14 21:51:15,626:INFO:Defining folds
2025-05-14 21:51:15,627:INFO:Declaring metric variables
2025-05-14 21:51:15,634:INFO:Importing untrained model
2025-05-14 21:51:15,641:INFO:Dummy Classifier Imported successfully
2025-05-14 21:51:15,655:INFO:Starting cross validation
2025-05-14 21:51:15,658:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:15,873:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:15,876:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:15,878:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:15,881:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:15,881:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:15,895:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:15,928:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:15,949:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:15,983:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:15,986:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:15,987:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:15,987:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:15,998:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:16,011:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:16,029:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:16,047:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:16,117:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:16,129:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:16,191:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:16,201:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 21:51:16,218:INFO:Calculating mean and std
2025-05-14 21:51:16,221:INFO:Creating metrics dataframe
2025-05-14 21:51:16,228:INFO:Uploading results into container
2025-05-14 21:51:16,229:INFO:Uploading model into container now
2025-05-14 21:51:16,229:INFO:_master_model_container: 14
2025-05-14 21:51:16,229:INFO:_display_container: 2
2025-05-14 21:51:16,230:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-05-14 21:51:16,230:INFO:create_model() successfully completed......................................
2025-05-14 21:51:16,342:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:16,342:INFO:Creating metrics dataframe
2025-05-14 21:51:16,360:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-14 21:51:16,375:INFO:Initializing create_model()
2025-05-14 21:51:16,375:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:51:16,375:INFO:Checking exceptions
2025-05-14 21:51:16,378:INFO:Importing libraries
2025-05-14 21:51:16,378:INFO:Copying training dataset
2025-05-14 21:51:16,381:INFO:Defining folds
2025-05-14 21:51:16,381:INFO:Declaring metric variables
2025-05-14 21:51:16,382:INFO:Importing untrained model
2025-05-14 21:51:16,382:INFO:Declaring custom model
2025-05-14 21:51:16,382:INFO:Naive Bayes Imported successfully
2025-05-14 21:51:16,383:INFO:Cross validation set to False
2025-05-14 21:51:16,383:INFO:Fitting Model
2025-05-14 21:51:16,467:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:16,476:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:51:16,476:INFO:create_model() successfully completed......................................
2025-05-14 21:51:16,591:INFO:_master_model_container: 14
2025-05-14 21:51:16,591:INFO:_display_container: 2
2025-05-14 21:51:16,592:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:51:16,592:INFO:compare_models() successfully completed......................................
2025-05-14 21:51:16,616:INFO:Initializing tune_model()
2025-05-14 21:51:16,616:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 21:51:16,616:INFO:Checking exceptions
2025-05-14 21:51:16,641:INFO:Copying training dataset
2025-05-14 21:51:16,647:INFO:Checking base model
2025-05-14 21:51:16,647:INFO:Base model : Naive Bayes
2025-05-14 21:51:16,681:INFO:Declaring metric variables
2025-05-14 21:51:16,690:INFO:Defining Hyperparameters
2025-05-14 21:51:16,820:INFO:Tuning with n_jobs=-1
2025-05-14 21:51:16,820:INFO:Initializing RandomizedSearchCV
2025-05-14 21:51:16,992:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:16,997:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,001:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,001:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,007:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,009:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,016:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,030:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,232:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,256:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,256:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,276:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,277:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,292:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,294:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,303:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,475:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,525:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,531:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,531:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,554:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,557:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,564:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,564:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,747:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,783:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,783:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,789:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,805:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,824:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,828:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:17,852:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,065:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,125:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,138:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,141:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,167:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,169:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,207:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,224:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,380:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,468:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,480:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,510:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,524:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,531:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,562:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,563:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,698:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,793:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,801:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,821:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,824:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,853:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,861:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,862:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:18,993:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,057:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,077:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,087:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,111:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,129:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,134:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,161:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,264:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,331:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,353:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,361:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,400:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,402:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,433:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,434:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,548:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,609:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,634:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,660:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,660:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,662:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,689:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,709:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,805:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,879:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,914:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,920:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,923:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,929:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,956:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:19,957:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,064:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,140:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,166:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,185:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,193:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,212:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,234:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,250:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,334:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,408:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,462:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,478:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,581:INFO:best_params: {'actual_estimator__var_smoothing': 1e-09}
2025-05-14 21:51:20,583:INFO:Hyperparameter search completed
2025-05-14 21:51:20,584:INFO:SubProcess create_model() called ==================================
2025-05-14 21:51:20,585:INFO:Initializing create_model()
2025-05-14 21:51:20,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C156C2B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 1e-09})
2025-05-14 21:51:20,586:INFO:Checking exceptions
2025-05-14 21:51:20,586:INFO:Importing libraries
2025-05-14 21:51:20,586:INFO:Copying training dataset
2025-05-14 21:51:20,600:INFO:Defining folds
2025-05-14 21:51:20,600:INFO:Declaring metric variables
2025-05-14 21:51:20,608:INFO:Importing untrained model
2025-05-14 21:51:20,608:INFO:Declaring custom model
2025-05-14 21:51:20,617:INFO:Naive Bayes Imported successfully
2025-05-14 21:51:20,635:INFO:Starting cross validation
2025-05-14 21:51:20,637:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:20,814:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,819:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,821:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,827:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,831:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,835:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,836:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:20,861:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:21,054:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:21,060:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:21,134:INFO:Calculating mean and std
2025-05-14 21:51:21,137:INFO:Creating metrics dataframe
2025-05-14 21:51:21,144:INFO:Finalizing model
2025-05-14 21:51:21,234:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:21,258:INFO:Uploading results into container
2025-05-14 21:51:21,259:INFO:Uploading model into container now
2025-05-14 21:51:21,260:INFO:_master_model_container: 15
2025-05-14 21:51:21,260:INFO:_display_container: 3
2025-05-14 21:51:21,260:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:51:21,260:INFO:create_model() successfully completed......................................
2025-05-14 21:51:21,372:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:21,372:INFO:choose_better activated
2025-05-14 21:51:21,377:INFO:SubProcess create_model() called ==================================
2025-05-14 21:51:21,377:INFO:Initializing create_model()
2025-05-14 21:51:21,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:51:21,377:INFO:Checking exceptions
2025-05-14 21:51:21,379:INFO:Importing libraries
2025-05-14 21:51:21,379:INFO:Copying training dataset
2025-05-14 21:51:21,384:INFO:Defining folds
2025-05-14 21:51:21,384:INFO:Declaring metric variables
2025-05-14 21:51:21,384:INFO:Importing untrained model
2025-05-14 21:51:21,384:INFO:Declaring custom model
2025-05-14 21:51:21,385:INFO:Naive Bayes Imported successfully
2025-05-14 21:51:21,385:INFO:Starting cross validation
2025-05-14 21:51:21,387:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:51:21,548:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:21,548:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:21,551:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:21,557:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:21,563:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:21,565:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:21,567:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:21,741:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:21,749:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:21,817:INFO:Calculating mean and std
2025-05-14 21:51:21,817:INFO:Creating metrics dataframe
2025-05-14 21:51:21,820:INFO:Finalizing model
2025-05-14 21:51:21,887:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:51:21,898:INFO:Uploading results into container
2025-05-14 21:51:21,898:INFO:Uploading model into container now
2025-05-14 21:51:21,899:INFO:_master_model_container: 16
2025-05-14 21:51:21,899:INFO:_display_container: 4
2025-05-14 21:51:21,899:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:51:21,899:INFO:create_model() successfully completed......................................
2025-05-14 21:51:21,991:INFO:SubProcess create_model() end ==================================
2025-05-14 21:51:21,993:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5167
2025-05-14 21:51:21,993:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5167
2025-05-14 21:51:21,993:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2025-05-14 21:51:21,993:INFO:choose_better completed
2025-05-14 21:51:21,993:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-14 21:51:22,004:INFO:_master_model_container: 16
2025-05-14 21:51:22,004:INFO:_display_container: 3
2025-05-14 21:51:22,006:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:51:22,006:INFO:tune_model() successfully completed......................................
2025-05-14 21:51:22,094:INFO:Initializing interpret_model()
2025-05-14 21:51:22,094:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 21:51:22,094:INFO:Checking exceptions
2025-05-14 21:51:22,094:INFO:Soft dependency imported: shap: 0.44.1
2025-05-14 21:52:01,213:INFO:Initializing tune_model()
2025-05-14 21:52:01,213:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 21:52:01,213:INFO:Checking exceptions
2025-05-14 21:52:01,240:INFO:Copying training dataset
2025-05-14 21:52:01,245:INFO:Checking base model
2025-05-14 21:52:01,246:INFO:Base model : Naive Bayes
2025-05-14 21:52:01,253:INFO:Declaring metric variables
2025-05-14 21:52:01,258:INFO:Defining Hyperparameters
2025-05-14 21:52:01,395:INFO:Tuning with n_jobs=-1
2025-05-14 21:52:01,396:INFO:Initializing RandomizedSearchCV
2025-05-14 21:52:01,571:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:01,571:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:01,573:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:01,576:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:01,578:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:01,583:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:01,599:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:01,606:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:01,794:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:01,803:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:01,849:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:01,863:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:01,874:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:01,901:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:01,918:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:01,941:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,012:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,044:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,089:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,096:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,102:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,149:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,160:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,242:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,318:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,330:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,374:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,375:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,387:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,405:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,432:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,471:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,533:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,554:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,589:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,590:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,607:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,625:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,629:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,700:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,750:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,751:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,806:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,851:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,864:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,867:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,872:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,911:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,969:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:02,977:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,020:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,054:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,079:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,084:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,099:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,131:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,186:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,199:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,247:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,277:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,299:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,329:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,331:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,379:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,407:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,423:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,486:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,502:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,533:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,545:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,547:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,595:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,630:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,690:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,698:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,731:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,737:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,744:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,814:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,829:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,853:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,911:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,944:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,947:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,952:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:03,970:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,018:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,033:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,062:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,131:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,161:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,178:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,193:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,198:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,267:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,272:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,284:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,375:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,436:INFO:best_params: {'actual_estimator__var_smoothing': 1e-09}
2025-05-14 21:52:04,437:INFO:Hyperparameter search completed
2025-05-14 21:52:04,437:INFO:SubProcess create_model() called ==================================
2025-05-14 21:52:04,438:INFO:Initializing create_model()
2025-05-14 21:52:04,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C156D1C490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 1e-09})
2025-05-14 21:52:04,438:INFO:Checking exceptions
2025-05-14 21:52:04,438:INFO:Importing libraries
2025-05-14 21:52:04,439:INFO:Copying training dataset
2025-05-14 21:52:04,443:INFO:Defining folds
2025-05-14 21:52:04,443:INFO:Declaring metric variables
2025-05-14 21:52:04,446:INFO:Importing untrained model
2025-05-14 21:52:04,446:INFO:Declaring custom model
2025-05-14 21:52:04,449:INFO:Naive Bayes Imported successfully
2025-05-14 21:52:04,456:INFO:Starting cross validation
2025-05-14 21:52:04,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:52:04,592:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,596:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,598:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,598:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,600:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,602:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,634:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,752:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,753:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:04,797:INFO:Calculating mean and std
2025-05-14 21:52:04,798:INFO:Creating metrics dataframe
2025-05-14 21:52:04,803:INFO:Finalizing model
2025-05-14 21:52:04,881:WARNING:In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.

2025-05-14 21:52:04,900:INFO:Uploading results into container
2025-05-14 21:52:04,902:INFO:Uploading model into container now
2025-05-14 21:52:04,902:INFO:_master_model_container: 17
2025-05-14 21:52:04,902:INFO:_display_container: 4
2025-05-14 21:52:04,903:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:52:04,903:INFO:create_model() successfully completed......................................
2025-05-14 21:52:05,019:INFO:SubProcess create_model() end ==================================
2025-05-14 21:52:05,020:INFO:choose_better activated
2025-05-14 21:52:05,025:INFO:SubProcess create_model() called ==================================
2025-05-14 21:52:05,025:INFO:Initializing create_model()
2025-05-14 21:52:05,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:52:05,025:INFO:Checking exceptions
2025-05-14 21:52:05,027:INFO:Importing libraries
2025-05-14 21:52:05,028:INFO:Copying training dataset
2025-05-14 21:52:05,031:INFO:Defining folds
2025-05-14 21:52:05,031:INFO:Declaring metric variables
2025-05-14 21:52:05,031:INFO:Importing untrained model
2025-05-14 21:52:05,031:INFO:Declaring custom model
2025-05-14 21:52:05,031:INFO:Naive Bayes Imported successfully
2025-05-14 21:52:05,031:INFO:Starting cross validation
2025-05-14 21:52:05,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:52:05,159:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:05,161:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:05,163:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:05,165:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:05,166:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:05,172:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:05,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:05,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:05,306:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:05,307:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:05,360:INFO:Calculating mean and std
2025-05-14 21:52:05,361:INFO:Creating metrics dataframe
2025-05-14 21:52:05,363:INFO:Finalizing model
2025-05-14 21:52:05,468:WARNING:In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.

2025-05-14 21:52:05,479:INFO:Uploading results into container
2025-05-14 21:52:05,479:INFO:Uploading model into container now
2025-05-14 21:52:05,480:INFO:_master_model_container: 18
2025-05-14 21:52:05,480:INFO:_display_container: 5
2025-05-14 21:52:05,480:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:52:05,480:INFO:create_model() successfully completed......................................
2025-05-14 21:52:05,597:INFO:SubProcess create_model() end ==================================
2025-05-14 21:52:05,598:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5167
2025-05-14 21:52:05,598:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5167
2025-05-14 21:52:05,598:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2025-05-14 21:52:05,598:INFO:choose_better completed
2025-05-14 21:52:05,598:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-14 21:52:05,609:INFO:_master_model_container: 18
2025-05-14 21:52:05,609:INFO:_display_container: 4
2025-05-14 21:52:05,609:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:52:05,610:INFO:tune_model() successfully completed......................................
2025-05-14 21:52:05,727:INFO:Initializing interpret_model()
2025-05-14 21:52:05,727:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 21:52:05,727:INFO:Checking exceptions
2025-05-14 21:52:05,727:INFO:Soft dependency imported: shap: 0.44.1
2025-05-14 21:52:19,027:INFO:Initializing tune_model()
2025-05-14 21:52:19,027:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 21:52:19,027:INFO:Checking exceptions
2025-05-14 21:52:19,053:INFO:Copying training dataset
2025-05-14 21:52:19,058:INFO:Checking base model
2025-05-14 21:52:19,058:INFO:Base model : Naive Bayes
2025-05-14 21:52:19,088:INFO:Declaring metric variables
2025-05-14 21:52:19,110:INFO:Defining Hyperparameters
2025-05-14 21:52:19,301:INFO:Tuning with n_jobs=-1
2025-05-14 21:52:19,301:INFO:Initializing RandomizedSearchCV
2025-05-14 21:52:19,466:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,492:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,497:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,497:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,505:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,519:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,531:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,560:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,671:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,690:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,697:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,703:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,704:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,717:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,731:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,753:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,860:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,890:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,900:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,919:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,927:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,960:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,963:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:19,967:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,100:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,132:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,138:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,139:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,154:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,191:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,239:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,341:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,361:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,385:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,394:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,407:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,419:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,430:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,477:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,581:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,597:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,651:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,678:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,679:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,687:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,698:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,811:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,836:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,841:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,876:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,877:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,883:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,884:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,916:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:20,994:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,018:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,030:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,054:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,068:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,072:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,076:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,114:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,200:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,229:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,236:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,259:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,261:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,269:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,279:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,329:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,413:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,416:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,431:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,437:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,456:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,463:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,468:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,510:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,597:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,626:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,650:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,660:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,678:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,681:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,689:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,789:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,815:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,826:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,851:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,857:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,880:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,881:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,882:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,975:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:21,996:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,000:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,004:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,046:INFO:best_params: {'actual_estimator__var_smoothing': 1e-09}
2025-05-14 21:52:22,047:INFO:Hyperparameter search completed
2025-05-14 21:52:22,047:INFO:SubProcess create_model() called ==================================
2025-05-14 21:52:22,048:INFO:Initializing create_model()
2025-05-14 21:52:22,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15F07B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 1e-09})
2025-05-14 21:52:22,048:INFO:Checking exceptions
2025-05-14 21:52:22,049:INFO:Importing libraries
2025-05-14 21:52:22,049:INFO:Copying training dataset
2025-05-14 21:52:22,053:INFO:Defining folds
2025-05-14 21:52:22,053:INFO:Declaring metric variables
2025-05-14 21:52:22,057:INFO:Importing untrained model
2025-05-14 21:52:22,057:INFO:Declaring custom model
2025-05-14 21:52:22,061:INFO:Naive Bayes Imported successfully
2025-05-14 21:52:22,067:INFO:Starting cross validation
2025-05-14 21:52:22,069:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:52:22,196:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,200:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,201:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,211:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,213:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,219:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,223:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,248:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,359:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,362:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,406:INFO:Calculating mean and std
2025-05-14 21:52:22,407:INFO:Creating metrics dataframe
2025-05-14 21:52:22,412:INFO:Finalizing model
2025-05-14 21:52:22,477:WARNING:In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.

2025-05-14 21:52:22,490:INFO:Uploading results into container
2025-05-14 21:52:22,491:INFO:Uploading model into container now
2025-05-14 21:52:22,491:INFO:_master_model_container: 19
2025-05-14 21:52:22,491:INFO:_display_container: 5
2025-05-14 21:52:22,493:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:52:22,493:INFO:create_model() successfully completed......................................
2025-05-14 21:52:22,607:INFO:SubProcess create_model() end ==================================
2025-05-14 21:52:22,607:INFO:choose_better activated
2025-05-14 21:52:22,611:INFO:SubProcess create_model() called ==================================
2025-05-14 21:52:22,611:INFO:Initializing create_model()
2025-05-14 21:52:22,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:52:22,611:INFO:Checking exceptions
2025-05-14 21:52:22,614:INFO:Importing libraries
2025-05-14 21:52:22,614:INFO:Copying training dataset
2025-05-14 21:52:22,621:INFO:Defining folds
2025-05-14 21:52:22,621:INFO:Declaring metric variables
2025-05-14 21:52:22,621:INFO:Importing untrained model
2025-05-14 21:52:22,621:INFO:Declaring custom model
2025-05-14 21:52:22,622:INFO:Naive Bayes Imported successfully
2025-05-14 21:52:22,622:INFO:Starting cross validation
2025-05-14 21:52:22,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:52:22,766:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,766:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,770:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,772:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,774:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,779:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,788:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,909:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,914:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:52:22,969:INFO:Calculating mean and std
2025-05-14 21:52:22,970:INFO:Creating metrics dataframe
2025-05-14 21:52:22,973:INFO:Finalizing model
2025-05-14 21:52:23,046:WARNING:In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.

2025-05-14 21:52:23,055:INFO:Uploading results into container
2025-05-14 21:52:23,055:INFO:Uploading model into container now
2025-05-14 21:52:23,056:INFO:_master_model_container: 20
2025-05-14 21:52:23,056:INFO:_display_container: 6
2025-05-14 21:52:23,056:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:52:23,056:INFO:create_model() successfully completed......................................
2025-05-14 21:52:23,166:INFO:SubProcess create_model() end ==================================
2025-05-14 21:52:23,167:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5167
2025-05-14 21:52:23,167:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5167
2025-05-14 21:52:23,167:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2025-05-14 21:52:23,167:INFO:choose_better completed
2025-05-14 21:52:23,167:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-14 21:52:23,177:INFO:_master_model_container: 20
2025-05-14 21:52:23,177:INFO:_display_container: 5
2025-05-14 21:52:23,177:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:52:23,177:INFO:tune_model() successfully completed......................................
2025-05-14 21:52:23,322:INFO:Initializing predict_model()
2025-05-14 21:52:23,322:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C15AA17E20>)
2025-05-14 21:52:23,322:INFO:Checking exceptions
2025-05-14 21:52:23,322:INFO:Preloading libraries
2025-05-14 21:52:39,011:INFO:Initializing predict_model()
2025-05-14 21:52:39,011:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C15F2A7B00>)
2025-05-14 21:52:39,011:INFO:Checking exceptions
2025-05-14 21:52:39,011:INFO:Preloading libraries
2025-05-14 21:53:47,544:INFO:Initializing tune_model()
2025-05-14 21:53:47,544:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 21:53:47,544:INFO:Checking exceptions
2025-05-14 21:53:47,564:INFO:Copying training dataset
2025-05-14 21:53:47,569:INFO:Checking base model
2025-05-14 21:53:47,569:INFO:Base model : Naive Bayes
2025-05-14 21:53:47,576:INFO:Declaring metric variables
2025-05-14 21:53:47,582:INFO:Defining Hyperparameters
2025-05-14 21:53:47,745:INFO:Tuning with n_jobs=-1
2025-05-14 21:53:47,745:INFO:Initializing RandomizedSearchCV
2025-05-14 21:53:47,890:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:47,898:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:47,900:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:47,967:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:47,992:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,033:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,040:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,075:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,150:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,156:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,177:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,269:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,290:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,310:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,313:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,376:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,385:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,389:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,406:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,477:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,498:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,533:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,533:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,577:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,584:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,610:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,615:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,658:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,709:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,741:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,741:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,773:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,783:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,799:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,849:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,897:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,917:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,924:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,961:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,964:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:48,967:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,020:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,048:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,094:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,130:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,140:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,170:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,190:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,217:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,248:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,297:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,321:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,355:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,367:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,384:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,395:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,426:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,453:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,506:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,515:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,560:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,560:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,575:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,587:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,626:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,664:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,704:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,708:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,752:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,757:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,766:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,777:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,819:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,850:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,890:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,911:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,929:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,943:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,952:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:49,969:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,009:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,044:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,102:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,103:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,120:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,135:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,140:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,223:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,291:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,304:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,310:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,343:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,364:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,397:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,412:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,461:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,521:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,607:INFO:best_params: {'actual_estimator__var_smoothing': 1e-09}
2025-05-14 21:53:50,607:INFO:Hyperparameter search completed
2025-05-14 21:53:50,607:INFO:SubProcess create_model() called ==================================
2025-05-14 21:53:50,607:INFO:Initializing create_model()
2025-05-14 21:53:50,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C15FD96ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 1e-09})
2025-05-14 21:53:50,607:INFO:Checking exceptions
2025-05-14 21:53:50,610:INFO:Importing libraries
2025-05-14 21:53:50,610:INFO:Copying training dataset
2025-05-14 21:53:50,614:INFO:Defining folds
2025-05-14 21:53:50,614:INFO:Declaring metric variables
2025-05-14 21:53:50,621:INFO:Importing untrained model
2025-05-14 21:53:50,621:INFO:Declaring custom model
2025-05-14 21:53:50,628:INFO:Naive Bayes Imported successfully
2025-05-14 21:53:50,641:INFO:Starting cross validation
2025-05-14 21:53:50,644:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:53:50,818:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,818:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,824:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,828:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,838:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,843:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:50,869:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:51,005:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:51,068:INFO:Calculating mean and std
2025-05-14 21:53:51,070:INFO:Creating metrics dataframe
2025-05-14 21:53:51,078:INFO:Finalizing model
2025-05-14 21:53:51,145:WARNING:In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.

2025-05-14 21:53:51,161:INFO:Uploading results into container
2025-05-14 21:53:51,163:INFO:Uploading model into container now
2025-05-14 21:53:51,163:INFO:_master_model_container: 21
2025-05-14 21:53:51,164:INFO:_display_container: 8
2025-05-14 21:53:51,164:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:53:51,164:INFO:create_model() successfully completed......................................
2025-05-14 21:53:51,349:INFO:SubProcess create_model() end ==================================
2025-05-14 21:53:51,350:INFO:choose_better activated
2025-05-14 21:53:51,355:INFO:SubProcess create_model() called ==================================
2025-05-14 21:53:51,355:INFO:Initializing create_model()
2025-05-14 21:53:51,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 21:53:51,356:INFO:Checking exceptions
2025-05-14 21:53:51,358:INFO:Importing libraries
2025-05-14 21:53:51,358:INFO:Copying training dataset
2025-05-14 21:53:51,362:INFO:Defining folds
2025-05-14 21:53:51,362:INFO:Declaring metric variables
2025-05-14 21:53:51,362:INFO:Importing untrained model
2025-05-14 21:53:51,362:INFO:Declaring custom model
2025-05-14 21:53:51,363:INFO:Naive Bayes Imported successfully
2025-05-14 21:53:51,363:INFO:Starting cross validation
2025-05-14 21:53:51,364:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 21:53:51,484:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:51,487:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:51,545:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:51,547:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:51,564:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:51,577:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:51,590:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:51,594:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:51,666:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:51,675:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 21:53:51,742:INFO:Calculating mean and std
2025-05-14 21:53:51,742:INFO:Creating metrics dataframe
2025-05-14 21:53:51,744:INFO:Finalizing model
2025-05-14 21:53:51,811:WARNING:In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.

2025-05-14 21:53:51,824:INFO:Uploading results into container
2025-05-14 21:53:51,824:INFO:Uploading model into container now
2025-05-14 21:53:51,825:INFO:_master_model_container: 22
2025-05-14 21:53:51,825:INFO:_display_container: 9
2025-05-14 21:53:51,825:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:53:51,825:INFO:create_model() successfully completed......................................
2025-05-14 21:53:51,975:INFO:SubProcess create_model() end ==================================
2025-05-14 21:53:51,975:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5167
2025-05-14 21:53:51,975:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.5167
2025-05-14 21:53:51,975:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2025-05-14 21:53:51,975:INFO:choose_better completed
2025-05-14 21:53:51,976:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-14 21:53:51,987:INFO:_master_model_container: 22
2025-05-14 21:53:51,988:INFO:_display_container: 8
2025-05-14 21:53:51,988:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 21:53:51,988:INFO:tune_model() successfully completed......................................
2025-05-14 21:53:52,199:INFO:Initializing predict_model()
2025-05-14 21:53:52,200:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C15F2A79C0>)
2025-05-14 21:53:52,200:INFO:Checking exceptions
2025-05-14 21:53:52,200:INFO:Preloading libraries
2025-05-14 21:54:08,782:INFO:Initializing predict_model()
2025-05-14 21:54:08,782:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C15F2A4720>)
2025-05-14 21:54:08,782:INFO:Checking exceptions
2025-05-14 21:54:08,782:INFO:Preloading libraries
2025-05-14 21:55:04,830:INFO:Initializing predict_model()
2025-05-14 21:55:04,830:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C15F2A7CE0>)
2025-05-14 21:55:04,830:INFO:Checking exceptions
2025-05-14 21:55:04,831:INFO:Preloading libraries
2025-05-14 21:55:25,980:INFO:Initializing predict_model()
2025-05-14 21:55:25,980:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C15AA14180>)
2025-05-14 21:55:25,980:INFO:Checking exceptions
2025-05-14 21:55:25,980:INFO:Preloading libraries
2025-05-14 21:57:23,121:INFO:Initializing predict_model()
2025-05-14 21:57:23,121:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C15F2A5D00>)
2025-05-14 21:57:23,121:INFO:Checking exceptions
2025-05-14 21:57:23,123:INFO:Preloading libraries
2025-05-14 21:57:29,337:INFO:Initializing predict_model()
2025-05-14 21:57:29,337:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C15F2A4680>)
2025-05-14 21:57:29,337:INFO:Checking exceptions
2025-05-14 21:57:29,338:INFO:Preloading libraries
2025-05-14 21:57:29,719:INFO:Initializing predict_model()
2025-05-14 21:57:29,719:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C15A70EED0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C15D3FACA0>)
2025-05-14 21:57:29,719:INFO:Checking exceptions
2025-05-14 21:57:29,720:INFO:Preloading libraries
2025-05-14 21:57:29,724:INFO:Set up data.
2025-05-14 21:57:29,730:INFO:Set up index.
2025-05-14 21:58:21,430:INFO:Initializing save_model()
2025-05-14 21:58:21,430:INFO:save_model(model=GaussianNB(priors=None, var_smoothing=1e-09), model_name=modelo_retencion_talento, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['antiguedad_meses', 'satisfaccion',
                                             'promociones', 'home_office'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('cat...
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.85))),
                ('bin_numeric_features',
                 TransformerWrapper(exclude=None,
                                    include=['antiguedad_meses',
                                             'satisfaccion'],
                                    transformer=KBinsDiscretizer(dtype=None,
                                                                 encode='ordinal',
                                                                 n_bins=5,
                                                                 random_state=None,
                                                                 strategy='kmeans',
                                                                 subsample='warn')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-14 21:58:21,430:INFO:Adding model into prep_pipe
2025-05-14 21:58:21,440:INFO:modelo_retencion_talento.pkl saved in current working directory
2025-05-14 21:58:21,461:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['antiguedad_meses', 'satisfaccion',
                                             'promociones', 'home_office'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                    transformer=RemoveMulticollinearity(threshold=0.85))),
                ('bin_numeric_features',
                 TransformerWrapper(exclude=None,
                                    include=['antiguedad_meses',
                                             'satisfaccion'],
                                    transformer=KBinsDiscretizer(dtype=None,
                                                                 encode='ordinal',
                                                                 n_bins=5,
                                                                 random_state=None,
                                                                 strategy='kmeans',
                                                                 subsample='warn'))),
                ('trained_model',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False)
2025-05-14 21:58:21,461:INFO:save_model() successfully completed......................................
2025-05-14 22:05:33,074:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 22:05:33,074:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 22:05:33,074:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 22:05:33,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-14 22:06:45,422:INFO:PyCaret ClassificationExperiment
2025-05-14 22:06:45,423:INFO:Logging name: clf-default-name
2025-05-14 22:06:45,423:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 22:06:45,423:INFO:version 3.3.2
2025-05-14 22:06:45,423:INFO:Initializing setup()
2025-05-14 22:06:45,423:INFO:self.USI: ab7f
2025-05-14 22:06:45,423:INFO:self._variable_keys: {'n_jobs_param', 'X_train', 'y_test', 'log_plots_param', 'fold_groups_param', 'logging_param', 'data', 'USI', 'html_param', 'seed', 'y', 'gpu_n_jobs_param', 'is_multiclass', 'gpu_param', '_available_plots', 'X', 'exp_name_log', 'fold_generator', 'memory', 'fold_shuffle_param', '_ml_usecase', 'y_train', 'fix_imbalance', 'X_test', 'idx', 'target_param', 'exp_id', 'pipeline'}
2025-05-14 22:06:45,423:INFO:Checking environment
2025-05-14 22:06:45,423:INFO:python_version: 3.11.8
2025-05-14 22:06:45,423:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-14 22:06:45,424:INFO:machine: AMD64
2025-05-14 22:06:45,424:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-14 22:06:45,429:INFO:Memory: svmem(total=16907886592, available=3668217856, percent=78.3, used=13239668736, free=3668217856)
2025-05-14 22:06:45,429:INFO:Physical Core: 4
2025-05-14 22:06:45,429:INFO:Logical Core: 8
2025-05-14 22:06:45,429:INFO:Checking libraries
2025-05-14 22:06:45,429:INFO:System:
2025-05-14 22:06:45,429:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-14 22:06:45,429:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-14 22:06:45,429:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-14 22:06:45,429:INFO:PyCaret required dependencies:
2025-05-14 22:06:45,508:INFO:                 pip: 24.0
2025-05-14 22:06:45,508:INFO:          setuptools: 65.5.0
2025-05-14 22:06:45,508:INFO:             pycaret: 3.3.2
2025-05-14 22:06:45,508:INFO:             IPython: 9.2.0
2025-05-14 22:06:45,508:INFO:          ipywidgets: 8.1.7
2025-05-14 22:06:45,508:INFO:                tqdm: 4.67.1
2025-05-14 22:06:45,508:INFO:               numpy: 1.26.4
2025-05-14 22:06:45,508:INFO:              pandas: 2.1.4
2025-05-14 22:06:45,508:INFO:              jinja2: 3.1.6
2025-05-14 22:06:45,508:INFO:               scipy: 1.11.4
2025-05-14 22:06:45,508:INFO:              joblib: 1.3.2
2025-05-14 22:06:45,508:INFO:             sklearn: 1.4.2
2025-05-14 22:06:45,508:INFO:                pyod: 2.0.5
2025-05-14 22:06:45,508:INFO:            imblearn: 0.13.0
2025-05-14 22:06:45,508:INFO:   category_encoders: 2.7.0
2025-05-14 22:06:45,508:INFO:            lightgbm: 4.6.0
2025-05-14 22:06:45,510:INFO:               numba: 0.61.0
2025-05-14 22:06:45,510:INFO:            requests: 2.32.3
2025-05-14 22:06:45,510:INFO:          matplotlib: 3.7.5
2025-05-14 22:06:45,510:INFO:          scikitplot: 0.3.7
2025-05-14 22:06:45,510:INFO:         yellowbrick: 1.5
2025-05-14 22:06:45,510:INFO:              plotly: 5.24.1
2025-05-14 22:06:45,510:INFO:    plotly-resampler: Not installed
2025-05-14 22:06:45,510:INFO:             kaleido: 0.2.1
2025-05-14 22:06:45,510:INFO:           schemdraw: 0.15
2025-05-14 22:06:45,510:INFO:         statsmodels: 0.14.4
2025-05-14 22:06:45,510:INFO:              sktime: 0.26.0
2025-05-14 22:06:45,510:INFO:               tbats: 1.1.3
2025-05-14 22:06:45,510:INFO:            pmdarima: 2.0.4
2025-05-14 22:06:45,510:INFO:              psutil: 7.0.0
2025-05-14 22:06:45,510:INFO:          markupsafe: 3.0.2
2025-05-14 22:06:45,510:INFO:             pickle5: Not installed
2025-05-14 22:06:45,510:INFO:         cloudpickle: 3.1.1
2025-05-14 22:06:45,510:INFO:         deprecation: 2.1.0
2025-05-14 22:06:45,511:INFO:              xxhash: 3.5.0
2025-05-14 22:06:45,511:INFO:           wurlitzer: Not installed
2025-05-14 22:06:45,511:INFO:PyCaret optional dependencies:
2025-05-14 22:06:45,520:INFO:                shap: 0.44.1
2025-05-14 22:06:45,520:INFO:           interpret: 0.6.10
2025-05-14 22:06:45,520:INFO:                umap: 0.5.7
2025-05-14 22:06:45,520:INFO:     ydata_profiling: 4.16.1
2025-05-14 22:06:45,520:INFO:  explainerdashboard: 0.4.8
2025-05-14 22:06:45,520:INFO:             autoviz: Not installed
2025-05-14 22:06:45,520:INFO:           fairlearn: 0.7.0
2025-05-14 22:06:45,520:INFO:          deepchecks: Not installed
2025-05-14 22:06:45,520:INFO:             xgboost: Not installed
2025-05-14 22:06:45,520:INFO:            catboost: Not installed
2025-05-14 22:06:45,520:INFO:              kmodes: Not installed
2025-05-14 22:06:45,520:INFO:             mlxtend: Not installed
2025-05-14 22:06:45,520:INFO:       statsforecast: Not installed
2025-05-14 22:06:45,520:INFO:        tune_sklearn: Not installed
2025-05-14 22:06:45,522:INFO:                 ray: Not installed
2025-05-14 22:06:45,522:INFO:            hyperopt: Not installed
2025-05-14 22:06:45,522:INFO:              optuna: Not installed
2025-05-14 22:06:45,522:INFO:               skopt: Not installed
2025-05-14 22:06:45,522:INFO:              mlflow: Not installed
2025-05-14 22:06:45,522:INFO:              gradio: Not installed
2025-05-14 22:06:45,522:INFO:             fastapi: Not installed
2025-05-14 22:06:45,522:INFO:             uvicorn: Not installed
2025-05-14 22:06:45,522:INFO:              m2cgen: Not installed
2025-05-14 22:06:45,522:INFO:           evidently: Not installed
2025-05-14 22:06:45,522:INFO:               fugue: Not installed
2025-05-14 22:06:45,522:INFO:           streamlit: Not installed
2025-05-14 22:06:45,522:INFO:             prophet: Not installed
2025-05-14 22:06:45,522:INFO:None
2025-05-14 22:06:45,522:INFO:Set up data.
2025-05-14 22:06:45,527:INFO:Set up folding strategy.
2025-05-14 22:06:45,527:INFO:Set up train/test split.
2025-05-14 22:06:45,535:INFO:Set up index.
2025-05-14 22:06:45,536:INFO:Assigning column types.
2025-05-14 22:06:45,539:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 22:06:45,597:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 22:06:45,599:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:06:45,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:45,635:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:45,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 22:06:45,678:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:06:45,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:45,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:45,700:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 22:06:45,739:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:06:45,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:45,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:45,813:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:06:45,834:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:45,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:45,835:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 22:06:45,908:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:45,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:45,985:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:45,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:45,987:INFO:Preparing preprocessing pipeline...
2025-05-14 22:06:45,987:INFO:Set up simple imputation.
2025-05-14 22:06:45,992:INFO:Set up encoding of categorical features.
2025-05-14 22:06:45,992:INFO:Set up polynomial features.
2025-05-14 22:06:45,992:INFO:Set up removing multicollinearity.
2025-05-14 22:06:45,992:INFO:Set up binning of numerical features.
2025-05-14 22:06:45,993:INFO:Set up feature selection.
2025-05-14 22:06:46,100:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:46,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:59,219:INFO:PyCaret ClassificationExperiment
2025-05-14 22:06:59,219:INFO:Logging name: clf-default-name
2025-05-14 22:06:59,219:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 22:06:59,219:INFO:version 3.3.2
2025-05-14 22:06:59,220:INFO:Initializing setup()
2025-05-14 22:06:59,220:INFO:self.USI: 7e96
2025-05-14 22:06:59,220:INFO:self._variable_keys: {'n_jobs_param', 'X_train', 'y_test', 'log_plots_param', 'fold_groups_param', 'logging_param', 'data', 'USI', 'html_param', 'seed', 'y', 'gpu_n_jobs_param', 'is_multiclass', 'gpu_param', '_available_plots', 'X', 'exp_name_log', 'fold_generator', 'memory', 'fold_shuffle_param', '_ml_usecase', 'y_train', 'fix_imbalance', 'X_test', 'idx', 'target_param', 'exp_id', 'pipeline'}
2025-05-14 22:06:59,220:INFO:Checking environment
2025-05-14 22:06:59,220:INFO:python_version: 3.11.8
2025-05-14 22:06:59,220:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-14 22:06:59,220:INFO:machine: AMD64
2025-05-14 22:06:59,220:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-14 22:06:59,229:INFO:Memory: svmem(total=16907886592, available=3582074880, percent=78.8, used=13325811712, free=3582074880)
2025-05-14 22:06:59,229:INFO:Physical Core: 4
2025-05-14 22:06:59,229:INFO:Logical Core: 8
2025-05-14 22:06:59,229:INFO:Checking libraries
2025-05-14 22:06:59,229:INFO:System:
2025-05-14 22:06:59,229:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-14 22:06:59,229:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-14 22:06:59,229:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-14 22:06:59,229:INFO:PyCaret required dependencies:
2025-05-14 22:06:59,230:INFO:                 pip: 24.0
2025-05-14 22:06:59,230:INFO:          setuptools: 65.5.0
2025-05-14 22:06:59,230:INFO:             pycaret: 3.3.2
2025-05-14 22:06:59,230:INFO:             IPython: 9.2.0
2025-05-14 22:06:59,230:INFO:          ipywidgets: 8.1.7
2025-05-14 22:06:59,230:INFO:                tqdm: 4.67.1
2025-05-14 22:06:59,230:INFO:               numpy: 1.26.4
2025-05-14 22:06:59,230:INFO:              pandas: 2.1.4
2025-05-14 22:06:59,230:INFO:              jinja2: 3.1.6
2025-05-14 22:06:59,230:INFO:               scipy: 1.11.4
2025-05-14 22:06:59,230:INFO:              joblib: 1.3.2
2025-05-14 22:06:59,230:INFO:             sklearn: 1.4.2
2025-05-14 22:06:59,230:INFO:                pyod: 2.0.5
2025-05-14 22:06:59,230:INFO:            imblearn: 0.13.0
2025-05-14 22:06:59,230:INFO:   category_encoders: 2.7.0
2025-05-14 22:06:59,230:INFO:            lightgbm: 4.6.0
2025-05-14 22:06:59,230:INFO:               numba: 0.61.0
2025-05-14 22:06:59,230:INFO:            requests: 2.32.3
2025-05-14 22:06:59,231:INFO:          matplotlib: 3.7.5
2025-05-14 22:06:59,231:INFO:          scikitplot: 0.3.7
2025-05-14 22:06:59,231:INFO:         yellowbrick: 1.5
2025-05-14 22:06:59,231:INFO:              plotly: 5.24.1
2025-05-14 22:06:59,231:INFO:    plotly-resampler: Not installed
2025-05-14 22:06:59,231:INFO:             kaleido: 0.2.1
2025-05-14 22:06:59,231:INFO:           schemdraw: 0.15
2025-05-14 22:06:59,231:INFO:         statsmodels: 0.14.4
2025-05-14 22:06:59,231:INFO:              sktime: 0.26.0
2025-05-14 22:06:59,231:INFO:               tbats: 1.1.3
2025-05-14 22:06:59,231:INFO:            pmdarima: 2.0.4
2025-05-14 22:06:59,231:INFO:              psutil: 7.0.0
2025-05-14 22:06:59,231:INFO:          markupsafe: 3.0.2
2025-05-14 22:06:59,231:INFO:             pickle5: Not installed
2025-05-14 22:06:59,231:INFO:         cloudpickle: 3.1.1
2025-05-14 22:06:59,231:INFO:         deprecation: 2.1.0
2025-05-14 22:06:59,231:INFO:              xxhash: 3.5.0
2025-05-14 22:06:59,232:INFO:           wurlitzer: Not installed
2025-05-14 22:06:59,232:INFO:PyCaret optional dependencies:
2025-05-14 22:06:59,232:INFO:                shap: 0.44.1
2025-05-14 22:06:59,232:INFO:           interpret: 0.6.10
2025-05-14 22:06:59,232:INFO:                umap: 0.5.7
2025-05-14 22:06:59,232:INFO:     ydata_profiling: 4.16.1
2025-05-14 22:06:59,232:INFO:  explainerdashboard: 0.4.8
2025-05-14 22:06:59,232:INFO:             autoviz: Not installed
2025-05-14 22:06:59,232:INFO:           fairlearn: 0.7.0
2025-05-14 22:06:59,232:INFO:          deepchecks: Not installed
2025-05-14 22:06:59,232:INFO:             xgboost: Not installed
2025-05-14 22:06:59,233:INFO:            catboost: Not installed
2025-05-14 22:06:59,233:INFO:              kmodes: Not installed
2025-05-14 22:06:59,233:INFO:             mlxtend: Not installed
2025-05-14 22:06:59,233:INFO:       statsforecast: Not installed
2025-05-14 22:06:59,233:INFO:        tune_sklearn: Not installed
2025-05-14 22:06:59,233:INFO:                 ray: Not installed
2025-05-14 22:06:59,233:INFO:            hyperopt: Not installed
2025-05-14 22:06:59,233:INFO:              optuna: Not installed
2025-05-14 22:06:59,233:INFO:               skopt: Not installed
2025-05-14 22:06:59,233:INFO:              mlflow: Not installed
2025-05-14 22:06:59,233:INFO:              gradio: Not installed
2025-05-14 22:06:59,233:INFO:             fastapi: Not installed
2025-05-14 22:06:59,233:INFO:             uvicorn: Not installed
2025-05-14 22:06:59,233:INFO:              m2cgen: Not installed
2025-05-14 22:06:59,233:INFO:           evidently: Not installed
2025-05-14 22:06:59,234:INFO:               fugue: Not installed
2025-05-14 22:06:59,234:INFO:           streamlit: Not installed
2025-05-14 22:06:59,234:INFO:             prophet: Not installed
2025-05-14 22:06:59,234:INFO:None
2025-05-14 22:06:59,234:INFO:Set up data.
2025-05-14 22:06:59,242:INFO:Set up folding strategy.
2025-05-14 22:06:59,242:INFO:Set up train/test split.
2025-05-14 22:06:59,246:INFO:Set up index.
2025-05-14 22:06:59,246:INFO:Assigning column types.
2025-05-14 22:06:59,251:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 22:06:59,297:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 22:06:59,300:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:06:59,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:59,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:59,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 22:06:59,389:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:06:59,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:59,425:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:59,426:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 22:06:59,475:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:06:59,505:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:59,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:59,555:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:06:59,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:59,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:59,588:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 22:06:59,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:59,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:59,726:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:59,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:59,727:INFO:Preparing preprocessing pipeline...
2025-05-14 22:06:59,730:INFO:Set up simple imputation.
2025-05-14 22:06:59,733:INFO:Set up encoding of categorical features.
2025-05-14 22:06:59,733:INFO:Set up polynomial features.
2025-05-14 22:06:59,733:INFO:Set up removing multicollinearity.
2025-05-14 22:06:59,733:INFO:Set up binning of numerical features.
2025-05-14 22:06:59,734:INFO:Set up feature selection.
2025-05-14 22:06:59,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:06:59,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:09:04,230:INFO:PyCaret ClassificationExperiment
2025-05-14 22:09:04,230:INFO:Logging name: clf-default-name
2025-05-14 22:09:04,230:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 22:09:04,231:INFO:version 3.3.2
2025-05-14 22:09:04,231:INFO:Initializing setup()
2025-05-14 22:09:04,231:INFO:self.USI: 9f9a
2025-05-14 22:09:04,231:INFO:self._variable_keys: {'n_jobs_param', 'X_train', 'y_test', 'log_plots_param', 'fold_groups_param', 'logging_param', 'data', 'USI', 'html_param', 'seed', 'y', 'gpu_n_jobs_param', 'is_multiclass', 'gpu_param', '_available_plots', 'X', 'exp_name_log', 'fold_generator', 'memory', 'fold_shuffle_param', '_ml_usecase', 'y_train', 'fix_imbalance', 'X_test', 'idx', 'target_param', 'exp_id', 'pipeline'}
2025-05-14 22:09:04,231:INFO:Checking environment
2025-05-14 22:09:04,231:INFO:python_version: 3.11.8
2025-05-14 22:09:04,231:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-14 22:09:04,231:INFO:machine: AMD64
2025-05-14 22:09:04,231:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-14 22:09:04,237:INFO:Memory: svmem(total=16907886592, available=3891654656, percent=77.0, used=13016231936, free=3891654656)
2025-05-14 22:09:04,237:INFO:Physical Core: 4
2025-05-14 22:09:04,237:INFO:Logical Core: 8
2025-05-14 22:09:04,237:INFO:Checking libraries
2025-05-14 22:09:04,237:INFO:System:
2025-05-14 22:09:04,237:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-14 22:09:04,237:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-14 22:09:04,237:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-14 22:09:04,237:INFO:PyCaret required dependencies:
2025-05-14 22:09:04,237:INFO:                 pip: 24.0
2025-05-14 22:09:04,237:INFO:          setuptools: 65.5.0
2025-05-14 22:09:04,237:INFO:             pycaret: 3.3.2
2025-05-14 22:09:04,237:INFO:             IPython: 9.2.0
2025-05-14 22:09:04,237:INFO:          ipywidgets: 8.1.7
2025-05-14 22:09:04,239:INFO:                tqdm: 4.67.1
2025-05-14 22:09:04,239:INFO:               numpy: 1.26.4
2025-05-14 22:09:04,239:INFO:              pandas: 2.1.4
2025-05-14 22:09:04,239:INFO:              jinja2: 3.1.6
2025-05-14 22:09:04,239:INFO:               scipy: 1.11.4
2025-05-14 22:09:04,239:INFO:              joblib: 1.3.2
2025-05-14 22:09:04,239:INFO:             sklearn: 1.4.2
2025-05-14 22:09:04,239:INFO:                pyod: 2.0.5
2025-05-14 22:09:04,239:INFO:            imblearn: 0.13.0
2025-05-14 22:09:04,239:INFO:   category_encoders: 2.7.0
2025-05-14 22:09:04,239:INFO:            lightgbm: 4.6.0
2025-05-14 22:09:04,239:INFO:               numba: 0.61.0
2025-05-14 22:09:04,239:INFO:            requests: 2.32.3
2025-05-14 22:09:04,239:INFO:          matplotlib: 3.7.5
2025-05-14 22:09:04,239:INFO:          scikitplot: 0.3.7
2025-05-14 22:09:04,239:INFO:         yellowbrick: 1.5
2025-05-14 22:09:04,239:INFO:              plotly: 5.24.1
2025-05-14 22:09:04,240:INFO:    plotly-resampler: Not installed
2025-05-14 22:09:04,240:INFO:             kaleido: 0.2.1
2025-05-14 22:09:04,240:INFO:           schemdraw: 0.15
2025-05-14 22:09:04,240:INFO:         statsmodels: 0.14.4
2025-05-14 22:09:04,240:INFO:              sktime: 0.26.0
2025-05-14 22:09:04,240:INFO:               tbats: 1.1.3
2025-05-14 22:09:04,240:INFO:            pmdarima: 2.0.4
2025-05-14 22:09:04,240:INFO:              psutil: 7.0.0
2025-05-14 22:09:04,240:INFO:          markupsafe: 3.0.2
2025-05-14 22:09:04,240:INFO:             pickle5: Not installed
2025-05-14 22:09:04,240:INFO:         cloudpickle: 3.1.1
2025-05-14 22:09:04,240:INFO:         deprecation: 2.1.0
2025-05-14 22:09:04,240:INFO:              xxhash: 3.5.0
2025-05-14 22:09:04,240:INFO:           wurlitzer: Not installed
2025-05-14 22:09:04,240:INFO:PyCaret optional dependencies:
2025-05-14 22:09:04,240:INFO:                shap: 0.44.1
2025-05-14 22:09:04,240:INFO:           interpret: 0.6.10
2025-05-14 22:09:04,240:INFO:                umap: 0.5.7
2025-05-14 22:09:04,240:INFO:     ydata_profiling: 4.16.1
2025-05-14 22:09:04,241:INFO:  explainerdashboard: 0.4.8
2025-05-14 22:09:04,241:INFO:             autoviz: Not installed
2025-05-14 22:09:04,241:INFO:           fairlearn: 0.7.0
2025-05-14 22:09:04,241:INFO:          deepchecks: Not installed
2025-05-14 22:09:04,241:INFO:             xgboost: Not installed
2025-05-14 22:09:04,241:INFO:            catboost: Not installed
2025-05-14 22:09:04,241:INFO:              kmodes: Not installed
2025-05-14 22:09:04,241:INFO:             mlxtend: Not installed
2025-05-14 22:09:04,241:INFO:       statsforecast: Not installed
2025-05-14 22:09:04,241:INFO:        tune_sklearn: Not installed
2025-05-14 22:09:04,241:INFO:                 ray: Not installed
2025-05-14 22:09:04,241:INFO:            hyperopt: Not installed
2025-05-14 22:09:04,241:INFO:              optuna: Not installed
2025-05-14 22:09:04,241:INFO:               skopt: Not installed
2025-05-14 22:09:04,241:INFO:              mlflow: Not installed
2025-05-14 22:09:04,241:INFO:              gradio: Not installed
2025-05-14 22:09:04,241:INFO:             fastapi: Not installed
2025-05-14 22:09:04,241:INFO:             uvicorn: Not installed
2025-05-14 22:09:04,241:INFO:              m2cgen: Not installed
2025-05-14 22:09:04,241:INFO:           evidently: Not installed
2025-05-14 22:09:04,241:INFO:               fugue: Not installed
2025-05-14 22:09:04,241:INFO:           streamlit: Not installed
2025-05-14 22:09:04,241:INFO:             prophet: Not installed
2025-05-14 22:09:04,241:INFO:None
2025-05-14 22:09:04,242:INFO:Set up data.
2025-05-14 22:09:04,248:INFO:Set up folding strategy.
2025-05-14 22:09:04,248:INFO:Set up train/test split.
2025-05-14 22:09:04,252:INFO:Set up index.
2025-05-14 22:09:04,252:INFO:Assigning column types.
2025-05-14 22:09:04,255:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 22:09:04,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 22:09:04,377:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:09:04,407:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:09:04,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:09:04,450:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 22:09:04,450:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:09:04,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:09:04,488:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:09:04,488:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 22:09:04,543:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:09:04,565:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:09:04,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:09:04,606:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:09:04,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:09:04,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:09:04,634:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 22:09:04,702:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:09:04,703:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:09:04,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:09:04,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:09:04,780:INFO:Preparing preprocessing pipeline...
2025-05-14 22:09:04,781:INFO:Set up simple imputation.
2025-05-14 22:09:04,783:INFO:Set up encoding of categorical features.
2025-05-14 22:09:04,783:INFO:Set up polynomial features.
2025-05-14 22:09:04,783:INFO:Set up removing multicollinearity.
2025-05-14 22:09:04,783:INFO:Set up binning of numerical features.
2025-05-14 22:09:04,784:INFO:Set up feature selection.
2025-05-14 22:09:04,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:09:04,885:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:09,831:INFO:PyCaret ClassificationExperiment
2025-05-14 22:10:09,831:INFO:Logging name: clf-default-name
2025-05-14 22:10:09,831:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 22:10:09,831:INFO:version 3.3.2
2025-05-14 22:10:09,832:INFO:Initializing setup()
2025-05-14 22:10:09,832:INFO:self.USI: 4d13
2025-05-14 22:10:09,832:INFO:self._variable_keys: {'n_jobs_param', 'X_train', 'y_test', 'log_plots_param', 'fold_groups_param', 'logging_param', 'data', 'USI', 'html_param', 'seed', 'y', 'gpu_n_jobs_param', 'is_multiclass', 'gpu_param', '_available_plots', 'X', 'exp_name_log', 'fold_generator', 'memory', 'fold_shuffle_param', '_ml_usecase', 'y_train', 'fix_imbalance', 'X_test', 'idx', 'target_param', 'exp_id', 'pipeline'}
2025-05-14 22:10:09,832:INFO:Checking environment
2025-05-14 22:10:09,832:INFO:python_version: 3.11.8
2025-05-14 22:10:09,833:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-14 22:10:09,833:INFO:machine: AMD64
2025-05-14 22:10:09,833:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-14 22:10:09,840:INFO:Memory: svmem(total=16907886592, available=3253354496, percent=80.8, used=13654532096, free=3253354496)
2025-05-14 22:10:09,840:INFO:Physical Core: 4
2025-05-14 22:10:09,840:INFO:Logical Core: 8
2025-05-14 22:10:09,840:INFO:Checking libraries
2025-05-14 22:10:09,840:INFO:System:
2025-05-14 22:10:09,841:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-14 22:10:09,841:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-14 22:10:09,841:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-14 22:10:09,841:INFO:PyCaret required dependencies:
2025-05-14 22:10:09,841:INFO:                 pip: 24.0
2025-05-14 22:10:09,841:INFO:          setuptools: 65.5.0
2025-05-14 22:10:09,841:INFO:             pycaret: 3.3.2
2025-05-14 22:10:09,841:INFO:             IPython: 9.2.0
2025-05-14 22:10:09,841:INFO:          ipywidgets: 8.1.7
2025-05-14 22:10:09,841:INFO:                tqdm: 4.67.1
2025-05-14 22:10:09,841:INFO:               numpy: 1.26.4
2025-05-14 22:10:09,843:INFO:              pandas: 2.1.4
2025-05-14 22:10:09,843:INFO:              jinja2: 3.1.6
2025-05-14 22:10:09,843:INFO:               scipy: 1.11.4
2025-05-14 22:10:09,843:INFO:              joblib: 1.3.2
2025-05-14 22:10:09,843:INFO:             sklearn: 1.4.2
2025-05-14 22:10:09,843:INFO:                pyod: 2.0.5
2025-05-14 22:10:09,843:INFO:            imblearn: 0.13.0
2025-05-14 22:10:09,843:INFO:   category_encoders: 2.7.0
2025-05-14 22:10:09,843:INFO:            lightgbm: 4.6.0
2025-05-14 22:10:09,843:INFO:               numba: 0.61.0
2025-05-14 22:10:09,843:INFO:            requests: 2.32.3
2025-05-14 22:10:09,843:INFO:          matplotlib: 3.7.5
2025-05-14 22:10:09,843:INFO:          scikitplot: 0.3.7
2025-05-14 22:10:09,843:INFO:         yellowbrick: 1.5
2025-05-14 22:10:09,844:INFO:              plotly: 5.24.1
2025-05-14 22:10:09,844:INFO:    plotly-resampler: Not installed
2025-05-14 22:10:09,844:INFO:             kaleido: 0.2.1
2025-05-14 22:10:09,844:INFO:           schemdraw: 0.15
2025-05-14 22:10:09,844:INFO:         statsmodels: 0.14.4
2025-05-14 22:10:09,844:INFO:              sktime: 0.26.0
2025-05-14 22:10:09,844:INFO:               tbats: 1.1.3
2025-05-14 22:10:09,844:INFO:            pmdarima: 2.0.4
2025-05-14 22:10:09,844:INFO:              psutil: 7.0.0
2025-05-14 22:10:09,844:INFO:          markupsafe: 3.0.2
2025-05-14 22:10:09,844:INFO:             pickle5: Not installed
2025-05-14 22:10:09,844:INFO:         cloudpickle: 3.1.1
2025-05-14 22:10:09,844:INFO:         deprecation: 2.1.0
2025-05-14 22:10:09,845:INFO:              xxhash: 3.5.0
2025-05-14 22:10:09,845:INFO:           wurlitzer: Not installed
2025-05-14 22:10:09,845:INFO:PyCaret optional dependencies:
2025-05-14 22:10:09,845:INFO:                shap: 0.44.1
2025-05-14 22:10:09,845:INFO:           interpret: 0.6.10
2025-05-14 22:10:09,845:INFO:                umap: 0.5.7
2025-05-14 22:10:09,845:INFO:     ydata_profiling: 4.16.1
2025-05-14 22:10:09,845:INFO:  explainerdashboard: 0.4.8
2025-05-14 22:10:09,845:INFO:             autoviz: Not installed
2025-05-14 22:10:09,845:INFO:           fairlearn: 0.7.0
2025-05-14 22:10:09,845:INFO:          deepchecks: Not installed
2025-05-14 22:10:09,845:INFO:             xgboost: Not installed
2025-05-14 22:10:09,845:INFO:            catboost: Not installed
2025-05-14 22:10:09,846:INFO:              kmodes: Not installed
2025-05-14 22:10:09,846:INFO:             mlxtend: Not installed
2025-05-14 22:10:09,846:INFO:       statsforecast: Not installed
2025-05-14 22:10:09,846:INFO:        tune_sklearn: Not installed
2025-05-14 22:10:09,846:INFO:                 ray: Not installed
2025-05-14 22:10:09,846:INFO:            hyperopt: Not installed
2025-05-14 22:10:09,846:INFO:              optuna: Not installed
2025-05-14 22:10:09,846:INFO:               skopt: Not installed
2025-05-14 22:10:09,846:INFO:              mlflow: Not installed
2025-05-14 22:10:09,846:INFO:              gradio: Not installed
2025-05-14 22:10:09,846:INFO:             fastapi: Not installed
2025-05-14 22:10:09,846:INFO:             uvicorn: Not installed
2025-05-14 22:10:09,846:INFO:              m2cgen: Not installed
2025-05-14 22:10:09,847:INFO:           evidently: Not installed
2025-05-14 22:10:09,847:INFO:               fugue: Not installed
2025-05-14 22:10:09,847:INFO:           streamlit: Not installed
2025-05-14 22:10:09,847:INFO:             prophet: Not installed
2025-05-14 22:10:09,847:INFO:None
2025-05-14 22:10:09,847:INFO:Set up data.
2025-05-14 22:10:09,854:INFO:Set up folding strategy.
2025-05-14 22:10:09,854:INFO:Set up train/test split.
2025-05-14 22:10:09,861:INFO:Set up index.
2025-05-14 22:10:09,862:INFO:Assigning column types.
2025-05-14 22:10:09,871:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 22:10:09,933:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 22:10:09,935:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:10:09,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:09,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:10,022:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 22:10:10,023:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:10:10,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:10,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:10,057:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 22:10:10,115:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:10:10,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:10,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:10,197:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:10:10,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:10,233:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:10,234:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 22:10:10,320:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:10,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:10,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:10,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:10,420:INFO:Preparing preprocessing pipeline...
2025-05-14 22:10:10,421:INFO:Set up simple imputation.
2025-05-14 22:10:10,422:INFO:Set up encoding of categorical features.
2025-05-14 22:10:10,422:INFO:Set up removing multicollinearity.
2025-05-14 22:10:10,422:INFO:Set up binning of numerical features.
2025-05-14 22:10:10,423:INFO:Set up feature selection.
2025-05-14 22:10:10,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:10,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:10,595:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:10,657:INFO:Finished creating preprocessing pipeline.
2025-05-14 22:10:10,693:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'imc', 'fuma',
                                             'ingesta_azucar', 'obesidad',
                                             'azucar_alta',
                                             'ejercicio_freq_num',
                                             'riesgo_metabolico'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              mi...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-05-14 22:10:10,693:INFO:Creating final display dataframe.
2025-05-14 22:10:11,092:INFO:Setup _display_container:                     Description               Value
0                    Session id                 777
1                        Target  enfermedad_cronica
2                   Target type              Binary
3           Original data shape           (200, 11)
4        Transformed data shape            (200, 2)
5   Transformed train set shape            (140, 2)
6    Transformed test set shape             (60, 2)
7               Ignore features                   1
8              Numeric features                   8
9          Categorical features                   1
10                   Preprocess                True
11              Imputation type              simple
12           Numeric imputation                mean
13       Categorical imputation                mode
14     Maximum one-hot encoding                  25
15              Encoding method                None
16     Remove multicollinearity                True
17  Multicollinearity threshold                 0.8
18            Feature selection                True
19     Feature selection method             classic
20  Feature selection estimator            lightgbm
21  Number of features selected                 0.2
22               Fold Generator     StratifiedKFold
23                  Fold Number                  10
24                     CPU Jobs                  -1
25                      Use GPU               False
26               Log Experiment               False
27              Experiment Name    clf-default-name
28                          USI                4d13
2025-05-14 22:10:11,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:11,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:11,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:11,313:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:10:11,314:INFO:setup() successfully completed in 1.49s...............
2025-05-14 22:10:11,323:INFO:Initializing compare_models()
2025-05-14 22:10:11,323:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 22:10:11,324:INFO:Checking exceptions
2025-05-14 22:10:11,329:INFO:Preparing display monitor
2025-05-14 22:10:11,433:INFO:Initializing Logistic Regression
2025-05-14 22:10:11,433:INFO:Total runtime is 0.0 minutes
2025-05-14 22:10:11,442:INFO:SubProcess create_model() called ==================================
2025-05-14 22:10:11,442:INFO:Initializing create_model()
2025-05-14 22:10:11,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809E266BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:10:11,443:INFO:Checking exceptions
2025-05-14 22:10:11,443:INFO:Importing libraries
2025-05-14 22:10:11,443:INFO:Copying training dataset
2025-05-14 22:10:11,449:INFO:Defining folds
2025-05-14 22:10:11,449:INFO:Declaring metric variables
2025-05-14 22:10:11,454:INFO:Importing untrained model
2025-05-14 22:10:11,461:INFO:Logistic Regression Imported successfully
2025-05-14 22:10:11,489:INFO:Starting cross validation
2025-05-14 22:10:11,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:10:26,575:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:26,639:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:26,856:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:26,970:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:26,987:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:27,219:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:27,354:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:27,653:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:28,819:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:28,819:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:28,822:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:29,034:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:29,077:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:29,108:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:29,113:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:29,482:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:29,504:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:29,660:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:29,870:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:29,911:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:29,937:INFO:Calculating mean and std
2025-05-14 22:10:29,940:INFO:Creating metrics dataframe
2025-05-14 22:10:29,947:INFO:Uploading results into container
2025-05-14 22:10:29,949:INFO:Uploading model into container now
2025-05-14 22:10:29,950:INFO:_master_model_container: 1
2025-05-14 22:10:29,950:INFO:_display_container: 2
2025-05-14 22:10:29,952:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 22:10:29,952:INFO:create_model() successfully completed......................................
2025-05-14 22:10:30,281:INFO:SubProcess create_model() end ==================================
2025-05-14 22:10:30,281:INFO:Creating metrics dataframe
2025-05-14 22:10:30,308:INFO:Initializing K Neighbors Classifier
2025-05-14 22:10:30,308:INFO:Total runtime is 0.31457611322402956 minutes
2025-05-14 22:10:30,324:INFO:SubProcess create_model() called ==================================
2025-05-14 22:10:30,326:INFO:Initializing create_model()
2025-05-14 22:10:30,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809E266BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:10:30,326:INFO:Checking exceptions
2025-05-14 22:10:30,326:INFO:Importing libraries
2025-05-14 22:10:30,327:INFO:Copying training dataset
2025-05-14 22:10:30,341:INFO:Defining folds
2025-05-14 22:10:30,341:INFO:Declaring metric variables
2025-05-14 22:10:30,352:INFO:Importing untrained model
2025-05-14 22:10:30,369:INFO:K Neighbors Classifier Imported successfully
2025-05-14 22:10:30,391:INFO:Starting cross validation
2025-05-14 22:10:30,410:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:10:30,574:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:30,594:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:30,633:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:30,664:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:30,674:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:30,762:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:30,778:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:30,804:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:31,918:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:31,950:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:31,969:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:32,172:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:32,185:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:32,232:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:32,285:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:32,477:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:32,485:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:32,703:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:32,717:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:32,744:INFO:Calculating mean and std
2025-05-14 22:10:32,748:INFO:Creating metrics dataframe
2025-05-14 22:10:32,758:INFO:Uploading results into container
2025-05-14 22:10:32,760:INFO:Uploading model into container now
2025-05-14 22:10:32,760:INFO:_master_model_container: 2
2025-05-14 22:10:32,762:INFO:_display_container: 2
2025-05-14 22:10:32,762:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 22:10:32,762:INFO:create_model() successfully completed......................................
2025-05-14 22:10:33,005:INFO:SubProcess create_model() end ==================================
2025-05-14 22:10:33,005:INFO:Creating metrics dataframe
2025-05-14 22:10:33,030:INFO:Initializing Naive Bayes
2025-05-14 22:10:33,030:INFO:Total runtime is 0.3599508364995321 minutes
2025-05-14 22:10:33,039:INFO:SubProcess create_model() called ==================================
2025-05-14 22:10:33,040:INFO:Initializing create_model()
2025-05-14 22:10:33,040:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809E266BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:10:33,042:INFO:Checking exceptions
2025-05-14 22:10:33,042:INFO:Importing libraries
2025-05-14 22:10:33,042:INFO:Copying training dataset
2025-05-14 22:10:33,055:INFO:Defining folds
2025-05-14 22:10:33,055:INFO:Declaring metric variables
2025-05-14 22:10:33,067:INFO:Importing untrained model
2025-05-14 22:10:33,077:INFO:Naive Bayes Imported successfully
2025-05-14 22:10:33,095:INFO:Starting cross validation
2025-05-14 22:10:33,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:10:33,268:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:33,272:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:33,278:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:33,288:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:33,312:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:33,397:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:33,399:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:33,443:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:34,390:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:34,433:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:34,515:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:34,577:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:34,640:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:34,743:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:34,825:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:34,927:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:34,998:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:35,005:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:35,209:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:35,222:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:35,243:INFO:Calculating mean and std
2025-05-14 22:10:35,246:INFO:Creating metrics dataframe
2025-05-14 22:10:35,252:INFO:Uploading results into container
2025-05-14 22:10:35,253:INFO:Uploading model into container now
2025-05-14 22:10:35,255:INFO:_master_model_container: 3
2025-05-14 22:10:35,255:INFO:_display_container: 2
2025-05-14 22:10:35,256:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 22:10:35,256:INFO:create_model() successfully completed......................................
2025-05-14 22:10:35,445:INFO:SubProcess create_model() end ==================================
2025-05-14 22:10:35,445:INFO:Creating metrics dataframe
2025-05-14 22:10:35,461:INFO:Initializing Decision Tree Classifier
2025-05-14 22:10:35,461:INFO:Total runtime is 0.4004653731981913 minutes
2025-05-14 22:10:35,471:INFO:SubProcess create_model() called ==================================
2025-05-14 22:10:35,474:INFO:Initializing create_model()
2025-05-14 22:10:35,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809E266BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:10:35,474:INFO:Checking exceptions
2025-05-14 22:10:35,474:INFO:Importing libraries
2025-05-14 22:10:35,474:INFO:Copying training dataset
2025-05-14 22:10:35,483:INFO:Defining folds
2025-05-14 22:10:35,483:INFO:Declaring metric variables
2025-05-14 22:10:35,495:INFO:Importing untrained model
2025-05-14 22:10:35,509:INFO:Decision Tree Classifier Imported successfully
2025-05-14 22:10:35,528:INFO:Starting cross validation
2025-05-14 22:10:35,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:10:35,746:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:35,747:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:35,754:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:35,788:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:35,822:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:35,826:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:35,836:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:35,892:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:36,445:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:36,445:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:36,492:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:36,602:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:36,646:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:36,865:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:36,908:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:37,060:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:37,105:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:37,204:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:37,372:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:37,391:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:37,408:INFO:Calculating mean and std
2025-05-14 22:10:37,411:INFO:Creating metrics dataframe
2025-05-14 22:10:37,414:INFO:Uploading results into container
2025-05-14 22:10:37,416:INFO:Uploading model into container now
2025-05-14 22:10:37,417:INFO:_master_model_container: 4
2025-05-14 22:10:37,417:INFO:_display_container: 2
2025-05-14 22:10:37,418:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=777, splitter='best')
2025-05-14 22:10:37,419:INFO:create_model() successfully completed......................................
2025-05-14 22:10:37,608:INFO:SubProcess create_model() end ==================================
2025-05-14 22:10:37,608:INFO:Creating metrics dataframe
2025-05-14 22:10:37,626:INFO:Initializing SVM - Linear Kernel
2025-05-14 22:10:37,626:INFO:Total runtime is 0.4365473906199137 minutes
2025-05-14 22:10:37,636:INFO:SubProcess create_model() called ==================================
2025-05-14 22:10:37,637:INFO:Initializing create_model()
2025-05-14 22:10:37,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809E266BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:10:37,637:INFO:Checking exceptions
2025-05-14 22:10:37,638:INFO:Importing libraries
2025-05-14 22:10:37,638:INFO:Copying training dataset
2025-05-14 22:10:37,655:INFO:Defining folds
2025-05-14 22:10:37,655:INFO:Declaring metric variables
2025-05-14 22:10:37,667:INFO:Importing untrained model
2025-05-14 22:10:37,680:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 22:10:37,700:INFO:Starting cross validation
2025-05-14 22:10:37,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:10:37,915:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:37,917:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:37,927:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:37,957:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:37,976:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:37,990:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:38,007:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:38,027:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:38,528:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:38,533:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:38,557:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:38,646:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:38,662:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:38,759:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:38,761:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:38,862:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:39,065:INFO:Calculating mean and std
2025-05-14 22:10:39,074:INFO:Creating metrics dataframe
2025-05-14 22:10:39,084:INFO:Uploading results into container
2025-05-14 22:10:39,086:INFO:Uploading model into container now
2025-05-14 22:10:39,087:INFO:_master_model_container: 5
2025-05-14 22:10:39,087:INFO:_display_container: 2
2025-05-14 22:10:39,087:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=777, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 22:10:39,089:INFO:create_model() successfully completed......................................
2025-05-14 22:10:39,424:INFO:SubProcess create_model() end ==================================
2025-05-14 22:10:39,425:INFO:Creating metrics dataframe
2025-05-14 22:10:39,467:INFO:Initializing Ridge Classifier
2025-05-14 22:10:39,467:INFO:Total runtime is 0.4672291040420532 minutes
2025-05-14 22:10:39,476:INFO:SubProcess create_model() called ==================================
2025-05-14 22:10:39,477:INFO:Initializing create_model()
2025-05-14 22:10:39,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809E266BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:10:39,478:INFO:Checking exceptions
2025-05-14 22:10:39,478:INFO:Importing libraries
2025-05-14 22:10:39,478:INFO:Copying training dataset
2025-05-14 22:10:39,491:INFO:Defining folds
2025-05-14 22:10:39,492:INFO:Declaring metric variables
2025-05-14 22:10:39,500:INFO:Importing untrained model
2025-05-14 22:10:39,533:INFO:Ridge Classifier Imported successfully
2025-05-14 22:10:39,552:INFO:Starting cross validation
2025-05-14 22:10:39,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:10:39,703:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:39,710:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:39,719:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:39,722:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:39,731:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:39,762:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:39,775:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:39,781:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:40,197:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:40,205:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:40,270:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:40,332:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:40,354:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:40,373:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:40,440:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:40,524:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:40,587:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:40,719:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:40,819:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:40,827:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:40,852:INFO:Calculating mean and std
2025-05-14 22:10:40,855:INFO:Creating metrics dataframe
2025-05-14 22:10:40,860:INFO:Uploading results into container
2025-05-14 22:10:40,862:INFO:Uploading model into container now
2025-05-14 22:10:40,863:INFO:_master_model_container: 6
2025-05-14 22:10:40,863:INFO:_display_container: 2
2025-05-14 22:10:40,865:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=777, solver='auto',
                tol=0.0001)
2025-05-14 22:10:40,865:INFO:create_model() successfully completed......................................
2025-05-14 22:10:41,018:INFO:SubProcess create_model() end ==================================
2025-05-14 22:10:41,018:INFO:Creating metrics dataframe
2025-05-14 22:10:41,031:INFO:Initializing Random Forest Classifier
2025-05-14 22:10:41,031:INFO:Total runtime is 0.49330818255742387 minutes
2025-05-14 22:10:41,041:INFO:SubProcess create_model() called ==================================
2025-05-14 22:10:41,042:INFO:Initializing create_model()
2025-05-14 22:10:41,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809E266BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:10:41,042:INFO:Checking exceptions
2025-05-14 22:10:41,042:INFO:Importing libraries
2025-05-14 22:10:41,042:INFO:Copying training dataset
2025-05-14 22:10:41,052:INFO:Defining folds
2025-05-14 22:10:41,053:INFO:Declaring metric variables
2025-05-14 22:10:41,060:INFO:Importing untrained model
2025-05-14 22:10:41,070:INFO:Random Forest Classifier Imported successfully
2025-05-14 22:10:41,089:INFO:Starting cross validation
2025-05-14 22:10:41,099:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:10:41,233:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:41,237:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:41,297:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:41,322:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:41,336:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:41,371:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:41,382:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:41,412:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:42,497:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:42,507:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:42,540:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:42,631:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:42,759:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:42,816:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:42,930:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:43,005:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:43,041:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:43,086:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:43,898:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:43,900:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:43,910:INFO:Calculating mean and std
2025-05-14 22:10:43,912:INFO:Creating metrics dataframe
2025-05-14 22:10:43,915:INFO:Uploading results into container
2025-05-14 22:10:43,916:INFO:Uploading model into container now
2025-05-14 22:10:43,917:INFO:_master_model_container: 7
2025-05-14 22:10:43,917:INFO:_display_container: 2
2025-05-14 22:10:43,918:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=777, verbose=0,
                       warm_start=False)
2025-05-14 22:10:43,919:INFO:create_model() successfully completed......................................
2025-05-14 22:10:44,047:INFO:SubProcess create_model() end ==================================
2025-05-14 22:10:44,048:INFO:Creating metrics dataframe
2025-05-14 22:10:44,063:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 22:10:44,063:INFO:Total runtime is 0.5438275416692098 minutes
2025-05-14 22:10:44,068:INFO:SubProcess create_model() called ==================================
2025-05-14 22:10:44,068:INFO:Initializing create_model()
2025-05-14 22:10:44,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809E266BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:10:44,068:INFO:Checking exceptions
2025-05-14 22:10:44,068:INFO:Importing libraries
2025-05-14 22:10:44,069:INFO:Copying training dataset
2025-05-14 22:10:44,076:INFO:Defining folds
2025-05-14 22:10:44,077:INFO:Declaring metric variables
2025-05-14 22:10:44,084:INFO:Importing untrained model
2025-05-14 22:10:44,089:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 22:10:44,101:INFO:Starting cross validation
2025-05-14 22:10:44,109:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:10:44,217:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:44,218:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:44,220:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:44,232:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:44,237:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:44,262:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:44,274:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:44,293:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:44,574:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:44,584:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:44,586:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:44,638:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:44,690:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:44,704:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:44,802:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:44,853:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:44,986:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:45,005:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:45,120:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:45,137:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:45,160:INFO:Calculating mean and std
2025-05-14 22:10:45,164:INFO:Creating metrics dataframe
2025-05-14 22:10:45,168:INFO:Uploading results into container
2025-05-14 22:10:45,172:INFO:Uploading model into container now
2025-05-14 22:10:45,174:INFO:_master_model_container: 8
2025-05-14 22:10:45,174:INFO:_display_container: 2
2025-05-14 22:10:45,175:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 22:10:45,175:INFO:create_model() successfully completed......................................
2025-05-14 22:10:45,315:INFO:SubProcess create_model() end ==================================
2025-05-14 22:10:45,316:INFO:Creating metrics dataframe
2025-05-14 22:10:45,332:INFO:Initializing Ada Boost Classifier
2025-05-14 22:10:45,332:INFO:Total runtime is 0.5649808724721272 minutes
2025-05-14 22:10:45,337:INFO:SubProcess create_model() called ==================================
2025-05-14 22:10:45,339:INFO:Initializing create_model()
2025-05-14 22:10:45,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809E266BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:10:45,339:INFO:Checking exceptions
2025-05-14 22:10:45,339:INFO:Importing libraries
2025-05-14 22:10:45,339:INFO:Copying training dataset
2025-05-14 22:10:45,349:INFO:Defining folds
2025-05-14 22:10:45,349:INFO:Declaring metric variables
2025-05-14 22:10:45,357:INFO:Importing untrained model
2025-05-14 22:10:45,366:INFO:Ada Boost Classifier Imported successfully
2025-05-14 22:10:45,382:INFO:Starting cross validation
2025-05-14 22:10:45,390:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:10:45,513:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:45,526:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:45,532:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:45,538:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:45,554:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:45,579:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:45,581:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:45,584:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:45,797:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:10:45,799:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:10:45,815:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:10:45,910:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:10:45,964:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:10:46,090:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:10:46,178:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:46,234:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:46,242:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:46,286:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:46,325:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:10:46,329:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:46,344:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:46,346:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:10:46,417:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:46,597:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:46,650:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:46,697:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:10:46,704:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:10:46,760:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:47,004:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:47,019:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:47,037:INFO:Calculating mean and std
2025-05-14 22:10:47,040:INFO:Creating metrics dataframe
2025-05-14 22:10:47,044:INFO:Uploading results into container
2025-05-14 22:10:47,045:INFO:Uploading model into container now
2025-05-14 22:10:47,047:INFO:_master_model_container: 9
2025-05-14 22:10:47,047:INFO:_display_container: 2
2025-05-14 22:10:47,047:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=777)
2025-05-14 22:10:47,048:INFO:create_model() successfully completed......................................
2025-05-14 22:10:47,180:INFO:SubProcess create_model() end ==================================
2025-05-14 22:10:47,180:INFO:Creating metrics dataframe
2025-05-14 22:10:47,192:INFO:Initializing Gradient Boosting Classifier
2025-05-14 22:10:47,192:INFO:Total runtime is 0.5959805965423584 minutes
2025-05-14 22:10:47,197:INFO:SubProcess create_model() called ==================================
2025-05-14 22:10:47,198:INFO:Initializing create_model()
2025-05-14 22:10:47,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809E266BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:10:47,198:INFO:Checking exceptions
2025-05-14 22:10:47,198:INFO:Importing libraries
2025-05-14 22:10:47,198:INFO:Copying training dataset
2025-05-14 22:10:47,205:INFO:Defining folds
2025-05-14 22:10:47,205:INFO:Declaring metric variables
2025-05-14 22:10:47,213:INFO:Importing untrained model
2025-05-14 22:10:47,219:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 22:10:47,228:INFO:Starting cross validation
2025-05-14 22:10:47,236:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:10:47,356:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:47,364:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:47,364:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:47,365:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:47,366:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:47,370:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:47,394:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:47,437:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:48,299:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:48,302:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:48,443:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:48,477:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:48,484:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:48,960:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:49,009:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:49,025:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:49,257:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:49,638:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:49,767:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:49,796:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:49,819:INFO:Calculating mean and std
2025-05-14 22:10:49,822:INFO:Creating metrics dataframe
2025-05-14 22:10:49,832:INFO:Uploading results into container
2025-05-14 22:10:49,834:INFO:Uploading model into container now
2025-05-14 22:10:49,835:INFO:_master_model_container: 10
2025-05-14 22:10:49,835:INFO:_display_container: 2
2025-05-14 22:10:49,837:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=777, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 22:10:49,837:INFO:create_model() successfully completed......................................
2025-05-14 22:10:50,050:INFO:SubProcess create_model() end ==================================
2025-05-14 22:10:50,050:INFO:Creating metrics dataframe
2025-05-14 22:10:50,082:INFO:Initializing Linear Discriminant Analysis
2025-05-14 22:10:50,082:INFO:Total runtime is 0.6441504001617431 minutes
2025-05-14 22:10:50,094:INFO:SubProcess create_model() called ==================================
2025-05-14 22:10:50,095:INFO:Initializing create_model()
2025-05-14 22:10:50,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809E266BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:10:50,095:INFO:Checking exceptions
2025-05-14 22:10:50,095:INFO:Importing libraries
2025-05-14 22:10:50,095:INFO:Copying training dataset
2025-05-14 22:10:50,110:INFO:Defining folds
2025-05-14 22:10:50,110:INFO:Declaring metric variables
2025-05-14 22:10:50,117:INFO:Importing untrained model
2025-05-14 22:10:50,127:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 22:10:50,145:INFO:Starting cross validation
2025-05-14 22:10:50,156:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:10:50,300:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:50,305:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:50,307:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:50,327:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:50,329:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:50,337:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:50,366:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:50,371:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:50,759:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:50,796:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:50,829:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:50,899:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:50,917:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:50,994:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:51,012:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:51,064:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:51,100:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:51,164:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:51,232:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:51,240:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:51,255:INFO:Calculating mean and std
2025-05-14 22:10:51,257:INFO:Creating metrics dataframe
2025-05-14 22:10:51,264:INFO:Uploading results into container
2025-05-14 22:10:51,264:INFO:Uploading model into container now
2025-05-14 22:10:51,265:INFO:_master_model_container: 11
2025-05-14 22:10:51,265:INFO:_display_container: 2
2025-05-14 22:10:51,266:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 22:10:51,266:INFO:create_model() successfully completed......................................
2025-05-14 22:10:51,412:INFO:SubProcess create_model() end ==================================
2025-05-14 22:10:51,413:INFO:Creating metrics dataframe
2025-05-14 22:10:51,429:INFO:Initializing Extra Trees Classifier
2025-05-14 22:10:51,430:INFO:Total runtime is 0.6665951530138651 minutes
2025-05-14 22:10:51,438:INFO:SubProcess create_model() called ==================================
2025-05-14 22:10:51,438:INFO:Initializing create_model()
2025-05-14 22:10:51,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809E266BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:10:51,439:INFO:Checking exceptions
2025-05-14 22:10:51,439:INFO:Importing libraries
2025-05-14 22:10:51,439:INFO:Copying training dataset
2025-05-14 22:10:51,447:INFO:Defining folds
2025-05-14 22:10:51,448:INFO:Declaring metric variables
2025-05-14 22:10:51,458:INFO:Importing untrained model
2025-05-14 22:10:51,467:INFO:Extra Trees Classifier Imported successfully
2025-05-14 22:10:51,482:INFO:Starting cross validation
2025-05-14 22:10:51,493:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:10:51,640:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:51,649:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:51,658:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:51,683:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:51,685:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:51,722:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:51,765:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:51,790:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:52,826:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:52,882:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:52,975:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:52,997:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:53,077:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:53,081:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:53,087:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:53,105:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:53,272:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:53,372:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:53,799:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:53,805:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:53,829:INFO:Calculating mean and std
2025-05-14 22:10:53,832:INFO:Creating metrics dataframe
2025-05-14 22:10:53,838:INFO:Uploading results into container
2025-05-14 22:10:53,839:INFO:Uploading model into container now
2025-05-14 22:10:53,839:INFO:_master_model_container: 12
2025-05-14 22:10:53,840:INFO:_display_container: 2
2025-05-14 22:10:53,843:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=777, verbose=0,
                     warm_start=False)
2025-05-14 22:10:53,843:INFO:create_model() successfully completed......................................
2025-05-14 22:10:53,982:INFO:SubProcess create_model() end ==================================
2025-05-14 22:10:53,982:INFO:Creating metrics dataframe
2025-05-14 22:10:54,000:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 22:10:54,001:INFO:Total runtime is 0.7094629327456156 minutes
2025-05-14 22:10:54,008:INFO:SubProcess create_model() called ==================================
2025-05-14 22:10:54,008:INFO:Initializing create_model()
2025-05-14 22:10:54,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809E266BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:10:54,009:INFO:Checking exceptions
2025-05-14 22:10:54,009:INFO:Importing libraries
2025-05-14 22:10:54,009:INFO:Copying training dataset
2025-05-14 22:10:54,015:INFO:Defining folds
2025-05-14 22:10:54,016:INFO:Declaring metric variables
2025-05-14 22:10:54,025:INFO:Importing untrained model
2025-05-14 22:10:54,031:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 22:10:54,047:INFO:Starting cross validation
2025-05-14 22:10:54,060:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:10:54,188:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:54,195:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:54,228:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:54,239:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:54,252:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:54,255:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:54,265:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:55,673:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:55,690:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:55,795:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:55,806:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:55,807:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:55,898:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:55,925:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:55,952:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:56,005:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:56,045:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:56,208:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:56,216:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:56,234:INFO:Calculating mean and std
2025-05-14 22:10:56,237:INFO:Creating metrics dataframe
2025-05-14 22:10:56,240:INFO:Uploading results into container
2025-05-14 22:10:56,242:INFO:Uploading model into container now
2025-05-14 22:10:56,243:INFO:_master_model_container: 13
2025-05-14 22:10:56,243:INFO:_display_container: 2
2025-05-14 22:10:56,245:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=777, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 22:10:56,245:INFO:create_model() successfully completed......................................
2025-05-14 22:10:56,387:INFO:SubProcess create_model() end ==================================
2025-05-14 22:10:56,388:INFO:Creating metrics dataframe
2025-05-14 22:10:56,401:INFO:Initializing Dummy Classifier
2025-05-14 22:10:56,401:INFO:Total runtime is 0.7494628588358561 minutes
2025-05-14 22:10:56,406:INFO:SubProcess create_model() called ==================================
2025-05-14 22:10:56,406:INFO:Initializing create_model()
2025-05-14 22:10:56,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809E266BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:10:56,407:INFO:Checking exceptions
2025-05-14 22:10:56,407:INFO:Importing libraries
2025-05-14 22:10:56,407:INFO:Copying training dataset
2025-05-14 22:10:56,415:INFO:Defining folds
2025-05-14 22:10:56,415:INFO:Declaring metric variables
2025-05-14 22:10:56,422:INFO:Importing untrained model
2025-05-14 22:10:56,428:INFO:Dummy Classifier Imported successfully
2025-05-14 22:10:56,441:INFO:Starting cross validation
2025-05-14 22:10:56,450:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:10:56,577:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:56,589:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:56,589:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:56,605:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:56,633:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:56,637:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:56,660:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:56,660:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:57,017:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:57,027:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:57,036:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:57,060:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:57,156:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:57,189:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:57,233:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:57,257:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:57,357:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:57,374:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:57,510:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:57,527:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:10:57,553:INFO:Calculating mean and std
2025-05-14 22:10:57,567:INFO:Creating metrics dataframe
2025-05-14 22:10:57,572:INFO:Uploading results into container
2025-05-14 22:10:57,573:INFO:Uploading model into container now
2025-05-14 22:10:57,573:INFO:_master_model_container: 14
2025-05-14 22:10:57,575:INFO:_display_container: 2
2025-05-14 22:10:57,575:INFO:DummyClassifier(constant=None, random_state=777, strategy='prior')
2025-05-14 22:10:57,575:INFO:create_model() successfully completed......................................
2025-05-14 22:10:57,783:INFO:SubProcess create_model() end ==================================
2025-05-14 22:10:57,783:INFO:Creating metrics dataframe
2025-05-14 22:10:57,808:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-14 22:10:57,825:INFO:Initializing create_model()
2025-05-14 22:10:57,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:10:57,826:INFO:Checking exceptions
2025-05-14 22:10:57,829:INFO:Importing libraries
2025-05-14 22:10:57,829:INFO:Copying training dataset
2025-05-14 22:10:57,837:INFO:Defining folds
2025-05-14 22:10:57,837:INFO:Declaring metric variables
2025-05-14 22:10:57,837:INFO:Importing untrained model
2025-05-14 22:10:57,837:INFO:Declaring custom model
2025-05-14 22:10:57,839:INFO:Logistic Regression Imported successfully
2025-05-14 22:10:57,849:INFO:Cross validation set to False
2025-05-14 22:10:57,849:INFO:Fitting Model
2025-05-14 22:10:57,920:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:57,945:INFO:[LightGBM] [Info] Number of positive: 29, number of negative: 111
2025-05-14 22:10:57,946:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.
2025-05-14 22:10:57,946:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 22:10:57,946:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 22:10:57,946:INFO:[LightGBM] [Info] Total Bins 25
2025-05-14 22:10:57,946:INFO:[LightGBM] [Info] Number of data points in the train set: 140, number of used features: 9
2025-05-14 22:10:57,947:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207143 -> initscore=-1.342234
2025-05-14 22:10:57,947:INFO:[LightGBM] [Info] Start training from score -1.342234
2025-05-14 22:10:57,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:10:57,992:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 22:10:57,993:INFO:create_model() successfully completed......................................
2025-05-14 22:10:58,176:INFO:_master_model_container: 14
2025-05-14 22:10:58,177:INFO:_display_container: 2
2025-05-14 22:10:58,177:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 22:10:58,179:INFO:compare_models() successfully completed......................................
2025-05-14 22:10:58,230:INFO:Initializing tune_model()
2025-05-14 22:10:58,231:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 22:10:58,231:INFO:Checking exceptions
2025-05-14 22:10:58,263:INFO:Copying training dataset
2025-05-14 22:10:58,270:INFO:Checking base model
2025-05-14 22:10:58,270:INFO:Base model : Logistic Regression
2025-05-14 22:10:58,278:INFO:Declaring metric variables
2025-05-14 22:10:58,286:INFO:Defining Hyperparameters
2025-05-14 22:10:58,436:INFO:Tuning with n_jobs=-1
2025-05-14 22:10:58,436:INFO:Initializing RandomizedSearchCV
2025-05-14 22:10:58,565:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:58,567:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:58,599:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:58,617:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:58,629:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:58,638:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:58,639:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:58,644:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:59,140:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:59,174:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:59,215:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:59,405:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:59,459:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:59,494:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:59,519:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:10:59,605:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:00,466:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:00,487:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:00,491:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:00,899:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:00,901:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:00,935:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:00,987:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:01,129:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:01,295:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:01,326:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:01,346:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:01,385:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:01,580:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:01,636:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:01,743:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:02,032:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:02,073:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:02,092:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:02,142:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:02,377:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:02,444:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:02,486:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:02,697:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:02,889:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:03,026:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:03,212:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:03,250:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:03,468:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:03,470:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:03,524:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:03,754:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:03,787:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:03,867:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:04,000:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:04,030:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:04,161:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:04,269:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:04,344:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:04,556:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:04,594:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:04,663:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:04,815:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:04,899:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:04,912:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:05,033:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:05,167:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:05,167:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:05,295:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:05,367:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:05,437:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:05,500:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:05,557:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:05,695:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:05,875:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:05,880:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:05,990:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:06,178:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:06,332:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:06,378:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:06,417:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:06,685:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:06,703:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:06,708:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:06,932:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:07,060:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:07,084:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:07,236:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:07,346:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:07,465:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:07,495:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:07,562:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:07,760:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:07,809:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:07,820:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:08,090:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:08,092:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:08,207:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:08,310:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:08,424:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:08,587:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:08,667:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:08,835:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:08,972:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:09,056:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:09,256:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 9.684}
2025-05-14 22:11:09,257:INFO:Hyperparameter search completed
2025-05-14 22:11:09,258:INFO:SubProcess create_model() called ==================================
2025-05-14 22:11:09,259:INFO:Initializing create_model()
2025-05-14 22:11:09,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809FC8E510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 9.684})
2025-05-14 22:11:09,259:INFO:Checking exceptions
2025-05-14 22:11:09,259:INFO:Importing libraries
2025-05-14 22:11:09,260:INFO:Copying training dataset
2025-05-14 22:11:09,266:INFO:Defining folds
2025-05-14 22:11:09,266:INFO:Declaring metric variables
2025-05-14 22:11:09,271:INFO:Importing untrained model
2025-05-14 22:11:09,271:INFO:Declaring custom model
2025-05-14 22:11:09,278:INFO:Logistic Regression Imported successfully
2025-05-14 22:11:09,288:INFO:Starting cross validation
2025-05-14 22:11:09,296:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:11:09,412:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:09,412:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:09,431:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:09,433:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:09,442:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:09,442:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:09,463:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:09,487:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:09,795:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:09,810:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:10,095:INFO:Calculating mean and std
2025-05-14 22:11:10,097:INFO:Creating metrics dataframe
2025-05-14 22:11:10,107:INFO:Finalizing model
2025-05-14 22:11:10,171:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:10,191:INFO:[LightGBM] [Info] Number of positive: 29, number of negative: 111
2025-05-14 22:11:10,191:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000068 seconds.
2025-05-14 22:11:10,191:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-14 22:11:10,191:INFO:[LightGBM] [Info] Total Bins 25
2025-05-14 22:11:10,192:INFO:[LightGBM] [Info] Number of data points in the train set: 140, number of used features: 9
2025-05-14 22:11:10,192:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207143 -> initscore=-1.342234
2025-05-14 22:11:10,192:INFO:[LightGBM] [Info] Start training from score -1.342234
2025-05-14 22:11:10,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:10,240:INFO:Uploading results into container
2025-05-14 22:11:10,242:INFO:Uploading model into container now
2025-05-14 22:11:10,244:INFO:_master_model_container: 15
2025-05-14 22:11:10,244:INFO:_display_container: 3
2025-05-14 22:11:10,244:INFO:LogisticRegression(C=9.684, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 22:11:10,244:INFO:create_model() successfully completed......................................
2025-05-14 22:11:10,379:INFO:SubProcess create_model() end ==================================
2025-05-14 22:11:10,379:INFO:choose_better activated
2025-05-14 22:11:10,385:INFO:SubProcess create_model() called ==================================
2025-05-14 22:11:10,386:INFO:Initializing create_model()
2025-05-14 22:11:10,386:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:11:10,386:INFO:Checking exceptions
2025-05-14 22:11:10,388:INFO:Importing libraries
2025-05-14 22:11:10,389:INFO:Copying training dataset
2025-05-14 22:11:10,393:INFO:Defining folds
2025-05-14 22:11:10,393:INFO:Declaring metric variables
2025-05-14 22:11:10,393:INFO:Importing untrained model
2025-05-14 22:11:10,393:INFO:Declaring custom model
2025-05-14 22:11:10,394:INFO:Logistic Regression Imported successfully
2025-05-14 22:11:10,394:INFO:Starting cross validation
2025-05-14 22:11:10,405:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:11:10,516:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:10,519:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:10,530:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:10,557:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:10,581:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:10,584:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:10,606:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:10,615:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:10,998:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:11:11,024:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:11:11,051:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:11:11,132:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:11,165:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:11,183:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:11:11,278:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:11:11,307:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:11:11,332:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:11:11,346:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:11:11,453:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:11:11,457:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:11:11,480:INFO:Calculating mean and std
2025-05-14 22:11:11,482:INFO:Creating metrics dataframe
2025-05-14 22:11:11,488:INFO:Finalizing model
2025-05-14 22:11:11,550:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:11:11,576:INFO:[LightGBM] [Info] Number of positive: 29, number of negative: 111
2025-05-14 22:11:11,576:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000078 seconds.
2025-05-14 22:11:11,576:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-14 22:11:11,576:INFO:[LightGBM] [Info] Total Bins 25
2025-05-14 22:11:11,576:INFO:[LightGBM] [Info] Number of data points in the train set: 140, number of used features: 9
2025-05-14 22:11:11,577:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207143 -> initscore=-1.342234
2025-05-14 22:11:11,577:INFO:[LightGBM] [Info] Start training from score -1.342234
2025-05-14 22:11:11,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:11:11,614:INFO:Uploading results into container
2025-05-14 22:11:11,615:INFO:Uploading model into container now
2025-05-14 22:11:11,616:INFO:_master_model_container: 16
2025-05-14 22:11:11,616:INFO:_display_container: 4
2025-05-14 22:11:11,617:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 22:11:11,617:INFO:create_model() successfully completed......................................
2025-05-14 22:11:11,739:INFO:SubProcess create_model() end ==================================
2025-05-14 22:11:11,739:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5519
2025-05-14 22:11:11,740:INFO:LogisticRegression(C=9.684, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5519
2025-05-14 22:11:11,740:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-05-14 22:11:11,742:INFO:choose_better completed
2025-05-14 22:11:11,742:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-14 22:11:11,758:INFO:_master_model_container: 16
2025-05-14 22:11:11,758:INFO:_display_container: 3
2025-05-14 22:11:11,758:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 22:11:11,759:INFO:tune_model() successfully completed......................................
2025-05-14 22:11:11,951:INFO:Initializing interpret_model()
2025-05-14 22:11:11,951:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F525C10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 22:11:11,952:INFO:Checking exceptions
2025-05-14 22:11:11,952:INFO:Soft dependency imported: shap: 0.44.1
2025-05-14 22:12:01,462:INFO:PyCaret ClassificationExperiment
2025-05-14 22:12:01,462:INFO:Logging name: clf-default-name
2025-05-14 22:12:01,462:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 22:12:01,463:INFO:version 3.3.2
2025-05-14 22:12:01,463:INFO:Initializing setup()
2025-05-14 22:12:01,463:INFO:self.USI: a95a
2025-05-14 22:12:01,463:INFO:self._variable_keys: {'n_jobs_param', 'X_train', 'y_test', 'log_plots_param', 'fold_groups_param', 'logging_param', 'data', 'USI', 'html_param', 'seed', 'y', 'gpu_n_jobs_param', 'is_multiclass', 'gpu_param', '_available_plots', 'X', 'exp_name_log', 'fold_generator', 'memory', 'fold_shuffle_param', '_ml_usecase', 'y_train', 'fix_imbalance', 'X_test', 'idx', 'target_param', 'exp_id', 'pipeline'}
2025-05-14 22:12:01,463:INFO:Checking environment
2025-05-14 22:12:01,463:INFO:python_version: 3.11.8
2025-05-14 22:12:01,463:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-14 22:12:01,463:INFO:machine: AMD64
2025-05-14 22:12:01,463:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-14 22:12:01,470:INFO:Memory: svmem(total=16907886592, available=2086371328, percent=87.7, used=14821515264, free=2086371328)
2025-05-14 22:12:01,470:INFO:Physical Core: 4
2025-05-14 22:12:01,470:INFO:Logical Core: 8
2025-05-14 22:12:01,470:INFO:Checking libraries
2025-05-14 22:12:01,470:INFO:System:
2025-05-14 22:12:01,470:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-14 22:12:01,470:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-14 22:12:01,470:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-14 22:12:01,470:INFO:PyCaret required dependencies:
2025-05-14 22:12:01,470:INFO:                 pip: 24.0
2025-05-14 22:12:01,470:INFO:          setuptools: 65.5.0
2025-05-14 22:12:01,470:INFO:             pycaret: 3.3.2
2025-05-14 22:12:01,470:INFO:             IPython: 9.2.0
2025-05-14 22:12:01,470:INFO:          ipywidgets: 8.1.7
2025-05-14 22:12:01,470:INFO:                tqdm: 4.67.1
2025-05-14 22:12:01,470:INFO:               numpy: 1.26.4
2025-05-14 22:12:01,470:INFO:              pandas: 2.1.4
2025-05-14 22:12:01,472:INFO:              jinja2: 3.1.6
2025-05-14 22:12:01,472:INFO:               scipy: 1.11.4
2025-05-14 22:12:01,472:INFO:              joblib: 1.3.2
2025-05-14 22:12:01,472:INFO:             sklearn: 1.4.2
2025-05-14 22:12:01,472:INFO:                pyod: 2.0.5
2025-05-14 22:12:01,472:INFO:            imblearn: 0.13.0
2025-05-14 22:12:01,472:INFO:   category_encoders: 2.7.0
2025-05-14 22:12:01,472:INFO:            lightgbm: 4.6.0
2025-05-14 22:12:01,472:INFO:               numba: 0.61.0
2025-05-14 22:12:01,472:INFO:            requests: 2.32.3
2025-05-14 22:12:01,472:INFO:          matplotlib: 3.7.5
2025-05-14 22:12:01,472:INFO:          scikitplot: 0.3.7
2025-05-14 22:12:01,472:INFO:         yellowbrick: 1.5
2025-05-14 22:12:01,472:INFO:              plotly: 5.24.1
2025-05-14 22:12:01,472:INFO:    plotly-resampler: Not installed
2025-05-14 22:12:01,472:INFO:             kaleido: 0.2.1
2025-05-14 22:12:01,472:INFO:           schemdraw: 0.15
2025-05-14 22:12:01,472:INFO:         statsmodels: 0.14.4
2025-05-14 22:12:01,472:INFO:              sktime: 0.26.0
2025-05-14 22:12:01,472:INFO:               tbats: 1.1.3
2025-05-14 22:12:01,472:INFO:            pmdarima: 2.0.4
2025-05-14 22:12:01,473:INFO:              psutil: 7.0.0
2025-05-14 22:12:01,473:INFO:          markupsafe: 3.0.2
2025-05-14 22:12:01,473:INFO:             pickle5: Not installed
2025-05-14 22:12:01,473:INFO:         cloudpickle: 3.1.1
2025-05-14 22:12:01,473:INFO:         deprecation: 2.1.0
2025-05-14 22:12:01,473:INFO:              xxhash: 3.5.0
2025-05-14 22:12:01,473:INFO:           wurlitzer: Not installed
2025-05-14 22:12:01,473:INFO:PyCaret optional dependencies:
2025-05-14 22:12:01,473:INFO:                shap: 0.44.1
2025-05-14 22:12:01,473:INFO:           interpret: 0.6.10
2025-05-14 22:12:01,473:INFO:                umap: 0.5.7
2025-05-14 22:12:01,473:INFO:     ydata_profiling: 4.16.1
2025-05-14 22:12:01,473:INFO:  explainerdashboard: 0.4.8
2025-05-14 22:12:01,473:INFO:             autoviz: Not installed
2025-05-14 22:12:01,473:INFO:           fairlearn: 0.7.0
2025-05-14 22:12:01,473:INFO:          deepchecks: Not installed
2025-05-14 22:12:01,473:INFO:             xgboost: Not installed
2025-05-14 22:12:01,473:INFO:            catboost: Not installed
2025-05-14 22:12:01,473:INFO:              kmodes: Not installed
2025-05-14 22:12:01,473:INFO:             mlxtend: Not installed
2025-05-14 22:12:01,473:INFO:       statsforecast: Not installed
2025-05-14 22:12:01,473:INFO:        tune_sklearn: Not installed
2025-05-14 22:12:01,473:INFO:                 ray: Not installed
2025-05-14 22:12:01,473:INFO:            hyperopt: Not installed
2025-05-14 22:12:01,473:INFO:              optuna: Not installed
2025-05-14 22:12:01,473:INFO:               skopt: Not installed
2025-05-14 22:12:01,473:INFO:              mlflow: Not installed
2025-05-14 22:12:01,474:INFO:              gradio: Not installed
2025-05-14 22:12:01,474:INFO:             fastapi: Not installed
2025-05-14 22:12:01,474:INFO:             uvicorn: Not installed
2025-05-14 22:12:01,474:INFO:              m2cgen: Not installed
2025-05-14 22:12:01,474:INFO:           evidently: Not installed
2025-05-14 22:12:01,474:INFO:               fugue: Not installed
2025-05-14 22:12:01,474:INFO:           streamlit: Not installed
2025-05-14 22:12:01,474:INFO:             prophet: Not installed
2025-05-14 22:12:01,474:INFO:None
2025-05-14 22:12:01,474:INFO:Set up data.
2025-05-14 22:12:01,482:INFO:Set up folding strategy.
2025-05-14 22:12:01,482:INFO:Set up train/test split.
2025-05-14 22:12:01,489:INFO:Set up index.
2025-05-14 22:12:01,490:INFO:Assigning column types.
2025-05-14 22:12:01,493:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 22:12:01,562:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 22:12:01,563:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:12:01,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:01,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:01,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 22:12:01,640:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:12:01,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:01,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:01,673:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 22:12:01,718:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:12:01,742:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:01,742:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:01,789:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:12:01,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:01,824:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:01,825:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 22:12:01,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:01,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:02,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:02,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:02,049:INFO:Preparing preprocessing pipeline...
2025-05-14 22:12:02,051:INFO:Set up simple imputation.
2025-05-14 22:12:02,054:INFO:Set up encoding of categorical features.
2025-05-14 22:12:02,054:INFO:Set up removing multicollinearity.
2025-05-14 22:12:02,054:INFO:Set up binning of numerical features.
2025-05-14 22:12:02,055:INFO:Set up imbalanced handling.
2025-05-14 22:12:02,055:INFO:Set up feature selection.
2025-05-14 22:12:02,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:02,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:02,262:WARNING:In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.

2025-05-14 22:12:02,313:INFO:Finished creating preprocessing pipeline.
2025-05-14 22:12:02,335:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'imc', 'fuma',
                                             'ingesta_azucar', 'obesidad',
                                             'azucar_alta',
                                             'ejercicio_freq_num',
                                             'riesgo_metabolico'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              mi...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-05-14 22:12:02,335:INFO:Creating final display dataframe.
2025-05-14 22:12:02,699:INFO:Setup _display_container:                     Description               Value
0                    Session id                 777
1                        Target  enfermedad_cronica
2                   Target type              Binary
3           Original data shape           (200, 11)
4        Transformed data shape            (282, 2)
5   Transformed train set shape            (222, 2)
6    Transformed test set shape             (60, 2)
7               Ignore features                   1
8              Numeric features                   8
9          Categorical features                   1
10                   Preprocess                True
11              Imputation type              simple
12           Numeric imputation                mean
13       Categorical imputation                mode
14     Maximum one-hot encoding                  25
15              Encoding method                None
16     Remove multicollinearity                True
17  Multicollinearity threshold                 0.8
18                Fix imbalance                True
19         Fix imbalance method               SMOTE
20            Feature selection                True
21     Feature selection method             classic
22  Feature selection estimator            lightgbm
23  Number of features selected                 0.2
24               Fold Generator     StratifiedKFold
25                  Fold Number                  10
26                     CPU Jobs                  -1
27                      Use GPU               False
28               Log Experiment               False
29              Experiment Name    clf-default-name
30                          USI                a95a
2025-05-14 22:12:02,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:02,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:02,913:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:02,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:12:02,915:INFO:setup() successfully completed in 1.46s...............
2025-05-14 22:12:02,942:INFO:Initializing compare_models()
2025-05-14 22:12:02,942:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 22:12:02,942:INFO:Checking exceptions
2025-05-14 22:12:02,949:INFO:Preparing display monitor
2025-05-14 22:12:02,995:INFO:Initializing Logistic Regression
2025-05-14 22:12:02,996:INFO:Total runtime is 1.668532689412435e-05 minutes
2025-05-14 22:12:03,003:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:03,004:INFO:Initializing create_model()
2025-05-14 22:12:03,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000280A1C176D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:03,004:INFO:Checking exceptions
2025-05-14 22:12:03,004:INFO:Importing libraries
2025-05-14 22:12:03,004:INFO:Copying training dataset
2025-05-14 22:12:03,008:INFO:Defining folds
2025-05-14 22:12:03,010:INFO:Declaring metric variables
2025-05-14 22:12:03,012:INFO:Importing untrained model
2025-05-14 22:12:03,017:INFO:Logistic Regression Imported successfully
2025-05-14 22:12:03,029:INFO:Starting cross validation
2025-05-14 22:12:03,040:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:03,140:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:03,143:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:03,146:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:03,159:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:03,159:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:03,165:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:03,182:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:03,186:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:03,545:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:03,558:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:03,834:INFO:Calculating mean and std
2025-05-14 22:12:03,834:INFO:Creating metrics dataframe
2025-05-14 22:12:03,837:INFO:Uploading results into container
2025-05-14 22:12:03,838:INFO:Uploading model into container now
2025-05-14 22:12:03,838:INFO:_master_model_container: 1
2025-05-14 22:12:03,838:INFO:_display_container: 2
2025-05-14 22:12:03,838:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 22:12:03,839:INFO:create_model() successfully completed......................................
2025-05-14 22:12:03,978:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:03,978:INFO:Creating metrics dataframe
2025-05-14 22:12:03,989:INFO:Initializing K Neighbors Classifier
2025-05-14 22:12:03,989:INFO:Total runtime is 0.016556910673777264 minutes
2025-05-14 22:12:03,991:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:03,991:INFO:Initializing create_model()
2025-05-14 22:12:03,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000280A1C176D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:03,993:INFO:Checking exceptions
2025-05-14 22:12:03,993:INFO:Importing libraries
2025-05-14 22:12:03,993:INFO:Copying training dataset
2025-05-14 22:12:03,997:INFO:Defining folds
2025-05-14 22:12:03,997:INFO:Declaring metric variables
2025-05-14 22:12:04,005:INFO:Importing untrained model
2025-05-14 22:12:04,010:INFO:K Neighbors Classifier Imported successfully
2025-05-14 22:12:04,019:INFO:Starting cross validation
2025-05-14 22:12:04,025:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:04,125:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:04,133:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:04,138:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:04,146:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:04,150:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:04,173:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:04,180:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:04,187:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:04,877:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:04,901:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:04,972:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:05,035:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:05,075:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:05,076:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:05,140:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:05,667:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:05,706:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:06,093:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:06,106:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:06,128:INFO:Calculating mean and std
2025-05-14 22:12:06,132:INFO:Creating metrics dataframe
2025-05-14 22:12:06,137:INFO:Uploading results into container
2025-05-14 22:12:06,139:INFO:Uploading model into container now
2025-05-14 22:12:06,140:INFO:_master_model_container: 2
2025-05-14 22:12:06,140:INFO:_display_container: 2
2025-05-14 22:12:06,140:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-14 22:12:06,140:INFO:create_model() successfully completed......................................
2025-05-14 22:12:06,372:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:06,372:INFO:Creating metrics dataframe
2025-05-14 22:12:06,390:INFO:Initializing Naive Bayes
2025-05-14 22:12:06,390:INFO:Total runtime is 0.056570569674173996 minutes
2025-05-14 22:12:06,399:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:06,401:INFO:Initializing create_model()
2025-05-14 22:12:06,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000280A1C176D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:06,401:INFO:Checking exceptions
2025-05-14 22:12:06,401:INFO:Importing libraries
2025-05-14 22:12:06,402:INFO:Copying training dataset
2025-05-14 22:12:06,412:INFO:Defining folds
2025-05-14 22:12:06,412:INFO:Declaring metric variables
2025-05-14 22:12:06,422:INFO:Importing untrained model
2025-05-14 22:12:06,430:INFO:Naive Bayes Imported successfully
2025-05-14 22:12:06,456:INFO:Starting cross validation
2025-05-14 22:12:06,470:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:06,663:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:06,665:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:06,672:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:06,687:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:06,706:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:06,713:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:06,713:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:06,715:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:07,402:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:07,406:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:07,883:INFO:Calculating mean and std
2025-05-14 22:12:07,886:INFO:Creating metrics dataframe
2025-05-14 22:12:07,891:INFO:Uploading results into container
2025-05-14 22:12:07,892:INFO:Uploading model into container now
2025-05-14 22:12:07,893:INFO:_master_model_container: 3
2025-05-14 22:12:07,893:INFO:_display_container: 2
2025-05-14 22:12:07,893:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-14 22:12:07,895:INFO:create_model() successfully completed......................................
2025-05-14 22:12:08,057:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:08,057:INFO:Creating metrics dataframe
2025-05-14 22:12:08,072:INFO:Initializing Decision Tree Classifier
2025-05-14 22:12:08,072:INFO:Total runtime is 0.08461031119028728 minutes
2025-05-14 22:12:08,079:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:08,080:INFO:Initializing create_model()
2025-05-14 22:12:08,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000280A1C176D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:08,080:INFO:Checking exceptions
2025-05-14 22:12:08,080:INFO:Importing libraries
2025-05-14 22:12:08,080:INFO:Copying training dataset
2025-05-14 22:12:08,088:INFO:Defining folds
2025-05-14 22:12:08,088:INFO:Declaring metric variables
2025-05-14 22:12:08,095:INFO:Importing untrained model
2025-05-14 22:12:08,104:INFO:Decision Tree Classifier Imported successfully
2025-05-14 22:12:08,120:INFO:Starting cross validation
2025-05-14 22:12:08,131:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:08,297:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:08,301:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:08,302:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:08,306:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:08,313:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:08,333:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:08,356:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:08,370:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:08,980:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:09,016:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:09,107:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:09,127:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:09,165:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:09,239:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:09,326:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:09,369:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:09,576:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:09,598:INFO:Calculating mean and std
2025-05-14 22:12:09,599:INFO:Creating metrics dataframe
2025-05-14 22:12:09,603:INFO:Uploading results into container
2025-05-14 22:12:09,604:INFO:Uploading model into container now
2025-05-14 22:12:09,605:INFO:_master_model_container: 4
2025-05-14 22:12:09,605:INFO:_display_container: 2
2025-05-14 22:12:09,606:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=777, splitter='best')
2025-05-14 22:12:09,607:INFO:create_model() successfully completed......................................
2025-05-14 22:12:09,782:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:09,782:INFO:Creating metrics dataframe
2025-05-14 22:12:09,797:INFO:Initializing SVM - Linear Kernel
2025-05-14 22:12:09,798:INFO:Total runtime is 0.11335784991582236 minutes
2025-05-14 22:12:09,806:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:09,806:INFO:Initializing create_model()
2025-05-14 22:12:09,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000280A1C176D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:09,807:INFO:Checking exceptions
2025-05-14 22:12:09,807:INFO:Importing libraries
2025-05-14 22:12:09,807:INFO:Copying training dataset
2025-05-14 22:12:09,820:INFO:Defining folds
2025-05-14 22:12:09,820:INFO:Declaring metric variables
2025-05-14 22:12:09,829:INFO:Importing untrained model
2025-05-14 22:12:09,837:INFO:SVM - Linear Kernel Imported successfully
2025-05-14 22:12:09,862:INFO:Starting cross validation
2025-05-14 22:12:09,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:10,015:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:10,021:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:10,028:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:10,032:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:10,039:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:10,063:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:10,071:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:10,117:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:10,769:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:10,809:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:10,870:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:11,190:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:11,210:INFO:Calculating mean and std
2025-05-14 22:12:11,212:INFO:Creating metrics dataframe
2025-05-14 22:12:11,217:INFO:Uploading results into container
2025-05-14 22:12:11,219:INFO:Uploading model into container now
2025-05-14 22:12:11,219:INFO:_master_model_container: 5
2025-05-14 22:12:11,219:INFO:_display_container: 2
2025-05-14 22:12:11,220:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=777, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-14 22:12:11,222:INFO:create_model() successfully completed......................................
2025-05-14 22:12:11,377:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:11,377:INFO:Creating metrics dataframe
2025-05-14 22:12:11,389:INFO:Initializing Ridge Classifier
2025-05-14 22:12:11,390:INFO:Total runtime is 0.13989398082097373 minutes
2025-05-14 22:12:11,397:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:11,397:INFO:Initializing create_model()
2025-05-14 22:12:11,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000280A1C176D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:11,397:INFO:Checking exceptions
2025-05-14 22:12:11,397:INFO:Importing libraries
2025-05-14 22:12:11,397:INFO:Copying training dataset
2025-05-14 22:12:11,404:INFO:Defining folds
2025-05-14 22:12:11,404:INFO:Declaring metric variables
2025-05-14 22:12:11,413:INFO:Importing untrained model
2025-05-14 22:12:11,419:INFO:Ridge Classifier Imported successfully
2025-05-14 22:12:11,433:INFO:Starting cross validation
2025-05-14 22:12:11,445:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:11,583:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:11,612:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:11,618:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:11,632:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:11,642:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:11,663:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:11,706:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:11,719:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:12,686:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:12,779:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:13,216:INFO:Calculating mean and std
2025-05-14 22:12:13,218:INFO:Creating metrics dataframe
2025-05-14 22:12:13,223:INFO:Uploading results into container
2025-05-14 22:12:13,226:INFO:Uploading model into container now
2025-05-14 22:12:13,227:INFO:_master_model_container: 6
2025-05-14 22:12:13,227:INFO:_display_container: 2
2025-05-14 22:12:13,228:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=777, solver='auto',
                tol=0.0001)
2025-05-14 22:12:13,228:INFO:create_model() successfully completed......................................
2025-05-14 22:12:13,398:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:13,398:INFO:Creating metrics dataframe
2025-05-14 22:12:13,411:INFO:Initializing Random Forest Classifier
2025-05-14 22:12:13,411:INFO:Total runtime is 0.1736018260320028 minutes
2025-05-14 22:12:13,419:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:13,419:INFO:Initializing create_model()
2025-05-14 22:12:13,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000280A1C176D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:13,419:INFO:Checking exceptions
2025-05-14 22:12:13,420:INFO:Importing libraries
2025-05-14 22:12:13,420:INFO:Copying training dataset
2025-05-14 22:12:13,431:INFO:Defining folds
2025-05-14 22:12:13,431:INFO:Declaring metric variables
2025-05-14 22:12:13,440:INFO:Importing untrained model
2025-05-14 22:12:13,445:INFO:Random Forest Classifier Imported successfully
2025-05-14 22:12:13,464:INFO:Starting cross validation
2025-05-14 22:12:13,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:13,647:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:13,657:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:13,669:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:13,675:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:13,687:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:13,701:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:13,717:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:13,741:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:14,956:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:15,032:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:15,088:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:15,106:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:15,144:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:15,295:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:15,296:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:15,497:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:15,819:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:16,028:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:16,064:INFO:Calculating mean and std
2025-05-14 22:12:16,066:INFO:Creating metrics dataframe
2025-05-14 22:12:16,072:INFO:Uploading results into container
2025-05-14 22:12:16,073:INFO:Uploading model into container now
2025-05-14 22:12:16,075:INFO:_master_model_container: 7
2025-05-14 22:12:16,075:INFO:_display_container: 2
2025-05-14 22:12:16,075:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=777, verbose=0,
                       warm_start=False)
2025-05-14 22:12:16,075:INFO:create_model() successfully completed......................................
2025-05-14 22:12:16,233:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:16,234:INFO:Creating metrics dataframe
2025-05-14 22:12:16,247:INFO:Initializing Quadratic Discriminant Analysis
2025-05-14 22:12:16,247:INFO:Total runtime is 0.2208519220352173 minutes
2025-05-14 22:12:16,254:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:16,254:INFO:Initializing create_model()
2025-05-14 22:12:16,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000280A1C176D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:16,255:INFO:Checking exceptions
2025-05-14 22:12:16,255:INFO:Importing libraries
2025-05-14 22:12:16,255:INFO:Copying training dataset
2025-05-14 22:12:16,262:INFO:Defining folds
2025-05-14 22:12:16,262:INFO:Declaring metric variables
2025-05-14 22:12:16,270:INFO:Importing untrained model
2025-05-14 22:12:16,279:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-14 22:12:16,292:INFO:Starting cross validation
2025-05-14 22:12:16,306:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:16,428:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:16,456:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:16,460:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:16,469:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:16,479:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:16,480:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:16,506:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:16,511:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:17,247:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:17,287:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:17,906:INFO:Calculating mean and std
2025-05-14 22:12:17,907:INFO:Creating metrics dataframe
2025-05-14 22:12:17,912:INFO:Uploading results into container
2025-05-14 22:12:17,913:INFO:Uploading model into container now
2025-05-14 22:12:17,913:INFO:_master_model_container: 8
2025-05-14 22:12:17,913:INFO:_display_container: 2
2025-05-14 22:12:17,915:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-14 22:12:17,916:INFO:create_model() successfully completed......................................
2025-05-14 22:12:18,079:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:18,079:INFO:Creating metrics dataframe
2025-05-14 22:12:18,094:INFO:Initializing Ada Boost Classifier
2025-05-14 22:12:18,095:INFO:Total runtime is 0.251656452814738 minutes
2025-05-14 22:12:18,099:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:18,099:INFO:Initializing create_model()
2025-05-14 22:12:18,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000280A1C176D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:18,100:INFO:Checking exceptions
2025-05-14 22:12:18,101:INFO:Importing libraries
2025-05-14 22:12:18,101:INFO:Copying training dataset
2025-05-14 22:12:18,107:INFO:Defining folds
2025-05-14 22:12:18,109:INFO:Declaring metric variables
2025-05-14 22:12:18,117:INFO:Importing untrained model
2025-05-14 22:12:18,124:INFO:Ada Boost Classifier Imported successfully
2025-05-14 22:12:18,138:INFO:Starting cross validation
2025-05-14 22:12:18,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:18,287:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:18,293:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:18,327:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:18,336:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:18,337:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:18,349:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:18,359:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:18,404:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:18,829:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:12:18,836:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:12:18,856:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:12:19,053:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:12:19,277:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:12:19,441:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:19,469:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:19,579:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:12:19,591:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:12:19,672:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:12:19,722:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:20,012:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:12:20,034:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-14 22:12:20,297:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:20,320:INFO:Calculating mean and std
2025-05-14 22:12:20,322:INFO:Creating metrics dataframe
2025-05-14 22:12:20,327:INFO:Uploading results into container
2025-05-14 22:12:20,328:INFO:Uploading model into container now
2025-05-14 22:12:20,329:INFO:_master_model_container: 9
2025-05-14 22:12:20,329:INFO:_display_container: 2
2025-05-14 22:12:20,330:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=777)
2025-05-14 22:12:20,330:INFO:create_model() successfully completed......................................
2025-05-14 22:12:20,491:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:20,491:INFO:Creating metrics dataframe
2025-05-14 22:12:20,510:INFO:Initializing Gradient Boosting Classifier
2025-05-14 22:12:20,510:INFO:Total runtime is 0.2919124245643616 minutes
2025-05-14 22:12:20,518:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:20,520:INFO:Initializing create_model()
2025-05-14 22:12:20,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000280A1C176D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:20,520:INFO:Checking exceptions
2025-05-14 22:12:20,521:INFO:Importing libraries
2025-05-14 22:12:20,521:INFO:Copying training dataset
2025-05-14 22:12:20,526:INFO:Defining folds
2025-05-14 22:12:20,527:INFO:Declaring metric variables
2025-05-14 22:12:20,536:INFO:Importing untrained model
2025-05-14 22:12:20,544:INFO:Gradient Boosting Classifier Imported successfully
2025-05-14 22:12:20,565:INFO:Starting cross validation
2025-05-14 22:12:20,579:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:20,722:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:20,728:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:20,752:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:20,757:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:20,769:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:20,797:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:20,802:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:20,817:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:21,572:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:21,585:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:21,662:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:21,702:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:21,715:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:22,205:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:22,222:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:22,459:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:22,885:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:22,927:INFO:Calculating mean and std
2025-05-14 22:12:22,930:INFO:Creating metrics dataframe
2025-05-14 22:12:22,933:INFO:Uploading results into container
2025-05-14 22:12:22,935:INFO:Uploading model into container now
2025-05-14 22:12:22,936:INFO:_master_model_container: 10
2025-05-14 22:12:22,936:INFO:_display_container: 2
2025-05-14 22:12:22,937:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=777, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-14 22:12:22,938:INFO:create_model() successfully completed......................................
2025-05-14 22:12:23,211:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:23,211:INFO:Creating metrics dataframe
2025-05-14 22:12:23,236:INFO:Initializing Linear Discriminant Analysis
2025-05-14 22:12:23,236:INFO:Total runtime is 0.3373415072758993 minutes
2025-05-14 22:12:23,245:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:23,246:INFO:Initializing create_model()
2025-05-14 22:12:23,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000280A1C176D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:23,247:INFO:Checking exceptions
2025-05-14 22:12:23,247:INFO:Importing libraries
2025-05-14 22:12:23,247:INFO:Copying training dataset
2025-05-14 22:12:23,256:INFO:Defining folds
2025-05-14 22:12:23,257:INFO:Declaring metric variables
2025-05-14 22:12:23,266:INFO:Importing untrained model
2025-05-14 22:12:23,272:INFO:Linear Discriminant Analysis Imported successfully
2025-05-14 22:12:23,295:INFO:Starting cross validation
2025-05-14 22:12:23,309:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:23,450:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:23,479:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:23,492:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:23,518:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:23,519:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:23,555:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:23,556:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:24,495:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:24,501:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:25,105:INFO:Calculating mean and std
2025-05-14 22:12:25,107:INFO:Creating metrics dataframe
2025-05-14 22:12:25,111:INFO:Uploading results into container
2025-05-14 22:12:25,112:INFO:Uploading model into container now
2025-05-14 22:12:25,113:INFO:_master_model_container: 11
2025-05-14 22:12:25,113:INFO:_display_container: 2
2025-05-14 22:12:25,113:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-14 22:12:25,115:INFO:create_model() successfully completed......................................
2025-05-14 22:12:25,295:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:25,295:INFO:Creating metrics dataframe
2025-05-14 22:12:25,307:INFO:Initializing Extra Trees Classifier
2025-05-14 22:12:25,308:INFO:Total runtime is 0.37185689210891726 minutes
2025-05-14 22:12:25,316:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:25,317:INFO:Initializing create_model()
2025-05-14 22:12:25,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000280A1C176D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:25,317:INFO:Checking exceptions
2025-05-14 22:12:25,317:INFO:Importing libraries
2025-05-14 22:12:25,317:INFO:Copying training dataset
2025-05-14 22:12:25,323:INFO:Defining folds
2025-05-14 22:12:25,324:INFO:Declaring metric variables
2025-05-14 22:12:25,332:INFO:Importing untrained model
2025-05-14 22:12:25,337:INFO:Extra Trees Classifier Imported successfully
2025-05-14 22:12:25,355:INFO:Starting cross validation
2025-05-14 22:12:25,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:25,520:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:25,546:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:25,573:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:25,578:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:25,586:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:25,607:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:25,633:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:25,651:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:26,673:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:26,696:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:26,718:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:26,787:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:26,829:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:26,862:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:27,372:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:27,495:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:27,738:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:27,785:INFO:Calculating mean and std
2025-05-14 22:12:27,787:INFO:Creating metrics dataframe
2025-05-14 22:12:27,792:INFO:Uploading results into container
2025-05-14 22:12:27,794:INFO:Uploading model into container now
2025-05-14 22:12:27,795:INFO:_master_model_container: 12
2025-05-14 22:12:27,795:INFO:_display_container: 2
2025-05-14 22:12:27,796:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=777, verbose=0,
                     warm_start=False)
2025-05-14 22:12:27,796:INFO:create_model() successfully completed......................................
2025-05-14 22:12:27,972:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:27,973:INFO:Creating metrics dataframe
2025-05-14 22:12:28,005:INFO:Initializing Light Gradient Boosting Machine
2025-05-14 22:12:28,005:INFO:Total runtime is 0.4168217897415161 minutes
2025-05-14 22:12:28,017:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:28,017:INFO:Initializing create_model()
2025-05-14 22:12:28,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000280A1C176D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:28,019:INFO:Checking exceptions
2025-05-14 22:12:28,019:INFO:Importing libraries
2025-05-14 22:12:28,019:INFO:Copying training dataset
2025-05-14 22:12:28,029:INFO:Defining folds
2025-05-14 22:12:28,030:INFO:Declaring metric variables
2025-05-14 22:12:28,038:INFO:Importing untrained model
2025-05-14 22:12:28,050:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-14 22:12:28,074:INFO:Starting cross validation
2025-05-14 22:12:28,094:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:28,259:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:28,263:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:28,274:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:28,286:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:28,288:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:28,303:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:28,317:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:28,322:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:29,353:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:29,358:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:29,495:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:29,510:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:29,817:INFO:Calculating mean and std
2025-05-14 22:12:29,820:INFO:Creating metrics dataframe
2025-05-14 22:12:29,827:INFO:Uploading results into container
2025-05-14 22:12:29,828:INFO:Uploading model into container now
2025-05-14 22:12:29,829:INFO:_master_model_container: 13
2025-05-14 22:12:29,829:INFO:_display_container: 2
2025-05-14 22:12:29,830:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=777, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-14 22:12:29,830:INFO:create_model() successfully completed......................................
2025-05-14 22:12:29,990:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:29,990:INFO:Creating metrics dataframe
2025-05-14 22:12:30,008:INFO:Initializing Dummy Classifier
2025-05-14 22:12:30,009:INFO:Total runtime is 0.45022566318511964 minutes
2025-05-14 22:12:30,015:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:30,015:INFO:Initializing create_model()
2025-05-14 22:12:30,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000280A1C176D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:30,015:INFO:Checking exceptions
2025-05-14 22:12:30,015:INFO:Importing libraries
2025-05-14 22:12:30,015:INFO:Copying training dataset
2025-05-14 22:12:30,076:INFO:Defining folds
2025-05-14 22:12:30,077:INFO:Declaring metric variables
2025-05-14 22:12:30,090:INFO:Importing untrained model
2025-05-14 22:12:30,101:INFO:Dummy Classifier Imported successfully
2025-05-14 22:12:30,146:INFO:Starting cross validation
2025-05-14 22:12:30,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:30,346:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:30,346:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:30,383:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:30,416:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:30,423:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:30,435:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:30,444:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:30,462:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:31,150:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:31,165:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:31,187:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:31,259:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:31,277:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:31,283:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:31,333:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:31,420:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:31,437:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:31,476:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:31,606:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:31,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-14 22:12:31,637:INFO:Calculating mean and std
2025-05-14 22:12:31,640:INFO:Creating metrics dataframe
2025-05-14 22:12:31,646:INFO:Uploading results into container
2025-05-14 22:12:31,648:INFO:Uploading model into container now
2025-05-14 22:12:31,649:INFO:_master_model_container: 14
2025-05-14 22:12:31,649:INFO:_display_container: 2
2025-05-14 22:12:31,650:INFO:DummyClassifier(constant=None, random_state=777, strategy='prior')
2025-05-14 22:12:31,650:INFO:create_model() successfully completed......................................
2025-05-14 22:12:31,814:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:31,814:INFO:Creating metrics dataframe
2025-05-14 22:12:31,833:WARNING:Styler.applymap has been deprecated. Use Styler.map instead.

2025-05-14 22:12:31,850:INFO:Initializing create_model()
2025-05-14 22:12:31,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:31,851:INFO:Checking exceptions
2025-05-14 22:12:31,856:INFO:Importing libraries
2025-05-14 22:12:31,856:INFO:Copying training dataset
2025-05-14 22:12:31,860:INFO:Defining folds
2025-05-14 22:12:31,860:INFO:Declaring metric variables
2025-05-14 22:12:31,860:INFO:Importing untrained model
2025-05-14 22:12:31,860:INFO:Declaring custom model
2025-05-14 22:12:31,862:INFO:Logistic Regression Imported successfully
2025-05-14 22:12:31,877:INFO:Cross validation set to False
2025-05-14 22:12:31,877:INFO:Fitting Model
2025-05-14 22:12:31,955:WARNING:In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.

2025-05-14 22:12:31,991:INFO:[LightGBM] [Info] Number of positive: 111, number of negative: 111
2025-05-14 22:12:31,993:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.
2025-05-14 22:12:31,993:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 22:12:31,993:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 22:12:31,993:INFO:[LightGBM] [Info] Total Bins 91
2025-05-14 22:12:31,993:INFO:[LightGBM] [Info] Number of data points in the train set: 222, number of used features: 9
2025-05-14 22:12:31,993:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 22:12:31,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:31,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:32,046:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 22:12:32,046:INFO:create_model() successfully completed......................................
2025-05-14 22:12:32,247:INFO:_master_model_container: 14
2025-05-14 22:12:32,247:INFO:_display_container: 2
2025-05-14 22:12:32,247:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 22:12:32,247:INFO:compare_models() successfully completed......................................
2025-05-14 22:12:32,315:INFO:Initializing tune_model()
2025-05-14 22:12:32,315:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-14 22:12:32,315:INFO:Checking exceptions
2025-05-14 22:12:32,345:INFO:Copying training dataset
2025-05-14 22:12:32,352:INFO:Checking base model
2025-05-14 22:12:32,352:INFO:Base model : Logistic Regression
2025-05-14 22:12:32,361:INFO:Declaring metric variables
2025-05-14 22:12:32,368:INFO:Defining Hyperparameters
2025-05-14 22:12:32,564:INFO:Tuning with n_jobs=-1
2025-05-14 22:12:32,565:INFO:Initializing RandomizedSearchCV
2025-05-14 22:12:32,719:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:32,722:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:32,743:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:32,785:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:32,786:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:32,807:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:32,812:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:32,831:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:33,429:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:33,468:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:33,475:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:33,510:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:33,667:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:34,109:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:34,247:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:34,537:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:34,989:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:35,016:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:35,055:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:35,139:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:35,355:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:35,367:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:35,425:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:35,713:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:35,954:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:35,961:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:35,986:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:35,988:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:36,224:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:36,226:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:36,280:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:36,713:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:36,725:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:36,727:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:36,827:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:37,009:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:37,212:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:37,233:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:37,387:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:37,653:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:37,663:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:37,742:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:37,926:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:38,062:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:38,125:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:38,169:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:38,469:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:38,559:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:38,594:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:38,901:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:39,016:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:39,035:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:39,235:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:39,295:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:39,532:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:39,604:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:39,643:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:39,858:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:39,919:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:39,932:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:40,098:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:40,169:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:40,316:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:40,322:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:40,446:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:40,591:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:40,710:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:40,796:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:41,126:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:41,143:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:41,403:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:41,418:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:41,447:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:41,676:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:41,707:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:41,856:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:42,059:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:42,081:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:42,264:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:42,332:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:42,372:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:42,642:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:42,673:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:42,912:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:43,035:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:43,171:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:43,203:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:43,334:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:43,427:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:43,590:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:43,619:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:43,748:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:43,829:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:43,862:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:43,982:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:44,106:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:44,164:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:44,331:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:44,364:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:44,465:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:45,010:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 9.684}
2025-05-14 22:12:45,012:INFO:Hyperparameter search completed
2025-05-14 22:12:45,013:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:45,015:INFO:Initializing create_model()
2025-05-14 22:12:45,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002809FC8EED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 9.684})
2025-05-14 22:12:45,016:INFO:Checking exceptions
2025-05-14 22:12:45,017:INFO:Importing libraries
2025-05-14 22:12:45,017:INFO:Copying training dataset
2025-05-14 22:12:45,028:INFO:Defining folds
2025-05-14 22:12:45,028:INFO:Declaring metric variables
2025-05-14 22:12:45,035:INFO:Importing untrained model
2025-05-14 22:12:45,035:INFO:Declaring custom model
2025-05-14 22:12:45,043:INFO:Logistic Regression Imported successfully
2025-05-14 22:12:45,061:INFO:Starting cross validation
2025-05-14 22:12:45,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:45,222:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:45,238:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:45,238:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:45,239:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:45,243:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:45,247:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:45,270:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:45,277:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:45,798:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:45,812:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:46,223:INFO:Calculating mean and std
2025-05-14 22:12:46,227:INFO:Creating metrics dataframe
2025-05-14 22:12:46,255:INFO:Finalizing model
2025-05-14 22:12:46,343:WARNING:In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.

2025-05-14 22:12:46,382:INFO:[LightGBM] [Info] Number of positive: 111, number of negative: 111
2025-05-14 22:12:46,382:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.
2025-05-14 22:12:46,382:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-14 22:12:46,383:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-14 22:12:46,383:INFO:[LightGBM] [Info] Total Bins 91
2025-05-14 22:12:46,383:INFO:[LightGBM] [Info] Number of data points in the train set: 222, number of used features: 9
2025-05-14 22:12:46,383:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 22:12:46,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:46,473:INFO:Uploading results into container
2025-05-14 22:12:46,475:INFO:Uploading model into container now
2025-05-14 22:12:46,476:INFO:_master_model_container: 15
2025-05-14 22:12:46,476:INFO:_display_container: 3
2025-05-14 22:12:46,477:INFO:LogisticRegression(C=9.684, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 22:12:46,477:INFO:create_model() successfully completed......................................
2025-05-14 22:12:46,667:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:46,667:INFO:choose_better activated
2025-05-14 22:12:46,672:INFO:SubProcess create_model() called ==================================
2025-05-14 22:12:46,674:INFO:Initializing create_model()
2025-05-14 22:12:46,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:12:46,674:INFO:Checking exceptions
2025-05-14 22:12:46,678:INFO:Importing libraries
2025-05-14 22:12:46,678:INFO:Copying training dataset
2025-05-14 22:12:46,683:INFO:Defining folds
2025-05-14 22:12:46,683:INFO:Declaring metric variables
2025-05-14 22:12:46,683:INFO:Importing untrained model
2025-05-14 22:12:46,683:INFO:Declaring custom model
2025-05-14 22:12:46,684:INFO:Logistic Regression Imported successfully
2025-05-14 22:12:46,684:INFO:Starting cross validation
2025-05-14 22:12:46,697:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-14 22:12:46,839:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:46,850:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:46,859:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:46,861:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:46,885:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:46,886:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:46,901:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:46,929:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:47,604:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:47,618:WARNING:c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-14 22:12:47,971:INFO:Calculating mean and std
2025-05-14 22:12:47,972:INFO:Creating metrics dataframe
2025-05-14 22:12:47,975:INFO:Finalizing model
2025-05-14 22:12:48,022:WARNING:In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.

2025-05-14 22:12:48,052:INFO:[LightGBM] [Info] Number of positive: 111, number of negative: 111
2025-05-14 22:12:48,053:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2025-05-14 22:12:48,054:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-14 22:12:48,054:INFO:[LightGBM] [Info] Total Bins 91
2025-05-14 22:12:48,054:INFO:[LightGBM] [Info] Number of data points in the train set: 222, number of used features: 9
2025-05-14 22:12:48,054:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2025-05-14 22:12:48,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-14 22:12:48,101:INFO:Uploading results into container
2025-05-14 22:12:48,103:INFO:Uploading model into container now
2025-05-14 22:12:48,103:INFO:_master_model_container: 16
2025-05-14 22:12:48,103:INFO:_display_container: 4
2025-05-14 22:12:48,103:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 22:12:48,103:INFO:create_model() successfully completed......................................
2025-05-14 22:12:48,252:INFO:SubProcess create_model() end ==================================
2025-05-14 22:12:48,254:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5913
2025-05-14 22:12:48,256:INFO:LogisticRegression(C=9.684, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5913
2025-05-14 22:12:48,256:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-05-14 22:12:48,257:INFO:choose_better completed
2025-05-14 22:12:48,257:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-14 22:12:48,279:INFO:_master_model_container: 16
2025-05-14 22:12:48,279:INFO:_display_container: 3
2025-05-14 22:12:48,280:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-14 22:12:48,280:INFO:tune_model() successfully completed......................................
2025-05-14 22:12:48,493:INFO:Initializing interpret_model()
2025-05-14 22:12:48,494:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-14 22:12:48,494:INFO:Checking exceptions
2025-05-14 22:12:48,495:INFO:Soft dependency imported: shap: 0.44.1
2025-05-14 22:13:10,329:INFO:Initializing predict_model()
2025-05-14 22:13:10,330:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F9759D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000280A1C58F40>)
2025-05-14 22:13:10,330:INFO:Checking exceptions
2025-05-14 22:13:10,330:INFO:Preloading libraries
2025-05-14 22:13:10,333:INFO:Set up data.
2025-05-14 22:13:10,339:INFO:Set up index.
2025-05-14 22:13:10,617:INFO:Initializing save_model()
2025-05-14 22:13:10,617:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=modelo_salud_cronico_movil, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'imc', 'fuma',
                                             'ingesta_azucar', 'obesidad',
                                             'azucar_alta',
                                             'ejercicio_freq_num',
                                             'riesgo_metabolico'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              mi...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-14 22:13:10,618:INFO:Adding model into prep_pipe
2025-05-14 22:13:10,642:INFO:modelo_salud_cronico_movil.pkl saved in current working directory
2025-05-14 22:13:10,668:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'imc', 'fuma',
                                             'ingesta_azucar', 'obesidad',
                                             'azucar_alta',
                                             'ejercicio_freq_num',
                                             'riesgo_metabolico'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('c...
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=777,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-05-14 22:13:10,669:INFO:save_model() successfully completed......................................
2025-05-14 22:34:28,104:INFO:PyCaret ClassificationExperiment
2025-05-14 22:34:28,104:INFO:Logging name: clf-default-name
2025-05-14 22:34:28,104:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-14 22:34:28,104:INFO:version 3.3.2
2025-05-14 22:34:28,104:INFO:Initializing setup()
2025-05-14 22:34:28,104:INFO:self.USI: 418f
2025-05-14 22:34:28,104:INFO:self._variable_keys: {'n_jobs_param', 'X_train', 'y_test', 'log_plots_param', 'fold_groups_param', 'logging_param', 'data', 'USI', 'html_param', 'seed', 'y', 'gpu_n_jobs_param', 'is_multiclass', 'gpu_param', '_available_plots', 'X', 'exp_name_log', 'fold_generator', 'memory', 'fold_shuffle_param', '_ml_usecase', 'y_train', 'fix_imbalance', 'X_test', 'idx', 'target_param', 'exp_id', 'pipeline'}
2025-05-14 22:34:28,104:INFO:Checking environment
2025-05-14 22:34:28,104:INFO:python_version: 3.11.8
2025-05-14 22:34:28,104:INFO:python_build: ('tags/v3.11.8:db85d51', 'Feb  6 2024 22:03:32')
2025-05-14 22:34:28,104:INFO:machine: AMD64
2025-05-14 22:34:28,104:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-14 22:34:28,112:INFO:Memory: svmem(total=16907886592, available=4149694464, percent=75.5, used=12758192128, free=4149694464)
2025-05-14 22:34:28,112:INFO:Physical Core: 4
2025-05-14 22:34:28,112:INFO:Logical Core: 8
2025-05-14 22:34:28,112:INFO:Checking libraries
2025-05-14 22:34:28,112:INFO:System:
2025-05-14 22:34:28,112:INFO:    python: 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)]
2025-05-14 22:34:28,112:INFO:executable: c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe
2025-05-14 22:34:28,112:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-14 22:34:28,112:INFO:PyCaret required dependencies:
2025-05-14 22:34:28,112:INFO:                 pip: 24.0
2025-05-14 22:34:28,113:INFO:          setuptools: 65.5.0
2025-05-14 22:34:28,113:INFO:             pycaret: 3.3.2
2025-05-14 22:34:28,113:INFO:             IPython: 9.2.0
2025-05-14 22:34:28,113:INFO:          ipywidgets: 8.1.7
2025-05-14 22:34:28,113:INFO:                tqdm: 4.67.1
2025-05-14 22:34:28,113:INFO:               numpy: 1.26.4
2025-05-14 22:34:28,113:INFO:              pandas: 2.1.4
2025-05-14 22:34:28,113:INFO:              jinja2: 3.1.6
2025-05-14 22:34:28,113:INFO:               scipy: 1.11.4
2025-05-14 22:34:28,113:INFO:              joblib: 1.3.2
2025-05-14 22:34:28,113:INFO:             sklearn: 1.4.2
2025-05-14 22:34:28,113:INFO:                pyod: 2.0.5
2025-05-14 22:34:28,113:INFO:            imblearn: 0.13.0
2025-05-14 22:34:28,113:INFO:   category_encoders: 2.7.0
2025-05-14 22:34:28,113:INFO:            lightgbm: 4.6.0
2025-05-14 22:34:28,113:INFO:               numba: 0.61.0
2025-05-14 22:34:28,113:INFO:            requests: 2.32.3
2025-05-14 22:34:28,113:INFO:          matplotlib: 3.7.5
2025-05-14 22:34:28,113:INFO:          scikitplot: 0.3.7
2025-05-14 22:34:28,113:INFO:         yellowbrick: 1.5
2025-05-14 22:34:28,114:INFO:              plotly: 5.24.1
2025-05-14 22:34:28,114:INFO:    plotly-resampler: Not installed
2025-05-14 22:34:28,114:INFO:             kaleido: 0.2.1
2025-05-14 22:34:28,114:INFO:           schemdraw: 0.15
2025-05-14 22:34:28,114:INFO:         statsmodels: 0.14.4
2025-05-14 22:34:28,114:INFO:              sktime: 0.26.0
2025-05-14 22:34:28,114:INFO:               tbats: 1.1.3
2025-05-14 22:34:28,114:INFO:            pmdarima: 2.0.4
2025-05-14 22:34:28,114:INFO:              psutil: 7.0.0
2025-05-14 22:34:28,114:INFO:          markupsafe: 3.0.2
2025-05-14 22:34:28,114:INFO:             pickle5: Not installed
2025-05-14 22:34:28,114:INFO:         cloudpickle: 3.1.1
2025-05-14 22:34:28,116:INFO:         deprecation: 2.1.0
2025-05-14 22:34:28,116:INFO:              xxhash: 3.5.0
2025-05-14 22:34:28,116:INFO:           wurlitzer: Not installed
2025-05-14 22:34:28,116:INFO:PyCaret optional dependencies:
2025-05-14 22:34:28,116:INFO:                shap: 0.44.1
2025-05-14 22:34:28,116:INFO:           interpret: 0.6.10
2025-05-14 22:34:28,116:INFO:                umap: 0.5.7
2025-05-14 22:34:28,116:INFO:     ydata_profiling: 4.16.1
2025-05-14 22:34:28,116:INFO:  explainerdashboard: 0.4.8
2025-05-14 22:34:28,116:INFO:             autoviz: Not installed
2025-05-14 22:34:28,116:INFO:           fairlearn: 0.7.0
2025-05-14 22:34:28,117:INFO:          deepchecks: Not installed
2025-05-14 22:34:28,117:INFO:             xgboost: Not installed
2025-05-14 22:34:28,117:INFO:            catboost: Not installed
2025-05-14 22:34:28,117:INFO:              kmodes: Not installed
2025-05-14 22:34:28,117:INFO:             mlxtend: Not installed
2025-05-14 22:34:28,117:INFO:       statsforecast: Not installed
2025-05-14 22:34:28,117:INFO:        tune_sklearn: Not installed
2025-05-14 22:34:28,117:INFO:                 ray: Not installed
2025-05-14 22:34:28,117:INFO:            hyperopt: Not installed
2025-05-14 22:34:28,117:INFO:              optuna: Not installed
2025-05-14 22:34:28,117:INFO:               skopt: Not installed
2025-05-14 22:34:28,117:INFO:              mlflow: Not installed
2025-05-14 22:34:28,117:INFO:              gradio: Not installed
2025-05-14 22:34:28,117:INFO:             fastapi: Not installed
2025-05-14 22:34:28,117:INFO:             uvicorn: Not installed
2025-05-14 22:34:28,117:INFO:              m2cgen: Not installed
2025-05-14 22:34:28,117:INFO:           evidently: Not installed
2025-05-14 22:34:28,117:INFO:               fugue: Not installed
2025-05-14 22:34:28,117:INFO:           streamlit: Not installed
2025-05-14 22:34:28,117:INFO:             prophet: Not installed
2025-05-14 22:34:28,117:INFO:None
2025-05-14 22:34:28,117:INFO:Set up data.
2025-05-14 22:34:28,122:INFO:Set up folding strategy.
2025-05-14 22:34:28,122:INFO:Set up train/test split.
2025-05-14 22:34:28,128:INFO:Set up index.
2025-05-14 22:34:28,128:INFO:Assigning column types.
2025-05-14 22:34:28,131:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-14 22:34:28,184:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 22:34:28,185:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:34:28,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:28,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:28,327:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-14 22:34:28,328:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:34:28,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:28,374:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:28,374:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-14 22:34:28,462:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:34:28,506:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:28,506:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:28,572:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-14 22:34:28,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:28,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:28,611:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-14 22:34:28,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:28,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:28,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:28,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:28,844:INFO:Preparing preprocessing pipeline...
2025-05-14 22:34:28,846:INFO:Set up simple imputation.
2025-05-14 22:34:28,850:INFO:Set up encoding of categorical features.
2025-05-14 22:34:28,850:INFO:Set up removing multicollinearity.
2025-05-14 22:34:28,850:INFO:Set up binning of numerical features.
2025-05-14 22:34:28,852:INFO:Set up feature selection.
2025-05-14 22:34:28,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:28,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:28,994:WARNING:In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.

2025-05-14 22:34:29,023:INFO:Finished creating preprocessing pipeline.
2025-05-14 22:34:29,046:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'imc', 'fuma',
                                             'ingesta_azucar', 'obesidad',
                                             'azucar_alta',
                                             'ejercicio_freq_num',
                                             'riesgo_metabolico'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              mi...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-05-14 22:34:29,046:INFO:Creating final display dataframe.
2025-05-14 22:34:29,386:INFO:Setup _display_container:                     Description               Value
0                    Session id                 777
1                        Target  enfermedad_cronica
2                   Target type              Binary
3           Original data shape           (200, 11)
4        Transformed data shape            (200, 2)
5   Transformed train set shape            (140, 2)
6    Transformed test set shape             (60, 2)
7               Ignore features                   1
8              Numeric features                   8
9          Categorical features                   1
10                   Preprocess                True
11              Imputation type              simple
12           Numeric imputation                mean
13       Categorical imputation                mode
14     Maximum one-hot encoding                  25
15              Encoding method                None
16     Remove multicollinearity                True
17  Multicollinearity threshold                 0.8
18            Feature selection                True
19     Feature selection method             classic
20  Feature selection estimator            lightgbm
21  Number of features selected                 0.2
22               Fold Generator     StratifiedKFold
23                  Fold Number                  10
24                     CPU Jobs                  -1
25                      Use GPU               False
26               Log Experiment               False
27              Experiment Name    clf-default-name
28                          USI                418f
2025-05-14 22:34:29,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:29,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:29,564:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:29,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-14 22:34:29,566:INFO:setup() successfully completed in 1.47s...............
2025-05-14 22:34:29,585:INFO:Initializing compare_models()
2025-05-14 22:34:29,585:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F822F50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002809F822F50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-14 22:34:29,585:INFO:Checking exceptions
2025-05-14 22:34:29,591:INFO:Preparing display monitor
2025-05-14 22:34:29,620:INFO:Initializing Logistic Regression
2025-05-14 22:34:29,620:INFO:Total runtime is 0.0 minutes
2025-05-14 22:34:29,626:INFO:SubProcess create_model() called ==================================
2025-05-14 22:34:29,627:INFO:Initializing create_model()
2025-05-14 22:34:29,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002809F822F50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000280A1BF4E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-14 22:34:29,627:INFO:Checking exceptions
2025-05-14 22:34:29,627:INFO:Importing libraries
2025-05-14 22:34:29,627:INFO:Copying training dataset
2025-05-14 22:34:29,631:INFO:Defining folds
2025-05-14 22:34:29,631:INFO:Declaring metric variables
2025-05-14 22:34:29,636:INFO:Importing untrained model
2025-05-14 22:34:29,640:INFO:Logistic Regression Imported successfully
2025-05-14 22:34:29,649:INFO:Starting cross validation
2025-05-14 22:34:29,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
